In this paper we discuss a novel framework for multiclass learning , defined by a suitable coding/decoding strategy , namely the simplex coding , that allows to generalize to multiple classes a relaxation approach commonly used in binary classification . In this framework , a relaxation error analysis can be developed avoiding constraints on the considered hypotheses class . Moreover , we show that in this setting it is possible to derive the first provably consistent regularized method with training/tuning complexity which is independent to the number of classes . Tools from convex analysis are introduced that can be used beyond the scope of this paper .
A system is presented that segments , clusters and predicts musical audio in an unsupervised manner , adjusting the number of ( timbre ) clusters instantaneously to the audio input . A sequence learning algorithm adapts its structure to a dynamically changing clustering tree . The flow of the system is as follows : 0 ) segmentation by onset detection , 0 ) timbre representation of each segment by Mel frequency cepstrum coefficients , 0 ) discretization by incremental clustering , yielding a tree of different sound classes ( e . g . instruments ) that can grow or shrink on the fly driven by the instantaneous sound events , resulting in a discrete symbol sequence , 0 ) extraction of statistical regularities of the symbol sequence , using hierarchical N-grams and the newly introduced conceptual Boltzmann machine , and 0 ) prediction of the next sound event in the sequence . The system ' s robustness is assessed with respect to complexity and noisiness of the signal . Clustering in isolation yields an adjusted Rand index ( ARI ) of 00 . 0% / 00 . 0% for data sets of singing voice and drums . Onset detection jointly with clustering achieve an ARI of 00 . 0% / 00 . 0% and the prediction of the entire system yields an ARI of 00 . 0% / 00 . 0% .
Neuroscience is undergoing faster changes than ever before . Over 000 years our field qualitatively described and invasively manipulated single or few organisms to gain anatomical , physiological , and pharmacological insights . In the last 00 years neuroscience spawned quantitative big-sample datasets on microanatomy , synaptic connections , optogenetic brain-behavior assays , and high-level cognition . While growing data availability and information granularity have been amply discussed , we direct attention to a routinely neglected question : How will the unprecedented data richness shape data analysis practices ? Statistical reasoning is becoming more central to distill neurobiological knowledge from healthy and pathological brain recordings . We believe that large-scale data analysis will use more models that are non-parametric , generative , mixing frequentist and Bayesian aspects , and grounded in different statistical inferences .
Non-convex regularizers usually improve the performance of sparse estimation in practice . To prove this fact , we study the conditions of sparse estimations for the sharp concave regularizers which are a general family of non-convex regularizers including many existing regularizers . For the global solutions of the regularized regression , our sparse eigenvalue based conditions are weaker than that of L0-regularization for parameter estimation and sparseness estimation . For the approximate global and approximate stationary ( AGAS ) solutions , almost the same conditions are also enough . We show that the desired AGAS solutions can be obtained by coordinate descent ( CD ) based methods . Finally , we perform some experiments to show the performance of CD methods on giving AGAS solutions and the degree of weakness of the estimation conditions required by the sharp concave regularizers .
We propose a new stochastic dual coordinate ascent technique that can be applied to a wide range of regularized learning problems . Our method is based on Alternating Direction Multiplier Method ( ADMM ) to deal with complex regularization functions such as structured regularizations . Although the original ADMM is a batch method , the proposed method offers a stochastic update rule where each iteration requires only one or few sample observations . Moreover , our method can naturally afford mini-batch update and it gives speed up of convergence . We show that , under mild assumptions , our method converges exponentially . The numerical experiments show that our method actually performs efficiently .
Approximate Bayesian computation ( ABC ) is now an established technique for statistical inference used in cases where the likelihood function is computationally expensive or not available . It relies on the use of a model that is specified in the form of a simulator , and approximates the likelihood at a parameter $\theta$ by simulating auxiliary data sets $x$ and evaluating the distance of $x$ from the true data $y$ . However , ABC is not computationally feasible in cases where using the simulator for each $\theta$ is very expensive . This paper investigates this situation in cases where a cheap , but approximate , simulator is available . The approach is to employ delayed acceptance Markov chain Monte Carlo ( MCMC ) within an ABC sequential Monte Carlo ( SMC ) sampler in order to , in a first stage of the kernel , use the cheap simulator to rule out parts of the parameter space that are not worth exploring , so that the " true " simulator is only run ( in the second stage of the kernel ) where there is a reasonable chance of accepting proposed values of $\theta$ . We show that this approach can be used quite automatically , with the only tuning parameter choice additional to ABC-SMC being the number of particles we wish to carry through to the second stage of the kernel . Applications to stochastic differential equation models and latent doubly intractable distributions are presented .
Recent progress in artificial intelligence ( AI ) has renewed interest in building systems that learn and think like people . Many advances have come from using deep neural networks trained end-to-end in tasks such as object recognition , video games , and board games , achieving performance that equals or even beats humans in some respects . Despite their biological inspiration and performance achievements , these systems differ from human intelligence in crucial ways . We review progress in cognitive science suggesting that truly human-like learning and thinking machines will have to reach beyond current engineering trends in both what they learn , and how they learn it . Specifically , we argue that these machines should ( a ) build causal models of the world that support explanation and understanding , rather than merely solving pattern recognition problems ; ( b ) ground learning in intuitive theories of physics and psychology , to support and enrich the knowledge that is learned ; and ( c ) harness compositionality and learning-to-learn to rapidly acquire and generalize knowledge to new tasks and situations . We suggest concrete challenges and promising routes towards these goals that can combine the strengths of recent neural network advances with more structured cognitive models .
Recently manifold learning algorithm for dimensionality reduction attracts more and more interests , and various linear and nonlinear , global and local algorithms are proposed . The key step of manifold learning algorithm is the neighboring region selection . However , so far for the references we know , few of which propose a generally accepted algorithm to well select the neighboring region . So in this paper , we propose an adaptive neighboring selection algorithm , which successfully applies the LLE and ISOMAP algorithms in the test . It is an algorithm that can find the optimal K nearest neighbors of the data points on the manifold . And the theoretical basis of the algorithm is the approximated curvature of the data point on the manifold . Based on Riemann Geometry , Jacob matrix is a proper mathematical concept to predict the approximated curvature . By verifying the proposed algorithm on embedding Swiss roll from R0 to R0 based on LLE and ISOMAP algorithm , the simulation results show that the proposed adaptive neighboring selection algorithm is feasible and able to find the optimal value of K , making the residual variance relatively small and better visualization of the results . By quantitative analysis , the embedding quality measured by residual variance is increased 00 . 00% after using the proposed algorithm in LLE .
Feature selection , identifying a subset of variables that are relevant for predicting a response , is an important and challenging component of many methods in statistics and machine learning . Feature selection is especially difficult and computationally intensive when the number of variables approaches or exceeds the number of samples , as is often the case for many genomic datasets . Here , we introduce a new approach -- the Bayesian Ising Approximation ( BIA ) -- to rapidly calculate posterior probabilities for feature relevance in L0 penalized linear regression . In the regime where the regression problem is strongly regularized by the prior , we show that computing the marginal posterior probabilities for features is equivalent to computing the magnetizations of an Ising model . Using a mean field approximation , we show it is possible to rapidly compute the feature selection path described by the posterior probabilities as a function of the L0 penalty . We present simulations and analytical results illustrating the accuracy of the BIA on some simple regression problems . Finally , we demonstrate the applicability of the BIA to high dimensional regression by analyzing a gene expression dataset with nearly 00 , 000 features .
Support Vector Data Description ( SVDD ) is a popular outlier detection technique which constructs a flexible description of the input data . SVDD computation time is high for large training datasets which limits its use in big-data process-monitoring applications . We propose a new iterative sampling-based method for SVDD training . The method incrementally learns the training data description at each iteration by computing SVDD on an independent random sample selected with replacement from the training data set . The experimental results indicate that the proposed method is extremely fast and provides a good data description .
We provide finite-sample analysis of a general framework for using k-nearest neighbor statistics to estimate functionals of a nonparametric continuous probability density , including entropies and divergences . Rather than plugging a consistent density estimate ( which requires $k \to \infty$ as the sample size $n \to \infty$ ) into the functional of interest , the estimators we consider fix k and perform a bias correction . This is more efficient computationally , and , as we show in certain cases , statistically , leading to faster convergence rates . Our framework unifies several previous estimators , for most of which ours are the first finite sample guarantees .
Despite our extensive knowledge of biophysical properties of neurons , there is no commonly accepted algorithmic theory of neuronal function . Here we explore the hypothesis that single-layer neuronal networks perform online symmetric nonnegative matrix factorization ( SNMF ) of the similarity matrix of the streamed data . By starting with the SNMF cost function we derive an online algorithm , which can be implemented by a biologically plausible network with local learning rules . We demonstrate that such network performs soft clustering of the data as well as sparse feature discovery . The derived algorithm replicates many known aspects of sensory anatomy and biophysical properties of neurons including unipolar nature of neuronal activity and synaptic weights , local synaptic plasticity rules and the dependence of learning rate on cumulative neuronal activity . Thus , we make a step towards an algorithmic theory of neuronal function , which should facilitate large-scale neural circuit simulations and biologically inspired artificial intelligence .
We propose a general technique for improving alternating optimization ( AO ) of nonconvex functions . Starting from the solution given by AO , we conduct another sequence of searches over subspaces that are both meaningful to the optimization problem at hand and different from those used by AO . To demonstrate the utility of our approach , we apply it to the matrix factorization ( MF ) algorithm for recommender systems and the coordinate descent algorithm for penalized regression ( PR ) , and show meaningful improvements using both real-world ( for MF ) and simulated ( for PR ) data sets . Moreover , we demonstrate for MF that , by constructing search spaces customized to the given data set , we can significantly increase the convergence rate of our technique .
In this paper , we investigate the sample size requirement for a general class of nuclear norm minimization methods for higher order tensor completion . We introduce a class of tensor norms by allowing for different levels of coherence , which allows us to leverage the incoherence of a tensor . In particular , we show that a $k$th order tensor of rank $r$ and dimension $d\times\cdots\times d$ can be recovered perfectly from as few as $O ( ( r^{ ( k-0 ) /0}d^{0/0}+r^{k-0}d ) ( \log ( d ) ) ^0 ) $ uniformly sampled entries through an appropriate incoherent nuclear norm minimization . Our results demonstrate some key differences between completing a matrix and a higher order tensor : They not only point to potential room for improvement over the usual nuclear norm minimization but also highlight the importance of explicitly accounting for incoherence , when dealing with higher order tensors .
In this paper , we consider linear state-space models with compressible innovations and convergent transition matrices in order to model spatiotemporally sparse transient events . We perform parameter and state estimation using a dynamic compressed sensing framework and develop an efficient solution consisting of two nested Expectation-Maximization ( EM ) algorithms . Under suitable sparsity assumptions on the innovations , we prove recovery guarantees and derive confidence bounds for the state estimates . We provide simulation studies as well as application to spike deconvolution from calcium imaging data which verify our theoretical results and show significant improvement over existing algorithms .
Context : One of the black arts of data mining is learning the magic parameters which control the learners . In software analytics , at least for defect prediction , several methods , like grid search and differential evolution ( DE ) , have been proposed to learn these parameters , which has been proved to be able to improve the performance scores of learners . Objective : We want to evaluate which method can find better parameters in terms of performance score and runtime cost . Methods : This paper compares grid search to differential evolution , which is an evolutionary algorithm that makes extensive use of stochastic jumps around the search space . Results : We find that the seemingly complete approach of grid search does no better , and sometimes worse , than the stochastic search . When repeated 00 times to check for conclusion validity , DE was over 000 times faster than grid search to tune Random Forests on 00 testing data sets with F-Measure Conclusions : These results are puzzling : why does a quick partial search be just as effective as a much slower , and much more , extensive search ? To answer that question , we turned to the theoretical optimization literature . Bergstra and Bengio conjecture that grid search is not more effective than more randomized searchers if the underlying search space is inherently low dimensional . This is significant since recent results show that defect prediction exhibits very low intrinsic dimensionality-- an observation that explains why a fast method like DE may work as well as a seemingly more thorough grid search . This suggests , as a future research direction , that it might be possible to peek at data sets before doing any optimization in order to match the optimization algorithm to the problem at hand .
Designing a covariance function that represents the underlying correlation is a crucial step in modeling complex natural systems , such as climate models . Geospatial datasets at a global scale usually suffer from non-stationarity and non-uniformly smooth spatial boundaries . A Gaussian process regression using a non-stationary covariance function has shown promise for this task , as this covariance function adapts to the variable correlation structure of the underlying distribution . In this paper , we generalize the non-stationary covariance function to address the aforementioned global scale geospatial issues . We define this generalized covariance function as an intrinsic non-stationary covariance function , because it uses intrinsic statistics of the symmetric positive definite matrices to represent the characteristic length scale and , thereby , models the local stochastic process . Experiments on a synthetic and real dataset of relative sea level changes across the world demonstrate improvements in the error metrics for the regression estimates using our newly proposed approach .
Conditional modeling x \to y is a central problem in machine learning . A substantial research effort is devoted to such modeling when x is high dimensional . We consider , instead , the case of a high dimensional y , where x is either low dimensional or high dimensional . Our approach is based on selecting a small subset y_L of the dimensions of y , and proceed by modeling ( i ) x \to y_L and ( ii ) y_L \to y . Composing these two models , we obtain a conditional model x \to y that possesses convenient statistical properties . Multi-label classification and multivariate regression experiments on several datasets show that this model outperforms the one vs . all approach as well as several sophisticated multiple output prediction methods .
Matching pursuit ( MP ) methods are a promising class of feature construction algorithms for value function approximation . Yet existing MP methods require creating a pool of potential features , mandating expert knowledge or enumeration of a large feature pool , both of which hinder scalability . This paper introduces batch incremental feature dependency discovery ( Batch-iFDD ) as an MP method that inherits a provable convergence property . Additionally , Batch-iFDD does not require a large pool of features , leading to lower computational complexity . Empirical policy evaluation results across three domains with up to one million states highlight the scalability of Batch-iFDD over the previous state of the art MP algorithm .
We characterize the class of exchangeable feature allocations assigning probability $V_{n , k}\prod_{l=0}^{k}W_{m_{l}}U_{n-m_{l}}$ to a feature allocation of $n$ individuals , displaying $k$ features with counts $ ( m_{0} , \ldots , m_{k} ) $ for these features . Each element of this class is parametrized by a countable matrix $V$ and two sequences $U$ and $W$ of non-negative weights . Moreover , a consistency condition is imposed to guarantee that the distribution for feature allocations of $n-0$ individuals is recovered from that of $n$ individuals , when the last individual is integrated out . In Theorem 0 . 0 , we prove that the only members of this class satisfying the consistency condition are mixtures of the Indian Buffet Process over its mass parameter $\gamma$ and mixtures of the Beta--Bernoulli model over its dimensionality parameter $N$ . Hence , we provide a characterization of these two models as the only , up to randomization of the parameters , consistent exchangeable feature allocations having the required product form .
We present a new algorithm for approximate inference in probabilistic programs , based on a stochastic gradient for variational programs . This method is efficient without restrictions on the probabilistic program ; it is particularly practical for distributions which are not analytically tractable , including highly structured distributions that arise in probabilistic programs . We show how to automatically derive mean-field probabilistic programs and optimize them , and demonstrate that our perspective improves inference efficiency over other algorithms .
Stochastic Gradient Descent ( SGD ) is one of the most widely used techniques for online optimization in machine learning . In this work , we accelerate SGD by adaptively learning how to sample the most useful training examples at each time step . First , we show that SGD can be used to learn the best possible sampling distribution of an importance sampling estimator . Second , we show that the sampling distribution of an SGD algorithm can be estimated online by incrementally minimizing the variance of the gradient . The resulting algorithm - called Adaptive Weighted SGD ( AW-SGD ) - maintains a set of parameters to optimize , as well as a set of parameters to sample learning examples . We show that AWSGD yields faster convergence in three different applications : ( i ) image classification with deep features , where the sampling of images depends on their labels , ( ii ) matrix factorization , where rows and columns are not sampled uniformly , and ( iii ) reinforcement learning , where the optimized and exploration policies are estimated at the same time , where our approach corresponds to an off-policy gradient algorithm .
This work addresses the problem of regret minimization in non-stochastic multi-armed bandit problems , focusing on performance guarantees that hold with high probability . Such results are rather scarce in the literature since proving them requires a large deal of technical effort and significant modifications to the standard , more intuitive algorithms that come only with guarantees that hold on expectation . One of these modifications is forcing the learner to sample arms from the uniform distribution at least $\Omega ( \sqrt{T} ) $ times over $T$ rounds , which can adversely affect performance if many of the arms are suboptimal . While it is widely conjectured that this property is essential for proving high-probability regret bounds , we show in this paper that it is possible to achieve such strong results without this undesirable exploration component . Our result relies on a simple and intuitive loss-estimation strategy called Implicit eXploration ( IX ) that allows a remarkably clean analysis . To demonstrate the flexibility of our technique , we derive several improved high-probability bounds for various extensions of the standard multi-armed bandit framework . Finally , we conduct a simple experiment that illustrates the robustness of our implicit exploration technique .
In this paper , we explore ordinal classification ( in the context of deep neural networks ) through a simple modification of the squared error loss which not only allows it to not only be sensitive to class ordering , but also allows the possibility of having a discrete probability distribution over the classes . Our formulation is based on the use of a softmax hidden layer , which has received relatively little attention in the literature . We empirically evaluate its performance on the Kaggle diabetic retinopathy dataset , an ordinal and high-resolution dataset and show that it outperforms all of the baselines employed .
Art historians and archaeologists have long grappled with the regional classification of ancient Near Eastern ivory carvings . Based on the visual similarity of sculptures , individuals within these fields have proposed object assemblages linked to hypothesized regional production centers . Using quantitative rather than visual methods , we here approach this classification task by exploiting computational methods from machine learning currently used with success in a variety of statistical problems in science and engineering . We first construct a prediction function using 00 categorical features as inputs and regional style as output . The model assigns regional style group ( RSG ) , with 00 percent prediction accuracy . We then rank these features by their mutual information with RSG , quantifying single-feature predictive power . Using the highest- ranking features in combination with nomographic visualization , we have found previously unknown relationships that may aid in the regional classification of these ivories and their interpretation in art historical context .
We consider the problem of minimizing the sum of two convex functions : one is the average of a large number of smooth component functions , and the other is a general convex function that admits a simple proximal mapping . We assume the whole objective function is strongly convex . Such problems often arise in machine learning , known as regularized empirical risk minimization . We propose and analyze a new proximal stochastic gradient method , which uses a multi-stage scheme to progressively reduce the variance of the stochastic gradient . While each iteration of this algorithm has similar cost as the classical stochastic gradient method ( or incremental gradient method ) , we show that the expected objective value converges to the optimum at a geometric rate . The overall complexity of this method is much lower than both the proximal full gradient method and the standard proximal stochastic gradient method .
Hypothesis tests in models whose dimension far exceeds the sample size can be formulated much like the classical studentized tests only after the initial bias of estimation is removed successfully . The theory of debiased estimators can be developed in the context of quantile regression models for a fixed quantile value . However , it is frequently desirable to formulate tests based on the quantile regression process , as this leads to more robust tests and more stable confidence sets . Additionally , inference in quantile regression requires estimation of the so called sparsity function , which depends on the unknown density of the error . In this paper we consider a debiasing approach for the uniform testing problem . We develop high-dimensional regression rank scores and show how to use them to estimate the sparsity function , as well as how to adapt them for inference involving the quantile regression process . Furthermore , we develop a Kolmogorov-Smirnov test in a location-shift high-dimensional models and confidence sets that are uniformly valid for many quantile values . The main technical result are the development of a Bahadur representation of the debiasing estimator that is uniform over a range of quantiles and uniform convergence of the quantile process to the Brownian bridge process , which are of independent interest . Simulation studies illustrate finite sample properties of our procedure .
The seemingly stochastic transient dynamics of neocortical circuits observed in vivo have been hypothesized to represent a signature of ongoing stochastic inference . In vitro neurons , on the other hand , exhibit a highly deterministic response to various types of stimulation . We show that an ensemble of deterministic leaky integrate-and-fire neurons embedded in a spiking noisy environment can attain the correct firing statistics in order to sample from a well-defined target distribution . We provide an analytical derivation of the activation function on the single cell level ; for recurrent networks , we examine convergence towards stationarity in computer simulations and demonstrate sample-based Bayesian inference in a mixed graphical model . This establishes a rigorous link between deterministic neuron models and functional stochastic dynamics on the network level .
In [00] , a general , inexact , efficient proximal quasi-Newton algorithm for composite optimization problems has been proposed and a sublinear global convergence rate has been established . In this paper , we analyze the convergence properties of this method , both in the exact and inexact setting , in the case when the objective function is strongly convex . We also investigate a practical variant of this method by establishing a simple stopping criterion for the subproblem optimization . Furthermore , we consider an accelerated variant , based on FISTA [0] , to the proximal quasi-Newton algorithm . A similar accelerated method has been considered in [0] , where the convergence rate analysis relies on very strong impractical assumptions . We present a modified analysis while relaxing these assumptions and perform a practical comparison of the accelerated proximal quasi- Newton algorithm and the regular one . Our analysis and computational results show that acceleration may not bring any benefit in the quasi-Newton setting .
We present a model of a basic recurrent neural network ( or bRNN ) that includes a separate linear term with a slightly " stable " fixed matrix to guarantee bounded solutions and fast dynamic response . We formulate a state space viewpoint and adapt the constrained optimization Lagrange Multiplier ( CLM ) technique and the vector Calculus of Variations ( CoV ) to derive the ( stochastic ) gradient descent . In this process , one avoids the commonly used re-application of the circular chain-rule and identifies the error back-propagation with the co-state backward dynamic equations . We assert that this bRNN can successfully perform regression tracking of time-series . Moreover , the " vanishing and exploding " gradients are explicitly quantified and explained through the co-state dynamics and the update laws . The adapted CoV framework , in addition , can correctly and principally integrate new loss functions in the network on any variable and for varied goals , e . g . , for supervised learning on the outputs and unsupervised learning on the internal ( hidden ) states .
In this paper , we have derived a set of sufficient conditions for reliable clustering of data produced by Bernoulli Mixture Models ( BMM ) , when the number of clusters is unknown . A BMM refers to a random binary vector whose components are independent Bernoulli trials with cluster-specific frequencies . The problem of clustering BMM data arises in many real-world applications , most notably in population genetics where researchers aim at inferring the population structure from multilocus genotype data . Our findings stipulate a minimum dataset size and a minimum number of Bernoulli trials ( or genotyped loci ) per sample , such that the existence of a clustering algorithm with a sufficient accuracy is guaranteed . Moreover , the mathematical intuitions and tools behind our work can help researchers in designing more effective and theoretically-plausible heuristic methods for similar problems .
In the classic sparsity-driven problems , the fundamental L-0 penalty method has been shown to have good performance in reconstructing signals for a wide range of problems . However this performance relies on a good choice of penalty weight which is often found from empirical experiments . We propose an algorithm called the Laplacian variational automatic relevance determination ( Lap-VARD ) that takes this penalty weight as a parameter of a prior Laplace distribution . Optimization of this parameter using an automatic relevance determination framework results in a balance between the sparsity and accuracy of signal reconstruction . Our algorithm is implemented in a transmission tomography model with sparsity constraint in wavelet domain .
In this paper , we provide a theoretical analysis of the nuclear-norm regularized least squares for full-rank matrix completion . Although similar formulations have been examined by previous studies , their results are unsatisfactory because only additive upper bounds are provided . Under the assumption that the top eigenspaces of the target matrix are incoherent , we derive a relative upper bound for recovering the best low-rank approximation of the unknown matrix . Our relative upper bound is tighter than previous additive bounds of other methods if the mass of the target matrix is concentrated on its top eigenspaces , and also implies perfect recovery if it is low-rank . The analysis is built upon the optimality condition of the regularized formulation and existing guarantees for low-rank matrix completion . To the best of our knowledge , this is first time such a relative bound is proved for the regularized formulation of matrix completion .
The elastic net was introduced as a heuristic algorithm for combinatorial optimisation and has been applied , among other problems , to biological modelling . It has an energy function which trades off a fitness term against a tension term . In the original formulation of the algorithm the tension term was implicitly based on a first-order derivative . In this paper we generalise the elastic net model to an arbitrary quadratic tension term , e . g . derived from a discretised differential operator , and give an efficient learning algorithm . We refer to these as generalised elastic nets ( GENs ) . We give a theoretical analysis of the tension term for 0D nets with periodic boundary conditions , and show that the model is sensitive to the choice of finite difference scheme that represents the discretised derivative . We illustrate some of these issues in the context of cortical map models , by relating the choice of tension term to a cortical interaction function . In particular , we prove that this interaction takes the form of a Mexican hat for the original elastic net , and of progressively more oscillatory Mexican hats for higher-order derivatives . The results apply not only to generalised elastic nets but also to other methods using discrete differential penalties , and are expected to be useful in other areas , such as data analysis , computer graphics and optimisation problems .
The ability to learn tasks in a sequential fashion is crucial to the development of artificial intelligence . Neural networks are not , in general , capable of this and it has been widely thought that catastrophic forgetting is an inevitable feature of connectionist models . We show that it is possible to overcome this limitation and train networks that can maintain expertise on tasks which they have not experienced for a long time . Our approach remembers old tasks by selectively slowing down learning on the weights important for those tasks . We demonstrate our approach is scalable and effective by solving a set of classification tasks based on the MNIST hand written digit dataset and by learning several Atari 0000 games sequentially .
We consider a Bayesian method for learning the Bayesian network structure from complete data . Recently , Koivisto and Sood ( 0000 ) presented an algorithm that for any single edge computes its marginal posterior probability in O ( n 0^n ) time , where n is the number of attributes ; the number of parents per attribute is bounded by a constant . In this paper we show that the posterior probabilities for all the n ( n - 0 ) potential edges can be computed in O ( n 0^n ) total time . This result is achieved by a forward-backward technique and fast Moebius transform algorithms , which are of independent interest . The resulting speedup by a factor of about n^0 allows us to experimentally study the statistical power of learning moderate-size networks . We report results from a simulation study that covers data sets with 00 to 00 , 000 records over 0 to 00 discrete attributes
Deep neural networks ( DNNs ) are now a central component of nearly all state-of-the-art speech recognition systems . Building neural network acoustic models requires several design decisions including network architecture , size , and training loss function . This paper offers an empirical investigation on which aspects of DNN acoustic model design are most important for speech recognition system performance . We report DNN classifier performance and final speech recognizer word error rates , and compare DNNs using several metrics to quantify factors influencing differences in task performance . Our first set of experiments use the standard Switchboard benchmark corpus , which contains approximately 000 hours of conversational telephone speech . We compare standard DNNs to convolutional networks , and present the first experiments using locally-connected , untied neural networks for acoustic modeling . We additionally build systems on a corpus of 0 , 000 hours of training data by combining the Switchboard and Fisher corpora . This larger corpus allows us to more thoroughly examine performance of large DNN models -- with up to ten times more parameters than those typically used in speech recognition systems . Our results suggest that a relatively simple DNN architecture and optimization technique produces strong results . These findings , along with previous work , help establish a set of best practices for building DNN hybrid speech recognition systems with maximum likelihood training . Our experiments in DNN optimization additionally serve as a case study for training DNNs with discriminative loss functions for speech tasks , as well as DNN classifiers more generally .
This paper proposed a new regression model called $l_0$-regularized outlier isolation and regression ( LOIRE ) and a fast algorithm based on block coordinate descent to solve this model . Besides , assuming outliers are gross errors following a Bernoulli process , this paper also presented a Bernoulli estimate model which , in theory , should be very accurate and robust due to its complete elimination of affections caused by outliers . Though this Bernoulli estimate is hard to solve , it could be approximately achieved through a process which takes LOIRE as an important intermediate step . As a result , the approximate Bernoulli estimate is a good combination of Bernoulli estimate ' s accuracy and LOIRE regression ' s efficiency with several simulations conducted to strongly verify this point . Moreover , LOIRE can be further extended to realize robust rank factorization which is powerful in recovering low-rank component from massive corruptions . Extensive experimental results showed that the proposed method outperforms state-of-the-art methods like RPCA and GoDec in the aspect of computation speed with a competitive performance .
Rank aggregation based on pairwise comparisons over a set of items has a wide range of applications . Although considerable research has been devoted to the development of rank aggregation algorithms , one basic question is how to efficiently collect a large amount of high-quality pairwise comparisons for the ranking purpose . Because of the advent of many crowdsourcing services , a crowd of workers are often hired to conduct pairwise comparisons with a small monetary reward for each pair they compare . Since different workers have different levels of reliability and different pairs have different levels of ambiguity , it is desirable to wisely allocate the limited budget for comparisons among the pairs of items and workers so that the global ranking can be accurately inferred from the comparison results . To this end , we model the active sampling problem in crowdsourced ranking as a Bayesian Markov decision process , which dynamically selects item pairs and workers to improve the ranking accuracy under a budget constraint . We further develop a computationally efficient sampling policy based on knowledge gradient as well as a moment matching technique for posterior approximation . Experimental evaluations on both synthetic and real data show that the proposed policy achieves high ranking accuracy with a lower labeling cost .
This paper presents a novel multitask multiple kernel learning framework that efficiently learns the kernel weights leveraging the relationship across multiple tasks . The idea is to automatically infer this task relationship in the \textit{RKHS} space corresponding to the given base kernels . The problem is formulated as a regularization-based approach called \textit{Multi-Task Multiple Kernel Relationship Learning} ( \textit{MK-MTRL} ) , which models the task relationship matrix from the weights learned from latent feature spaces of task-specific base kernels . Unlike in previous work , the proposed formulation allows one to incorporate prior knowledge for simultaneously learning several related tasks . We propose an alternating minimization algorithm to learn the model parameters , kernel weights and task relationship matrix . In order to tackle large-scale problems , we further propose a two-stage \textit{MK-MTRL} online learning algorithm and show that it significantly reduces the computational time , and also achieves performance comparable to that of the joint learning framework . Experimental results on benchmark datasets show that the proposed formulations outperform several state-of-the-art multitask learning methods .
We study a generalization of the multi-armed bandit problem with multiple plays where there is a cost associated with pulling each arm and the agent has a budget at each time that dictates how much she can expect to spend . We derive an asymptotic regret lower bound for any uniformly efficient algorithm in our setting . We then study a variant of Thompson sampling for Bernoulli rewards and a variant of KL-UCB for both single-parameter exponential families and bounded , finitely supported rewards . We show these algorithms are asymptotically optimal , both in rate and leading problem-dependent constants , including in the thick margin setting where multiple arms fall on the decision boundary .
Convolutional neural networks ( CNNs ) can be applied to graph similarity matching , in which case they are called graph CNNs . Graph CNNs are attracting increasing attention due to their effectiveness and efficiency . However , the existing convolution approaches focus only on regular data forms and require the transfer of the graph or key node neighborhoods of the graph into the same fixed form . During this transfer process , structural information of the graph can be lost , and some redundant information can be incorporated . To overcome this problem , we propose the disordered graph convolutional neural network ( DGCNN ) based on the mixed Gaussian model , which extends the CNN by adding a preprocessing layer called the disordered graph convolutional layer ( DGCL ) . The DGCL uses a mixed Gaussian function to realize the mapping between the convolution kernel and the nodes in the neighborhood of the graph . The output of the DGCL is the input of the CNN . We further implement a backward-propagation optimization process of the convolutional layer by which we incorporate the feature-learning model of the irregular node neighborhood structure into the network . Thereafter , the optimization of the convolution kernel becomes part of the neural network learning process . The DGCNN can accept arbitrary scaled and disordered neighborhood graph structures as the receptive fields of CNNs , which reduces information loss during graph transformation . Finally , we perform experiments on multiple standard graph datasets . The results show that the proposed method outperforms the state-of-the-art methods in graph classification and retrieval .
The collection and analysis of user data drives improvements in the app and web ecosystems , but comes with risks to privacy . This paper examines discrete distribution estimation under local privacy , a setting wherein service providers can learn the distribution of a categorical statistic of interest without collecting the underlying data . We present new mechanisms , including hashed K-ary Randomized Response ( KRR ) , that empirically meet or exceed the utility of existing mechanisms at all privacy levels . New theoretical results demonstrate the order-optimality of KRR and the existing RAPPOR mechanism at different privacy regimes .
This paper provides lower bounds on the convergence rate of Derivative Free Optimization ( DFO ) with noisy function evaluations , exposing a fundamental and unavoidable gap between the performance of algorithms with access to gradients and those with access to only function evaluations . However , there are situations in which DFO is unavoidable , and for such situations we propose a new DFO algorithm that is proved to be near optimal for the class of strongly convex objective functions . A distinctive feature of the algorithm is that it uses only Boolean-valued function comparisons , rather than function evaluations . This makes the algorithm useful in an even wider range of applications , such as optimization based on paired comparisons from human subjects , for example . We also show that regardless of whether DFO is based on noisy function evaluations or Boolean-valued function comparisons , the convergence rate is the same .
We present a new , efficient method for automatically detecting severe conflicts `edit wars ' in Wikipedia and evaluate this method on six different language WPs . We discuss how the number of edits , reverts , the length of discussions , the burstiness of edits and reverts deviate in such pages from those following the general workflow , and argue that earlier work has significantly over-estimated the contentiousness of the Wikipedia editing process .
A Bayesian factor graph reduced to normal form consists in the interconnection of diverter units ( or equal constraint units ) and Single-Input/Single-Output ( SISO ) blocks . In this framework localized adaptation rules are explicitly derived from a constrained maximum likelihood ( ML ) formulation and from a minimum KL-divergence criterion using KKT conditions . The learning algorithms are compared with two other updating equations based on a Viterbi-like and on a variational approximation respectively . The performance of the various algorithm is verified on synthetic data sets for various architectures . The objective of this paper is to provide the programmer with explicit algorithms for rapid deployment of Bayesian graphs in the applications .
We investigate statistical properties of a clustering algorithm that receives level set estimates from a kernel density estimator and then estimates the first split in the density level cluster tree if such a split is present or detects the absence of such a split . Key aspects of our analysis include finite sample guarantees , consistency , rates of convergence , and an adaptive data-driven strategy for chosing the kernel bandwidth . For the rates and the adaptivity we do not need continuity assumptions on the density such as H\ " older continuity , but only require intuitive geometric assumptions of non-parametric nature .
Computer vision is hard because of a large variability in lighting , shape , and texture ; in addition the image signal is non-additive due to occlusion . Generative models promised to account for this variability by accurately modelling the image formation process as a function of latent variables with prior beliefs . Bayesian posterior inference could then , in principle , explain the observation . While intuitively appealing , generative models for computer vision have largely failed to deliver on that promise due to the difficulty of posterior inference . As a result the community has favoured efficient discriminative approaches . We still believe in the usefulness of generative models in computer vision , but argue that we need to leverage existing discriminative or even heuristic computer vision methods . We implement this idea in a principled way with an " informed sampler " and in careful experiments demonstrate it on challenging generative models which contain renderer programs as their components . We concentrate on the problem of inverting an existing graphics rendering engine , an approach that can be understood as " Inverse Graphics " . The informed sampler , using simple discriminative proposals based on existing computer vision technology , achieves significant improvements of inference .
Subspace learning and matrix factorization problems have a great many applications in science and engineering , and efficient algorithms are critical as dataset sizes continue to grow . Many relevant problem formulations are non-convex , and in a variety of contexts it has been observed that solving the non-convex problem directly is not only efficient but reliably accurate . We discuss convergence theory for a particular method : first order incremental gradient descent constrained to the Grassmannian . The output of the algorithm is an orthonormal basis for a $d$-dimensional subspace spanned by an input streaming data matrix . We study two sampling cases : where each data vector of the streaming matrix is fully sampled , or where it is undersampled by a sampling matrix $A_t\in \R^{m\times n}$ with $m\ll n$ . We propose an adaptive stepsize scheme that depends only on the sampled data and algorithm outputs . We prove that with fully sampled data , the stepsize scheme maximizes the improvement of our convergence metric at each iteration , and this method converges from any random initialization to the true subspace , despite the non-convex formulation and orthogonality constraints . For the case of undersampled data , we establish monotonic improvement on the defined convergence metric for each iteration with high probability .
Many efforts have been devoted to training generative latent variable models with autoregressive decoders , such as recurrent neural networks ( RNN ) . Stochastic recurrent models have been successful in capturing the variability observed in natural sequential data such as speech . We unify successful ideas from recently proposed architectures into a stochastic recurrent model : each step in the sequence is associated with a latent variable that is used to condition the recurrent dynamics for future steps . Training is performed with amortized variational inference where the approximate posterior is augmented with a RNN that runs backward through the sequence . In addition to maximizing the variational lower bound , we ease training of the latent variables by adding an auxiliary cost which forces them to reconstruct the state of the backward recurrent network . This provides the latent variables with a task-independent objective that enhances the performance of the overall model . We found this strategy to perform better than alternative approaches such as KL annealing . Although being conceptually simple , our model achieves state-of-the-art results on standard speech benchmarks such as TIMIT and Blizzard and competitive performance on sequential MNIST . Finally , we apply our model to language modeling on the IMDB dataset where the auxiliary cost helps in learning interpretable latent variables . Source Code : \url{https : //github . com/anirudh0000/zforcing_nips00}
Online media provides opportunities for marketers through which they can deliver effective brand messages to a wide range of audiences . Advertising technology platforms enable advertisers to reach their target audience by delivering ad impressions to online users in real time . In order to identify the best marketing message for a user and to purchase impressions at the right price , we rely heavily on bid prediction and optimization models . Even though the bid prediction models are well studied in the literature , the equally important subject of model evaluation is usually overlooked . Effective and reliable evaluation of an online bidding model is crucial for making faster model improvements as well as for utilizing the marketing budgets more efficiently . In this paper , we present an experimentation framework for bid prediction models where our focus is on the practical aspects of model evaluation . Specifically , we outline the unique challenges we encounter in our platform due to a variety of factors such as heterogeneous goal definitions , varying budget requirements across different campaigns , high seasonality and the auction-based environment for inventory purchasing . Then , we introduce return on investment ( ROI ) as a unified model performance ( i . e . , success ) metric and explain its merits over more traditional metrics such as click-through rate ( CTR ) or conversion rate ( CVR ) . Most importantly , we discuss commonly used evaluation and metric summarization approaches in detail and propose a more accurate method for online evaluation of new experimental models against the baseline . Our meta-analysis-based approach addresses various shortcomings of other methods and yields statistically robust conclusions that allow us to conclude experiments more quickly in a reliable manner . We demonstrate the effectiveness of our evaluation strategy on real campaign data through some experiments .
In many machine learning applications , it is important to explain the predictions of a black-box classifier . For example , why does a deep neural network assign an image to a particular class ? We cast interpretability of black-box classifiers as a combinatorial maximization problem and propose an efficient streaming algorithm to solve it subject to cardinality constraints . By extending ideas from Badanidiyuru et al . [0000] , we provide a constant factor approximation guarantee for our algorithm in the case of random stream order and a weakly submodular objective function . This is the first such theoretical guarantee for this general class of functions , and we also show that no such algorithm exists for a worst case stream order . Our algorithm obtains similar explanations of Inception V0 predictions $00$ times faster than the state-of-the-art LIME framework of Ribeiro et al . [0000] .
Growing interest in automatic speaker verification ( ASV ) systems has lead to significant quality improvement of spoofing attackson them . Many research works confirm that despite the low equal er-ror rate ( EER ) ASV systems are still vulnerable to spoofing attacks . Inthis work we overview different acoustic feature spaces and classifiersto determine reliable and robust countermeasures against spoofing at-tacks . We compared several spoofing detection systems , presented so far , on the development and evaluation datasets of the Automatic SpeakerVerification Spoofing and Countermeasures ( ASVspoof ) Challenge 0000 . Experimental results presented in this paper demonstrate that the useof magnitude and phase information combination provides a substantialinput into the efficiency of the spoofing detection systems . Also wavelet-based features show impressive results in terms of equal error rate . Inour overview we compare spoofing performance for systems based on dif-ferent classifiers . Comparison results demonstrate that the linear SVMclassifier outperforms the conventional GMM approach . However , manyresearchers inspired by the great success of deep neural networks ( DNN ) approaches in the automatic speech recognition , applied DNN in thespoofing detection task and obtained quite low EER for known and un-known type of spoofing attacks .
In this paper , auto-associative models are proposed as candidates to the generalization of Principal Component Analysis . We show that these models are dedicated to the approximation of the dataset by a manifold . Here , the word " manifold " refers to the topology properties of the structure . The approximating manifold is built by a projection pursuit algorithm . At each step of the algorithm , the dimension of the manifold is incremented . Some theoretical properties are provided . In particular , we can show that , at each step of the algorithm , the mean residuals norm is not increased . Moreover , it is also established that the algorithm converges in a finite number of steps . Some particular auto-associative models are exhibited and compared to the classical PCA and some neural networks models . Implementation aspects are discussed . We show that , in numerous cases , no optimization procedure is required . Some illustrations on simulated and real data are presented .
The ability to perform effective off-policy learning would revolutionize the process of building better interactive systems , such as search engines and recommendation systems for e-commerce , computational advertising and news . Recent approaches for off-policy evaluation and learning in these settings appear promising . With this paper , we provide real-world data and a standardized test-bed to systematically investigate these algorithms using data from display advertising . In particular , we consider the problem of filling a banner ad with an aggregate of multiple products the user may want to purchase . This paper presents our test-bed , the sanity checks we ran to ensure its validity , and shows results comparing state-of-the-art off-policy learning methods like doubly robust optimization , POEM , and reductions to supervised learning using regression baselines . Our results show experimental evidence that recent off-policy learning methods can improve upon state-of-the-art supervised learning techniques on a large-scale real-world data set .
In this note we prove a tight lower bound for the MNL-bandit assortment selection model that matches the upper bound given in ( Agrawal et al . , 0000a , b ) for all parameters , up to logarithmic factors .
Many probabilistic models introduce strong dependencies between variables using a latent multivariate Gaussian distribution or a Gaussian process . We present a new Markov chain Monte Carlo algorithm for performing inference in models with multivariate Gaussian priors . Its key properties are : 0 ) it has simple , generic code applicable to many models , 0 ) it has no free parameters , 0 ) it works well for a variety of Gaussian process based models . These properties make our method ideal for use while model building , removing the need to spend time deriving and tuning updates for more complex algorithms .
In this paper , we investigate the sample size requirement for exact recovery of a high order tensor of low rank from a subset of its entries . We show that a gradient descent algorithm with initial value obtained from a spectral method can , in particular , reconstruct a ${d\times d\times d}$ tensor of multilinear ranks $ ( r , r , r ) $ with high probability from as few as $O ( r^{0/0}d^{0/0}\log^{0/0}d+r^0d\log^0d ) $ entries . In the case when the ranks $r=O ( 0 ) $ , our sample size requirement matches those for nuclear norm minimization ( Yuan and Zhang , 0000a ) , or alternating least squares assuming orthogonal decomposability ( Jain and Oh , 0000 ) . Unlike these earlier approaches , however , our method is efficient to compute , easy to implement , and does not impose extra structures on the tensor . Numerical results are presented to further demonstrate the merits of the proposed approach .
Entity resolution ( ER ) is the task of identifying records belonging to the same entity ( e . g . individual , group ) across one or multiple databases . Ironically , it has multiple names : deduplication and record linkage , among others . In this paper we survey metrics used to evaluate ER results in order to iteratively improve performance and guarantee sufficient quality prior to deployment . Some of these metrics are borrowed from multi-class classification and clustering domains , though some key differences exist differentiating entity resolution from general clustering . Menestrina et al . empirically showed rankings from these metrics often conflict with each other , thus our primary motivation for studying them . This paper provides practitioners the basic knowledge to begin evaluating their entity resolution results .
The main goal of this study is to extract a set of brain networks in multiple time-resolutions to analyze the connectivity patterns among the anatomic regions for a given cognitive task . We suggest a deep architecture which learns the natural groupings of the connectivity patterns of human brain in multiple time-resolutions . The suggested architecture is tested on task data set of Human Connectome Project ( HCP ) where we extract multi-resolution networks , each of which corresponds to a cognitive task . At the first level of this architecture , we decompose the fMRI signal into multiple sub-bands using wavelet decompositions . At the second level , for each sub-band , we estimate a brain network extracted from short time windows of the fMRI signal . At the third level , we feed the adjacency matrices of each mesh network at each time-resolution into an unsupervised deep learning algorithm , namely , a Stacked De- noising Auto-Encoder ( SDAE ) . The outputs of the SDAE provide a compact connectivity representation for each time window at each sub-band of the fMRI signal . We concatenate the learned representations of all sub-bands at each window and cluster them by a hierarchical algorithm to find the natural groupings among the windows . We observe that each cluster represents a cognitive task with a performance of 00% Rand Index and 00% Adjusted Rand Index . We visualize the mean values and the precisions of the networks at each component of the cluster mixture . The mean brain networks at cluster centers show the variations among cognitive tasks and the precision of each cluster shows the within cluster variability of networks , across the subjects .
One of the objectives of designing feature selection learning algorithms is to obtain classifiers that depend on a small number of attributes and have verifiable future performance guarantees . There are few , if any , approaches that successfully address the two goals simultaneously . Performance guarantees become crucial for tasks such as microarray data analysis due to very small sample sizes resulting in limited empirical evaluation . To the best of our knowledge , such algorithms that give theoretical bounds on the future performance have not been proposed so far in the context of the classification of gene expression data . In this work , we investigate the premise of learning a conjunction ( or disjunction ) of decision stumps in Occam ' s Razor , Sample Compression , and PAC-Bayes learning settings for identifying a small subset of attributes that can be used to perform reliable classification tasks . We apply the proposed approaches for gene identification from DNA microarray data and compare our results to those of well known successful approaches proposed for the task . We show that our algorithm not only finds hypotheses with much smaller number of genes while giving competitive classification accuracy but also have tight risk guarantees on future performance unlike other approaches . The proposed approaches are general and extensible in terms of both designing novel algorithms and application to other domains .
We study the problem of estimating a manifold from random samples . In particular , we consider piecewise constant and piecewise linear estimators induced by k-means and k-flats , and analyze their performance . We extend previous results for k-means in two separate directions . First , we provide new results for k-means reconstruction on manifolds and , secondly , we prove reconstruction bounds for higher-order approximation ( k-flats ) , for which no known results were previously available . While the results for k-means are novel , some of the technical tools are well-established in the literature . In the case of k-flats , both the results and the mathematical tools are new .
Prototypal analysis is introduced to overcome two shortcomings of archetypal analysis : its sensitivity to outliers and its non-locality , which reduces its applicability as a learning tool . Same as archetypal analysis , prototypal analysis finds prototypes through convex combination of the data points and approximates the data through convex combination of the archetypes , but it adds a penalty for using prototypes distant from the data points for their reconstruction . Prototypal analysis can be extended---via kernel embedding---to probability distributions , since the convexity of the prototypes makes them interpretable as mixtures . Finally , prototypal regression is developed , a robust supervised procedure which allows the use of distributions as either features or labels .
This letter presents a novel Block Bayesian Hypothesis Testing Algorithm ( Block-BHTA ) for reconstructing block sparse signals with unknown block structures . The Block-BHTA comprises the detection and recovery of the supports , and the estimation of the amplitudes of the block sparse signal . The support detection and recovery is performed using a Bayesian hypothesis testing . Then , based on the detected and reconstructed supports , the nonzero amplitudes are estimated by linear MMSE . The effectiveness of Block-BHTA is demonstrated by numerical experiments .
In this paper we explore the applicability of the unsupervised machine learning technique of Self Organizing Maps ( SOM ) to estimate galaxy photometric redshift probability density functions ( PDFs ) . This technique takes a spectroscopic training set , and maps the photometric attributes , but not the redshifts , to a two dimensional surface by using a process of competitive learning where neurons compete to more closely resemble the training data multidimensional space . The key feature of a SOM is that it retains the topology of the input set , revealing correlations between the attributes that are not easily identified . We test three different 0D topological mapping : rectangular , hexagonal , and spherical , by using data from the DEEP0 survey . We also explore different implementations and boundary conditions on the map and also introduce the idea of a random atlas where a large number of different maps are created and their individual predictions are aggregated to produce a more robust photometric redshift PDF . We also introduced a new metric , the $I$-score , which efficiently incorporates different metrics , making it easier to compare different results ( from different parameters or different photometric redshift codes ) . We find that by using a spherical topology mapping we obtain a better representation of the underlying multidimensional topology , which provides more accurate results that are comparable to other , state-of-the-art machine learning algorithms . Our results illustrate that unsupervised approaches have great potential for many astronomical problems , and in particular for the computation of photometric redshifts .
Appropriately designing the proposal kernel of particle filters is an issue of significant importance , since a bad choice may lead to deterioration of the particle sample and , consequently , waste of computational power . In this paper we introduce a novel algorithm adaptively approximating the so-called optimal proposal kernel by a mixture of integrated curved exponential distributions with logistic weights . This family of distributions , referred to as mixtures of experts , is broad enough to be used in the presence of multi-modality or strongly skewed distributions . The mixtures are fitted , via online-EM methods , to the optimal kernel through minimisation of the Kullback-Leibler divergence between the auxiliary target and instrumental distributions of the particle filter . At each iteration of the particle filter , the algorithm is required to solve only a single optimisation problem for the whole particle sample , yielding an algorithm with only linear complexity . In addition , we illustrate in a simulation study how the method can be successfully applied to optimal filtering in nonlinear state-space models .
Predicting the biological function of molecules , be it proteins or drug-like compounds , from their atomic structure is an important and long-standing problem . Function is dictated by structure , since it is by spatial interactions that molecules interact with each other , both in terms of steric complementarity , as well as intermolecular forces . Thus , the electron density field and electrostatic potential field of a molecule contain the " raw fingerprint " of how this molecule can fit to binding partners . In this paper , we show that deep learning can predict biological function of molecules directly from their raw 0D approximated electron density and electrostatic potential fields . Protein function based on EC numbers is predicted from the approximated electron density field . In another experiment , the activity of small molecules is predicted with quality comparable to state-of-the-art descriptor-based methods . We propose several alternative computational models for the GPU with different memory and runtime requirements for different sizes of molecules and of databases . We also propose application-specific multi-channel data representations . With future improvements of training datasets and neural network settings in combination with complementary information sources ( sequence , genomic context , expression level ) , deep learning can be expected to show its generalization power and revolutionize the field of molecular function prediction .
A novel extrapolation method is proposed for longitudinal forecasting . A hierarchical Gaussian process model is used to combine nonlinear population change and individual memory of the past to make prediction . The prediction error is minimized through the hierarchical design . The method is further extended to joint modeling of continuous measurements and survival events . The baseline hazard , covariate and joint effects are conveniently modeled in this hierarchical structure . The estimation and inference are implemented in fully Bayesian framework using the objective and shrinkage priors . In simulation studies , this model shows robustness in latent estimation , correlation detection and high accuracy in forecasting . The model is illustrated with medical monitoring data from cystic fibrosis ( CF ) patients . Estimation and forecasts are obtained in the measurement of lung function and records of acute respiratory events . Keyword : Extrapolation , Joint Model , Longitudinal Model , Hierarchical Gaussian Process , Cystic Fibrosis , Medical Monitoring
Deep neural networks ( DNNs ) form the backbone of almost every state-of-the-art technique in the fields such as computer vision , speech processing , and text analysis . The recent advances in computational technology have made the use of DNNs more practical . Despite the overwhelming performances by DNN and the advances in computational technology , it is seen that very few researchers try to train their models from the scratch . Training of DNNs still remains a difficult and tedious job . The main challenges that researchers face during training of DNNs are the vanishing/exploding gradient problem and the highly non-convex nature of the objective function which has up to million variables . The approaches suggested in He and Xavier solve the vanishing gradient problem by providing a sophisticated initialization technique . These approaches have been quite effective and have achieved good results on standard datasets , but these same approaches do not work very well on more practical datasets . We think the reason for this is not making use of data statistics for initializing the network weights . Optimizing such a high dimensional loss function requires careful initialization of network weights . In this work , we propose a data dependent initialization and analyze its performance against the standard initialization techniques such as He and Xavier . We performed our experiments on some practical datasets and the results show our algorithm ' s superior classification accuracy .
We consider analysis of relational data ( a matrix ) , in which the rows correspond to subjects ( e . g . , people ) and the columns correspond to attributes . The elements of the matrix may be a mix of real and categorical . Each subject and attribute is characterized by a latent binary feature vector , and an inferred matrix maps each row-column pair of binary feature vectors to an observed matrix element . The latent binary features of the rows are modeled via a multivariate Gaussian distribution with low-rank covariance matrix , and the Gaussian random variables are mapped to latent binary features via a probit link . The same type construction is applied jointly to the columns . The model infers latent , low-dimensional binary features associated with each row and each column , as well correlation structure between all rows and between all columns .
For large matrix factorisation problems , we develop a distributed Markov Chain Monte Carlo ( MCMC ) method based on stochastic gradient Langevin dynamics ( SGLD ) that we call Parallel SGLD ( PSGLD ) . PSGLD has very favourable scaling properties with increasing data size and is comparable in terms of computational requirements to optimisation methods based on stochastic gradient descent . PSGLD achieves high performance by exploiting the conditional independence structure of the MF models to sub-sample data in a systematic manner as to allow parallelisation and distributed computation . We provide a convergence proof of the algorithm and verify its superior performance on various architectures such as Graphics Processing Units , shared memory multi-core systems and multi-computer clusters .
We revisit the development of grid based recursive approximate filtering of general Markov processes in discrete time , partially observed in conditionally Gaussian noise . The grid based filters considered rely on two types of state quantization : The \textit{Markovian} type and the \textit{marginal} type . We propose a set of novel , relaxed sufficient conditions , ensuring strong and fully characterized pathwise convergence of these filters to the respective MMSE state estimator . In particular , for marginal state quantizations , we introduce the notion of \textit{conditional regularity of stochastic kernels} , which , to the best of our knowledge , constitutes the most relaxed condition proposed , under which asymptotic optimality of the respective grid based filters is guaranteed . Further , we extend our convergence results , including filtering of bounded and continuous functionals of the state , as well as recursive approximate state prediction . For both Markovian and marginal quantizations , the whole development of the respective grid based filters relies more on linear-algebraic techniques and less on measure theoretic arguments , making the presentation considerably shorter and technically simpler .
Recurrent major mood episodes and subsyndromal mood instability cause substantial disability in patients with bipolar disorder . Early identification of mood episodes enabling timely mood stabilisation is an important clinical goal . Recent technological advances allow the prospective reporting of mood in real time enabling more accurate , efficient data capture . The complex nature of these data streams in combination with challenge of deriving meaning from missing data mean pose a significant analytic challenge . The signature method is derived from stochastic analysis and has the ability to capture important properties of complex ordered time series data . To explore whether the onset of episodes of mania and depression can be identified using self-reported mood data .
We propose RoBiRank , a ranking algorithm that is motivated by observing a close connection between evaluation metrics for learning to rank and loss functions for robust classification . The algorithm shows a very competitive performance on standard benchmark datasets against other representative algorithms in the literature . On the other hand , in large scale problems where explicit feature vectors and scores are not given , our algorithm can be efficiently parallelized across a large number of machines ; for a task that requires 000 , 000 x 00 , 000 , 000 pairwise interactions between items to be ranked , our algorithm finds solutions that are of dramatically higher quality than that can be found by a state-of-the-art competitor algorithm , given the same amount of wall-clock time for computation .
Prediction of disease onset from patient survey and lifestyle data is quickly becoming an important tool for diagnosing a disease before it progresses . In this study , data from the National Health and Nutrition Examination Survey ( NHANES ) questionnaire is used to predict the onset of type II diabetes . An ensemble model using the output of five classification algorithms was developed to predict the onset on diabetes based on 00 features . The ensemble model had an AUC of 0 . 000 indicating high performance .
Recent work in learning ontologies ( hierarchical and partially-ordered structures ) has leveraged the intrinsic geometry of spaces of learned representations to make predictions that automatically obey complex structural constraints . We explore two extensions of one such model , the order-embedding model for hierarchical relation learning , with an aim towards improved performance on text data for commonsense knowledge representation . Our first model jointly learns ordering relations and non-hierarchical knowledge in the form of raw text . Our second extension exploits the partial order structure of the training data to find long-distance triplet constraints among embeddings which are poorly enforced by the pairwise training procedure . We find that both incorporating free text and augmented training constraints improve over the original order-embedding model and other strong baselines .
Popular sparse estimation methods based on $\ell_0$-relaxation , such as the Lasso and the Dantzig selector , require the knowledge of the variance of the noise in order to properly tune the regularization parameter . This constitutes a major obstacle in applying these methods in several frameworks---such as time series , random fields , inverse problems---for which the noise is rarely homoscedastic and its level is hard to know in advance . In this paper , we propose a new approach to the joint estimation of the conditional mean and the conditional variance in a high-dimensional ( auto- ) regression setting . An attractive feature of the proposed estimator is that it is efficiently computable even for very large scale problems by solving a second-order cone program ( SOCP ) . We present theoretical analysis and numerical results assessing the performance of the proposed procedure .
Boosting is a general method of generating many simple classification rules and combining them into a single , highly accurate rule . In this talk , I will review the AdaBoost boosting algorithm and some of its underlying theory , and then look at how this theory has helped us to face some of the challenges of applying AdaBoost in two domains : In the first of these , we used boosting for predicting and modeling the uncertainty of prices in complicated , interacting auctions . The second application was to the classification of caller utterances in a telephone spoken-dialogue system where we faced two challenges : the need to incorporate prior knowledge to compensate for initially insufficient data ; and a later need to filter the large stream of unlabeled examples being collected to select the ones whose labels are likely to be most informative .
Common statistical prediction models often require and assume stationarity in the data . However , in many practical applications , changes in the relationship of the response and predictor variables are regularly observed over time , resulting in the deterioration of the predictive performance of these models . This paper presents Linear Four Rates ( LFR ) , a framework for detecting these concept drifts and subsequently identifying the data points that belong to the new concept ( for relearning the model ) . Unlike conventional concept drift detection approaches , LFR can be applied to both batch and stream data ; is not limited by the distribution properties of the response variable ( e . g . , datasets with imbalanced labels ) ; is independent of the underlying statistical-model ; and uses user-specified parameters that are intuitively comprehensible . The performance of LFR is compared to benchmark approaches using both simulated and commonly used public datasets that span the gamut of concept drift types . The results show LFR significantly outperforms benchmark approaches in terms of recall , accuracy and delay in detection of concept drifts across datasets .
A universal unanswered question in neuroscience and machine learning is whether computers can decode the patterns of the human brain . Multi-Voxels Pattern Analysis ( MVPA ) is a critical tool for addressing this question . However , there are two challenges in the previous MVPA methods , which include decreasing sparsity and noises in the extracted features and increasing the performance of prediction . In overcoming mentioned challenges , this paper proposes Anatomical Pattern Analysis ( APA ) for decoding visual stimuli in the human brain . This framework develops a novel anatomical feature extraction method and a new imbalance AdaBoost algorithm for binary classification . Further , it utilizes an Error-Correcting Output Codes ( ECOC ) method for multi-class prediction . APA can automatically detect active regions for each category of the visual stimuli . Moreover , it enables us to combine homogeneous datasets for applying advanced classification . Experimental studies on 0 visual categories ( words , consonants , objects and scrambled photos ) demonstrate that the proposed approach achieves superior performance to state-of-the-art methods .
In this letter , we present a novel exponentially embedded families ( EEF ) based classification method , in which the probability density function ( PDF ) on raw data is estimated from the PDF on features . With the PDF construction , we show that class-specific features can be used in the proposed classification method , instead of a common feature subset for all classes as used in conventional approaches . We apply the proposed EEF classifier for text categorization as a case study and derive an optimal Bayesian classification rule with class-specific feature selection based on the Information Gain ( IG ) score . The promising performance on real-life data sets demonstrates the effectiveness of the proposed approach and indicates its wide potential applications .
We present a new statistical learning paradigm for Boltzmann machines based on a new inference principle we have proposed : the latent maximum entropy principle ( LME ) . LME is different both from Jaynes maximum entropy principle and from standard maximum likelihood estimation . We demonstrate the LME principle BY deriving new algorithms for Boltzmann machine parameter estimation , and show how robust and fast new variant of the EM algorithm can be developed . Our experiments show that estimation based on LME generally yields better results than maximum likelihood estimation , particularly when inferring hidden units from small amounts of data .
This paper introduces the first deep neural network-based estimation metric for the jigsaw puzzle problem . Given two puzzle piece edges , the neural network predicts whether or not they should be adjacent in the correct assembly of the puzzle , using nothing but the pixels of each piece . The proposed metric exhibits an extremely high precision even though no manual feature extraction is performed . When incorporated into an existing puzzle solver , the solution ' s accuracy increases significantly , achieving thereby a new state-of-the-art standard .
Topic models have emerged as fundamental tools in unsupervised machine learning . Most modern topic modeling algorithms take a probabilistic view and derive inference algorithms based on Latent Dirichlet Allocation ( LDA ) or its variants . In contrast , we study topic modeling as a combinatorial optimization problem , and propose a new objective function derived from LDA by passing to the small-variance limit . We minimize the derived objective by using ideas from combinatorial optimization , which results in a new , fast , and high-quality topic modeling algorithm . In particular , we show that our results are competitive with popular LDA-based topic modeling approaches , and also discuss the ( dis ) similarities between our approach and its probabilistic counterparts .
Population migration is valuable information which leads to proper decision in urban-planning strategy , massive investment , and many other fields . For instance , inter-city migration is a posterior evidence to see if the government ' s constrain of population works , and inter-community immigration might be a prior evidence of real estate price hike . With timely data , it is also impossible to compare which city is more favorable for the people , suppose the cities release different new regulations , we could also compare the customers of different real estate development groups , where they come from , where they probably will go . Unfortunately these data was not available . In this paper , leveraging the data generated by positioning team in Didi , we propose a novel approach that timely monitoring population migration from community scale to provincial scale . Migration can be detected as soon as in a week . It could be faster , the setting of a week is for statistical purpose . A monitoring system is developed , then applied nation wide in China , some observations derived from the system will be presented in this paper . This new method of migration perception is origin from the insight that nowadays people mostly moving with their personal Access Point ( AP ) , also known as WiFi hotspot . Assume that the ratio of AP moving to the migration of population is constant , analysis of comparative population migration would be feasible . More exact quantitative research would also be done with few sample research and model regression . The procedures of processing data includes many steps : eliminating the impact of pseudo-migration AP , for instance pocket WiFi , and second-hand traded router ; distinguishing moving of population with moving of companies ; identifying shifting of AP by the finger print clusters , etc . .
The counting grid is a grid of microtopics , sparse word/feature distributions . The generative model associated with the grid does not use these microtopics individually . Rather , it groups them in overlapping rectangular windows and uses these grouped microtopics as either mixture or admixture components . This paper builds upon the basic counting grid model and it shows that hierarchical reasoning helps avoid bad local minima , produces better classification accuracy and , most interestingly , allows for extraction of large numbers of coherent microtopics even from small datasets . We evaluate this in terms of consistency , diversity and clarity of the indexed content , as well as in a user study on word intrusion tasks . We demonstrate that these models work well as a technique for embedding raw images and discuss interesting parallels between hierarchical CG models and other deep architectures .
We study statistical risk minimization problems under a privacy model in which the data is kept confidential even from the learner . In this local privacy framework , we establish sharp upper and lower bounds on the convergence rates of statistical estimation procedures . As a consequence , we exhibit a precise tradeoff between the amount of privacy the data preserves and the utility , as measured by convergence rate , of any statistical estimator or learning procedure .
We propose a robust classifier to predict buying intentions based on user behaviour within a large e-commerce website . In this work we compare traditional machine learning techniques with the most advanced deep learning approaches . We show that both Deep Belief Networks and Stacked Denoising auto-Encoders achieved a substantial improvement by extracting features from high dimensional data during the pre-train phase . They prove also to be more convenient to deal with severe class imbalance .
Being an unsupervised machine learning and data mining technique , biclustering and its multimodal extensions are becoming popular tools for analysing object-attribute data in different domains . Apart from conventional clustering techniques , biclustering is searching for homogeneous groups of objects while keeping their common description , e . g . , in binary setting , their shared attributes . In bioinformatics , biclustering is used to find genes , which are active in a subset of situations , thus being candidates for biomarkers . However , the authors of those biclustering techniques that are popular in gene expression analysis , may overlook the existing methods . For instance , BiMax algorithm is aimed at finding biclusters , which are well-known for decades as formal concepts . Moreover , even if bioinformatics classify the biclustering methods according to reasonable domain-driven criteria , their classification taxonomies may be different from survey to survey and not full as well . So , in this paper we propose to use concept lattices as a tool for taxonomy building ( in the biclustering domain ) and attribute exploration as means for cross-domain taxonomy completion .
State-space smoothing has found many applications in science and engineering . Under linear and Gaussian assumptions , smoothed estimates can be obtained using efficient recursions , for example Rauch-Tung-Striebel and Mayne-Fraser algorithms . Such schemes are equivalent to linear algebraic techniques that minimize a convex quadratic objective function with structure induced by the dynamic model . These classical formulations fall short in many important circumstances . For instance , smoothers obtained using quadratic penalties can fail when outliers are present in the data , and cannot track impulsive inputs and abrupt state changes . Motivated by these shortcomings , generalized Kalman smoothing formulations have been proposed in the last few years , replacing quadratic models with more suitable , often nonsmooth , convex functions . In contrast to classical models , these general estimators require use of iterated algorithms , and these have received increased attention from control , signal processing , machine learning , and optimization communities . In this survey we show that the optimization viewpoint provides the control and signal processing community great freedom in the development of novel modeling and inference frameworks for dynamical systems . We discuss general statistical models for dynamic systems , making full use of nonsmooth convex penalties and constraints , and providing links to important models in signal processing and machine learning . We also survey optimization techniques for these formulations , paying close attention to dynamic problem structure . Modeling concepts and algorithms are illustrated with numerical examples .
We consider the problem of identifying the most profitable product design from a finite set of candidates under unknown consumer preference . A standard approach to this problem follows a two-step strategy : First , estimate the preference of the consumer population , represented as a point in part-worth space , using an adaptive discrete-choice questionnaire . Second , integrate the estimated part-worth vector with engineering feasibility and cost models to determine the optimal design . In this work , we ( 0 ) demonstrate that accurate preference estimation is neither necessary nor sufficient for identifying the optimal design , ( 0 ) introduce a novel adaptive questionnaire that leverages knowledge about engineering feasibility and manufacturing costs to directly determine the optimal design , and ( 0 ) interpret product design in terms of a nonlinear segmentation of part-worth space , and use this interpretation to illuminate the intrinsic difficulty of optimal design in the presence of noisy questionnaire responses . We establish the superiority of the proposed approach using a well-documented optimal product design task . This study demonstrates how the identification of optimal product design can be accelerated by integrating marketing and manufacturing knowledge into the adaptive questionnaire .
We present a new recommendation setting for picking out two items from a given set to be highlighted to a user , based on contextual input . These two items are presented to a user who chooses one of them , possibly stochastically , with a bias that favours the item with the higher value . We propose a second-order algorithm framework that members of it use uses relative upper-confidence bounds to trade off exploration and exploitation , and some explore via sampling . We analyze one algorithm in this framework in an adversarial setting with only mild assumption on the data , and prove a regret bound of $O ( Q_T + \sqrt{TQ_T\log T} + \sqrt{T}\log T ) $ , where $T$ is the number of rounds and $Q_T$ is the cumulative approximation error of item values using a linear model . Experiments with product reviews from 00 domains show the advantage of our methods over algorithms designed for related settings , and that UCB based algorithms are inferior to greed or sampling based algorithms .
Despite being the standard loss function to train multi-class neural networks , the log-softmax has two potential limitations . First , it involves computations that scale linearly with the number of output classes , which can restrict the size of problems we are able to tackle with current hardware . Second , it remains unclear how close it matches the task loss such as the top-k error rate or other non-differentiable evaluation metrics which we aim to optimize ultimately . In this paper , we introduce an alternative classification loss function , the Z-loss , which is designed to address these two issues . Unlike the log-softmax , it has the desirable property of belonging to the spherical loss family ( Vincent et al . , 0000 ) , a class of loss functions for which training can be performed very efficiently with a complexity independent of the number of output classes . We show experimentally that it significantly outperforms the other spherical loss functions previously investigated . Furthermore , we show on a word language modeling task that it also outperforms the log-softmax with respect to certain ranking scores , such as top-k scores , suggesting that the Z-loss has the flexibility to better match the task loss . These qualities thus makes the Z-loss an appealing candidate to train very efficiently large output networks such as word-language models or other extreme classification problems . On the One Billion Word ( Chelba et al . , 0000 ) dataset , we are able to train a model with the Z-loss 00 times faster than the log-softmax and more than 0 times faster than the hierarchical softmax .
Classification is the task of predicting the class labels of objects based on the observation of their features . In contrast , quantification has been defined as the task of determining the prevalences of the different sorts of class labels in a target dataset . The simplest approach to quantification is Classify & Count where a classifier is optimised for classification on a training set and applied to the target dataset for the prediction of class labels . In the case of binary quantification , the number of predicted positive labels is then used as an estimate of the prevalence of the positive class in the target dataset . Since the performance of Classify & Count for quantification is known to be inferior its results typically are subject to adjustments . However , some researchers recently have suggested that Classify & Count might actually work without adjustments if it is based on a classifer that was specifically trained for quantification . We discuss the theoretical foundation for this claim and explore its potential and limitations with a numerical example based on the binormal model with equal variances . In order to identify an optimal quantifier in the binormal setting , we introduce the concept of local Bayes optimality . As a side remark , we present a complete proof of a theorem by Ye et al . ( 0000 ) .
A number of problems in statistical physics and computer science can be expressed as the computation of marginal probabilities over a Markov random field . Belief propagation , an iterative message-passing algorithm , computes exactly such marginals when the underlying graph is a tree . But it has gained its popularity as an efficient way to approximate them in the more general case , even if it can exhibits multiple fixed points and is not guaranteed to converge . In this paper , we express a new sufficient condition for local stability of a belief propagation fixed point in terms of the graph structure and the beliefs values at the fixed point . This gives credence to the usual understanding that Belief Propagation performs better on sparse graphs .
The Artificial Prediction Market is a recent machine learning technique for multi-class classification , inspired from the financial markets . It involves a number of trained market participants that bet on the possible outcomes and are rewarded if they predict correctly . This paper generalizes the scope of the Artificial Prediction Markets to regression , where there are uncountably many possible outcomes and the error is usually the MSE . For that , we introduce the reward kernel that rewards each participant based on its prediction error and we derive the price equations . Using two reward kernels we obtain two different learning rules , one of which is approximated using Hermite-Gauss quadrature . The market setting makes it easy to aggregate specialized regressors that only predict when an observation falls into their specialization domain . Experiments show that regression markets based on the two learning rules outperform Random Forest Regression on many UCI datasets and are rarely outperformed .
We propose a novel non-parametric adaptive anomaly detection algorithm for high dimensional data based on rank-SVM . Data points are first ranked based on scores derived from nearest neighbor graphs on n-point nominal data . We then train a rank-SVM using this ranked data . A test-point is declared as an anomaly at alpha-false alarm level if the predicted score is in the alpha-percentile . The resulting anomaly detector is shown to be asymptotically optimal and adaptive in that for any false alarm rate alpha , its decision region converges to the alpha-percentile level set of the unknown underlying density . In addition we illustrate through a number of synthetic and real-data experiments both the statistical performance and computational efficiency of our anomaly detector .
In this paper , we consider the Graphical Lasso ( GL ) , a popular optimization problem for learning the sparse representations of high-dimensional datasets , which is well-known to be computationally expensive for large-scale problems . Recently , we have shown that the sparsity pattern of the optimal solution of GL is equivalent to the one obtained from simply thresholding the sample covariance matrix , for sparse graphs under different conditions . We have also derived a closed-form solution that is optimal when the thresholded sample covariance matrix has an acyclic structure . As a major generalization of the previous result , in this paper we derive a closed-form solution for the GL for graphs with chordal structures . We show that the GL and thresholding equivalence conditions can significantly be simplified and are expected to hold for high-dimensional problems if the thresholded sample covariance matrix has a chordal structure . We then show that the GL and thresholding equivalence is enough to reduce the GL to a maximum determinant matrix completion problem and drive a recursive closed-form solution for the GL when the thresholded sample covariance matrix has a chordal structure . For large-scale problems with up to 000 million variables , the proposed method can solve the GL problem in less than 0 minutes , while the state-of-the-art methods converge in more than 0 hours .
Persistence diagrams are two-dimensional plots that summarize the topological features of functions and are an important part of topological data analysis . A problem that has received much attention is how deal with sets of persistence diagrams . How do we summarize them , average them or cluster them ? One approach -- the persistence intensity function -- was introduced informally by Edelsbrunner , Ivanov , and Karasev ( 0000 ) . Here we provide a modification and formalization of this approach . Using the persistence intensity function , we can visualize multiple diagrams , perform clustering and conduct two-sample tests .
We introduce an application of the group lasso to design of exper- iments . We show that the problem of constructing an optimal design matrix can be transformed into a problem of the group lasso . We also give a numerical example that we can obtain several orthogonal arrays as the solutions of the group lasso problems .
Most recommender systems recommend a list of items . The user examines the list , from the first item to the last , and often chooses the first attractive item and does not examine the rest . This type of user behavior can be modeled by the cascade model . In this work , we study cascading bandits , an online learning variant of the cascade model where the goal is to recommend $K$ most attractive items from a large set of $L$ candidate items . We propose two algorithms for solving this problem , which are based on the idea of linear generalization . The key idea in our solutions is that we learn a predictor of the attraction probabilities of items from their features , as opposing to learning the attraction probability of each item independently as in the existing work . This results in practical learning algorithms whose regret does not depend on the number of items $L$ . We bound the regret of one algorithm and comprehensively evaluate the other on a range of recommendation problems . The algorithm performs well and outperforms all baselines .
We propose a general formalism of iterated random functions with semigroup property , under which exact and approximate Bayesian posterior updates can be viewed as specific instances . A convergence theory for iterated random functions is presented . As an application of the general theory we analyze convergence behaviors of exact and approximate message-passing algorithms that arise in a sequential change point detection problem formulated via a latent variable directed graphical model . The sequential inference algorithm and its supporting theory are illustrated by simulated examples .
We describe a method for parameter estimation in bipartite probabilistic graphical models for joint prediction of clinical conditions from the electronic medical record . The method does not rely on the availability of gold-standard labels , but rather uses noisy labels , called anchors , for learning . We provide a likelihood-based objective and a moments-based initialization that are effective at learning the model parameters . The learned model is evaluated in a task of assigning a heldout clinical condition to patients based on retrospective analysis of the records , and outperforms baselines which do not account for the noisiness in the labels or do not model the conditions jointly .
This paper presents an approach for automation of interpretable feature selection for Internet Of Things Analytics ( IoTA ) using machine learning ( ML ) techniques . Authors have conducted a survey over different people involved in different IoTA based application development tasks . The survey reveals that feature selection is the most time consuming and niche skill demanding part of the entire workflow . This paper shows how feature selection is successfully automated without sacrificing the decision making accuracy and thereby reducing the project completion time and cost of hiring expensive resources . Several pattern recognition principles and state of art ( SoA ) ML techniques are followed to design the overall approach for the proposed automation . Three data sets are considered to establish the proof-of-concept . Experimental results show that the proposed automation is able to reduce the time for feature selection to $0$ days instead of $0-0$ months which would have been required in absence of the automation . This reduction in time is achieved without any sacrifice in the accuracy of the decision making process . Proposed method is also compared against Multi Layer Perceptron ( MLP ) model as most of the state of the art works on IoTA uses MLP based Deep Learning . Moreover the feature selection method is compared against SoA feature reduction technique namely Principal Component Analysis ( PCA ) and its variants . The results obtained show that the proposed method is effective .
In many settings , it is important that a model be capable of providing reasons for its predictions ( i . e . , the model must be interpretable ) . However , the model ' s reasoning may not conform with well-established knowledge . In such cases , while interpretable , the model lacks \textit{credibility} . In this work , we formally define credibility in the linear setting and focus on techniques for learning models that are both accurate and credible . In particular , we propose a regularization penalty , expert yielded estimates ( EYE ) , that incorporates expert knowledge about well-known relationships among covariates and the outcome of interest . We give both theoretical and empirical results comparing our proposed method to several other regularization techniques . Across a range of settings , experiments on both synthetic and real data show that models learned using the EYE penalty are significantly more credible than those learned using other penalties . Applied to a large-scale patient risk stratification task , our proposed technique results in a model whose top features overlap significantly with known clinical risk factors , while still achieving good predictive performance .
The problem of optimizing unknown costly-to-evaluate functions has been studied for a long time in the context of Bayesian Optimization . Algorithms in this field aim to find the optimizer of the function by asking only a few function evaluations at locations carefully selected based on a posterior model . In this paper , we assume the unknown function is Lipschitz continuous . Leveraging the Lipschitz property , we propose an algorithm with a distinct exploration phase followed by an exploitation phase . The exploration phase aims to select samples that shrink the search space as much as possible . The exploitation phase then focuses on the reduced search space and selects samples closest to the optimizer . Considering the Expected Improvement ( EI ) as a baseline , we empirically show that the proposed algorithm significantly outperforms EI .
A variety of real-world tasks involve the classification of images into pre-determined categories . Designing image classification algorithms that exhibit robustness to acquisition noise and image distortions , particularly when the available training data are insufficient to learn accurate models , is a significant challenge . This dissertation explores the development of discriminative models for robust image classification that exploit underlying signal structure , via probabilistic graphical models and sparse signal representations . Probabilistic graphical models are widely used in many applications to approximate high-dimensional data in a reduced complexity set-up . Learning graphical structures to approximate probability distributions is an area of active research . Recent work has focused on learning graphs in a discriminative manner with the goal of minimizing classification error . In the first part of the dissertation , we develop a discriminative learning framework that exploits the complementary yet correlated information offered by multiple representations ( or projections ) of a given signal/image . Specifically , we propose a discriminative tree-based scheme for feature fusion by explicitly learning the conditional correlations among such multiple projections in an iterative manner . Experiments reveal the robustness of the resulting graphical model classifier to training insufficiency .
We propose a new approach to inverse reinforcement learning ( IRL ) based on the deep Gaussian process ( deep GP ) model , which is capable of learning complicated reward structures with few demonstrations . Our model stacks multiple latent GP layers to learn abstract representations of the state feature space , which is linked to the demonstrations through the Maximum Entropy learning framework . Incorporating the IRL engine into the nonlinear latent structure renders existing deep GP inference approaches intractable . To tackle this , we develop a non-standard variational approximation framework which extends previous inference schemes . This allows for approximate Bayesian treatment of the feature space and guards against overfitting . Carrying out representation and inverse reinforcement learning simultaneously within our model outperforms state-of-the-art approaches , as we demonstrate with experiments on standard benchmarks ( " object world " , " highway driving " ) and a new benchmark ( " binary world " ) .
Genome-wide association studies have proven to be essential for understanding the genetic basis of disease . However , many complex traits---personality traits , facial features , disease subtyping---are inherently high-dimensional , impeding simple approaches to association mapping . We developed a nonparametric Bayesian reduced rank regression model for multi-SNP , multi-trait association mapping that does not require the rank of the linear subspace to be specified . We show in simulations and real data that our model shares strength over SNPs and over correlated traits , improving statistical power to identify genetic associations with an interpretable , SNP-supervised low-dimensional linear projection of the high-dimensional phenotype . On the HapMap phase 0 gene expression QTL study data , we identify pleiotropic expression QTLs that classical univariate tests are underpowered to find and that two step approaches cannot recover . Our Python software , BERRRI , is publicly available at GitHub : https : //github . com/ashlee0000/BERRRI .
Fragmentation methods such as the many-body expansion ( MBE ) are a common strategy to model large systems by partitioning energies into a hierarchy of decreasingly significant contributions . The number of fragments required for chemical accuracy is still prohibitively expensive for ab-initio MBE to compete with force field approximations for applications beyond single-point energies . Alongside the MBE , empirical models of ab-initio potential energy surfaces have improved , especially non-linear models based on neural networks ( NN ) which can reproduce ab-initio potential energy surfaces rapidly and accurately . Although they are fast , NNs suffer from their own curse of dimensionality ; they must be trained on a representative sample of chemical space . In this paper we examine the synergy of the MBE and NN ' s , and explore their complementarity . The MBE offers a systematic way to treat systems of arbitrary size and intelligently sample chemical space . NN ' s reduce , by a factor in excess of $00^0$ the computational overhead of the MBE and reproduce the accuracy of ab-initio calculations without specialized force fields . We show they are remarkably general , providing comparable accuracy with drastically different chemical embeddings . To assess this we test a new chemical embedding which can be inverted to predict molecules with desired properties .
We are interested in solving the multiple measurement vector ( MMV ) problem for instances , where the underlying sparsity pattern exhibit spatio-temporal structure motivated by the electroencephalogram ( EEG ) source localization problem . We propose a probabilistic model that takes this structure into account by generalizing the structured spike and slab prior and the associated Expectation Propagation inference scheme . Based on numerical experiments , we demonstrate the viability of the model and the approximate inference scheme .
Experience replay is a key technique behind many recent advances in deep reinforcement learning . Allowing the agent to learn from earlier memories can speed up learning and break undesirable temporal correlations . Despite its wide-spread application , very little is understood about the properties of experience replay . How does the amount of memory kept affect learning dynamics ? Does it help to prioritize certain experiences ? In this paper , we address these questions by formulating a dynamical systems ODE model of Q-learning with experience replay . We derive analytic solutions of the ODE for a simple setting . We show that even in this very simple setting , the amount of memory kept can substantially affect the agent ' s performance . Too much or too little memory both slow down learning . Moreover , we characterize regimes where prioritized replay harms the agent ' s learning . We show that our analytic solutions have excellent agreement with experiments . Finally , we propose a simple algorithm for adaptively changing the memory buffer size which achieves consistently good empirical performance .
The group lasso is a penalized regression method , used in regression problems where the covariates are partitioned into groups to promote sparsity at the group level . Existing methods for finding the group lasso estimator either use gradient projection methods to update the entire coefficient vector simultaneously at each step , or update one group of coefficients at a time using an inexact line search to approximate the optimal value for the group of coefficients when all other groups ' coefficients are fixed . We present a new method of computation for the group lasso in the linear regression case , the Single Line Search ( SLS ) algorithm , which operates by computing the exact optimal value for each group ( when all other coefficients are fixed ) with one univariate line search . We perform simulations demonstrating that the SLS algorithm is often more efficient than existing computational methods . We also extend the SLS algorithm to the sparse group lasso problem via the Signed Single Line Search ( SSLS ) algorithm , and give theoretical results to support both algorithms .
This paper considers the problem of decentralized optimization with a composite objective containing smooth and non-smooth terms . To solve the problem , a proximal-gradient scheme is studied . Specifically , the smooth and nonsmooth terms are dealt with by gradient update and proximal update , respectively . The studied algorithm is closely related to a previous decentralized optimization algorithm , PG-EXTRA [00] , but has a few advantages . First of all , in our new scheme , agents use uncoordinated step-sizes and the stable upper bounds on step-sizes are independent from network topology . The step-sizes depend on local objective functions , and they can be as large as that of the gradient descent . Secondly , for the special case without non-smooth terms , linear convergence can be achieved under the strong convexity assumption . The dependence of the convergence rate on the objective functions and the network are separated , and the convergence rate of our new scheme is as good as one of the two convergence rates that match the typical rates for the general gradient descent and the consensus averaging . We also provide some numerical experiments to demonstrate the efficacy of the introduced algorithms and validate our theoretical discoveries .
The interplay between computational efficiency and statistical accuracy in high-dimensional inference has drawn increasing attention in the literature . In this paper , we study computational and statistical boundaries for submatrix localization . Given one observation of ( one or multiple non-overlapping ) signal submatrix ( of magnitude $\lambda$ and size $k_m \times k_n$ ) contaminated with a noise matrix ( of size $m \times n$ ) , we establish two transition thresholds for the signal to noise $\lambda/\sigma$ ratio in terms of $m$ , $n$ , $k_m$ , and $k_n$ . The first threshold , $\sf SNR_c$ , corresponds to the computational boundary . Below this threshold , it is shown that no polynomial time algorithm can succeed in identifying the submatrix , under the \textit{hidden clique hypothesis} . We introduce adaptive linear time spectral algorithms that identify the submatrix with high probability when the signal strength is above the threshold $\sf SNR_c$ . The second threshold , $\sf SNR_s$ , captures the statistical boundary , below which no method can succeed with probability going to one in the minimax sense . The exhaustive search method successfully finds the submatrix above this threshold . The results show an interesting phenomenon that $\sf SNR_c$ is always significantly larger than $\sf SNR_s$ , which implies an essential gap between statistical optimality and computational efficiency for submatrix localization .
Sampling from distributions to find the one with the largest mean arises in a broad range of applications , and it can be mathematically modeled as a multi-armed bandit problem in which each distribution is associated with an arm . This paper studies the sample complexity of identifying the best arm ( largest mean ) in a multi-armed bandit problem . Motivated by large-scale applications , we are especially interested in identifying situations where the total number of samples that are necessary and sufficient to find the best arm scale linearly with the number of arms . We present a single-parameter multi-armed bandit model that spans the range from linear to superlinear sample complexity . We also give a new algorithm for best arm identification , called PRISM , with linear sample complexity for a wide range of mean distributions . The algorithm , like most exploration procedures for multi-armed bandits , is adaptive in the sense that the next arms to sample are selected based on previous samples . We compare the sample complexity of adaptive procedures with simpler non-adaptive procedures using new lower bounds . For many problem instances , the increased sample complexity required by non-adaptive procedures is a polynomial factor of the number of arms .
The classical approach to linear system identification is given by parametric Prediction Error Methods ( PEM ) . In this context , model complexity is often unknown so that a model order selection step is needed to suitably trade-off bias and variance . Recently , a different approach to linear system identification has been introduced , where model order determination is avoided by using a regularized least squares framework . In particular , the penalty term on the impulse response is defined by so called stable spline kernels . They embed information on regularity and BIBO stability , and depend on a small number of parameters which can be estimated from data . In this paper , we provide new nonsmooth formulations of the stable spline estimator . In particular , we consider linear system identification problems in a very broad context , where regularization functionals and data misfits can come from a rich set of piecewise linear quadratic functions . Moreover , our anal- ysis includes polyhedral inequality constraints on the unknown impulse response . For any formulation in this class , we show that interior point methods can be used to solve the system identification problem , with complexity O ( n0 ) +O ( mn0 ) in each iteration , where n and m are the number of impulse response coefficients and measurements , respectively . The usefulness of the framework is illustrated via a numerical experiment where output measurements are contaminated by outliers .
After building a classifier with modern tools of machine learning we typically have a black box at hand that is able to predict well for unseen data . Thus , we get an answer to the question what is the most likely label of a given unseen data point . However , most methods will provide no answer why the model predicted the particular label for a single instance and what features were most influential for that particular instance . The only method that is currently able to provide such explanations are decision trees . This paper proposes a procedure which ( based on a set of assumptions ) allows to explain the decisions of any classification method .
Recurrent neural networks ( RNNs ) have been used extensively and with increasing success to model various types of sequential data . Much of this progress has been achieved through devising recurrent units and architectures with the flexibility to capture complex statistics in the data , such as long range dependency or localized attention phenomena . However , while many sequential data ( such as video , speech or language ) can have highly variable information flow , most recurrent models still consume input features at a constant rate and perform a constant number of computations per time step , which can be detrimental to both speed and model capacity . In this paper , we explore a modification to existing recurrent units which allows them to learn to vary the amount of computation they perform at each step , without prior knowledge of the sequence ' s time structure . We show experimentally that not only do our models require fewer operations , they also lead to better performance overall on evaluation tasks .
We consider the problem of minimizing a sum of $n$ functions over a convex parameter set $\mathcal{C} \subset \mathbb{R}^p$ where $n\gg p\gg 0$ . In this regime , algorithms which utilize sub-sampling techniques are known to be effective . In this paper , we use sub-sampling techniques together with low-rank approximation to design a new randomized batch algorithm which possesses comparable convergence rate to Newton ' s method , yet has much smaller per-iteration cost . The proposed algorithm is robust in terms of starting point and step size , and enjoys a composite convergence rate , namely , quadratic convergence at start and linear convergence when the iterate is close to the minimizer . We develop its theoretical analysis which also allows us to select near-optimal algorithm parameters . Our theoretical results can be used to obtain convergence rates of previously proposed sub-sampling based algorithms as well . We demonstrate how our results apply to well-known machine learning problems . Lastly , we evaluate the performance of our algorithm on several datasets under various scenarios .
In this paper we study general $l_p$ regularized unconstrained minimization problems . In particular , we derive lower bounds for nonzero entries of first- and second-order stationary points , and hence also of local minimizers of the $l_p$ minimization problems . We extend some existing iterative reweighted $l_0$ ( IRL0 ) and $l_0$ ( IRL0 ) minimization methods to solve these problems and proposed new variants for them in which each subproblem has a closed form solution . Also , we provide a unified convergence analysis for these methods . In addition , we propose a novel Lipschitz continuous $\epsilon$-approximation to $\|x\|^p_p$ . Using this result , we develop new IRL0 methods for the $l_p$ minimization problems and showed that any accumulation point of the sequence generated by these methods is a first-order stationary point , provided that the approximation parameter $\epsilon$ is below a computable threshold value . This is a remarkable result since all existing iterative reweighted minimization methods require that $\epsilon$ be dynamically updated and approach zero . Our computational results demonstrate that the new IRL0 method is generally more stable than the existing IRL0 methods [00 , 00] in terms of objective function value and CPU time .
Probabilistic modeling is iterative . A scientist posits a simple model , fits it to her data , refines it according to her analysis , and repeats . However , fitting complex models to large data is a bottleneck in this process . Deriving algorithms for new models can be both mathematically and computationally challenging , which makes it difficult to efficiently cycle through the steps . To this end , we develop automatic differentiation variational inference ( ADVI ) . Using our method , the scientist only provides a probabilistic model and a dataset , nothing else . ADVI automatically derives an efficient variational inference algorithm , freeing the scientist to refine and explore many models . ADVI supports a broad class of models-no conjugacy assumptions are required . We study ADVI across ten different models and apply it to a dataset with millions of observations . ADVI is integrated into Stan , a probabilistic programming system ; it is available for immediate use .
Incorporating spatial information into hyperspectral unmixing procedures has been shown to have positive effects , due to the inherent spatial-spectral duality in hyperspectral scenes . Current research works that consider spatial information are mainly focused on the linear mixing model . In this paper , we investigate a variational approach to incorporating spatial correlation into a nonlinear unmixing procedure . A nonlinear algorithm operating in reproducing kernel Hilbert spaces , associated with an $\ell_0$ local variation norm as the spatial regularizer , is derived . Experimental results , with both synthetic and real data , illustrate the effectiveness of the proposed scheme .
With widespread adoption of electronic health records , there is an increased emphasis for predictive models that can effectively deal with clinical time-series data . Powered by Recurrent Neural Network ( RNN ) architectures with Long Short-Term Memory ( LSTM ) units , deep neural networks have achieved state-of-the-art results in several clinical prediction tasks . Despite the success of RNNs , its sequential nature prohibits parallelized computing , thus making it inefficient particularly when processing long sequences . Recently , architectures which are based solely on attention mechanisms have shown remarkable success in transduction tasks in NLP , while being computationally superior . In this paper , for the first time , we utilize attention models for clinical time-series modeling , thereby dispensing recurrence entirely . We develop the \textit{SAnD} ( Simply Attend and Diagnose ) architecture , which employs a masked , self-attention mechanism , and uses positional encoding and dense interpolation strategies for incorporating temporal order . Furthermore , we develop a multi-task variant of \textit{SAnD} to jointly infer models with multiple diagnosis tasks . Using the recent MIMIC-III benchmark datasets , we demonstrate that the proposed approach achieves state-of-the-art performance in all tasks , outperforming LSTM models and classical baselines with hand-engineered features .
We consider classification tasks in the regime of scarce labeled training data in high dimensional feature space , where specific expert knowledge is also available . We propose a new hybrid optimization algorithm that solves the elastic-net support vector machine ( SVM ) through an alternating direction method of multipliers in the first phase , followed by an interior-point method for the classical SVM in the second phase . Both SVM formulations are adapted to knowledge incorporation . Our proposed algorithm addresses the challenges of automatic feature selection , high optimization accuracy , and algorithmic flexibility for taking advantage of prior knowledge . We demonstrate the effectiveness and efficiency of our algorithm and compare it with existing methods on a collection of synthetic and real-world data .
The last decade has seen a surge of interest in adaptive learning algorithms for data stream classification , with applications ranging from predicting ozone level peaks , learning stock market indicators , to detecting computer security violations . In addition , a number of methods have been developed to detect concept drifts in these streams . Consider a scenario where we have a number of classifiers with diverse learning styles and different drift detectors . Intuitively , the current ' best ' ( classifier , detector ) pair is application dependent and may change as a result of the stream evolution . Our research builds on this observation . We introduce the $\mbox{Tornado}$ framework that implements a reservoir of diverse classifiers , together with a variety of drift detection algorithms . In our framework , all ( classifier , detector ) pairs proceed , in parallel , to construct models against the evolving data streams . At any point in time , we select the pair which currently yields the best performance . We further incorporate two novel stacking-based drift detection methods , namely the $\mbox{FHDDMS}$ and $\mbox{FHDDMS}_{add}$ approaches . The experimental evaluation confirms that the current ' best ' ( classifier , detector ) pair is not only heavily dependent on the characteristics of the stream , but also that this selection evolves as the stream flows . Further , our $\mbox{FHDDMS}$ variants detect concept drifts accurately in a timely fashion while outperforming the state-of-the-art .
Multi-task learning ( MTL ) has recently contributed to learning better representations in service of various NLP tasks . MTL aims at improving the performance of a primary task , by jointly training on a secondary task . This paper introduces automated tasks , which exploit the sequential nature of the input data , as secondary tasks in an MTL model . We explore next word prediction , next character prediction , and missing word completion as potential automated tasks . Our results show that training on a primary task in parallel with a secondary automated task improves both the convergence speed and accuracy for the primary task . We suggest two methods for augmenting an existing network with automated tasks and establish better performance in topic prediction , sentiment analysis , and hashtag recommendation . Finally , we show that the MTL models can perform well on datasets that are small and colloquial by nature .
Modeling structure in complex networks using Bayesian non-parametrics makes it possible to specify flexible model structures and infer the adequate model complexity from the observed data . This paper provides a gentle introduction to non-parametric Bayesian modeling of complex networks : Using an infinite mixture model as running example we go through the steps of deriving the model as an infinite limit of a finite parametric model , inferring the model parameters by Markov chain Monte Carlo , and checking the model ' s fit and predictive performance . We explain how advanced non-parametric models for complex networks can be derived and point out relevant literature .
Cyber-physical systems , such as mobile robots , must respond adaptively to dynamic operating conditions . Effective operation of these systems requires that sensing and actuation tasks are performed in a timely manner . Additionally , execution of mission specific tasks such as imaging a room must be balanced against the need to perform more general tasks such as obstacle avoidance . This problem has been addressed by maintaining relative utilization of shared resources among tasks near a user-specified target level . Producing optimal scheduling strategies requires complete prior knowledge of task behavior , which is unlikely to be available in practice . Instead , suitable scheduling strategies must be learned online through interaction with the system . We consider the sample complexity of reinforcement learning in this domain , and demonstrate that while the problem state space is countably infinite , we may leverage the problem ' s structure to guarantee efficient learning .
The most important aspect of any classifier is its error rate , because this quantifies its predictive capacity . Thus , the accuracy of error estimation is critical . Error estimation is problematic in small-sample classifier design because the error must be estimated using the same data from which the classifier has been designed . Use of prior knowledge , in the form of a prior distribution on an uncertainty class of feature-label distributions to which the true , but unknown , feature-distribution belongs , can facilitate accurate error estimation ( in the mean-square sense ) in circumstances where accurate completely model-free error estimation is impossible . This paper provides analytic asymptotically exact finite-sample approximations for various performance metrics of the resulting Bayesian Minimum Mean-Square-Error ( MMSE ) error estimator in the case of linear discriminant analysis ( LDA ) in the multivariate Gaussian model . These performance metrics include the first , second , and cross moments of the Bayesian MMSE error estimator with the true error of LDA , and therefore , the Root-Mean-Square ( RMS ) error of the estimator . We lay down the theoretical groundwork for Kolmogorov double-asymptotics in a Bayesian setting , which enables us to derive asymptotic expressions of the desired performance metrics . From these we produce analytic finite-sample approximations and demonstrate their accuracy via numerical examples . Various examples illustrate the behavior of these approximations and their use in determining the necessary sample size to achieve a desired RMS . The Supplementary Material contains derivations for some equations and added figures .
Gaussian processes are typically used for smoothing and interpolation on small datasets . We introduce a new Bayesian nonparametric framework -- GPatt -- enabling automatic pattern extrapolation with Gaussian processes on large multidimensional datasets . GPatt unifies and extends highly expressive kernels and fast exact inference techniques . Without human intervention -- no hand crafting of kernel features , and no sophisticated initialisation procedures -- we show that GPatt can solve large scale pattern extrapolation , inpainting , and kernel discovery problems , including a problem with 000000 training points . We find that GPatt significantly outperforms popular alternative scalable Gaussian process methods in speed and accuracy . Moreover , we discover profound differences between each of these methods , suggesting expressive kernels , nonparametric representations , and exact inference are useful for modelling large scale multidimensional patterns .
Discussion of " Latent variable graphical model selection via convex optimization " by Venkat Chandrasekaran , Pablo A . Parrilo and Alan S . Willsky [arXiv : 0000 . 0000] .
Wireless sensor networks usually comprise a large number of sensors monitoring changes in variables . These changes in variables represent changes in physical quantities . The changes can occur for various reasons ; these reasons are highlighted in this work . Outliers are unusual measurements . Outliers are important ; they are information-bearing occurrences . This work seeks to identify them based on an approach presented in [0] . A critical review of most previous works in this area has been presented in [0] , and few more are considered here just to set the stage . The main work can be described as this ; given a set of measurements from sensors that represent a normal situation , [0] proceeds by first estimating the probability density function ( pdf ) of the set using a data-split approach , then estimate the entropy of the set using the arithmetic mean as an approximation for the expectation . The increase in entropy that occurs when strange data is recorded is used to detect unusual measurements in the test set depending on the desired confidence interval or false alarm rate . The results presented in [0] have been confirmed for different test signals such as the Gaussian , Beta , in one dimension and beta in two dimensions , and a beta and uniform mixture distribution in two dimensions . Finally , the method was confirmed on real data and the results are presented . The major drawbacks of [0] were identified , and a method that seeks to mitigate this using the Bhattacharyya distance is presented . This method detects more subtle anomalies , especially the type that would pass as normal in [0] . Finally , recommendations for future research are presented : the subject of interpretability , especially for subtle measurements , being the most elusive as of today .
COCO is a platform for Comparing Continuous Optimizers in a black-box setting . It aims at automatizing the tedious and repetitive task of benchmarking numerical optimization algorithms to the greatest possible extent . We present the rationals behind the development of the platform as a general proposition for a guideline towards better benchmarking . We detail underlying fundamental concepts of COCO such as its definition of a problem , the idea of instances , the relevance of target values , and runtime as central performance measure . Finally , we give a quick overview of the basic code structure and the available test suites .
We present SDA-Bayes , a framework for ( S ) treaming , ( D ) istributed , ( A ) synchronous computation of a Bayesian posterior . The framework makes streaming updates to the estimated posterior according to a user-specified approximation batch primitive . We demonstrate the usefulness of our framework , with variational Bayes ( VB ) as the primitive , by fitting the latent Dirichlet allocation model to two large-scale document collections . We demonstrate the advantages of our algorithm over stochastic variational inference ( SVI ) by comparing the two after a single pass through a known amount of data---a case where SVI may be applied---and in the streaming setting , where SVI does not apply .
A nonparametric kernel-based method for realizing Bayes ' rule is proposed , based on representations of probabilities in reproducing kernel Hilbert spaces . Probabilities are uniquely characterized by the mean of the canonical map to the RKHS . The prior and conditional probabilities are expressed in terms of RKHS functions of an empirical sample : no explicit parametric model is needed for these quantities . The posterior is likewise an RKHS mean of a weighted sample . The estimator for the expectation of a function of the posterior is derived , and rates of consistency are shown . Some representative applications of the kernel Bayes ' rule are presented , including Baysian computation without likelihood and filtering with a nonparametric state-space model .
This manuscript studies statistical properties of linear classifiers obtained through minimization of an unregularized convex risk over a finite sample . Although the results are explicitly finite-dimensional , inputs may be passed through feature maps ; in this way , in addition to treating the consistency of logistic regression , this analysis also handles boosting over a finite weak learning class with , for instance , the exponential , logistic , and hinge losses . In this finite-dimensional setting , it is still possible to fit arbitrary decision boundaries : scaling the complexity of the weak learning class with the sample size leads to the optimal classification risk almost surely .
Approximate dynamic programming ( ADP ) has proven itself in a wide range of applications spanning large-scale transportation problems , health care , revenue management , and energy systems . The design of effective ADP algorithms has many dimensions , but one crucial factor is the stepsize rule used to update a value function approximation . Many operations research applications are computationally intensive , and it is important to obtain good results quickly . Furthermore , the most popular stepsize formulas use tunable parameters and can produce very poor results if tuned improperly . We derive a new stepsize rule that optimizes the prediction error in order to improve the short-term performance of an ADP algorithm . With only one , relatively insensitive tunable parameter , the new rule adapts to the level of noise in the problem and produces faster convergence in numerical experiments .
We study large-scale kernel methods for acoustic modeling and compare to DNNs on performance metrics related to both acoustic modeling and recognition . Measuring perplexity and frame-level classification accuracy , kernel-based acoustic models are as effective as their DNN counterparts . However , on token-error-rates DNN models can be significantly better . We have discovered that this might be attributed to DNN ' s unique strength in reducing both the perplexity and the entropy of the predicted posterior probabilities . Motivated by our findings , we propose a new technique , entropy regularized perplexity , for model selection . This technique can noticeably improve the recognition performance of both types of models , and reduces the gap between them . While effective on Broadcast News , this technique could be also applicable to other tasks .
This paper proposes a web-based visual graph analytics platform for interactive graph mining , visualization , and real-time exploration of networks . GraphVis is fast , intuitive , and flexible , combining interactive visualizations with analytic techniques to reveal important patterns and insights for sense making , reasoning , and decision making . Networks can be visualized and explored within seconds by simply drag-and-dropping a graph file into the web browser . The structure , properties , and patterns of the network are computed automatically and can be instantly explored in real-time . At the heart of GraphVis lies a multi-level interactive network visualization and analytics engine that allows for real-time graph mining and exploration across multiple levels of granularity simultaneously . Both the graph analytic and visualization techniques ( at each level of granularity ) are dynamic and interactive , with immediate and continuous visual feedback upon every user interaction ( e . g . , change of a slider for filtering ) . Furthermore , nodes , edges , and subgraphs are easily inserted , deleted or exported via a number of novel techniques and tools that make it extremely easy and flexible for exploring , testing hypothesis , and understanding networks in real-time over the web . A number of interactive visual graph analytic techniques are also proposed including interactive role discovery methods , community detection , as well as a number of novel block models for generating graphs with community structure . Finally , we also highlight other key aspects including filtering , querying , ranking , manipulating , exporting , partitioning , as well as tools for dynamic network analysis and visualization , interactive graph generators , and a variety of multi-level network analysis , summarization , and statistical techniques .
Marginalising out uncertain quantities within the internal representations or parameters of neural networks is of central importance for a wide range of learning techniques , such as empirical , variational or full Bayesian methods . We set out to generalise fast dropout ( Wang & Manning , 0000 ) to cover a wider variety of noise processes in neural networks . This leads to an efficient calculation of the marginal likelihood and predictive distribution which evades sampling and the consequential increase in training time due to highly variant gradient estimates . This allows us to approximate variational Bayes for the parameters of feed-forward neural networks . Inspired by the minimum description length principle , we also propose and experimentally verify the direct optimisation of the regularised predictive distribution . The methods yield results competitive with previous neural network based approaches and Gaussian processes on a wide range of regression tasks .
While most Bayesian nonparametric models in machine learning have focused on the Dirichlet process , the beta process , or their variants , the gamma process has recently emerged as a useful nonparametric prior in its own right . Current inference schemes for models involving the gamma process are restricted to MCMC-based methods , which limits their scalability . In this paper , we present a variational inference framework for models involving gamma process priors . Our approach is based on a novel stick-breaking constructive definition of the gamma process . We prove correctness of this stick-breaking process by using the characterization of the gamma process as a completely random measure ( CRM ) , and we explicitly derive the rate measure of our construction using Poisson process machinery . We also derive error bounds on the truncation of the infinite process required for variational inference , similar to the truncation analyses for other nonparametric models based on the Dirichlet and beta processes . Our representation is then used to derive a variational inference algorithm for a particular Bayesian nonparametric latent structure formulation known as the infinite Gamma-Poisson model , where the latent variables are drawn from a gamma process prior with Poisson likelihoods . Finally , we present results for our algorithms on nonnegative matrix factorization tasks on document corpora , and show that we compare favorably to both sampling-based techniques and variational approaches based on beta-Bernoulli priors .
Given a matrix the seriation problem consists in permuting its rows in such way that all its columns have the same shape , for example , they are monotone increasing . We propose a statistical approach to this problem where the matrix of interest is observed with noise and study the corresponding minimax rate of estimation of the matrices . Specifically , when the columns are either unimodal or monotone , we show that the least squares estimator is optimal up to logarithmic factors and adapts to matrices with a certain natural structure . Finally , we propose a computationally efficient estimator in the monotonic case and study its performance both theoretically and experimentally . Our work is at the intersection of shape constrained estimation and recent work that involves permutation learning , such as graph denoising and ranking .
We use statistical learning methods to construct an adaptive state estimator for nonlinear stochastic systems . Optimal state estimation , in the form of a Kalman filter , requires knowledge of the system ' s process and measurement uncertainty . We propose that these uncertainties can be estimated from ( conditioned on ) past observed data , and without making any assumptions of the system ' s prior distribution . The system ' s prior distribution at each time step is constructed from an ensemble of least-squares estimates on sub-sampled sets of the data via jackknife sampling . As new data is acquired , the state estimates , process uncertainty , and measurement uncertainty are updated accordingly , as described in this manuscript .
The Schatten quasi-norm can be used to bridge the gap between the nuclear norm and rank function , and is the tighter approximation to matrix rank . However , most existing Schatten quasi-norm minimization ( SQNM ) algorithms , as well as for nuclear norm minimization , are too slow or even impractical for large-scale problems , due to the SVD or EVD of the whole matrix in each iteration . In this paper , we rigorously prove that for any p , p0 , p0>0 satisfying 0/p=0/p0+0/p0 , the Schatten-p quasi-norm of any matrix is equivalent to minimizing the product of the Schatten-p0 norm ( or quasi-norm ) and Schatten-p0 norm ( or quasi-norm ) of its two factor matrices . Then we present and prove the equivalence relationship between the product formula of the Schatten quasi-norm and its weighted sum formula for the two cases of p0 and p0 : p0=p0 and p0\neq p0 . In particular , when p>0/0 , there is an equivalence between the Schatten-p quasi-norm of any matrix and the Schatten-0p norms of its two factor matrices , where the widely used equivalent formulation of the nuclear norm can be viewed as a special case . That is , various SQNM problems with p>0/0 can be transformed into the one only involving smooth , convex norms of two factor matrices , which can lead to simpler and more efficient algorithms than conventional methods . We further extend the theoretical results of two factor matrices to the cases of three and more factor matrices , from which we can see that for any 0<p<0 , the Schatten-p quasi-norm of any matrix is the minimization of the mean of the Schatten- ( p0+0 ) p norms of all factor matrices , where p0 denotes the largest integer not exceeding 0/p . In other words , for any 0<p<0 , the SQNM problem can be transformed into an optimization problem only involving the smooth , convex norms of multiple factor matrices .
Error backpropagation is a highly effective mechanism for learning high-quality hierarchical features in deep networks . Updating the features or weights in one layer , however , requires waiting for the propagation of error signals from higher layers . Learning using delayed and non-local errors makes it hard to reconcile backpropagation with the learning mechanisms observed in biological neural networks as it requires the neurons to maintain a memory of the input long enough until the higher-layer errors arrive . In this paper , we propose an alternative learning mechanism where errors are generated locally in each layer using fixed , random auxiliary classifiers . Lower layers could thus be trained independently of higher layers and training could either proceed layer by layer , or simultaneously in all layers using local error information . We address biological plausibility concerns such as weight symmetry requirements and show that the proposed learning mechanism based on fixed , broad , and random tuning of each neuron to the classification categories outperforms the biologically-motivated feedback alignment learning technique on the MNIST , CIFAR00 , and SVHN datasets , approaching the performance of standard backpropagation . Our approach highlights a potential biological mechanism for the supervised , or task-dependent , learning of feature hierarchies . In addition , we show that it is well suited for learning deep networks in custom hardware where it can drastically reduce memory traffic and data communication overheads .
We propose a general approach for supervised learning with structured output spaces , such as combinatorial and polyhedral sets , that is based on minimizing estimated conditional risk functions . Given a loss function defined over pairs of output labels , we first estimate the conditional risk function by solving a ( possibly infinite ) collection of regularized least squares problems . A prediction is made by solving an inference problem that minimizes the estimated conditional risk function over the output space . We show that this approach enables , in some cases , efficient training and inference without explicitly introducing a convex surrogate for the original loss function , even when it is discontinuous . Empirical evaluations on real-world and synthetic data sets demonstrate the effectiveness of our method in adapting to a variety of loss functions .
This paper proposes a set of new error criteria and learning approaches , Adaptive Normalized Risk-Averting Training ( ANRAT ) , to attack the non-convex optimization problem in training deep neural networks ( DNNs ) . Theoretically , we demonstrate its effectiveness on global and local convexity lower-bounded by the standard $L_p$-norm error . By analyzing the gradient on the convexity index $\lambda$ , we explain the reason why to learn $\lambda$ adaptively using gradient descent works . In practice , we show how this method improves training of deep neural networks to solve visual recognition tasks on the MNIST and CIFAR-00 datasets . Without using pretraining or other tricks , we obtain results comparable or superior to those reported in recent literature on the same tasks using standard ConvNets + MSE/cross entropy . Performance on deep/shallow multilayer perceptrons and Denoised Auto-encoders is also explored . ANRAT can be combined with other quasi-Newton training methods , innovative network variants , regularization techniques and other specific tricks in DNNs . Other than unsupervised pretraining , it provides a new perspective to address the non-convex optimization problem in DNNs .
We study the problem of using i . i . d . samples from an unknown multivariate probability distribution $p$ to estimate the mutual information of $p$ . This problem has recently received attention in two settings : ( 0 ) where $p$ is assumed to be Gaussian and ( 0 ) where $p$ is assumed only to lie in a large nonparametric smoothness class . Estimators proposed for the Gaussian case converge in high dimensions when the Gaussian assumption holds , but are brittle , failing dramatically when $p$ is not Gaussian . Estimators proposed for the nonparametric case fail to converge with realistic sample sizes except in very low dimensions . As a result , there is a lack of robust mutual information estimators for many realistic data . To address this , we propose estimators for mutual information when $p$ is assumed to be a nonparanormal ( a . k . a . , Gaussian copula ) model , a semiparametric compromise between Gaussian and nonparametric extremes . Using theoretical bounds and experiments , we show these estimators strike a practical balance between robustness and scaling with dimensionality .
In this article , we derive concentration inequalities for the cross-validation estimate of the generalization error for subagged estimators , both for classification and regressor . General loss functions and class of predictors with both finite and infinite VC-dimension are considered . We slightly generalize the formalism introduced by \cite{DUD00} to cover a large variety of cross-validation procedures including leave-one-out cross-validation , $k$-fold cross-validation , hold-out cross-validation ( or split sample ) , and the leave-$\upsilon$-out cross-validation . \bigskip \noindent An interesting consequence is that the probability upper bound is bounded by the minimum of a Hoeffding-type bound and a Vapnik-type bounds , and thus is smaller than 0 even for small learning set . Finally , we give a simple rule on how to subbag the predictor . \bigskip
To ensure interpretability of extracted sources in tensor decomposition , we introduce in this paper a dictionary-based tensor canonical polyadic decomposition which enforces one factor to belong exactly to a known dictionary . A new formulation of sparse coding is proposed which enables high dimensional tensors dictionary-based canonical polyadic decomposition . The benefits of using a dictionary in tensor decomposition models are explored both in terms of parameter identifiability and estimation accuracy . Performances of the proposed algorithms are evaluated on the decomposition of simulated data and the unmixing of hyperspectral images .
Let \phi ( G ) be the minimum conductance of an undirected graph G , and let 0=\lambda_0 <= \lambda_0 <= . . . <= \lambda_n <= 0 be the eigenvalues of the normalized Laplacian matrix of G . We prove that for any graph G and any k >= 0 , \phi ( G ) = O ( k ) \lambda_0 / \sqrt{\lambda_k} , and this performance guarantee is achieved by the spectral partitioning algorithm . This improves Cheeger ' s inequality , and the bound is optimal up to a constant factor for any k . Our result shows that the spectral partitioning algorithm is a constant factor approximation algorithm for finding a sparse cut if \lambda_k$ is a constant for some constant k . This provides some theoretical justification to its empirical performance in image segmentation and clustering problems . We extend the analysis to other graph partitioning problems , including multi-way partition , balanced separator , and maximum cut .
There is a large literature explaining why AdaBoost is a successful classifier . The literature on AdaBoost focuses on classifier margins and boosting ' s interpretation as the optimization of an exponential likelihood function . These existing explanations , however , have been pointed out to be incomplete . A random forest is another popular ensemble method for which there is substantially less explanation in the literature . We introduce a novel perspective on AdaBoost and random forests that proposes that the two algorithms work for similar reasons . While both classifiers achieve similar predictive accuracy , random forests cannot be conceived as a direct optimization procedure . Rather , random forests is a self-averaging , interpolating algorithm which creates what we denote as a " spikey-smooth " classifier , and we view AdaBoost in the same light . We conjecture that both AdaBoost and random forests succeed because of this mechanism . We provide a number of examples and some theoretical justification to support this explanation . In the process , we question the conventional wisdom that suggests that boosting algorithms for classification require regularization or early stopping and should be limited to low complexity classes of learners , such as decision stumps . We conclude that boosting should be used like random forests : with large decision trees and without direct regularization or early stopping .
Inverse reinforcement learning ( IRL ) has become a useful tool for learning behavioral models from demonstration data . However , IRL remains mostly unexplored for multi-agent systems . In this paper , we show how the principle of IRL can be extended to homogeneous large-scale problems , inspired by the collective swarming behavior of natural systems . In particular , we make the following contributions to the field : 0 ) We introduce the swarMDP framework , a sub-class of decentralized partially observable Markov decision processes endowed with a swarm characterization . 0 ) Exploiting the inherent homogeneity of this framework , we reduce the resulting multi-agent IRL problem to a single-agent one by proving that the agent-specific value functions in this model coincide . 0 ) To solve the corresponding control problem , we propose a novel heterogeneous learning scheme that is particularly tailored to the swarm setting . Results on two example systems demonstrate that our framework is able to produce meaningful local reward models from which we can replicate the observed global system dynamics .
We propose a quantum machine learning algorithm for efficiently solving a class of problems encoded in quantum controlled unitary operations . The central physical mechanism of the protocol is the iteration of a quantum time-delayed equation that introduces feedback in the dynamics and eliminates the necessity of intermediate measurements . The performance of the quantum algorithm is analyzed by comparing the results obtained in numerical simulations with the outcome of classical machine learning methods for the same problem . The use of time-delayed equations enhances the toolbox of the field of quantum machine learning , which may enable unprecedented applications in quantum technologies .
This paper studies the problem of multivariate linear regression where a portion of the observations is grossly corrupted or is missing , and the magnitudes and locations of such occurrences are unknown in priori . To deal with this problem , we propose a new approach by explicitly consider the error source as well as its sparseness nature . An interesting property of our approach lies in its ability of allowing individual regression output elements or tasks to possess their unique noise levels . Moreover , despite working with a non-smooth optimization problem , our approach still guarantees to converge to its optimal solution . Experiments on synthetic data demonstrate the competitiveness of our approach compared with existing multivariate regression models . In addition , empirically our approach has been validated with very promising results on two exemplar real-world applications : The first concerns the prediction of \textit{Big-Five} personality based on user behaviors at social network sites ( SNSs ) , while the second is 0D human hand pose estimation from depth images . The implementation of our approach and comparison methods as well as the involved datasets are made publicly available in support of the open-source and reproducible research initiatives .
Labeling training data is increasingly the largest bottleneck in deploying machine learning systems . We present Snorkel , a first-of-its-kind system that enables users to train state-of-the-art models without hand labeling any training data . Instead , users write labeling functions that express arbitrary heuristics , which can have unknown accuracies and correlations . Snorkel denoises their outputs without access to ground truth by incorporating the first end-to-end implementation of our recently proposed machine learning paradigm , data programming . We present a flexible interface layer for writing labeling functions based on our experience over the past year collaborating with companies , agencies , and research labs . In a user study , subject matter experts build models 0 . 0x faster and increase predictive performance an average 00 . 0% versus seven hours of hand labeling . We study the modeling tradeoffs in this new setting and propose an optimizer for automating tradeoff decisions that gives up to 0 . 0x speedup per pipeline execution . In two collaborations , with the U . S . Department of Veterans Affairs and the U . S . Food and Drug Administration , and on four open-source text and image data sets representative of other deployments , Snorkel provides 000% average improvements to predictive performance over prior heuristic approaches and comes within an average 0 . 00% of the predictive performance of large hand-curated training sets .
The determination of cluster centers generally depends on the scale that we use to analyze the data to be clustered . Inappropriate scale usually leads to unreasonable cluster centers and thus unreasonable results . In this study , we first consider the similarity of elements in the data as the connectivity of nodes in an undirected graph , then present the concept of a connection center and regard it as the cluster center of the data . Based on this definition , the determination of cluster centers and the assignment of class are very simple , natural and effective . One more crucial finding is that the cluster centers of different scales can be obtained easily by the different powers of a similarity matrix and the change of power from small to large leads to the dynamic evolution of cluster centers from local ( microscopic ) to global ( microscopic ) . Further , in this process of evolution , the number of categories changes discontinuously , which means that the presented method can automatically skip the unreasonable number of clusters , suggest appropriate observation scales and provide corresponding cluster results .
We describe a Markov latent state space ( MLSS ) model , where the latent state distribution is a decaying mixture over multiple past states . We present a simple sampling algorithm that allows to approximate such high-order MLSS with fixed time and memory costs .
Ensembles of decision trees have good prediction accuracy but suffer from a lack of interpretability . We propose a new approach for interpreting tree ensembles by finding prototypes in tree space , utilizing the naturally-learned similarity measure from the tree ensemble . Demonstrating the method on random forests , we show that the method benefits from unique aspects of tree ensembles by leveraging tree structure to sequentially find prototypes . The method provides good prediction accuracy when found prototypes are used in nearest-prototype classifiers , while using fewer prototypes than competitor methods . We are investigating the sensitivity of the method to different prototype-finding procedures and demonstrating it on higher-dimensional data .
Matrix completion has been well studied under the uniform sampling model and the trace-norm regularized methods perform well both theoretically and numerically in such a setting . However , the uniform sampling model is unrealistic for a range of applications and the standard trace-norm relaxation can behave very poorly when the underlying sampling scheme is non-uniform . In this paper we propose and analyze a max-norm constrained empirical risk minimization method for noisy matrix completion under a general sampling model . The optimal rate of convergence is established under the Frobenius norm loss in the context of approximately low-rank matrix reconstruction . It is shown that the max-norm constrained method is minimax rate-optimal and yields a unified and robust approximate recovery guarantee , with respect to the sampling distributions . The computational effectiveness of this method is also discussed , based on first-order algorithms for solving convex optimizations involving max-norm regularization .
There has been an explosion of interest in functional Magnetic Resonance Imaging ( MRI ) during the past two decades . Naturally , this has been accompanied by many major advances in the understanding of the human connectome . These advances have served to pose novel challenges as well as open new avenues for research . One of the most promising and exciting of such avenues is the study of functional MRI in real-time . Such studies have recently gained momentum and have been applied in a wide variety of settings ; ranging from training of healthy subjects to self-regulate neuronal activity to being suggested as potential treatments for clinical populations . To date , the vast majority of these studies have focused on a single region at a time . This is due in part to the many challenges faced when estimating dynamic functional connectivity networks in real-time . In this work we propose a novel methodology with which to accurately track changes in functional connectivity networks in real-time . We adapt the recently proposed SINGLE algorithm for estimating sparse and temporally homo- geneous dynamic networks to be applicable in real-time . The proposed method is applied to motor task data from the Human Connectome Project as well as to real-time data ob- tained while exploring a virtual environment . We show that the algorithm is able to estimate significant task-related changes in network structure quickly enough to be useful in future brain-computer interface applications .
While significant progress has been made separately on analytics systems for scalable stochastic gradient descent ( SGD ) and private SGD , none of the major scalable analytics frameworks have incorporated differentially private SGD . There are two inter-related issues for this disconnect between research and practice : ( 0 ) low model accuracy due to added noise to guarantee privacy , and ( 0 ) high development and runtime overhead of the private algorithms . This paper takes a first step to remedy this disconnect and proposes a private SGD algorithm to address \emph{both} issues in an integrated manner . In contrast to the white-box approach adopted by previous work , we revisit and use the classical technique of {\em output perturbation} to devise a novel " bolt-on " approach to private SGD . While our approach trivially addresses ( 0 ) , it makes ( 0 ) even more challenging . We address this challenge by providing a novel analysis of the $L_0$-sensitivity of SGD , which allows , under the same privacy guarantees , better convergence of SGD when only a constant number of passes can be made over the data . We integrate our algorithm , as well as other state-of-the-art differentially private SGD , into Bismarck , a popular scalable SGD-based analytics system on top of an RDBMS . Extensive experiments show that our algorithm can be easily integrated , incurs virtually no overhead , scales well , and most importantly , yields substantially better ( up to 0X ) test accuracy than the state-of-the-art algorithms on many real datasets .
We present algorithms for the detection of a class of heart arrhythmias with the goal of eventual adoption by practicing cardiologists . In clinical practice , detection is based on a small number of meaningful features extracted from the heartbeat cycle . However , techniques proposed in the literature use high dimensional vectors consisting of morphological , and time based features for detection . Using electrocardiogram ( ECG ) signals , we found smaller subsets of features sufficient to detect arrhythmias with high accuracy . The features were found by an iterative step-wise feature selection method . We depart from common literature in the following aspects : 0 . As opposed to a high dimensional feature vectors , we use a small set of features with meaningful clinical interpretation , 0 . we eliminate the necessity of short-duration patient-specific ECG data to append to the global training data for classification 0 . We apply semi-parametric classification procedures ( in an ensemble framework ) for arrhythmia detection , and 0 . our approach is based on a reduced sampling rate of ~ 000 Hz as opposed to 000 Hz in standard literature .
This paper presents an efficient Bayesian framework for solving nonlinear , high-dimensional model calibration problems . It is based on a Variational Bayesian formulation that aims at approximating the exact posterior by means of solving an optimization problem over an appropriately selected family of distributions . The goal is two-fold . Firstly , to find lower-dimensional representations of the unknown parameter vector that capture as much as possible of the associated posterior density , and secondly to enable the computation of the approximate posterior density with as few forward calls as possible . We discuss how these objectives can be achieved by using a fully Bayesian argumentation and employing the marginal likelihood or evidence as the ultimate model validation metric for any proposed dimensionality reduction . We demonstrate the performance of the proposed methodology for problems in nonlinear elastography where the identification of the mechanical properties of biological materials can inform non-invasive , medical diagnosis . An Importance Sampling scheme is finally employed in order to validate the results and assess the efficacy of the approximations provided .
The detection of anomalous activity in graphs is a statistical problem that arises in many applications , such as network surveillance , disease outbreak detection , and activity monitoring in social networks . Beyond its wide applicability , graph structured anomaly detection serves as a case study in the difficulty of balancing computational complexity with statistical power . In this work , we develop from first principles the generalized likelihood ratio test for determining if there is a well connected region of activation over the vertices in the graph in Gaussian noise . Because this test is computationally infeasible , we provide a relaxation , called the Lovasz extended scan statistic ( LESS ) that uses submodularity to approximate the intractable generalized likelihood ratio . We demonstrate a connection between LESS and maximum a-posteriori inference in Markov random fields , which provides us with a poly-time algorithm for LESS . Using electrical network theory , we are able to control type 0 error for LESS and prove conditions under which LESS is risk consistent . Finally , we consider specific graph models , the torus , k-nearest neighbor graphs , and epsilon-random graphs . We show that on these graphs our results provide near-optimal performance by matching our results to known lower bounds .
Regularization is a powerful technique for extracting useful information from noisy data . Typically , it is implemented by adding some sort of norm constraint to an objective function and then exactly optimizing the modified objective function . This procedure often leads to optimization problems that are computationally more expensive than the original problem , a fact that is clearly problematic if one is interested in large-scale applications . On the other hand , a large body of empirical work has demonstrated that heuristics , and in some cases approximation algorithms , developed to speed up computations sometimes have the side-effect of performing regularization implicitly . Thus , we consider the question : What is the regularized optimization objective that an approximation algorithm is exactly optimizing ? We address this question in the context of computing approximations to the smallest nontrivial eigenvector of a graph Laplacian ; and we consider three random-walk-based procedures : one based on the heat kernel of the graph , one based on computing the the PageRank vector associated with the graph , and one based on a truncated lazy random walk . In each case , we provide a precise characterization of the manner in which the approximation method can be viewed as implicitly computing the exact solution to a regularized problem . Interestingly , the regularization is not on the usual vector form of the optimization problem , but instead it is on a related semidefinite program .
Gaussian processes ( GPs ) , or distributions over arbitrary functions in a continuous domain , can be generalized to the multi-output case : a linear model of coregionalization ( LMC ) is one approach . LMCs estimate and exploit correlations across the multiple outputs . While model estimation can be performed efficiently for single-output GPs , these assume stationarity , but in the multi-output case the cross-covariance interaction is not stationary . We propose Large Linear GP ( LLGP ) , which circumvents the need for stationarity by inducing structure in the LMC kernel through a common grid of inputs shared between outputs , enabling optimization of GP hyperparameters for multi-dimensional outputs and low-dimensional inputs . When applied to synthetic two-dimensional and real time series data , we find our theoretical improvement relative to the current solutions for multi-output GPs is realized with LLGP reducing training time while improving or maintaining predictive mean accuracy . Moreover , by using a direct likelihood approximation rather than a variational one , model confidence estimates are significantly improved .
In this paper , we consider the matrix completion problem when the observations are one-bit measurements of some underlying matrix M , and in particular the observed samples consist only of ones and no zeros . This problem is motivated by modern applications such as recommender systems and social networks where only " likes " or " friendships " are observed . The problem of learning from only positive and unlabeled examples , called PU ( positive-unlabeled ) learning , has been studied in the context of binary classification . We consider the PU matrix completion problem , where an underlying real-valued matrix M is first quantized to generate one-bit observations and then a subset of positive entries is revealed . Under the assumption that M has bounded nuclear norm , we provide recovery guarantees for two different observation models : 0 ) M parameterizes a distribution that generates a binary matrix , 0 ) M is thresholded to obtain a binary matrix . For the first case , we propose a " shifted matrix completion " method that recovers M using only a subset of indices corresponding to ones , while for the second case , we propose a " biased matrix completion " method that recovers the ( thresholded ) binary matrix . Both methods yield strong error bounds --- if M is n by n , the Frobenius error is bounded as O ( 0/ ( ( 0-rho ) n ) , where 0-rho denotes the fraction of ones observed . This implies a sample complexity of O ( n\log n ) ones to achieve a small error , when M is dense and n is large . We extend our methods and guarantees to the inductive matrix completion problem , where rows and columns of M have associated features . We provide efficient and scalable optimization procedures for both the methods and demonstrate the effectiveness of the proposed methods for link prediction ( on real-world networks consisting of over 0 million nodes and 00 million links ) and semi-supervised clustering tasks .
In online discussion communities , users can interact and share information and opinions on a wide variety of topics . However , some users may create multiple identities , or sockpuppets , and engage in undesired behavior by deceiving others or manipulating discussions . In this work , we study sockpuppetry across nine discussion communities , and show that sockpuppets differ from ordinary users in terms of their posting behavior , linguistic traits , as well as social network structure . Sockpuppets tend to start fewer discussions , write shorter posts , use more personal pronouns such as " I " , and have more clustered ego-networks . Further , pairs of sockpuppets controlled by the same individual are more likely to interact on the same discussion at the same time than pairs of ordinary users . Our analysis suggests a taxonomy of deceptive behavior in discussion communities . Pairs of sockpuppets can vary in their deceptiveness , i . e . , whether they pretend to be different users , or their supportiveness , i . e . , if they support arguments of other sockpuppets controlled by the same user . We apply these findings to a series of prediction tasks , notably , to identify whether a pair of accounts belongs to the same underlying user or not . Altogether , this work presents a data-driven view of deception in online discussion communities and paves the way towards the automatic detection of sockpuppets .
Empirical analysis serves as an important complement to theoretical analysis for studying practical Bayesian optimization . Often empirical insights expose strengths and weaknesses inaccessible to theoretical analysis . We define two metrics for comparing the performance of Bayesian optimization methods and propose a ranking mechanism for summarizing performance within various genres or strata of test functions . These test functions serve to mimic the complexity of hyperparameter optimization problems , the most prominent application of Bayesian optimization , but with a closed form which allows for rapid evaluation and more predictable behavior . This offers a flexible and efficient way to investigate functions with specific properties of interest , such as oscillatory behavior or an optimum on the domain boundary .
In this work , we give the first algorithms for tolerant testing of nontrivial classes in the active model : estimating the distance of a target function to a hypothesis class C with respect to some arbitrary distribution D , using only a small number of label queries to a polynomial-sized pool of unlabeled examples drawn from D . Specifically , we show that for the class D of unions of d intervals on the line , we can estimate the error rate of the best hypothesis in the class to an additive error epsilon from only $O ( \frac{0}{\epsilon^0}\log \frac{0}{\epsilon} ) $ label queries to an unlabeled pool of size $O ( \frac{d}{\epsilon^0}\log \frac{0}{\epsilon} ) $ . The key point here is the number of labels needed is independent of the VC-dimension of the class . This extends the work of Balcan et al . [0000] who solved the non-tolerant testing problem for this class ( distinguishing the zero-error case from the case that the best hypothesis in the class has error greater than epsilon ) . We also consider the related problem of estimating the performance of a given learning algorithm A in this setting . That is , given a large pool of unlabeled examples drawn from distribution D , can we , from only a few label queries , estimate how well A would perform if the entire dataset were labeled ? We focus on k-Nearest Neighbor style algorithms , and also show how our results can be applied to the problem of hyperparameter tuning ( selecting the best value of k for the given learning problem ) .
These are lecture notes that are based on the lectures from a class I taught on the topic of Spectral Graph Methods at UC Berkeley during the Spring 0000 semester .
Many high dimensional sparse learning problems are formulated as nonconvex optimization . A popular approach to solve these nonconvex optimization problems is through convex relaxations such as linear and semidefinite programming . In this paper , we study the statistical limits of convex relaxations . Particularly , we consider two problems : Mean estimation for sparse principal submatrix and edge probability estimation for stochastic block model . We exploit the sum-of-squares relaxation hierarchy to sharply characterize the limits of a broad class of convex relaxations . Our result shows statistical optimality needs to be compromised for achieving computational tractability using convex relaxations . Compared with existing results on computational lower bounds for statistical problems , which consider general polynomial-time algorithms and rely on computational hardness hypotheses on problems like planted clique detection , our theory focuses on a broad class of convex relaxations and does not rely on unproven hypotheses .
Inference for latent feature models is inherently difficult as the inference space grows exponentially with the size of the input data and number of latent features . In this work , we use Kurihara & Welling ( 0000 ) ' s maximization-expectation framework to perform approximate MAP inference for linear-Gaussian latent feature models with an Indian Buffet Process ( IBP ) prior . This formulation yields a submodular function of the features that corresponds to a lower bound on the model evidence . By adding a constant to this function , we obtain a nonnegative submodular function that can be maximized via a greedy algorithm that obtains at least a one-third approximation to the optimal solution . Our inference method scales linearly with the size of the input data , and we show the efficacy of our method on the largest datasets currently analyzed using an IBP model .
Forward-backward selection is one of the most basic and commonly-used feature selection algorithms available . It is also general and conceptually applicable to many different types of data . In this paper , we propose a heuristic that significantly improves its running time , while preserving predictive accuracy . The idea is to temporarily discard the variables that are conditionally independent with the outcome given the selected variable set . Depending on how those variables are reconsidered and reintroduced , this heuristic gives rise to a family of algorithms with increasingly stronger theoretical guarantees . In distributions that can be faithfully represented by Bayesian networks or maximal ancestral graphs , members of this algorithmic family are able to correctly identify the Markov blanket in the sample limit . In experiments we show that the proposed heuristic increases computational efficiency by about two orders of magnitude in high-dimensional problems , while selecting fewer variables and retaining predictive performance . Furthermore , we show that the proposed algorithm and feature selection with LASSO perform similarly when restricted to select the same number of variables , making the proposed algorithm an attractive alternative for problems where no ( efficient ) algorithm for LASSO exists .
Uncertainty principles such as Heisenberg ' s provide limits on the time-frequency concentration of a signal , and constitute an important theoretical tool for designing and evaluating linear signal transforms . Generalizations of such principles to the graph setting can inform dictionary design for graph signals , lead to algorithms for reconstructing missing information from graph signals via sparse representations , and yield new graph analysis tools . While previous work has focused on generalizing notions of spreads of a graph signal in the vertex and graph spectral domains , our approach is to generalize the methods of Lieb in order to develop uncertainty principles that provide limits on the concentration of the analysis coefficients of any graph signal under a dictionary transform whose atoms are jointly localized in the vertex and graph spectral domains . One challenge we highlight is that due to the inhomogeneity of the underlying graph data domain , the local structure in a single small region of the graph can drastically affect the uncertainty bounds for signals concentrated in different regions of the graph , limiting the information provided by global uncertainty principles . Accordingly , we suggest a new way to incorporate a notion of locality , and develop local uncertainty principles that bound the concentration of the analysis coefficients of each atom of a localized graph spectral filter frame in terms of quantities that depend on the local structure of the graph around the center vertex of the given atom . Finally , we demonstrate how our proposed local uncertainty measures can improve the random sampling of graph signals .
Generative models such as Variational Auto Encoders ( VAEs ) and Generative Adversarial Networks ( GANs ) are typically trained for a fixed prior distribution in the latent space , such as uniform or Gaussian . After a trained model is obtained , one can sample the Generator in various forms for exploration and understanding , such as interpolating between two samples , sampling in the vicinity of a sample or exploring differences between a pair of samples applied to a third sample . In this paper , we show that the latent space operations used in the literature so far induce a distribution mismatch between the resulting outputs and the prior distribution the model was trained on . To address this , we propose to use distribution matching transport maps to ensure that such latent space operations preserve the prior distribution , while minimally modifying the original operation . Our experimental results validate that the proposed operations give higher quality samples compared to the original operations .
Autonomous learning has been a promising direction in control and robotics for more than a decade since data-driven learning allows to reduce the amount of engineering knowledge , which is otherwise required . However , autonomous reinforcement learning ( RL ) approaches typically require many interactions with the system to learn controllers , which is a practical limitation in real systems , such as robots , where many interactions can be impractical and time consuming . To address this problem , current learning approaches typically require task-specific knowledge in form of expert demonstrations , realistic simulators , pre-shaped policies , or specific knowledge about the underlying dynamics . In this article , we follow a different approach and speed up learning by extracting more information from data . In particular , we learn a probabilistic , non-parametric Gaussian process transition model of the system . By explicitly incorporating model uncertainty into long-term planning and controller learning our approach reduces the effects of model errors , a key problem in model-based learning . Compared to state-of-the art RL our model-based policy search method achieves an unprecedented speed of learning . We demonstrate its applicability to autonomous learning in real robot and control tasks .
This work includes all the technical details of the Sequential Principal Curves Analysis ( SPCA ) in a single document . SPCA is an unsupervised nonlinear and invertible feature extraction technique . The identified curvilinear features can be interpreted as a set of nonlinear sensors : the response of each sensor is the projection onto the corresponding feature . Moreover , it can be easily tuned for different optimization criteria ; e . g . infomax , error minimization , decorrelation ; by choosing the right way to measure distances along each curvilinear feature . Even though proposed in [Laparra et al . Neural Comp . 00] and shown to work in multiple modalities in [Laparra and Malo Frontiers Hum . Neuro . 00] , the SPCA framework has its original roots in the nonlinear ICA algorithm in [Malo and Gutierrez Network 00] . Later on , the SPCA philosophy for nonlinear generalization of PCA originated substantially faster alternatives at the cost of introducing different constraints in the model . Namely , the Principal Polynomial Analysis ( PPA ) [Laparra et al . IJNS 00] , and the Dimensionality Reduction via Regression ( DRR ) [Laparra et al . IEEE TGRS 00] . This report illustrates the reasons why we developed such family and is the appropriate technical companion for the missing details in [Laparra et al . , NeCo 00 , Laparra and Malo , Front . Hum . Neuro . 00] . See also the data , code and examples in the dedicated sites http : //isp . uv . es/spca . html and http : //isp . uv . es/after effects . html
In this paper , we revisit the recently established theoretical guarantees for the convergence of the Langevin Monte Carlo algorithm of sampling from a smooth and ( strongly ) log-concave density . We improve , in terms of constants , the existing results when the accuracy of sampling is measured in the Wasserstein distance and provide further insights on relations between , on the one hand , the Langevin Monte Carlo for sampling and , on the other hand , the gradient descent for optimization . More importantly , we establish non-asymptotic guarantees for the accuracy of a version of the Langevin Monte Carlo algorithm that is based on inaccurate evaluations of the gradient . Finally , we propose a variable-step version of the Langevin Monte Carlo algorithm that has two advantages . First , its step-sizes are independent of the target accuracy and , second , its rate provides a logarithmic improvement over the constant-step Langevin Monte Carlo algorithm .
This paper introduces a latent position network model , called the generalised random dot product graph , comprising as special cases the stochastic blockmodel , mixed membership stochastic blockmodel , and random dot product graph . In this model , nodes are represented as random vectors on $\mathbb{R}^d$ , and the probability of an edge between nodes $i$ and $j$ is given by the bilinear form $X_i^T I_{p , q} X_j$ , where $I_{p , q} = \mathrm{diag} ( 0 , \ldots , 0 , -0 , \ldots , -0 ) $ with $p$ ones and $q$ minus ones , where $p+q=d$ . As we show , this provides the only possible representation of nodes in $\mathbb{R}^d$ such that mixed membership is encoded as the corresponding convex combination of latent positions . The positions are identifiable only up to transformation in the indefinite orthogonal group $O ( p , q ) $ , and we discuss some consequences for typical follow-on inference tasks , such as clustering and prediction .
In recent years Variation Autoencoders have become one of the most popular unsupervised learning of complicated distributions . Variational Autoencoder ( VAE ) provides more efficient reconstructive performance over a traditional autoencoder . Variational auto enocders make better approximaiton than MCMC . The VAE defines a generative process in terms of ancestral sampling through a cascade of hidden stochastic layers . They are a directed graphic models . Variational autoencoder is trained to maximise the variational lower bound . Here we are trying maximise the likelihood and also at the same time we are trying to make a good approximation of the data . Its basically trading of the data log-likelihood and the KL divergence from the true posterior . This paper describes the scenario in which we wish to find a point-estimate to the parameters $\theta$ of some parametric model in which we generate each observations by first sampling a local latent variable and then sampling the associated observation . Here we use least square loss function with regularization in the the reconstruction of the image , the least square loss function was found to give better reconstructed images and had a faster training time .
We propose a technique for making Convolutional Neural Network ( CNN ) -based models more transparent by visualizing input regions that are ' important ' for predictions -- or visual explanations . Our approach , called Gradient-weighted Class Activation Mapping ( Grad-CAM ) , uses class-specific gradient information to localize important regions . These localizations are combined with existing pixel-space visualizations to create a novel high-resolution and class-discriminative visualization called Guided Grad-CAM . These methods help better understand CNN-based models , including image captioning and visual question answering ( VQA ) models . We evaluate our visual explanations by measuring their ability to discriminate between classes , to inspire trust in humans , and their correlation with occlusion maps . Grad-CAM provides a new way to understand CNN-based models . We have released code , an online demo hosted on CloudCV , and a full version of this extended abstract .
Deep generative models provide a systematic way to learn nonlinear data distributions , through a set of latent variables and a nonlinear " generator " function that maps latent points into the input space . The nonlinearity of the generator imply that the latent space gives a distorted view of the input space . Under mild conditions , we show that this distortion can be characterized by a stochastic Riemannian metric , and demonstrate that distances and interpolants are significantly improved under this metric . This in turn improves probability distributions , sampling algorithms and clustering in the latent space . Our geometric analysis further reveals that current generators provide poor variance estimates and we propose a new generator architecture with vastly improved variance estimates . Results are demonstrated on convolutional and fully connected variational autoencoders , but the formalism easily generalize to other deep generative models .
A Discriminative Deep Forest ( DisDF ) as a metric learning algorithm is proposed in the paper . It is based on the Deep Forest or gcForest proposed by Zhou and Feng and can be viewed as a gcForest modification . The case of the fully supervised learning is studied when the class labels of individual training examples are known . The main idea underlying the algorithm is to assign weights to decision trees in random forest in order to reduce distances between objects from the same class and to increase them between objects from different classes . The weights are training parameters . A specific objective function which combines Euclidean and Manhattan distances and simplifies the optimization problem for training the DisDF is proposed . The numerical experiments illustrate the proposed distance metric algorithm .
We propose a novel learning method for multilayered neural networks which uses feedforward supervisory signal and associates classification of a new input with that of pre-trained input . The proposed method effectively uses rich input information in the earlier layer for robust leaning and revising internal representation in a multilayer neural network .
We investigate unsupervised pre-training of deep architectures as feature generators for " shallow " classifiers . Stacked Denoising Autoencoders ( SdA ) , when used as feature pre-processing tools for SVM classification , can lead to significant improvements in accuracy - however , at the price of a substantial increase in computational cost . In this paper we create a simple algorithm which mimics the layer by layer training of SdAs . However , in contrast to SdAs , our algorithm requires no training through gradient descent as the parameters can be computed in closed-form . It can be implemented in less than 00 lines of MATLABTMand reduces the computation time from several hours to mere seconds . We show that our feature transformation reliably improves the results of SVM classification significantly on all our data sets - often outperforming SdAs and even deep neural networks in three out of four deep learning benchmarks .
This paper describes a distributed MapReduce implementation of the minimum Redundancy Maximum Relevance algorithm , a popular feature selection method in bioinformatics and network inference problems . The proposed approach handles both tall/narrow and wide/short datasets . We further provide an open source implementation based on Hadoop/Spark , and illustrate its scalability on datasets involving millions of observations or features .
The problem of joint feature selection across a group of related tasks has applications in many areas including biomedical informatics and computer vision . We consider the l0 , 0-norm regularized regression model for joint feature selection from multiple tasks , which can be derived in the probabilistic framework by assuming a suitable prior from the exponential family . One appealing feature of the l0 , 0-norm regularization is that it encourages multiple predictors to share similar sparsity patterns . However , the resulting optimization problem is challenging to solve due to the non-smoothness of the l0 , 0-norm regularization . In this paper , we propose to accelerate the computation by reformulating it as two equivalent smooth convex optimization problems which are then solved via the Nesterov ' s method-an optimal first-order black-box method for smooth convex optimization . A key building block in solving the reformulations is the Euclidean projection . We show that the Euclidean projection for the first reformulation can be analytically computed , while the Euclidean projection for the second one can be computed in linear time . Empirical evaluations on several data sets verify the efficiency of the proposed algorithms .
This paper proposes a new interpretation of sparse penalties such as the elastic-net and the group-lasso . Beyond providing a new viewpoint on these penalization schemes , our approach results in a unified optimization strategy . Our experiments demonstrate that this strategy , implemented on the elastic-net , is computationally extremely efficient for small to medium size problems . Our accompanying software solves problems very accurately , at machine precision , in the time required to get a rough estimate with competing state-of-the-art algorithms . We illustrate on real and artificial datasets that this accuracy is required to for the correctness of the support of the solution , which is an important element for the interpretability of sparsity-inducing penalties .
Discovering causal relations among observed variables in a given data set is a main topic in studies of statistics and artificial intelligence . Recently , some techniques to discover an identifiable causal structure have been explored based on non-Gaussianity of the observed data distribution . However , most of these are limited to continuous data . In this paper , we present a novel causal model for binary data and propose a new approach to derive an identifiable causal structure governing the data based on skew Bernoulli distributions of external noise . Experimental evaluation shows excellent performance for both artificial and real world data sets .
Machine learning is the science of discovering statistical dependencies in data , and the use of those dependencies to perform predictions . During the last decade , machine learning has made spectacular progress , surpassing human performance in complex tasks such as object recognition , car driving , and computer gaming . However , the central role of prediction in machine learning avoids progress towards general-purpose artificial intelligence . As one way forward , we argue that causal inference is a fundamental component of human intelligence , yet ignored by learning algorithms . Causal inference is the problem of uncovering the cause-effect relationships between the variables of a data generating system . Causal structures provide understanding about how these systems behave under changing , unseen environments . In turn , knowledge about these causal dynamics allows to answer " what if " questions , describing the potential responses of the system under hypothetical manipulations and interventions . Thus , understanding cause and effect is one step from machine learning towards machine reasoning and machine intelligence . But , currently available causal inference algorithms operate in specific regimes , and rely on assumptions that are difficult to verify in practice . This thesis advances the art of causal inference in three different ways . First , we develop a framework for the study of statistical dependence based on copulas and random features . Second , we build on this framework to interpret the problem of causal inference as the task of distribution classification , yielding a family of novel causal inference algorithms . Third , we discover causal structures in convolutional neural network features using our algorithms . The algorithms presented in this thesis are scalable , exhibit strong theoretical guarantees , and achieve state-of-the-art performance in a variety of real-world benchmarks .
This paper introduces matrix product state ( MPS ) decomposition as a new and systematic method to compress multidimensional data represented by higher-order tensors . It solves two major bottlenecks in tensor compression : computation and compression quality . Regardless of tensor order , MPS compresses tensors to matrices of moderate dimension which can be used for classification . Mainly based on a successive sequence of singular value decompositions ( SVD ) , MPS is quite simple to implement and arrives at the global optimal matrix , bypassing local alternating optimization , which is not only computationally expensive but cannot yield the global solution . Benchmark results show that MPS can achieve better classification performance with favorable computation cost compared to other tensor compression methods .
We introduce a new method for training deep Boltzmann machines jointly . Prior methods of training DBMs require an initial learning pass that trains the model greedily , one layer at a time , or do not perform well on classification tasks . In our approach , we train all layers of the DBM simultaneously , using a novel training procedure called multi-prediction training . The resulting model can either be interpreted as a single generative model trained to maximize a variational approximation to the generalized pseudolikelihood , or as a family of recurrent networks that share parameters and may be approximately averaged together using a novel technique we call the multi-inference trick . We show that our approach performs competitively for classification and outperforms previous methods in terms of accuracy of approximate inference and classification with missing inputs .
Sepsis is a poorly understood and potentially life-threatening complication that can occur as a result of infection . Early detection and treatment improves patient outcomes , and as such it poses an important challenge in medicine . In this work , we develop a flexible classifier that leverages streaming lab results , vitals , and medications to predict sepsis before it occurs . We model patient clinical time series with multi-output Gaussian processes , maintaining uncertainty about the physiological state of a patient while also imputing missing values . The mean function takes into account the effects of medications administered on the trajectories of the physiological variables . Latent function values from the Gaussian process are then fed into a deep recurrent neural network to classify patient encounters as septic or not , and the overall model is trained end-to-end using back-propagation . We train and validate our model on a large dataset of 00 months of heterogeneous inpatient stays from the Duke University Health System , and develop a new " real-time " validation scheme for simulating the performance of our model as it will actually be used . Our proposed method substantially outperforms clinical baselines , and improves on a previous related model for detecting sepsis . Our model ' s predictions will be displayed in a real-time analytics dashboard to be used by a sepsis rapid response team to help detect and improve treatment of sepsis .
We propose a nonparametric approach to link prediction in large-scale dynamic networks . Our model uses graph-based features of pairs of nodes as well as those of their local neighborhoods to predict whether those nodes will be linked at each time step . The model allows for different types of evolution in different parts of the graph ( e . g , growing or shrinking communities ) . We focus on large-scale graphs and present an implementation of our model that makes use of locality-sensitive hashing to allow it to be scaled to large problems . Experiments with simulated data as well as five real-world dynamic graphs show that we outperform the state of the art , especially when sharp fluctuations or nonlinearities are present . We also establish theoretical properties of our estimator , in particular consistency and weak convergence , the latter making use of an elaboration of Stein ' s method for dependency graphs .
In this paper we propose an efficient algorithm ProtoDash for selecting prototypical examples from complex datasets . Our work builds on top of the learn to criticize ( L0C ) work by Kim et al . ( 0000 ) and generalizes it to not only select prototypes for a given sparsity level $m$ but also to associate non-negative weights with each of them indicative of the importance of each prototype . Unlike in the case of L0C , this extension provides a single coherent framework under which both prototypes and criticisms ( i . e . lowest weighted prototypes ) can be found . Furthermore , our framework works for any symmetric positive definite kernel thus addressing one of the open questions laid out in Kim et al . ( 0000 ) . Our additional requirement of learning non-negative weights introduces technical challenges as the objective is no longer submodular as in the previous work . However , we show that the problem is weakly submodular and derive approximation guarantees for our fast ProtoDash algorithm . Moreover , ProtoDash can not only find prototypical examples for a dataset $X$ , but it can also find ( weighted ) prototypical examples from $X^{ ( 0 ) }$ that best represent another dataset $X^{ ( 0 ) }$ , where $X^{ ( 0 ) }$ and $X^{ ( 0 ) }$ belong to the same feature space . We demonstrate the efficacy of our method on diverse domains namely ; retail , digit recognition ( MNIST ) and on the latest publicly available 00 health questionnaires obtained from the Center for Disease Control ( CDC ) website maintained by the US Dept . of Health . We validate the results quantitatively as well as qualitatively based on expert feedback and recently published scientific studies on public health .
Super-resolution methods form high-resolution images from low-resolution images . In this paper , we develop a new Bayesian nonparametric model for super-resolution . Our method uses a beta-Bernoulli process to learn a set of recurring visual patterns , called dictionary elements , from the data . Because it is nonparametric , the number of elements found is also determined from the data . We test the results on both benchmark and natural images , comparing with several other models from the research literature . We perform large-scale human evaluation experiments to assess the visual quality of the results . In a first implementation , we use Gibbs sampling to approximate the posterior . However , this algorithm is not feasible for large-scale data . To circumvent this , we then develop an online variational Bayes ( VB ) algorithm . This algorithm finds high quality dictionaries in a fraction of the time needed by the Gibbs sampler .
Standard sparse pseudo-input approximations to the Gaussian process ( GP ) cannot handle complex functions well . Sparse spectrum alternatives attempt to answer this but are known to over-fit . We suggest the use of variational inference for the sparse spectrum approximation to avoid both issues . We model the covariance function with a finite Fourier series approximation and treat it as a random variable . The random covariance function has a posterior , on which a variational distribution is placed . The variational distribution transforms the random covariance function to fit the data . We study the properties of our approximate inference , compare it to alternative ones , and extend it to the distributed and stochastic domains . Our approximation captures complex functions better than standard approaches and avoids over-fitting .
We address the issue of limit cycling behavior in training Generative Adversarial Networks and propose the use of Optimistic Mirror Decent ( OMD ) for training Wasserstein GANs . Recent theoretical results have shown that optimistic mirror decent ( OMD ) can enjoy faster regret rates in the context of zero-sum games . WGANs is exactly a context of solving a zero-sum game with simultaneous no-regret dynamics . Moreover , we show that optimistic mirror decent addresses the limit cycling problem in training WGANs . We formally show that in the case of bi-linear zero-sum games the last iterate of OMD dynamics converges to an equilibrium , in contrast to GD dynamics which are bound to cycle . We also portray the huge qualitative difference between GD and OMD dynamics with toy examples , even when GD is modified with many adaptations proposed in the recent literature , such as gradient penalty or momentum . We apply OMD WGAN training to a bioinformatics problem of generating DNA sequences . We observe that models trained with OMD achieve consistently smaller KL divergence with respect to the true underlying distribution , than models trained with GD variants . Finally , we introduce a new algorithm , Optimistic Adam , which is an optimistic variant of Adam . We apply it to WGAN training on CIFAR00 and observe improved performance in terms of inception score as compared to Adam .
The aim of this chapter is twofold . In the first part we will provide a brief overview of the mathematical and statistical foundations of graphical models , along with their fundamental properties , estimation and basic inference procedures . In particular we will develop Markov networks ( also known as Markov random fields ) and Bayesian networks , which comprise most past and current literature on graphical models . In the second part we will review some applications of graphical models in systems biology .
Gaussian Graphical Models ( GGMs ) are popular tools for studying network structures . However , many modern applications such as gene network discovery and social interactions analysis often involve high-dimensional noisy data with outliers or heavier tails than the Gaussian distribution . In this paper , we propose the Trimmed Graphical Lasso for robust estimation of sparse GGMs . Our method guards against outliers by an implicit trimming mechanism akin to the popular Least Trimmed Squares method used for linear regression . We provide a rigorous statistical analysis of our estimator in the high-dimensional setting . In contrast , existing approaches for robust sparse GGMs estimation lack statistical guarantees . Our theoretical results are complemented by experiments on simulated and real gene expression data which further demonstrate the value of our approach .
In this paper we propose a novel approach for learning from data using rule based fuzzy inference systems where the model parameters are estimated using Bayesian inference and Markov Chain Monte Carlo ( MCMC ) techniques . We show the applicability of the method for regression and classification tasks using synthetic data-sets and also a real world example in the financial services industry . Then we demonstrate how the method can be extended for knowledge extraction to select the individual rules in a Bayesian way which best explains the given data . Finally we discuss the advantages and pitfalls of using this method over state-of-the-art techniques and highlight the specific class of problems where this would be useful .
Bregman divergences play a central role in the design and analysis of a range of machine learning algorithms . This paper explores the use of Bregman divergences to establish reductions between such algorithms and their analyses . We present a new scaled isodistortion theorem involving Bregman divergences ( scaled Bregman theorem for short ) which shows that certain " Bregman distortions ' " ( employing a potentially non-convex generator ) may be exactly re-written as a scaled Bregman divergence computed over transformed data . Admissible distortions include geodesic distances on curved manifolds and projections or gauge-normalisation , while admissible data include scalars , vectors and matrices . Our theorem allows one to leverage to the wealth and convenience of Bregman divergences when analysing algorithms relying on the aforementioned Bregman distortions . We illustrate this with three novel applications of our theorem : a reduction from multi-class density ratio to class-probability estimation , a new adaptive projection free yet norm-enforcing dual norm mirror descent algorithm , and a reduction from clustering on flat manifolds to clustering on curved manifolds . Experiments on each of these domains validate the analyses and suggest that the scaled Bregman theorem might be a worthy addition to the popular handful of Bregman divergence properties that have been pervasive in machine learning .
In this paper we construct a learning architecture for high dimensional time series sampled by sensor arrangements . Using a redundant wavelet decomposition on a graph constructed over the sensor locations , our algorithm is able to construct discriminative features that exploit the mutual information between the sensors . The algorithm then applies scattering networks to the time series graphs to create the feature space . We demonstrate our method on a machine olfaction problem , where one needs to classify the gas type and the location where it originates from data sampled by an array of sensors . Our experimental results clearly demonstrate that our method outperforms classical machine learning techniques used in previous studies .
We consider the setting of sequential prediction of arbitrary sequences based on specialized experts . We first provide a review of the relevant literature and present two theoretical contributions : a general analysis of the specialist aggregation rule of Freund et al . ( 0000 ) and an adaptation of fixed-share rules of Herbster and Warmuth ( 0000 ) in this setting . We then apply these rules to the sequential short-term ( one-day-ahead ) forecasting of electricity consumption ; to do so , we consider two data sets , a Slovakian one and a French one , respectively concerned with hourly and half-hourly predictions . We follow a general methodology to perform the stated empirical studies and detail in particular tuning issues of the learning parameters . The introduced aggregation rules demonstrate an improved accuracy on the data sets at hand ; the improvements lie in a reduced mean squared error but also in a more robust behavior with respect to large occasional errors .
The article describe the model , derivation , and implementation of variational Bayesian inference for linear and logistic regression , both with and without automatic relevance determination . It has the dual function of acting as a tutorial for the derivation of variational Bayesian inference for simple models , as well as documenting , and providing brief examples for the MATLAB functions that implement this inference . These functions are freely available online .
We present an efficient algorithm for the inference of stochastic block models in large networks . The algorithm can be used as an optimized Markov chain Monte Carlo ( MCMC ) method , with a fast mixing time and a much reduced susceptibility to getting trapped in metastable states , or as a greedy agglomerative heuristic , with an almost linear $O ( N\ln^0N ) $ complexity , where $N$ is the number of nodes in the network , independent on the number of blocks being inferred . We show that the heuristic is capable of delivering results which are indistinguishable from the more exact and numerically expensive MCMC method in many artificial and empirical networks , despite being much faster . The method is entirely unbiased towards any specific mixing pattern , and in particular it does not favor assortative community structures .
The goal of a learner , in standard online learning , is to have the cumulative loss not much larger compared with the best-performing function from some fixed class . Numerous algorithms were shown to have this gap arbitrarily close to zero , compared with the best function that is chosen off-line . Nevertheless , many real-world applications , such as adaptive filtering , are non-stationary in nature , and the best prediction function may drift over time . We introduce two novel algorithms for online regression , designed to work well in non-stationary environment . Our first algorithm performs adaptive resets to forget the history , while the second is last-step min-max optimal in context of a drift . We analyze both algorithms in the worst-case regret framework and show that they maintain an average loss close to that of the best slowly changing sequence of linear functions , as long as the cumulative drift is sublinear . In addition , in the stationary case , when no drift occurs , our algorithms suffer logarithmic regret , as for previous algorithms . Our bounds improve over the existing ones , and simulations demonstrate the usefulness of these algorithms compared with other state-of-the-art approaches .
In this paper , we study the stochastic combinatorial multi-armed bandit ( CMAB ) framework that allows a general nonlinear reward function , whose expected value may not depend only on the means of the input random variables but possibly on the entire distributions of these variables . Our framework enables a much larger class of reward functions such as the $\max ( ) $ function and nonlinear utility functions . Existing techniques relying on accurate estimations of the means of random variables , such as the upper confidence bound ( UCB ) technique , do not work directly on these functions . We propose a new algorithm called stochastically dominant confidence bound ( SDCB ) , which estimates the distributions of underlying random variables and their stochastically dominant confidence bounds . We prove that SDCB can achieve $O ( \log{T} ) $ distribution-dependent regret and $\tilde{O} ( \sqrt{T} ) $ distribution-independent regret , where $T$ is the time horizon . We apply our results to the $K$-MAX problem and expected utility maximization problems . In particular , for $K$-MAX , we provide the first polynomial-time approximation scheme ( PTAS ) for its offline problem , and give the first $\tilde{O} ( \sqrt T ) $ bound on the $ ( 0-\epsilon ) $-approximation regret of its online problem , for any $\epsilon>0$ .
On a periodic basis , publicly traded companies are required to report fundamentals : financial data such as revenue , operating income , debt , among others . These data points provide some insight into the financial health of a company . Academic research has identified some factors , i . e . computed features of the reported data , that are known through retrospective analysis to outperform the market average . Two popular factors are the book value normalized by market capitalization ( book-to-market ) and the operating income normalized by the enterprise value ( EBIT/EV ) . In this paper : we first show through simulation that if we could ( clairvoyantly ) select stocks using factors calculated on future fundamentals ( via oracle ) , then our portfolios would far outperform a standard factor approach . Motivated by this analysis , we train deep neural networks to forecast future fundamentals based on a trailing 0-years window . Quantitative analysis demonstrates a significant improvement in MSE over a naive strategy . Moreover , in retrospective analysis using an industry-grade stock portfolio simulator ( backtester ) , we show an improvement in compounded annual return to 00 . 0% ( MLP ) vs 00 . 0% for a standard factor model .
In the multiple changepoint setting , various search methods have been proposed which involve optimising either a constrained or penalised cost function over possible numbers and locations of changepoints using dynamic programming . Such methods are typically computationally intensive . Recent work in the penalised optimisation setting has focussed on developing a pruning-based approach which gives an improved computational cost that , under certain conditions , is linear in the number of data points . Such an approach naturally requires the specification of a penalty to avoid under/over-fitting . Work has been undertaken to identify the appropriate penalty choice for data generating processes with known distributional form , but in many applications the model assumed for the data is not correct and these penalty choices are not always appropriate . Consequently it is desirable to have an approach that enables us to compare segmentations for different choices of penalty . To this end we present a method to obtain optimal changepoint segmentations of data sequences for all penalty values across a continuous range . This permits an evaluation of the various segmentations to identify a suitably parsimonious penalty choice . The computational complexity of this approach can be linear in the number of data points and linear in the difference between the number of changepoints in the optimal segmentations for the smallest and largest penalty values . This can be orders of magnitude faster than alternative approaches that find optimal segmentations for a range of the number of changepoints .
Image of an entity can be defined as a structured and dynamic representation which can be extracted from the opinions of a group of users or population . Automatic extraction of such an image has certain importance in political science and sociology related studies , e . g . , when an extended inquiry from large-scale data is required . We study the images of two politically significant entities of France . These images are constructed by analyzing the opinions collected from a well known social media called Twitter . Our goal is to build a system which can be used to automatically extract the image of entities over time . In this paper , we propose a novel evolutionary clustering method based on the parametric link among Multinomial mixture models . First we propose the formulation of a generalized model that establishes parametric links among the Multinomial distributions . Afterward , we follow a model-based clustering approach to explore different parametric sub-models and select the best model . For the experiments , first we use synthetic temporal data . Next , we apply the method to analyze the annotated social media data . Results show that the proposed method is better than the state-of-the-art based on the common evaluation metrics . Additionally , our method can provide interpretation about the temporal evolution of the clusters .
Dataset augmentation , the practice of applying a wide array of domain-specific transformations to synthetically expand a training set , is a standard tool in supervised learning . While effective in tasks such as visual recognition , the set of transformations must be carefully designed , implemented , and tested for every new domain , limiting its re-use and generality . In this paper , we adopt a simpler , domain-agnostic approach to dataset augmentation . We start with existing data points and apply simple transformations such as adding noise , interpolating , or extrapolating between them . Our main insight is to perform the transformation not in input space , but in a learned feature space . A re-kindling of interest in unsupervised representation learning makes this technique timely and more effective . It is a simple proposal , but to-date one that has not been tested empirically . Working in the space of context vectors generated by sequence-to-sequence models , we demonstrate a technique that is effective for both static and sequential data .
We consider the problem of reinforcement learning over episodes of a finite-horizon deterministic system and as a solution propose optimistic constraint propagation ( OCP ) , an algorithm designed to synthesize efficient exploration and value function generalization . We establish that when the true value function lies within a given hypothesis class , OCP selects optimal actions over all but at most K episodes , where K is the eluder dimension of the given hypothesis class . We establish further efficiency and asymptotic performance guarantees that apply even if the true value function does not lie in the given hypothesis class , for the special case where the hypothesis class is the span of pre-specified indicator functions over disjoint sets . We also discuss the computational complexity of OCP and present computational results involving two illustrative examples .
The problem of image restoration in cryo-EM entails correcting for the effects of the Contrast Transfer Function ( CTF ) and noise . Popular methods for image restoration include `phase flipping ' , which corrects only for the Fourier phases but not amplitudes , and Wiener filtering , which requires the spectral signal to noise ratio . We propose a new image restoration method which we call `Covariance Wiener Filtering ' ( CWF ) . In CWF , the covariance matrix of the projection images is used within the classical Wiener filtering framework for solving the image restoration deconvolution problem . Our estimation procedure for the covariance matrix is new and successfully corrects for the CTF . We demonstrate the efficacy of CWF by applying it to restore both simulated and experimental cryo-EM images . Results with experimental datasets demonstrate that CWF provides a good way to evaluate the particle images and to see what the dataset contains even without 0D classification and averaging .
Undirected graphical models known as Markov networks are popular for a wide variety of applications ranging from statistical physics to computational biology . Traditionally , learning of the network structure has been done under the assumption of chordality which ensures that efficient scoring methods can be used . In general , non-chordal graphs have intractable normalizing constants which renders the calculation of Bayesian and other scores difficult beyond very small-scale systems . Recently , there has been a surge of interest towards the use of regularized pseudo-likelihood methods for structural learning of large-scale Markov network models , as such an approach avoids the assumption of chordality . The currently available methods typically necessitate the use of a tuning parameter to adapt the level of regularization for a particular dataset , which can be optimized for example by cross-validation . Here we introduce a Bayesian version of pseudo-likelihood scoring of Markov networks , which enables an automatic regularization through marginalization over the nuisance parameters in the model . We prove consistency of the resulting MPL estimator for the network structure via comparison with the pseudo information criterion . Identification of the MPL-optimal network on a prescanned graph space is considered with both greedy hill climbing and exact pseudo-Boolean optimization algorithms . We find that for reasonable sample sizes the hill climbing approach most often identifies networks that are at a negligible distance from the restricted global optimum . Using synthetic and existing benchmark networks , the marginal pseudo-likelihood method is shown to generally perform favorably against recent popular inference methods for Markov networks .
Purely data driven approaches for machine learning present difficulties when data is scarce relative to the complexity of the model or when the model is forced to extrapolate . On the other hand , purely mechanistic approaches need to identify and specify all the interactions in the problem at hand ( which may not be feasible ) and still leave the issue of how to parameterize the system . In this paper , we present a hybrid approach using Gaussian processes and differential equations to combine data driven modelling with a physical model of the system . We show how different , physically-inspired , kernel functions can be developed through sensible , simple , mechanistic assumptions about the underlying system . The versatility of our approach is illustrated with three case studies from motion capture , computational biology and geostatistics .
Random sampling has become a critical tool in solving massive matrix problems . For linear regression , a small , manageable set of data rows can be randomly selected to approximate a tall , skinny data matrix , improving processing time significantly . For theoretical performance guarantees , each row must be sampled with probability proportional to its statistical leverage score . Unfortunately , leverage scores are difficult to compute . A simple alternative is to sample rows uniformly at random . While this often works , uniform sampling will eliminate critical row information for many natural instances . We take a fresh look at uniform sampling by examining what information it does preserve . Specifically , we show that uniform sampling yields a matrix that , in some sense , well approximates a large fraction of the original . While this weak form of approximation is not enough for solving linear regression directly , it is enough to compute a better approximation . This observation leads to simple iterative row sampling algorithms for matrix approximation that run in input-sparsity time and preserve row structure and sparsity at all intermediate steps . In addition to an improved understanding of uniform sampling , our main proof introduces a structural result of independent interest : we show that every matrix can be made to have low coherence by reweighting a small subset of its rows .
We develop an off-policy actor-critic algorithm for learning an optimal policy from a training set composed of data from multiple individuals . This algorithm is developed with a view towards its use in mobile health .
Variational methods are widely used for approximate posterior inference . However , their use is typically limited to families of distributions that enjoy particular conjugacy properties . To circumvent this limitation , we propose a family of variational approximations inspired by nonparametric kernel density estimation . The locations of these kernels and their bandwidth are treated as variational parameters and optimized to improve an approximate lower bound on the marginal likelihood of the data . Using multiple kernels allows the approximation to capture multiple modes of the posterior , unlike most other variational approximations . We demonstrate the efficacy of the nonparametric approximation with a hierarchical logistic regression model and a nonlinear matrix factorization model . We obtain predictive performance as good as or better than more specialized variational methods and sample-based approximations . The method is easy to apply to more general graphical models for which standard variational methods are difficult to derive .
Recently , a framework for application-oriented optimal experiment design has been introduced . In this context , the distance of the estimated system from the true one is measured in terms of a particular end-performance metric . This treatment leads to superior unknown system estimates to classical experiment designs based on usual pointwise functional distances of the estimated system from the true one . The separation of the system estimator from the experiment design is done within this new framework by choosing and fixing the estimation method to either a maximum likelihood ( ML ) approach or a Bayesian estimator such as the minimum mean square error ( MMSE ) . Since the MMSE estimator delivers a system estimate with lower mean square error ( MSE ) than the ML estimator for finite-length experiments , it is usually considered the best choice in practice in signal processing and control applications . Within the application-oriented framework a related meaningful question is : Are there end-performance metrics for which the ML estimator outperforms the MMSE when the experiment is finite-length ? In this paper , we affirmatively answer this question based on a simple linear Gaussian regression example .
Deep neural networks ( DNNs ) have transformed several artificial intelligence research areas including computer vision , speech recognition , and natural language processing . However , recent studies demonstrated that DNNs are vulnerable to adversarial manipulations at testing time . Specifically , suppose we have a testing example , whose label can be correctly predicted by a DNN classifier . An attacker can add a small carefully crafted noise to the testing example such that the DNN classifier predicts an incorrect label , where the crafted testing example is called adversarial example . Such attacks are called evasion attacks . Evasion attacks are one of the biggest challenges for deploying DNNs in safety and security critical applications such as self-driving cars . In this work , we develop new methods to defend against evasion attacks . Our key observation is that adversarial examples are close to the classification boundary . Therefore , we propose region-based classification to be robust to adversarial examples . For a benign/adversarial testing example , we ensemble information in a hypercube centered at the example to predict its label . In contrast , traditional classifiers are point-based classification , i . e . , given a testing example , the classifier predicts its label based on the testing example alone . Our evaluation results on MNIST and CIFAR-00 datasets demonstrate that our region-based classification can significantly mitigate evasion attacks without sacrificing classification accuracy on benign examples . Specifically , our region-based classification achieves the same classification accuracy on testing benign examples as point-based classification , but our region-based classification is significantly more robust than point-based classification to various evasion attacks .
Outlier detection aims to identify unusual data instances that deviate from expected patterns . The outlier detection is particularly challenging when outliers are context dependent and when they are defined by unusual combinations of multiple outcome variable values . In this paper , we develop and study a new conditional outlier detection approach for multivariate outcome spaces that works by ( 0 ) transforming the conditional detection to the outlier detection problem in a new ( unconditional ) space and ( 0 ) defining outlier scores by analyzing the data in the new space . Our approach relies on the classifier chain decomposition of the multi-dimensional classification problem that lets us transform the output space into a probability vector , one probability for each dimension of the output space . Outlier scores applied to these transformed vectors are then used to detect the outliers . Experiments on multiple multi-dimensional classification problems with the different outlier injection rates show that our methodology is robust and able to successfully identify outliers when outliers are either sparse ( manifested in one or very few dimensions ) or dense ( affecting multiple dimensions ) .
Successful implementation of California ' s Renewable Portfolio Standard ( RPS ) mandating 00 percent renewable energy generation by 0000 requires inclusion of a robust strategy to mitigate increased risk of energy deficits ( blackouts ) due to short time-scale ( sub 0 hour ) intermittencies in renewable energy sources . Of these RPS sources , wind energy has the fastest growth rate--over 00% year-over-year . If these growth trends continue , wind energy could make up 00 percent of California ' s energy portfolio by 0000 ( wRPS00 ) . However , the hour-to-hour variations in wind energy ( speed ) will create large hourly energy deficits that require installation of other , more predictable , compensation generation capacity and infrastructure . Compensating for the energy deficits of wRPS00 could potentially cost tens of billions in additional dollar-expenditure for fossil and / or nuclear generation capacity . There is a real possibility that carbon dioxide and other greenhouse gas ( GHG ) emission reductions will miss the California Assembly Bill 00 ( CA AB 00 ) target by a wide margin once the wRPS00 compensation system is in place . This work presents a set of analytics tools that show the impact of short-term intermittencies to help policy makers understand and plan for wRPS00 integration . What are the right policy choices for RPS that include wind energy ?
In high dimensional settings , sparse structures are crucial for efficiency , either in term of memory , computation or performance . In some contexts , it is natural to handle more refined structures than pure sparsity , such as for instance group sparsity . Sparse-Group Lasso has recently been introduced in the context of linear regression to enforce sparsity both at the feature level and at the group level . We adapt to the case of Sparse-Group Lasso recent safe screening rules that discard early in the solver irrelevant features/groups . Such rules have led to important speed-ups for a wide range of iterative methods . Thanks to dual gap computations , we provide new safe screening rules for Sparse-Group Lasso and show significant gains in term of computing time for a coordinate descent implementation .
In statistical genetics an important task involves building predictive models for the genotype-phenotype relationships and thus attribute a proportion of the total phenotypic variance to the variation in genotypes . Numerous models have been proposed to incorporate additive genetic effects into models for prediction or association . However , there is a scarcity of models that can adequately account for gene by gene or other forms of genetical interactions . In addition , there is an increased interest in using marker annotations in genome-wide prediction and association . In this paper , we discuss an hybrid modeling methodology which combines the parametric mixed modeling approach and the non-parametric rule ensembles . This approach gives us a flexible class of models that can be used to capture additive , locally epistatic genetic effects , gene x background interactions and allows us to incorporate one or more annotations into the genomic selection or association models . We use benchmark data sets covering a range of organisms and traits in addition to simulated data sets to illustrate the strengths of this approach . The improvement of model accuracies and association results suggest that a part of the " missing heritability " in complex traits can be captured by modeling local epistasis .
The growing trend of using wearable devices for context-aware computing and pervasive sensing systems has raised its potentials for quick and reliable authentication techniques . Since personal writing habitats differ from each other , it is possible to realize user authentication through writing . This is of great significance as sensible information is easily collected by these devices . This paper presents a novel user authentication system through wrist-worn devices by analyzing the interaction behavior with users , which is both accurate and efficient for future usage . The key feature of our approach lies in using much more effective Savitzky-Golay filter and Dynamic Time Wrapping method to obtain fine-grained writing metrics for user authentication . These new metrics are relatively unique from person to person and independent of the computing platform . Analyses are conducted on the wristband-interaction data collected from 00 users with diversity in gender , age , and height . Extensive experimental results show that the proposed approach can identify users in a timely and accurate manner , with a false-negative rate of 0 . 00\% , false-positive rate of 0 . 0\% , and Area Under ROC Curve of 0 . 000 . Additional examination on robustness to various mimic attacks , tolerance to training data , and comparisons to further analyze the applicability .
We present a recurrent encoder-decoder deep neural network architecture that directly translates speech in one language into text in another . The model does not explicitly transcribe the speech into text in the source language , nor does it require supervision from the ground truth source language transcription during training . We apply a slightly modified sequence-to-sequence with attention architecture that has previously been used for speech recognition and show that it can be repurposed for this more complex task , illustrating the power of attention-based models . A single model trained end-to-end obtains state-of-the-art performance on the Fisher Callhome Spanish-English speech translation task , outperforming a cascade of independently trained sequence-to-sequence speech recognition and machine translation models by 0 . 0 BLEU points on the Fisher test set . In addition , we find that making use of the training data in both languages by multi-task training sequence-to-sequence speech translation and recognition models with a shared encoder network can improve performance by a further 0 . 0 BLEU points .
We consider an online model for recommendation systems , with each user being recommended an item at each time-step and providing ' like ' or ' dislike ' feedback . A latent variable model specifies the user preferences : both users and items are clustered into types . All users of a given type have identical preferences for the items , and similarly , items of a given type are either all liked or all disliked by a given user . The model captures structure in both the item and user spaces , and in this paper , we assume that the type preference matrix is randomly generated . We describe two algorithms inspired by user-user and item-item collaborative filtering ( CF ) , modified to explicitly make exploratory recommendations , and prove performance guarantees in terms of their expected regret . For two regimes of model parameters , with structure only in item space or only in user space , we prove information-theoretic lower bounds on regret that match our upper bounds up to logarithmic factors . Our analysis elucidates system operating regimes in which existing CF algorithms are nearly optimal .
We present a new method for estimating multivariate , second-order stationary Gaussian Random Field ( GRF ) models based on the Sparse Precision matrix Selection ( SPS ) algorithm , proposed by Davanloo et al . ( 0000 ) for estimating scalar GRF models . Theoretical convergence rates for the estimated between-response covariance matrix and for the estimated parameters of the underlying spatial correlation function are established . Numerical tests using simulated and real datasets validate our theoretical findings . Data segmentation is used to handle large data sets .
The successive projection algorithm ( SPA ) can quickly solve a nonnegative matrix factorization problem under a separability assumption . Even if noise is added to the problem , SPA is robust as long as the perturbations caused by the noise are small . In particular , robustness against noise should be high when handling the problems arising from real applications . The preconditioner proposed by Gillis and Vavasis ( 0000 ) makes it possible to enhance the noise robustness of SPA . Meanwhile , an additional computational cost is required . The construction of the preconditioner contains a step to compute the top-$k$ truncated singular value decomposition of an input matrix . It is known that the decomposition provides the best rank-$k$ approximation to the input matrix ; in other words , a matrix with the smallest approximation error among all matrices of rank less than $k$ . This step is an obstacle to an efficient implementation of the preconditioned SPA . To address the cost issue , we propose a modification of the algorithm for constructing the preconditioner . Although the original algorithm uses the best rank-$k$ approximation , instead of it , our modification uses an alternative . Ideally , this alternative should have high approximation accuracy and low computational cost . To ensure this , our modification employs a rank-$k$ approximation produced by an SPA based algorithm . We analyze the accuracy of the approximation and evaluate the computational cost of the algorithm . We then present an empirical study revealing the actual performance of the SPA based rank-$k$ approximation algorithm and the modified preconditioned SPA .
Sparse coding consists in representing signals as sparse linear combinations of atoms selected from a dictionary . We consider an extension of this framework where the atoms are further assumed to be embedded in a tree . This is achieved using a recently introduced tree-structured sparse regularization norm , which has proven useful in several applications . This norm leads to regularized problems that are difficult to optimize , and we propose in this paper efficient algorithms for solving them . More precisely , we show that the proximal operator associated with this norm is computable exactly via a dual approach that can be viewed as the composition of elementary proximal operators . Our procedure has a complexity linear , or close to linear , in the number of atoms , and allows the use of accelerated gradient techniques to solve the tree-structured sparse approximation problem at the same computational cost as traditional ones using the L0-norm . Our method is efficient and scales gracefully to millions of variables , which we illustrate in two types of applications : first , we consider fixed hierarchical dictionaries of wavelets to denoise natural images . Then , we apply our optimization tools in the context of dictionary learning , where learned dictionary elements naturally organize in a prespecified arborescent structure , leading to a better performance in reconstruction of natural image patches . When applied to text documents , our method learns hierarchies of topics , thus providing a competitive alternative to probabilistic topic models .
We study contextual multi-armed bandit problems under linear realizability on rewards and uncertainty ( or noise ) on features . For the case of identical noise on features across actions , we propose an algorithm , coined {\em NLinRel} , having $O\left ( T^{\frac{0}{0}} \left ( \log{ ( dT ) }+K\sqrt{d}\right ) \right ) $ regret bound for $T$ rounds , $K$ actions , and $d$-dimensional feature vectors . Next , for the case of non-identical noise , we observe that popular linear hypotheses including {\em NLinRel} are impossible to achieve such sub-linear regret . Instead , under assumption of Gaussian feature vectors , we prove that a greedy algorithm has $O\left ( T^{\frac00}\sqrt{\log d}\right ) $ regret bound with respect to the optimal linear hypothesis . Utilizing our theoretical understanding on the Gaussian case , we also design a practical variant of {\em NLinRel} , coined {\em Universal-NLinRel} , for arbitrary feature distributions . It first runs {\em NLinRel} for finding the `true ' coefficient vector using feature uncertainties and then adjust it to minimize its regret using the statistical feature information . We justify the performance of {\em Universal-NLinRel} on both synthetic and real-world datasets .
Currently , Markov-Gibbs random field ( MGRF ) image models which include high-order interactions are almost always built by modelling responses of a stack of local linear filters . Actual interaction structure is specified implicitly by the filter coefficients . In contrast , we learn an explicit high-order MGRF structure by considering the learning process in terms of general exponential family distributions nested over base models , so that potentials added later can build on previous ones . We relatively rapidly add new features by skipping over the costly optimisation of parameters . We introduce the use of local binary patterns as features in MGRF texture models , and generalise them by learning offsets to the surrounding pixels . These prove effective as high-order features , and are fast to compute . Several schemes for selecting high-order features by composition or search of a small subclass are compared . Additionally we present a simple modification of the maximum likelihood as a texture modelling-specific objective function which aims to improve generalisation by local windowing of statistics . The proposed method was experimentally evaluated by learning high-order MGRF models for a broad selection of complex textures and then performing texture synthesis , and succeeded on much of the continuum from stochastic through irregularly structured to near-regular textures . Learning interaction structure is very beneficial for textures with large-scale structure , although those with complex irregular structure still provide difficulties . The texture models were also quantitatively evaluated on two tasks and found to be competitive with other works : grading of synthesised textures by a panel of observers ; and comparison against several recent MGRF models by evaluation on a constrained inpainting task .
Undirected graphical models are applied in genomics , protein structure prediction , and neuroscience to identify sparse interactions that underlie discrete data . Although Bayesian methods for inference would be favorable in these contexts , they are rarely used because they require doubly intractable Monte Carlo sampling . Here , we develop a framework for scalable Bayesian inference of discrete undirected models based on two new methods . The first is Persistent VI , an algorithm for variational inference of discrete undirected models that avoids doubly intractable MCMC and approximations of the partition function . The second is Fadeout , a reparameterization approach for variational inference under sparsity-inducing priors that captures a posteriori correlations between parameters and hyperparameters with noncentered parameterizations . We find that , together , these methods for variational inference substantially improve learning of sparse undirected graphical models in simulated and real problems from physics and biology .
We propose a new algorithm to learn a dictionary for reconstructing and sparsely encoding signals from measurements without phase . Specifically , we consider the task of estimating a two-dimensional image from squared-magnitude measurements of a complex-valued linear transformation of the original image . Several recent phase retrieval algorithms exploit underlying sparsity of the unknown signal in order to improve recovery performance . In this work , we consider such a sparse signal prior in the context of phase retrieval , when the sparsifying dictionary is not known in advance . Our algorithm jointly reconstructs the unknown signal - possibly corrupted by noise - and learns a dictionary such that each patch of the estimated image can be sparsely represented . Numerical experiments demonstrate that our approach can obtain significantly better reconstructions for phase retrieval problems with noise than methods that cannot exploit such " hidden " sparsity . Moreover , on the theoretical side , we provide a convergence result for our method .
Multilayer bootstrap network builds a gradually narrowed multilayer nonlinear network from bottom up for unsupervised nonlinear dimensionality reduction . Each layer of the network is a group of k-centers clusterings . Each clustering uses randomly sampled data points with randomly selected features as its centers , and learns a one-of-k encoding by one-nearest-neighbor optimization . Thanks to the binarized encoding , the similarity of two data points is measured by the number of the nearest centers they share in common , which is an adaptive similarity metric in the discrete space that needs no model assumption and parameter tuning . Thanks to the network structure , larger and larger local variations of data are gradually reduced from bottom up . The information loss caused by the binarized encoding is proportional to the correlation of the clusterings , both of which are reduced by the randomization steps .
Singular values of a data in a matrix form provide insights on the structure of the data , the effective dimensionality , and the choice of hyper-parameters on higher-level data analysis tools . However , in many practical applications such as collaborative filtering and network analysis , we only get a partial observation . Under such scenarios , we consider the fundamental problem of recovering spectral properties of the underlying matrix from a sampling of its entries . We are particularly interested in directly recovering the spectrum , which is the set of singular values , and also in sample-efficient approaches for recovering a spectral sum function , which is an aggregate sum of the same function applied to each of the singular values . We propose first estimating the Schatten $k$-norms of a matrix , and then applying Chebyshev approximation to the spectral sum function or applying moment matching in Wasserstein distance to recover the singular values . The main technical challenge is in accurately estimating the Schatten norms from a sampling of a matrix . We introduce a novel unbiased estimator based on counting small structures in a graph and provide guarantees that match its empirical performance . Our theoretical analysis shows that Schatten norms can be recovered accurately from strictly smaller number of samples compared to what is needed to recover the underlying low-rank matrix . Numerical experiments suggest that we significantly improve upon a competing approach of using matrix completion methods .
Policy evaluation or value function or Q-function approximation is a key procedure in reinforcement learning ( RL ) . It is a necessary component of policy iteration and can be used for variance reduction in policy gradient methods . Therefore its quality has a significant impact on most RL algorithms . Motivated by manifold regularized learning , we propose a novel kernelized policy evaluation method that takes advantage of the intrinsic geometry of the state space learned from data , in order to achieve better sample efficiency and higher accuracy in Q-function approximation . Applying the proposed method in the Least-Squares Policy Iteration ( LSPI ) framework , we observe superior performance compared to widely used parametric basis functions on two standard benchmarks in terms of policy quality .
Combining the flexibility of deep learning with Bayesian uncertainty estimation has long been a goal in our field , and many modern approaches are based on variational Bayes . Unfortunately , one is forced to choose between overly simplistic variational families ( e . g . fully factorized ) or expensive and complicated inference procedures . We show that natural gradient ascent with adaptive weight noise can be interpreted as fitting a variational posterior to maximize the evidence lower bound ( ELBO ) . This insight allows us to train full covariance , fully factorized , and matrix variate Gaussian variational posteriors using noisy versions of natural gradient , Adam , and K-FAC , respectively . On standard regression benchmarks , our noisy K-FAC algorithm makes better predictions and matches HMC ' s predictive variances better than existing methods . Its improved uncertainty estimates lead to more efficient exploration in the settings of active learning and intrinsic motivation for reinforcement learning .
We derive a second-order ordinary differential equation ( ODE ) which is the limit of Nesterov ' s accelerated gradient method . This ODE exhibits approximate equivalence to Nesterov ' s scheme and thus can serve as a tool for analysis . We show that the continuous time ODE allows for a better understanding of Nesterov ' s scheme . As a byproduct , we obtain a family of schemes with similar convergence rates . The ODE interpretation also suggests restarting Nesterov ' s scheme leading to an algorithm , which can be rigorously proven to converge at a linear rate whenever the objective is strongly convex .
In this paper , we presented a novel semi-supervised one-class classification algorithm which assumes that class is linearly separable from other elements . We proved theoretically that class is linearly separable if and only if it is maximal by probability within the sets with the same mean . Furthermore , we presented an algorithm for identifying such linearly separable class utilizing linear programming . We described three application cases including an assumption of linear separability , Gaussian distribution , and the case of linear separability in transformed space of kernel functions . Finally , we demonstrated the work of the proposed algorithm on the USPS dataset and analyzed the relationship of the performance of the algorithm and the size of the initially labeled sample .
Increasingly complex generative models are being used across disciplines as they allow for realistic characterization of data , but a common difficulty with them is the prohibitively large computational cost to evaluate the likelihood function and thus to perform likelihood-based statistical inference . A likelihood-free inference framework has emerged where the parameters are identified by finding values that yield simulated data resembling the observed data . While widely applicable , a major difficulty in this framework is how to measure the discrepancy between the simulated and observed data . Transforming the original problem into a problem of classifying the data into simulated versus observed , we find that classification accuracy can be used to assess the discrepancy . The complete arsenal of classification methods becomes thereby available for inference of intractable generative models . We validate our approach using theory and simulations for both point estimation and Bayesian inference , and demonstrate its use on real data by inferring an individual-based epidemiological model for bacterial infections in child care centers .
Crowdsourcing systems are popular for solving large-scale labelling tasks with low-paid workers . We study the problem of recovering the true labels from the possibly erroneous crowdsourced labels under the popular Dawid-Skene model . To address this inference problem , several algorithms have recently been proposed , but the best known guarantee is still significantly larger than the fundamental limit . We close this gap by introducing a tighter lower bound on the fundamental limit and proving that Belief Propagation ( BP ) exactly matches this lower bound . The guaranteed optimality of BP is the strongest in the sense that it is information-theoretically impossible for any other algorithm to correctly label a larger fraction of the tasks . Experimental results suggest that BP is close to optimal for all regimes considered and improves upon competing state-of-the-art algorithms .
We describe the Fast Greedy Sparse Subspace Clustering ( FGSSC ) algorithm providing an efficient method for clustering data belonging to a few low-dimensional linear or affine subspaces . The main difference of our algorithm from predecessors is its ability to work with noisy data having a high rate of erasures ( missed entries with the known coordinates ) and errors ( corrupted entries with unknown coordinates ) . We discuss here how to implement the fast version of the greedy algorithm with the maximum efficiency whose greedy strategy is incorporated into iterations of the basic algorithm . We provide numerical evidences that , in the subspace clustering capability , the fast greedy algorithm outperforms not only the existing state-of-the art SSC algorithm taken by the authors as a basic algorithm but also the recent GSSC algorithm . At the same time , its computational cost is only slightly higher than the cost of SSC . The numerical evidence of the algorithm significant advantage is presented for a few synthetic models as well as for the Extended Yale B dataset of facial images . In particular , the face recognition misclassification rate turned out to be 0-00 times lower than for the SSC algorithm . We provide also the numerical evidence that the FGSSC algorithm is able to perform clustering of corrupted data efficiently even when the sum of subspace dimensions significantly exceeds the dimension of the ambient space .
Neural recordings are nonstationary time series , i . e . their properties typically change over time . Identifying specific changes , e . g . those induced by a learning task , can shed light on the underlying neural processes . However , such changes of interest are often masked by strong unrelated changes , which can be of physiological origin or due to measurement artifacts . We propose a novel algorithm for disentangling such different causes of non-stationarity and in this manner enable better neurophysiological interpretation for a wider set of experimental paradigms . A key ingredient is the repeated application of Stationary Subspace Analysis ( SSA ) using different temporal scales . The usefulness of our explorative approach is demonstrated in simulations , theory and EEG experiments with 00 Brain-Computer-Interfacing ( BCI ) subjects .
We present a numerical algorithm for nonnegative matrix factorization ( NMF ) problems under noisy separability . An NMF problem under separability can be stated as one of finding all vertices of the convex hull of data points . The research interest of this paper is to find the vectors as close to the vertices as possible in a situation in which noise is added to the data points . Our algorithm is designed to capture the shape of the convex hull of data points by using its enclosing ellipsoid . We show that the algorithm has correctness and robustness properties from theoretical and practical perspectives ; correctness here means that if the data points do not contain any noise , the algorithm can find the vertices of their convex hull ; robustness means that if the data points contain noise , the algorithm can find the near-vertices . Finally , we apply the algorithm to document clustering , and report the experimental results .
In this paper , we take a new look at the possibilistic c-means ( PCM ) and adaptive PCM ( APCM ) clustering algorithms from the perspective of uncertainty . This new perspective offers us insights into the clustering process , and also provides us greater degree of flexibility . We analyze the clustering behavior of PCM-based algorithms and introduce parameters $\sigma_v$ and $\alpha$ to characterize uncertainty of estimated bandwidth and noise level of the dataset respectively . Then uncertainty ( fuzziness ) of membership values caused by uncertainty of the estimated bandwidth parameter is modeled by a conditional fuzzy set , which is a new formulation of the type-0 fuzzy set . Experiments show that parameters $\sigma_v$ and $\alpha$ make the clustering process more easy to control , and main features of PCM and APCM are unified in this new clustering framework ( UPCM ) . More specifically , UPCM reduces to PCM when we set a small $\alpha$ or a large $\sigma_v$ , and UPCM reduces to APCM when clusters are confined in their physical clusters and possible cluster elimination are ensured . Finally we present further researches of this paper .
Networks capture our intuition about relationships in the world . They describe the friendships between Facebook users , interactions in financial markets , and synapses connecting neurons in the brain . These networks are richly structured with cliques of friends , sectors of stocks , and a smorgasbord of cell types that govern how neurons connect . Some networks , like social network friendships , can be directly observed , but in many cases we only have an indirect view of the network through the actions of its constituents and an understanding of how the network mediates that activity . In this work , we focus on the problem of latent network discovery in the case where the observable activity takes the form of a mutually-excitatory point process known as a Hawkes process . We build on previous work that has taken a Bayesian approach to this problem , specifying prior distributions over the latent network structure and a likelihood of observed activity given this network . We extend this work by proposing a discrete-time formulation and developing a computationally efficient stochastic variational inference ( SVI ) algorithm that allows us to scale the approach to long sequences of observations . We demonstrate our algorithm on the calcium imaging data used in the Chalearn neural connectomics challenge .
Autonomous driving is a multi-agent setting where the host vehicle must apply sophisticated negotiation skills with other road users when overtaking , giving way , merging , taking left and right turns and while pushing ahead in unstructured urban roadways . Since there are many possible scenarios , manually tackling all possible cases will likely yield a too simplistic policy . Moreover , one must balance between unexpected behavior of other drivers/pedestrians and at the same time not to be too defensive so that normal traffic flow is maintained . In this paper we apply deep reinforcement learning to the problem of forming long term driving strategies . We note that there are two major challenges that make autonomous driving different from other robotic tasks . First , is the necessity for ensuring functional safety - something that machine learning has difficulty with given that performance is optimized at the level of an expectation over many instances . Second , the Markov Decision Process model often used in robotics is problematic in our case because of unpredictable behavior of other agents in this multi-agent scenario . We make three contributions in our work . First , we show how policy gradient iterations can be used without Markovian assumptions . Second , we decompose the problem into a composition of a Policy for Desires ( which is to be learned ) and trajectory planning with hard constraints ( which is not learned ) . The goal of Desires is to enable comfort of driving , while hard constraints guarantees the safety of driving . Third , we introduce a hierarchical temporal abstraction we call an " Option Graph " with a gating mechanism that significantly reduces the effective horizon and thereby reducing the variance of the gradient estimation even further .
The process of dynamic state estimation ( filtering ) based on point process observations is in general intractable . Numerical sampling techniques are often practically useful , but lead to limited conceptual insight about optimal encoding/decoding strategies , which are of significant relevance to Computational Neuroscience . We develop an analytically tractable Bayesian approximation to optimal filtering based on point process observations , which allows us to introduce distributional assumptions about sensory cell properties , that greatly facilitates the analysis of optimal encoding in situations deviating from common assumptions of uniform coding . The analytic framework leads to insights which are difficult to obtain from numerical algorithms , and is consistent with experiments about the distribution of tuning curve centers . Interestingly , we find that the information gained from the absence of spikes may be crucial to performance .
Bayesian models provide a framework for probabilistic modelling of complex datasets . However , many of such models are computationally demanding especially in the presence of large datasets . On the other hand , in sensor network applications , statistical ( Bayesian ) parameter estimation usually needs distributed algorithms , in which both data and computation are distributed across the nodes of the network . In this paper we propose a general framework for distributed Bayesian learning using Bregman Alternating Direction Method of Multipliers ( B-ADMM ) . We demonstrate the utility of our framework , with Mean Field Variational Bayes ( MFVB ) as the primitive for distributed Matrix Factorization ( MF ) and distributed affine structure from motion ( SfM ) .
Research on probabilistic models of networks now spans a wide variety of fields , including physics , sociology , biology , statistics , and machine learning . These efforts have produced a diverse ecology of models and methods . Despite this diversity , many of these models share a common underlying structure : pairwise interactions ( edges ) are generated with probability conditional on latent vertex attributes . Differences between models generally stem from different philosophical choices about how to learn from data or different empirically-motivated goals . The highly interdisciplinary nature of work on these generative models , however , has inhibited the development of a unified view of their similarities and differences . For instance , novel theoretical models and optimization techniques developed in machine learning are largely unknown within the social and biological sciences , which have instead emphasized model interpretability . Here , we describe a unified view of generative models for networks that draws together many of these disparate threads and highlights the fundamental similarities and differences that span these fields . We then describe a number of opportunities and challenges for future work that are revealed by this view .
Constraint-based causal discovery ( CCD ) algorithms require fast and accurate conditional independence ( CI ) testing . The Kernel Conditional Independence Test ( KCIT ) is currently one of the most popular CI tests in the non-parametric setting , but many investigators cannot use KCIT with large datasets because the test scales cubicly with sample size . We therefore devise two relaxations called the Randomized Conditional Independence Test ( RCIT ) and the Randomized conditional Correlation Test ( RCoT ) which both approximate KCIT by utilizing random Fourier features . In practice , both of the proposed tests scale linearly with sample size and return accurate p-values much faster than KCIT in the large sample size context . CCD algorithms run with RCIT or RCoT also return graphs at least as accurate as the same algorithms run with KCIT but with large reductions in run time .
Large-scale recurrent networks have drawn increasing attention recently because of their capabilities in modeling a large variety of real-world phenomena and physical mechanisms . This paper studies how to identify all authentic connections and estimate system parameters of a recurrent network , given a sequence of node observations . This task becomes extremely challenging in modern network applications , because the available observations are usually very noisy and limited , and the associated dynamical system is strongly nonlinear . By formulating the problem as multivariate sparse sigmoidal regression , we develop simple-to-implement network learning algorithms , with rigorous convergence guarantee in theory , for a variety of sparsity-promoting penalty forms . A quantile variant of progressive recurrent network screening is proposed for efficient computation and allows for direct cardinality control of network topology in estimation . Moreover , we investigate recurrent network stability conditions in Lyapunov ' s sense , and integrate such stability constraints into sparse network learning . Experiments show excellent performance of the proposed algorithms in network topology identification and forecasting .
We present a new approach for learning compact and intuitive distributed representations with binary encoding . Rather than summing up expert votes as in products of experts , we employ for each variable the opinion of the most reliable expert . Data points are hence explained through a partitioning of the variables into expert supports . The partitions are dynamically adapted based on which experts are active . During the learning phase we adopt a smoothed version of this model that uses separate mixtures for each data dimension . In our experiments we achieve accurate reconstructions of high-dimensional data points with at most a dozen experts .
Deep learning takes advantage of large datasets and computationally efficient training algorithms to outperform other approaches at various machine learning tasks . However , imperfections in the training phase of deep neural networks make them vulnerable to adversarial samples : inputs crafted by adversaries with the intent of causing deep neural networks to misclassify . In this work , we formalize the space of adversaries against deep neural networks ( DNNs ) and introduce a novel class of algorithms to craft adversarial samples based on a precise understanding of the mapping between inputs and outputs of DNNs . In an application to computer vision , we show that our algorithms can reliably produce samples correctly classified by human subjects but misclassified in specific targets by a DNN with a 00% adversarial success rate while only modifying on average 0 . 00% of the input features per sample . We then evaluate the vulnerability of different sample classes to adversarial perturbations by defining a hardness measure . Finally , we describe preliminary work outlining defenses against adversarial samples by defining a predictive measure of distance between a benign input and a target classification .
Several problems such as network intrusion , community detection , and disease outbreak can be described by observations attributed to nodes or edges of a graph . In these applications presence of intrusion , community or disease outbreak is characterized by novel observations on some unknown connected subgraph . These problems can be formulated in terms of optimization of suitable objectives on connected subgraphs , a problem which is generally computationally difficult . We overcome the combinatorics of connectivity by embedding connected subgraphs into linear matrix inequalities ( LMI ) . Computationally efficient tests are then realized by optimizing convex objective functions subject to these LMI constraints . We prove , by means of a novel Euclidean embedding argument , that our tests are minimax optimal for exponential family of distributions on 0-D and 0-D lattices . We show that internal conductance of the connected subgraph family plays a fundamental role in characterizing detectability .
We address some theoretical guarantees for Schatten-$p$ quasi-norm minimization ( $p \in ( 0 , 0]$ ) in recovering low-rank matrices from compressed linear measurements . Firstly , using null space properties of the measurement operator , we provide a sufficient condition for exact recovery of low-rank matrices . This condition guarantees unique recovery of matrices of ranks equal or larger than what is guaranteed by nuclear norm minimization . Secondly , this sufficient condition leads to a theorem proving that all restricted isometry property ( RIP ) based sufficient conditions for $\ell_p$ quasi-norm minimization generalize to Schatten-$p$ quasi-norm minimization . Based on this theorem , we provide a few RIP-based recovery conditions .
Neural networks have recently had a lot of success for many tasks . However , neural network architectures that perform well are still typically designed manually by experts in a cumbersome trial-and-error process . We propose a new method to automatically search for well-performing CNN architectures based on a simple hill climbing procedure whose operators apply network morphisms , followed by short optimization runs by cosine annealing . Surprisingly , this simple method yields competitive results , despite only requiring resources in the same order of magnitude as training a single network . E . g . , on CIFAR-00 , our method designs and trains networks with an error rate below 0% in only 00 hours on a single GPU ; training for one day reduces this error further , to almost 0% .
GROUSE ( Grassmannian Rank-One Update Subspace Estimation ) is an incremental algorithm for identifying a subspace of Rn from a sequence of vectors in this subspace , where only a subset of components of each vector is revealed at each iteration . Recent analysis has shown that GROUSE converges locally at an expected linear rate , under certain assumptions . GROUSE has a similar flavor to the incremental singular value decomposition algorithm , which updates the SVD of a matrix following addition of a single column . In this paper , we modify the incremental SVD approach to handle missing data , and demonstrate that this modified approach is equivalent to GROUSE , for a certain choice of an algorithmic parameter .
We describe a new instance-based learning algorithm called the Boundary Forest ( BF ) algorithm , that can be used for supervised and unsupervised learning . The algorithm builds a forest of trees whose nodes store previously seen examples . It can be shown data points one at a time and updates itself incrementally , hence it is naturally online . Few instance-based algorithms have this property while being simultaneously fast , which the BF is . This is crucial for applications where one needs to respond to input data in real time . The number of children of each node is not set beforehand but obtained from the training procedure , which makes the algorithm very flexible with regards to what data manifolds it can learn . We test its generalization performance and speed on a range of benchmark datasets and detail in which settings it outperforms the state of the art . Empirically we find that training time scales as O ( DNlog ( N ) ) and testing as O ( Dlog ( N ) ) , where D is the dimensionality and N the amount of data ,
Recent advances in conditional recurrent language modelling have mainly focused on network architectures ( e . g . , attention mechanism ) , learning algorithms ( e . g . , scheduled sampling and sequence-level training ) and novel applications ( e . g . , image/video description generation , speech recognition , etc . ) On the other hand , we notice that decoding algorithms/strategies have not been investigated as much , and it has become standard to use greedy or beam search . In this paper , we propose a novel decoding strategy motivated by an earlier observation that nonlinear hidden layers of a deep neural network stretch the data manifold . The proposed strategy is embarrassingly parallelizable without any communication overhead , while improving an existing decoding algorithm . We extensively evaluate it with attention-based neural machine translation on the task of En->Cz translation .
Generative adversarial networks ( GANs ) transform latent vectors into visually plausible images . It is generally thought that the original GAN formulation gives no out-of-the-box method to reverse the mapping , projecting images back into latent space . We introduce a simple , gradient-based technique called stochastic clipping . In experiments , for images generated by the GAN , we precisely recover their latent vector pre-images 000% of the time . Additional experiments demonstrate that this method is robust to noise . Finally , we show that even for unseen images , our method appears to recover unique encodings .
Testing ( conditional ) independence of multivariate random variables is a task central to statistical inference and modelling in general - though unfortunately one for which to date there does not exist a practicable workflow . State-of-art workflows suffer from the need for heuristic or subjective manual choices , high computational complexity , or strong parametric assumptions . We address these problems by establishing a theoretical link between multivariate/conditional independence testing , and model comparison in the multivariate predictive modelling aka supervised learning task . This link allows advances in the extensively studied supervised learning workflow to be directly transferred to independence testing workflows - including automated tuning of machine learning type which addresses the need for a heuristic choice , the ability to quantitatively trade-off computational demand with accuracy , and the modern black-box philosophy for checking and interfacing . As a practical implementation of this link between the two workflows , we present a python package ' pcit ' , which implements our novel multivariate and conditional independence tests , interfacing the supervised learning API of the scikit-learn package . Theory and package also allow for straightforward independence test based learning of graphical model structure . We empirically show that our proposed predictive independence test outperform or are on par to current practice , and the derived graphical model structure learning algorithms asymptotically recover the ' true ' graph . This paper , and the ' pcit ' package accompanying it , thus provide powerful , scalable , generalizable , and easy-to-use methods for multivariate and conditional independence testing , as well as for graphical model structure learning .
Learning from prior tasks and transferring that experience to improve future performance is critical for building lifelong learning agents . Although results in supervised and reinforcement learning show that transfer may significantly improve the learning performance , most of the literature on transfer is focused on batch learning tasks . In this paper we study the problem of \textit{sequential transfer in online learning} , notably in the multi-armed bandit framework , where the objective is to minimize the cumulative regret over a sequence of tasks by incrementally transferring knowledge from prior tasks . We introduce a novel bandit algorithm based on a method-of-moments approach for the estimation of the possible tasks and derive regret bounds for it .
We propose an algorithm for the non-negative factorization of an occurrence tensor built from heterogeneous networks . We use l0 norm to model sparse errors over discrete values ( occurrences ) , and use decomposed factors to model the embedded groups of nodes . An efficient splitting method is developed to optimize the nonconvex and nonsmooth objective . We study both synthetic problems and a new dataset built from financial documents , resMBS .
Kernel methods are ubiquitous tools in machine learning . They have proven to be effective in many domains and tasks . Yet , kernel methods often require the user to select a predefined kernel to build an estimator with . However , there is often little reason for the a priori selection of a kernel . Even if a universal approximating kernel is selected , the quality of the finite sample estimator may be greatly effected by the choice of kernel . Furthermore , when directly applying kernel methods , one typically needs to compute a $N \times N$ Gram matrix of pairwise kernel evaluations to work with a dataset of $N$ instances . The computation of this Gram matrix precludes the direct application of kernel methods on large datasets . In this paper we introduce Bayesian nonparmetric kernel ( BaNK ) learning , a generic , data-driven framework for scalable learning of kernels . We show that this framework can be used for performing both regression and classification tasks and scale to large datasets . Furthermore , we show that BaNK outperforms several other scalable approaches for kernel learning on a variety of real world datasets .
We propose a Bayesian model that predicts recovery curves based on information available before the disruptive event . A recovery curve of interest is the quantified sexual function of prostate cancer patients after prostatectomy surgery . We illustrate the utility of our model as a pre-treatment medical decision aid , producing personalized predictions that are both interpretable and accurate . We uncover covariate relationships that agree with and supplement that in existing medical literature .
This paper shows that a perturbed form of gradient descent converges to a second-order stationary point in a number iterations which depends only poly-logarithmically on dimension ( i . e . , it is almost " dimension-free " ) . The convergence rate of this procedure matches the well-known convergence rate of gradient descent to first-order stationary points , up to log factors . When all saddle points are non-degenerate , all second-order stationary points are local minima , and our result thus shows that perturbed gradient descent can escape saddle points almost for free . Our results can be directly applied to many machine learning applications , including deep learning . As a particular concrete example of such an application , we show that our results can be used directly to establish sharp global convergence rates for matrix factorization . Our results rely on a novel characterization of the geometry around saddle points , which may be of independent interest to the non-convex optimization community .
Inference is typically intractable in high-treewidth undirected graphical models , making maximum likelihood learning a challenge . One way to overcome this is to restrict parameters to a tractable set , most typically the set of tree-structured parameters . This paper explores an alternative notion of a tractable set , namely a set of " fast-mixing parameters " where Markov chain Monte Carlo ( MCMC ) inference can be guaranteed to quickly converge to the stationary distribution . While it is common in practice to approximate the likelihood gradient using samples obtained from MCMC , such procedures lack theoretical guarantees . This paper proves that for any exponential family with bounded sufficient statistics , ( not just graphical models ) when parameters are constrained to a fast-mixing set , gradient descent with gradients approximated by sampling will approximate the maximum likelihood solution inside the set with high-probability . When unregularized , to find a solution epsilon-accurate in log-likelihood requires a total amount of effort cubic in 0/epsilon , disregarding logarithmic factors . When ridge-regularized , strong convexity allows a solution epsilon-accurate in parameter distance with effort quadratic in 0/epsilon . Both of these provide of a fully-polynomial time randomized approximation scheme .
Recent results in Compressive Sensing have shown that , under certain conditions , the solution to an underdetermined system of linear equations with sparsity-based regularization can be accurately recovered by solving convex relaxations of the original problem . In this work , we present a novel primal-dual analysis on a class of sparsity minimization problems . We show that the Lagrangian bidual ( i . e . , the Lagrangian dual of the Lagrangian dual ) of the sparsity minimization problems can be used to derive interesting convex relaxations : the bidual of the $\ell_0$-minimization problem is the $\ell_0$-minimization problem ; and the bidual of the $\ell_{0 , 0}$-minimization problem for enforcing group sparsity on structured data is the $\ell_{0 , \infty}$-minimization problem . The analysis provides a means to compute per-instance non-trivial lower bounds on the ( group ) sparsity of the desired solutions . In a real-world application , the bidual relaxation improves the performance of a sparsity-based classification framework applied to robust face recognition .
It was shown recently that the $K$ L0-norm principal components ( L0-PCs ) of a real-valued data matrix $\mathbf X \in \mathbb R^{D \times N}$ ( $N$ data samples of $D$ dimensions ) can be exactly calculated with cost $\mathcal{O} ( 0^{NK} ) $ or , when advantageous , $\mathcal{O} ( N^{dK - K + 0} ) $ where $d=\mathrm{rank} ( \mathbf X ) $ , $K<d$ [0] , [0] . In applications where $\mathbf X$ is large ( e . g . , " big " data of large $N$ and/or " heavy " data of large $d$ ) , these costs are prohibitive . In this work , we present a novel suboptimal algorithm for the calculation of the $K < d$ L0-PCs of $\mathbf X$ of cost $\mathcal O ( ND \mathrm{min} \{ N , D\} + N^0 ( K^0 + dK^0 ) + dNK^0 ) $ , which is comparable to that of standard ( L0-norm ) PC analysis . Our theoretical and experimental studies show that the proposed algorithm calculates the exact optimal L0-PCs with high frequency and achieves higher value in the L0-PC optimization metric than any known alternative algorithm of comparable computational cost . The superiority of the calculated L0-PCs over standard L0-PCs ( singular vectors ) in characterizing potentially faulty data/measurements is demonstrated with experiments on data dimensionality reduction and disease diagnosis from genomic data .
An important result from psycholinguistics ( Griffiths & Kalish , 0000 ) states that no language can be learned iteratively by rational agents in a self-sustaining manner . We show how to modify the learning process slightly in order to achieve self-sustainability . Our work is in two parts . First , we characterize iterated learnability in geometric terms and show how a slight , steady increase in the lengths of the training sessions ensures self-sustainability for any discrete language class . In the second part , we tackle the nondiscrete case and investigate self-sustainability for iterated linear regression . We discuss the implications of our findings to issues of non-equilibrium dynamics in natural algorithms .
This paper tackles the problem of selecting among several linear estimators in non-parametric regression ; this includes model selection for linear regression , the choice of a regularization parameter in kernel ridge regression , spline smoothing or locally weighted regression , and the choice of a kernel in multiple kernel learning . We propose a new algorithm which first estimates consistently the variance of the noise , based upon the concept of minimal penalty , which was previously introduced in the context of model selection . Then , plugging our variance estimate in Mallows ' $C_L$ penalty is proved to lead to an algorithm satisfying an oracle inequality . Simulation experiments with kernel ridge regression and multiple kernel learning show that the proposed algorithm often improves significantly existing calibration procedures such as generalized cross-validation .
Data often comes in the form of an array or matrix . Matrix factorization techniques attempt to recover missing or corrupted entries by assuming that the matrix can be written as the product of two low-rank matrices . In other words , matrix factorization approximates the entries of the matrix by a simple , fixed function---namely , the inner product---acting on the latent feature vectors for the corresponding row and column . Here we consider replacing the inner product by an arbitrary function that we learn from the data at the same time as we learn the latent feature vectors . In particular , we replace the inner product by a multi-layer feed-forward neural network , and learn by alternating between optimizing the network for fixed latent features , and optimizing the latent features for a fixed network . The resulting approach---which we call neural network matrix factorization or NNMF , for short---dominates standard low-rank techniques on a suite of benchmark but is dominated by some recent proposals that take advantage of the graph features . Given the vast range of architectures , activation functions , regularizers , and optimization techniques that could be used within the NNMF framework , it seems likely the true potential of the approach has yet to be reached .
The mirror descent algorithm ( MDA ) generalizes gradient descent by using a Bregman divergence to replace squared Euclidean distance . In this paper , we similarly generalize the alternating direction method of multipliers ( ADMM ) to Bregman ADMM ( BADMM ) , which allows the choice of different Bregman divergences to exploit the structure of problems . BADMM provides a unified framework for ADMM and its variants , including generalized ADMM , inexact ADMM and Bethe ADMM . We establish the global convergence and the $O ( 0/T ) $ iteration complexity for BADMM . In some cases , BADMM can be faster than ADMM by a factor of $O ( n/\log ( n ) ) $ . In solving the linear program of mass transportation problem , BADMM leads to massive parallelism and can easily run on GPU . BADMM is several times faster than highly optimized commercial software Gurobi .
Variable selection in high dimensional space has challenged many contemporary statistical problems from many frontiers of scientific disciplines . Recent technology advance has made it possible to collect a huge amount of covariate information such as microarray , proteomic and SNP data via bioimaging technology while observing survival information on patients in clinical studies . Thus , the same challenge applies to the survival analysis in order to understand the association between genomics information and clinical information about the survival time . In this work , we extend the sure screening procedure Fan and Lv ( 0000 ) to Cox ' s proportional hazards model with an iterative version available . Numerical simulation studies have shown encouraging performance of the proposed method in comparison with other techniques such as LASSO . This demonstrates the utility and versatility of the iterative sure independent screening scheme .
Large datasets often have unreliable labels-such as those obtained from Amazon ' s Mechanical Turk or social media platforms-and classifiers trained on mislabeled datasets often exhibit poor performance . We present a simple , effective technique for accounting for label noise when training deep neural networks . We augment a standard deep network with a softmax layer that models the label noise statistics . Then , we train the deep network and noise model jointly via end-to-end stochastic gradient descent on the ( perhaps mislabeled ) dataset . The augmented model is overdetermined , so in order to encourage the learning of a non-trivial noise model , we apply dropout regularization to the weights of the noise model during training . Numerical experiments on noisy versions of the CIFAR-00 and MNIST datasets show that the proposed dropout technique outperforms state-of-the-art methods .
Spectral clustering has become a popular technique due to its high performance in many contexts . It comprises three main steps : create a similarity graph between N objects to cluster , compute the first k eigenvectors of its Laplacian matrix to define a feature vector for each object , and run k-means on these features to separate objects into k classes . Each of these three steps becomes computationally intensive for large N and/or k . We propose to speed up the last two steps based on recent results in the emerging field of graph signal processing : graph filtering of random signals , and random sampling of bandlimited graph signals . We prove that our method , with a gain in computation time that can reach several orders of magnitude , is in fact an approximation of spectral clustering , for which we are able to control the error . We test the performance of our method on artificial and real-world network data .
We introduce a new method for training deep Boltzmann machines jointly . Prior methods require an initial learning pass that trains the deep Boltzmann machine greedily , one layer at a time , or do not perform well on classifi- cation tasks .
The use of Bayesian methods in large-scale data settings is attractive because of the rich hierarchical models , uncertainty quantification , and prior specification they provide . Standard Bayesian inference algorithms are computationally expensive , however , making their direct application to large datasets difficult or infeasible . Recent work on scaling Bayesian inference has focused on modifying the underlying algorithms to , for example , use only a random data subsample at each iteration . We leverage the insight that data is often redundant to instead obtain a weighted subset of the data ( called a coreset ) that is much smaller than the original dataset . We can then use this small coreset in any number of existing posterior inference algorithms without modification . In this paper , we develop an efficient coreset construction algorithm for Bayesian logistic regression models . We provide theoretical guarantees on the size and approximation quality of the coreset -- both for fixed , known datasets , and in expectation for a wide class of data generative models . Crucially , the proposed approach also permits efficient construction of the coreset in both streaming and parallel settings , with minimal additional effort . We demonstrate the efficacy of our approach on a number of synthetic and real-world datasets , and find that , in practice , the size of the coreset is independent of the original dataset size . Furthermore , constructing the coreset takes a negligible amount of time compared to that required to run MCMC on it .
We introduce stochastic variational inference for Gaussian process models . This enables the application of Gaussian process ( GP ) models to data sets containing millions of data points . We show how GPs can be vari- ationally decomposed to depend on a set of globally relevant inducing variables which factorize the model in the necessary manner to perform variational inference . Our ap- proach is readily extended to models with non-Gaussian likelihoods and latent variable models based around Gaussian processes . We demonstrate the approach on a simple toy problem and two real world data sets .
Inspired by recent advances in deep learning , we propose a novel iterative BP-CNN architecture for channel decoding under correlated noise . This architecture concatenates a trained convolutional neural network ( CNN ) with a standard belief-propagation ( BP ) decoder . The standard BP decoder is used to estimate the coded bits , followed by a CNN to remove the estimation errors of the BP decoder and obtain a more accurate estimation of the channel noise . Iterating between BP and CNN will gradually improve the decoding SNR and hence result in better decoding performance . To train a well-behaved CNN model , we define a new loss function which involves not only the accuracy of the noise estimation but also the normality test for the estimation errors , i . e . , to measure how likely the estimation errors follow a Gaussian distribution . The introduction of the normality test to the CNN training shapes the residual noise distribution and further reduces the BER of the iterative decoding , compared to using the standard quadratic loss function . We carry out extensive experiments to analyze and verify the proposed framework . The iterative BP-CNN decoder has better BER performance with lower complexity , is suitable for parallel implementation , does not rely on any specific channel model or encoding method , and is robust against training mismatches . All of these features make it a good candidate for decoding modern channel codes .
Non-negative matrix factorization ( NMF ) is a new knowledge discovery method that is used for text mining , signal processing , bioinformatics , and consumer analysis . However , its basic property as a learning machine is not yet clarified , as it is not a regular statistical model , resulting that theoretical optimization method of NMF has not yet established . In this paper , we study the real log canonical threshold of NMF and give an upper bound of the generalization error in Bayesian learning . The results show that the generalization error of the matrix factorization can be made smaller than regular statistical models if Bayesian learning is applied .
Successful attempts to predict judges ' votes shed light into how legal decisions are made and , ultimately , into the behavior and evolution of the judiciary . Here , we investigate to what extent it is possible to make predictions of a justice ' s vote based on the other justices ' votes in the same case . For our predictions , we use models and methods that have been developed to uncover hidden associations between actors in complex social networks . We show that these methods are more accurate at predicting justice ' s votes than forecasts made by legal experts and by algorithms that take into consideration the content of the cases . We argue that , within our framework , high predictability is a quantitative proxy for stable justice ( and case ) blocks , which probably reflect stable a priori attitudes toward the law . We find that U . S . Supreme Court justice votes are more predictable than one would expect from an ideal court composed of perfectly independent justices . Deviations from ideal behavior are most apparent in divided 0-0 decisions , where justice blocks seem to be most stable . Moreover , we find evidence that justice predictability decreased during the 00-year period spanning from the Warren Court to the Rehnquist Court , and that aggregate court predictability has been significantly lower during Democratic presidencies . More broadly , our results show that it is possible to use methods developed for the analysis of complex social networks to quantitatively investigate historical questions related to political decision-making .
Sources of variability in experimentally derived data include measurement error in addition to the physical phenomena of interest . This measurement error is a combination of systematic components , originating from the measuring instrument , and random measurement errors . Several novel biological technologies , such as mass cytometry and single-cell RNA-seq , are plagued with systematic errors that may severely affect statistical analysis if the data is not properly calibrated . We propose a novel deep learning approach for removing systematic batch effects . Our method is based on a residual network , trained to minimize the Maximum Mean Discrepancy ( MMD ) between the multivariate distributions of two replicates , measured in different batches . We apply our method to mass cytometry and single-cell RNA-seq datasets , and demonstrate that it effectively attenuates batch effects .
We study in this paper the consequences of using the Mean Absolute Percentage Error ( MAPE ) as a measure of quality for regression models . We show that finding the best model under the MAPE is equivalent to doing weighted Mean Absolute Error ( MAE ) regression . We also show that , under some asumptions , universal consistency of Empirical Risk Minimization remains possible using the MAPE .
Understanding the nature of dark energy , the mysterious force driving the accelerated expansion of the Universe , is a major challenge of modern cosmology . The next generation of cosmological surveys , specifically designed to address this issue , rely on accurate measurements of the apparent shapes of distant galaxies . However , shape measurement methods suffer from various unavoidable biases and therefore will rely on a precise calibration to meet the accuracy requirements of the science analysis . This calibration process remains an open challenge as it requires large sets of high quality galaxy images . To this end , we study the application of deep conditional generative models in generating realistic galaxy images . In particular we consider variations on conditional variational autoencoder and introduce a new adversarial objective for training of conditional generative networks . Our results suggest a reliable alternative to the acquisition of expensive high quality observations for generating the calibration data needed by the next generation of cosmological surveys .
Developers of text-to-speech synthesizers ( TTS ) often make use of human raters to assess the quality of synthesized speech . We demonstrate that we can model human raters ' mean opinion scores ( MOS ) of synthesized speech using a deep recurrent neural network whose inputs consist solely of a raw waveform . Our best models provide utterance-level estimates of MOS only moderately inferior to sampled human ratings , as shown by Pearson and Spearman correlations . When multiple utterances are scored and averaged , a scenario common in synthesizer quality assessment , AutoMOS achieves correlations approaching those of human raters . The AutoMOS model has a number of applications , such as the ability to explore the parameter space of a speech synthesizer without requiring a human-in-the-loop .
This article provides a new toolbox to derive sparse recovery guarantees from small deviations on extreme singular values or extreme eigenvalues obtained in Random Matrix Theory . This work is based on Restricted Isometry Constants ( RICs ) which are a pivotal notion in Compressed Sensing and High-Dimensional Statistics as these constants finely assess how a linear operator is conditioned on the set of sparse vectors and hence how it performs in SRSR . While it is an open problem to construct deterministic matrices with apposite RICs , one can prove that such matrices exist using random matrices models . In this paper , we show upper bounds on RICs for Gaussian and Rademacher matrices using state-of-the-art small deviation estimates on their extreme eigenvalues . This allows us to derive a lower bound on the probability of getting SRSR . One benefit of this paper is a direct and explicit derivation of upper bounds on RICs and lower bounds on SRSR from small deviations on the extreme eigenvalues given by Random Matrix theory .
This paper investigates domain generalization : How to take knowledge acquired from an arbitrary number of related domains and apply it to previously unseen domains ? We propose Domain-Invariant Component Analysis ( DICA ) , a kernel-based optimization algorithm that learns an invariant transformation by minimizing the dissimilarity across domains , whilst preserving the functional relationship between input and output variables . A learning-theoretic analysis shows that reducing dissimilarity improves the expected generalization ability of classifiers on new domains , motivating the proposed algorithm . Experimental results on synthetic and real-world datasets demonstrate that DICA successfully learns invariant features and improves classifier performance in practice .
We present mlrMBO , a flexible and comprehensive R toolbox for model-based optimization ( MBO ) , also known as Bayesian optimization , which addresses the problem of expensive black-box optimization by approximating the given objective function through a surrogate regression model . It is designed for both single- and multi-objective optimization with mixed continuous , categorical and conditional parameters . Additional features include multi-point batch proposal , parallelization , visualization , logging and error-handling . mlrMBO is implemented in a modular fashion , such that single components can be easily replaced or adapted by the user for specific use cases , e . g . , any regression learner from the mlr toolbox for machine learning can be used , and infill criteria and infill optimizers are easily exchangeable . We empirically demonstrate that mlrMBO provides state-of-the-art performance by comparing it on different benchmark scenarios against a wide range of other optimizers , including DiceOptim , rBayesianOptimization , SPOT , SMAC , Spearmint , and Hyperopt .
In the covariate shift learning scenario , the training and test covariate distributions differ , so that a predictor ' s average loss over the training and test distributions also differ . The importance weighting approach handles this shift by minimizing an estimate of test loss over predictors , obtained via a weighted sum over training sample losses . However , as the dimension of the covariates increases , this test loss estimator increases in variance . In this work , we adapt the importance weighting approach to more robustly handle higher dimensional covariates by incorporating dimension reduction into the learning process .
Learning invariant representations is an important problem in machine learning and pattern recognition . In this paper , we present a novel framework of transformation-invariant feature learning by incorporating linear transformations into the feature learning algorithms . For example , we present the transformation-invariant restricted Boltzmann machine that compactly represents data by its weights and their transformations , which achieves invariance of the feature representation via probabilistic max pooling . In addition , we show that our transformation-invariant feature learning framework can also be extended to other unsupervised learning methods , such as autoencoders or sparse coding . We evaluate our method on several image classification benchmark datasets , such as MNIST variations , CIFAR-00 , and STL-00 , and show competitive or superior classification performance when compared to the state-of-the-art . Furthermore , our method achieves state-of-the-art performance on phone classification tasks with the TIMIT dataset , which demonstrates wide applicability of our proposed algorithms to other domains .
Non-negative blind source separation ( non-negative BSS ) , which is also referred to as non-negative matrix factorization ( NMF ) , is a very active field in domains as different as astrophysics , audio processing or biomedical signal processing . In this context , the efficient retrieval of the sources requires the use of signal priors such as sparsity . If NMF has now been well studied with sparse constraints in the direct domain , only very few algorithms can encompass non-negativity together with sparsity in a transformed domain since simultaneously dealing with two priors in two different domains is challenging . In this article , we show how a sparse NMF algorithm coined non-negative generalized morphological component analysis ( nGMCA ) can be extended to impose non-negativity in the direct domain along with sparsity in a transformed domain , with both analysis and synthesis formulations . To our knowledge , this work presents the first comparison of analysis and synthesis priors ---as well as their reweighted versions--- in the context of blind source separation . Comparisons with state-of-the-art NMF algorithms on realistic data show the efficiency as well as the robustness of the proposed algorithms .
Deep structured output learning shows great promise in tasks like semantic image segmentation . We proffer a new , efficient deep structured model learning scheme , in which we show how deep Convolutional Neural Networks ( CNNs ) can be used to estimate the messages in message passing inference for structured prediction with Conditional Random Fields ( CRFs ) . With such CNN message estimators , we obviate the need to learn or evaluate potential functions for message calculation . This confers significant efficiency for learning , since otherwise when performing structured learning for a CRF with CNN potentials it is necessary to undertake expensive inference for every stochastic gradient iteration . The network output dimension for message estimation is the same as the number of classes , in contrast to the network output for general CNN potential functions in CRFs , which is exponential in the order of the potentials . Hence CNN message learning has fewer network parameters and is more scalable for cases that a large number of classes are involved . We apply our method to semantic image segmentation on the PASCAL VOC 0000 dataset . We achieve an intersection-over-union score of 00 . 0 on its test set , which is the best reported result for methods using the VOC training images alone . This impressive performance demonstrates the effectiveness and usefulness of our CNN message learning method .
A measure of dependence is said to be equitable if it gives similar scores to equally noisy relationships of different types . Equitability is important in data exploration when the goal is to identify a relatively small set of strongest associations within a dataset as opposed to finding as many non-zero associations as possible , which often are too many to sift through . Thus an equitable statistic , such as the maximal information coefficient ( MIC ) , can be useful for analyzing high-dimensional data sets . Here , we explore both equitability and the properties of MIC , and discuss several aspects of the theory and practice of MIC . We begin by presenting an intuition behind the equitability of MIC through the exploration of the maximization and normalization steps in its definition . We then examine the speed and optimality of the approximation algorithm used to compute MIC , and suggest some directions for improving both . Finally , we demonstrate in a range of noise models and sample sizes that MIC is more equitable than natural alternatives , such as mutual information estimation and distance correlation .
Latent force models ( LFM ) are principled approaches to incorporating solutions to differential equations within non-parametric inference methods . Unfortunately , the development and application of LFMs can be inhibited by their computational cost , especially when closed-form solutions for the LFM are unavailable , as is the case in many real world problems where these latent forces exhibit periodic behaviour . Given this , we develop a new sparse representation of LFMs which considerably improves their computational efficiency , as well as broadening their applicability , in a principled way , to domains with periodic or near periodic latent forces . Our approach uses a linear basis model to approximate one generative model for each periodic force . We assume that the latent forces are generated from Gaussian process priors and develop a linear basis model which fully expresses these priors . We apply our approach to model the thermal dynamics of domestic buildings and show that it is effective at predicting day-ahead temperatures within the homes . We also apply our approach within queueing theory in which quasi-periodic arrival rates are modelled as latent forces . In both cases , we demonstrate that our approach can be implemented efficiently using state-space methods which encode the linear dynamic systems via LFMs . Further , we show that state estimates obtained using periodic latent force models can reduce the root mean squared error to 00% of that from non-periodic models and 00% of the nearest rival approach which is the resonator model .
To cope with the high level of ambiguity faced in domains such as Computer Vision or Natural Language processing , robust prediction methods often search for a diverse set of high-quality candidate solutions or proposals . In structured prediction problems , this becomes a daunting task , as the solution space ( image labelings , sentence parses , etc . ) is exponentially large . We study greedy algorithms for finding a diverse subset of solutions in structured-output spaces by drawing new connections between submodular functions over combinatorial item sets and High-Order Potentials ( HOPs ) studied for graphical models . Specifically , we show via examples that when marginal gains of submodular diversity functions allow structured representations , this enables efficient ( sub-linear time ) approximate maximization by reducing the greedy augmentation step to inference in a factor graph with appropriately constructed HOPs . We discuss benefits , tradeoffs , and show that our constructions lead to significantly better proposals .
Networks are a useful representation for data on connections between units of interests , but the observed connections are often noisy and/or include missing values . One common approach to network analysis is to treat the network as a realization from a random graph model , and estimate the underlying edge probability matrix , which is sometimes referred to as network denoising . Here we propose a generalized linear model with low rank effects to model network edges . This model can be applied to various types of networks , including directed and undirected , binary and weighted , and it can naturally utilize additional information such as node and/or edge covariates . We develop an efficient projected gradient ascent algorithm to fit the model , establish asymptotic consistency , and demonstrate empirical performance of the method on both simulated and real networks .
While the Matrix Generalized Inverse Gaussian ( $\mathcal{MGIG}$ ) distribution arises naturally in some settings as a distribution over symmetric positive semi-definite matrices , certain key properties of the distribution and effective ways of sampling from the distribution have not been carefully studied . In this paper , we show that the $\mathcal{MGIG}$ is unimodal , and the mode can be obtained by solving an Algebraic Riccati Equation ( ARE ) equation [0] . Based on the property , we propose an importance sampling method for the $\mathcal{MGIG}$ where the mode of the proposal distribution matches that of the target . The proposed sampling method is more efficient than existing approaches [00 , 00] , which use proposal distributions that may have the mode far from the $\mathcal{MGIG}$ ' s mode . Further , we illustrate that the the posterior distribution in latent factor models , such as probabilistic matrix factorization ( PMF ) [00] , when marginalized over one latent factor has the $\mathcal{MGIG}$ distribution . The characterization leads to a novel Collapsed Monte Carlo ( CMC ) inference algorithm for such latent factor models . We illustrate that CMC has a lower log loss or perplexity than MCMC , and needs fewer samples .
Observations consisting of measurements on relationships for pairs of objects arise in many settings , such as protein interaction and gene regulatory networks , collections of author-recipient email , and social networks . Analyzing such data with probabilisic models can be delicate because the simple exchangeability assumptions underlying many boilerplate models no longer hold . In this paper , we describe a latent variable model of such data called the mixed membership stochastic blockmodel . This model extends blockmodels for relational data to ones which capture mixed membership latent relational structure , thus providing an object-specific low-dimensional representation . We develop a general variational inference algorithm for fast approximate posterior inference . We explore applications to social and protein interaction networks .
The restricted isometry property ( RIP ) is a universal tool for data recovery . We explore the implication of the RIP in the framework of generalized sparsity and group measurements introduced in the Part I paper . It turns out that for a given measurement instrument the number of measurements for RIP can be improved by optimizing over families of Banach spaces . Second , we investigate the preservation of difference of two sparse vectors , which is not trivial in generalized models . Third , we extend the RIP of partial Fourier measurements at optimal scaling of number of measurements with random sign to far more general group structured measurements . Lastly , we also obtain RIP in infinite dimension in the context of Fourier measurement concepts with sparsity naturally replaced by smoothness assumptions .
This paper explores the following question : what kind of statistical guarantees can be given when doing variable selection in high-dimensional models ? In particular , we look at the error rates and power of some multi-stage regression methods . In the first stage we fit a set of candidate models . In the second stage we select one model by cross-validation . In the third stage we use hypothesis testing to eliminate some variables . We refer to the first two stages as " screening " and the last stage as " cleaning . " We consider three screening methods : the lasso , marginal regression , and forward stepwise regression . Our method gives consistent variable selection under certain conditions .
Clustering is one of the most important unsupervised problems in machine learning and statistics . Among many existing algorithms , kernel k-means has drawn much research attention due to its ability to find non-linear cluster boundaries and its inherent simplicity . There are two main approaches for kernel k-means : SVD of the kernel matrix and convex relaxations . Despite the attention kernel clustering has received both from theoretical and applied quarters , not much is known about robustness of the methods . In this paper we first introduce a semidefinite programming relaxation for the kernel clustering problem , then prove that under a suitable model specification , both the K-SVD and SDP approaches are consistent in the limit , albeit SDP is strongly consistent , i . e . achieves exact recovery , whereas K-SVD is weakly consistent , i . e . the fraction of misclassified nodes vanish .
Sparse representations have proven their efficiency in solving a wide class of inverse problems encountered in signal and image processing . Conversely , enforcing the information to be spread uniformly over representation coefficients exhibits relevant properties in various applications such as digital communications . Anti-sparse regularization can be naturally expressed through an $\ell_{\infty}$-norm penalty . This paper derives a probabilistic formulation of such representations . A new probability distribution , referred to as the democratic prior , is first introduced . Its main properties as well as three random variate generators for this distribution are derived . Then this probability distribution is used as a prior to promote anti-sparsity in a Gaussian linear inverse problem , yielding a fully Bayesian formulation of anti-sparse coding . Two Markov chain Monte Carlo ( MCMC ) algorithms are proposed to generate samples according to the posterior distribution . The first one is a standard Gibbs sampler . The second one uses Metropolis-Hastings moves that exploit the proximity mapping of the log-posterior distribution . These samples are used to approximate maximum a posteriori and minimum mean square error estimators of both parameters and hyperparameters . Simulations on synthetic data illustrate the performances of the two proposed samplers , for both complete and over-complete dictionaries . All results are compared to the recent deterministic variational FITRA algorithm .
This paper is devoted to the bipartite ranking problem , a classical statistical learning task , in a high dimensional setting . We propose a scoring and ranking strategy based on the PAC-Bayesian approach . We consider nonlinear additive scoring functions , and we derive non-asymptotic risk bounds under a sparsity assumption . In particular , oracle inequalities in probability holding under a margin condition assess the performance of our procedure , and prove its minimax optimality . An MCMC-flavored algorithm is proposed to implement our method , along with its behavior on synthetic and real-life datasets .
Inference for the stochastic blockmodel is currently of burgeoning interest in the statistical community , as well as in various application domains as diverse as social networks , citation networks , brain connectivity networks ( connectomics ) , etc . Recent theoretical developments have shown that spectral embedding of graphs yields tractable distributional results ; in particular , a random dot product latent position graph formulation of the stochastic blockmodel informs a mixture of normal distributions for the adjacency spectral embedding . We employ this new theory to provide an empirical Bayes methodology for estimation of block memberships of vertices in a random graph drawn from the stochastic blockmodel , and demonstrate its practical utility . The posterior inference is conducted using a Metropolis-within-Gibbs algorithm . The theory and methods are illustrated through Monte Carlo simulation studies , both within the stochastic blockmodel and beyond , and experimental results on a Wikipedia data set are presented .
Human communication takes many forms , including speech , text and instructional videos . It typically has an underlying structure , with a starting point , ending , and certain objective steps between them . In this paper , we consider instructional videos where there are tens of millions of them on the Internet . We propose a method for parsing a video into such semantic steps in an unsupervised way . Our method is capable of providing a semantic " storyline " of the video composed of its objective steps . We accomplish this using both visual and language cues in a joint generative model . Our method can also provide a textual description for each of the identified semantic steps and video segments . We evaluate our method on a large number of complex YouTube videos and show that our method discovers semantically correct instructions for a variety of tasks .
Testing independence is of significant interest in many important areas of large-scale inference . Using extreme-value form statistics to test against sparse alternatives and using quadratic form statistics to test against dense alternatives are two important testing procedures for high-dimensional independence . However , quadratic form statistics suffer from low power against sparse alternatives , and extreme-value form statistics suffer from low power against dense alternatives with small disturbances and may have size distortions due to its slow convergence . For real-world applications , it is important to derive powerful testing procedures against more general alternatives . Based on intermediate limiting distributions , we derive ( model-free ) joint limiting laws of extreme-value form and quadratic form statistics , and surprisingly , we prove that they are asymptotically independent . Given such asymptotic independencies , we propose ( model-free ) testing procedures to boost the power against general alternatives and also retain the correct asymptotic size . Under the high-dimensional setting , we derive the closed-form limiting null distributions , and obtain their explicit rates of uniform convergence . We prove their consistent statistical powers against general alternatives . We demonstrate the performance of our proposed test statistics in simulation studies . Our work provides very helpful insights to high-dimensional independence tests , and fills an important gap .
Several convex formulation methods have been proposed previously for statistical estimation with structured sparsity as the prior . These methods often require a carefully tuned regularization parameter , often a cumbersome or heuristic exercise . Furthermore , the estimate that these methods produce might not belong to the desired sparsity model , albeit accurately approximating the true parameter . Therefore , greedy-type algorithms could often be more desirable in estimating structured-sparse parameters . So far , these greedy methods have mostly focused on linear statistical models . In this paper we study the projected gradient descent with non-convex structured-sparse parameter model as the constraint set . Should the cost function have a Stable Model-Restricted Hessian the algorithm produces an approximation for the desired minimizer . As an example we elaborate on application of the main results to estimation in Generalized Linear Model .
Stochastic variance reduction algorithms have recently become popular for minimizing the average of a large , but finite number of loss functions . The present paper proposes a Riemannian stochastic quasi-Newton algorithm with variance reduction ( R-SQN-VR ) . The key challenges of averaging , adding , and subtracting multiple gradients are addressed with notions of retraction and vector transport . We present convergence analyses of R-SQN-VR on both non-convex and retraction-convex functions under retraction and vector transport operators . The proposed algorithm is evaluated on the Karcher mean computation on the symmetric positive-definite manifold and the low-rank matrix completion on the Grassmann manifold . In all cases , the proposed algorithm outperforms the state-of-the-art Riemannian batch and stochastic gradient algorithms .
In many recent applications , data is plentiful . By now , we have a rather clear understanding of how more data can be used to improve the accuracy of learning algorithms . Recently , there has been a growing interest in understanding how more data can be leveraged to reduce the required training runtime . In this paper , we study the runtime of learning as a function of the number of available training examples , and underscore the main high-level techniques . We provide some initial positive results showing that the runtime can decrease exponentially while only requiring a polynomial growth of the number of examples , and spell-out several interesting open problems .
We propose computationally efficient encoders and decoders for lossy compression using a Sparse Regression Code . The codebook is defined by a design matrix and codewords are structured linear combinations of columns of this matrix . The proposed encoding algorithm sequentially chooses columns of the design matrix to successively approximate the source sequence . It is shown to achieve the optimal distortion-rate function for i . i . d Gaussian sources under the squared-error distortion criterion . For a given rate , the parameters of the design matrix can be varied to trade off distortion performance with encoding complexity . An example of such a trade-off as a function of the block length n is the following . With computational resource ( space or time ) per source sample of O ( ( n/\log n ) ^0 ) , for a fixed distortion-level above the Gaussian distortion-rate function , the probability of excess distortion decays exponentially in n . The Sparse Regression Code is robust in the following sense : for any ergodic source , the proposed encoder achieves the optimal distortion-rate function of an i . i . d Gaussian source with the same variance . Simulations show that the encoder has good empirical performance , especially at low and moderate rates .
We take a new look at parameter estimation for Gaussian Mixture Models ( GMMs ) . In particular , we propose using \emph{Riemannian manifold optimization} as a powerful counterpart to Expectation Maximization ( EM ) . An out-of-the-box invocation of manifold optimization , however , fails spectacularly : it converges to the same solution but vastly slower . Driven by intuition from manifold convexity , we then propose a reparamerization that has remarkable empirical consequences . It makes manifold optimization not only match EM---a highly encouraging result in itself given the poor record nonlinear programming methods have had against EM so far---but also outperform EM in many practical settings , while displaying much less variability in running times . We further highlight the strengths of manifold optimization by developing a somewhat tuned manifold LBFGS method that proves even more competitive and reliable than existing manifold optimization tools . We hope that our results encourage a wider consideration of manifold optimization for parameter estimation problems .
The ICML 0000 Workshop on Challenges in Representation Learning focused on three challenges : the black box learning challenge , the facial expression recognition challenge , and the multimodal learning challenge . We describe the datasets created for these challenges and summarize the results of the competitions . We provide suggestions for organizers of future challenges and some comments on what kind of knowledge can be gained from machine learning competitions .
In many machine learning problems , labeled training data is limited but unlabeled data is ample . Some of these problems have instances that can be factored into multiple views , each of which is nearly sufficent in determining the correct labels . In this paper we present a new algorithm for probabilistic multi-view learning which uses the idea of stochastic agreement between views as regularization . Our algorithm works on structured and unstructured problems and easily generalizes to partial agreement scenarios . For the full agreement case , our algorithm minimizes the Bhattacharyya distance between the models of each view , and performs better than CoBoosting and two-view Perceptron on several flat and structured classification problems .
We present an information-theoretic framework for solving global black-box optimization problems that also have black-box constraints . Of particular interest to us is to efficiently solve problems with decoupled constraints , in which subsets of the objective and constraint functions may be evaluated independently . For example , when the objective is evaluated on a CPU and the constraints are evaluated independently on a GPU . These problems require an acquisition function that can be separated into the contributions of the individual function evaluations . We develop one such acquisition function and call it Predictive Entropy Search with Constraints ( PESC ) . PESC is an approximation to the expected information gain criterion and it compares favorably to alternative approaches based on improvement in several synthetic and real-world problems . In addition to this , we consider problems with a mix of functions that are fast and slow to evaluate . These problems require balancing the amount of time spent in the meta-computation of PESC and in the actual evaluation of the target objective . We take a bounded rationality approach and develop partial update for PESC which trades off accuracy against speed . We then propose a method for adaptively switching between the partial and full updates for PESC . This allows us to interpolate between versions of PESC that are efficient in terms of function evaluations and those that are efficient in terms of wall-clock time . Overall , we demonstrate that PESC is an effective algorithm that provides a promising direction towards a unified solution for constrained Bayesian optimization .
Modern Internet services , such as those at Google , Yahoo ! , and Amazon , handle billions of requests per day on clusters of thousands of computers . Because these services operate under strict performance requirements , a statistical understanding of their performance is of great practical interest . Such services are modeled by networks of queues , where each queue models one of the computers in the system . A key challenge is that the data are incomplete , because recording detailed information about every request to a heavily used system can require unacceptable overhead . In this paper we develop a Bayesian perspective on queueing models in which the arrival and departure times that are not observed are treated as latent variables . Underlying this viewpoint is the observation that a queueing model defines a deterministic transformation between the data and a set of independent variables called the service times . With this viewpoint in hand , we sample from the posterior distribution over missing data and model parameters using Markov chain Monte Carlo . We evaluate our framework on data from a benchmark Web application . We also present a simple technique for selection among nested queueing models . We are unaware of any previous work that considers inference in networks of queues in the presence of missing data .
Human infants can discover words directly from unsegmented speech signals without any explicitly labeled data . In this paper , we develop a novel machine learning method called nonparametric Bayesian double articulation analyzer ( NPB-DAA ) that can directly acquire language and acoustic models from observed continuous speech signals . For this purpose , we propose an integrative generative model that combines a language model and an acoustic model into a single generative model called the " hierarchical Dirichlet process hidden language model " ( HDP-HLM ) . The HDP-HLM is obtained by extending the hierarchical Dirichlet process hidden semi-Markov model ( HDP-HSMM ) proposed by Johnson et al . An inference procedure for the HDP-HLM is derived using the blocked Gibbs sampler originally proposed for the HDP-HSMM . This procedure enables the simultaneous and direct inference of language and acoustic models from continuous speech signals . Based on the HDP-HLM and its inference procedure , we developed a novel double articulation analyzer . By assuming HDP-HLM as a generative model of observed time series data , and by inferring latent variables of the model , the method can analyze latent double articulation structure , i . e . , hierarchically organized latent words and phonemes , of the data in an unsupervised manner . The novel unsupervised double articulation analyzer is called NPB-DAA . The NPB-DAA can automatically estimate double articulation structure embedded in speech signals . We also carried out two evaluation experiments using synthetic data and actual human continuous speech signals representing Japanese vowel sequences . In the word acquisition and phoneme categorization tasks , the NPB-DAA outperformed a conventional double articulation analyzer ( DAA ) and baseline automatic speech recognition system whose acoustic model was trained in a supervised manner .
This work characterizes the benefits of averaging techniques widely used in conjunction with stochastic gradient descent ( SGD ) . In particular , this work sharply analyzes : ( 0 ) mini-batching , a method of averaging many samples of the gradient to both reduce the variance of a stochastic gradient estimate and for parallelizing SGD and ( 0 ) tail-averaging , a method involving averaging the final few iterates of SGD in order to decrease the variance in SGD ' s final iterate . This work presents the first tight non-asymptotic generalization error bounds for these schemes for the stochastic approximation problem of least squares regression . Furthermore , this work establishes a precise problem-dependent extent to which mini-batching can be used to yield provable near-linear parallelization speedups over SGD with batch size one . These results are utilized in providing a highly parallelizable SGD algorithm that obtains the optimal statistical error rate with nearly the same number of serial updates as batch gradient descent , which improves significantly over existing SGD-style methods . Finally , this work sheds light on some fundamental differences in SGD ' s behavior when dealing with agnostic noise in the ( non-realizable ) least squares regression problem . In particular , the work shows that the stepsizes that ensure optimal statistical error rates for the agnostic case must be a function of the noise properties . The central analysis tools used by this paper are obtained through generalizing the operator view of averaged SGD , introduced by Defossez and Bach ( 0000 ) followed by developing a novel analysis in bounding these operators to characterize the generalization error . These techniques may be of broader interest in analyzing various computational aspects of stochastic approximation .
We study the classification performance of Kronecker-structured models in two asymptotic regimes and developed an algorithm for separable , fast and compact K-S dictionary learning for better classification and representation of multidimensional signals by exploiting the structure in the signal . First , we study the classification performance in terms of diversity order and pairwise geometry of the subspaces . We derive an exact expression for the diversity order as a function of the signal and subspace dimensions of a K-S model . Next , we study the classification capacity , the maximum rate at which the number of classes can grow as the signal dimension goes to infinity . Then we describe a fast algorithm for Kronecker-Structured Learning of Discriminative Dictionaries ( K-SLD0 ) . Finally , we evaluate the empirical classification performance of K-S models for the synthetic data , showing that they agree with the diversity order analysis . We also evaluate the performance of K-SLD0 on synthetic and real-world datasets showing that the K-SLD0 balances compact signal representation and good classification performance .
We study the problem of instance segmentation in biological images with crowded and compact cells . We formulate this task as an integer program where variables correspond to cells and constraints enforce that cells do not overlap . To solve this integer program , we propose a column generation formulation where the pricing program is solved via exact optimization of very small scale integer programs . Column generation is tightened using odd set inequalities which fit elegantly into pricing problem optimization . Our column generation approach achieves fast stable anytime inference for our instance segmentation problems . We demonstrate on three distinct light microscopy datasets , with several hundred cells each , that our proposed algorithm rapidly achieves or exceeds state of the art accuracy .
The lasso model has been widely used for model selection in data mining , machine learning , and high-dimensional statistical analysis . However , due to the ultrahigh-dimensional , large-scale data sets collected in many real-world applications , it remains challenging to solve the lasso problems even with state-of-the-art algorithms . Feature screening is a powerful technique for addressing the Big Data challenge by discarding inactive features from the lasso optimization . In this paper , we propose a family of hybrid safe-strong rules ( HSSR ) which incorporate safe screening rules into the sequential strong rule ( SSR ) to remove unnecessary computational burden . In particular , we present two instances of HSSR , namely SSR-Dome and SSR-BEDPP , for the standard lasso problem . We further extend SSR-BEDPP to the elastic net and group lasso problems to demonstrate the generalizability of the hybrid screening idea . Extensive numerical experiments with synthetic and real data sets are conducted for both the standard lasso and the group lasso problems . Results show that our proposed hybrid rules substantially outperform existing state-of-the-art rules .
We present a new technique called contrastive principal component analysis ( cPCA ) that is designed to discover low-dimensional structure that is unique to a dataset , or enriched in one dataset relative to other data . The technique is a generalization of standard PCA , for the setting where multiple datasets are available -- e . g . a treatment and a control group , or a mixed versus a homogeneous population -- and the goal is to explore patterns that are specific to one of the datasets . We conduct a wide variety of experiments in which cPCA identifies important dataset-specific patterns that are missed by PCA , demonstrating that it is useful for many applications : subgroup discovery , visualizing trends , feature selection , denoising , and data-dependent standardization . We provide geometrical interpretations of cPCA and show that it satisfies desirable theoretical guarantees . We also extend cPCA to nonlinear settings in the form of kernel cPCA . We have released our code as a python package and documentation is on Github .
This paper considers \emph{volume minimization} ( VolMin ) -based structured matrix factorization ( SMF ) . VolMin is a factorization criterion that decomposes a given data matrix into a basis matrix times a structured coefficient matrix via finding the minimum-volume simplex that encloses all the columns of the data matrix . Recent work showed that VolMin guarantees the identifiability of the factor matrices under mild conditions that are realistic in a wide variety of applications . This paper focuses on both theoretical and practical aspects of VolMin . On the theory side , exact equivalence of two independently developed sufficient conditions for VolMin identifiability is proven here , thereby providing a more comprehensive understanding of this aspect of VolMin . On the algorithm side , computational complexity and sensitivity to outliers are two key challenges associated with real-world applications of VolMin . These are addressed here via a new VolMin algorithm that handles volume regularization in a computationally simple way , and automatically detects and {iteratively downweights} outliers , simultaneously . Simulations and real-data experiments using a remotely sensed hyperspectral image and the Reuters document corpus are employed to showcase the effectiveness of the proposed algorithm .
Facial pain expression is an important modality for assessing pain , especially when a patient ' s verbal ability to communicate is impaired . A set of eight facial muscle based action units ( AUs ) , which are defined by the Facial Action Coding System ( FACS ) , have been widely studied and are highly reliable for pain detection through facial expressions . However , using FACS is a very time consuming task that makes its clinical use prohibitive . An automated facial expression recognition system ( AFER ) reliably detecting pain-related AUs would be highly beneficial for efficient and practical pain monitoring . Automated pain detection under clinical settings is viewed as a weakly supervised problem , which is not suitable general AFER system that trained on well labeled data . Existing pain oriented AFER research either focus on the individual pain-related AU recognition or bypassing the AU detection procedure by training a binary pain classifier from pain intensity data . In this paper , we decouple pain detection into two consecutive tasks : the AFER based AU labeling at video frame level and a probabilistic measure of pain at sequence level from AU combination scores . Our work is distinguished in the following aspects , 0 ) State of the art AFER tools Emotient is applied on pain oriented data sets for single AU labeling . 0 ) Two different data structures are proposed to encode AU combinations from single AU scores , which forms low-dimensional feature vectors for the learning framework . 0 ) Two weakly supervised learning frameworks namely multiple instance learning and multiple clustered instance learning are employed corresponding to each feature structure to learn pain from video sequences . The results shows 00% pain recognition accuracy with 0 . 00 AUC on UNBC-McMaster dataset . Tests on Wilkie ' s dataset suggests the potential value of the proposed system for pain monitoring task under clinical settings .
Variational inference is a powerful concept that underlies many iterative approximation algorithms ; expectation propagation , mean-field methods and belief propagations were all central themes at the school that can be perceived from this unifying framework . The lectures of Manfred Opper introduce the archetypal example of Expectation Propagation , before establishing the connection with the other approximation methods . Corrections by expansion about the expectation propagation are then explained . Finally some advanced inference topics and applications are explored in the final sections .
We focus in this work on the estimation of the first $k$ eigenvectors of any graph Laplacian using filtering of Gaussian random signals . We prove that we only need $k$ such signals to be able to exactly recover as many of the smallest eigenvectors , regardless of the number of nodes in the graph . In addition , we address key issues in implementing the theoretical concepts in practice using accurate approximated methods . We also propose fast algorithms both for eigenspace approximation and for the determination of the $k$th smallest eigenvalue $\lambda_k$ . The latter proves to be extremely efficient under the assumption of locally uniform distribution of the eigenvalue over the spectrum . Finally , we present experiments which show the validity of our method in practice and compare it to state-of-the-art methods for clustering and visualization both on synthetic small-scale datasets and larger real-world problems of millions of nodes . We show that our method allows a better scaling with the number of nodes than all previous methods while achieving an almost perfect reconstruction of the eigenspace formed by the first $k$ eigenvectors .
We extend kernelized matrix factorization with a fully Bayesian treatment and with an ability to work with multiple side information sources expressed as different kernels . Kernel functions have been introduced to matrix factorization to integrate side information about the rows and columns ( e . g . , objects and users in recommender systems ) , which is necessary for making out-of-matrix ( i . e . , cold start ) predictions . We discuss specifically bipartite graph inference , where the output matrix is binary , but extensions to more general matrices are straightforward . We extend the state of the art in two key aspects : ( i ) A fully conjugate probabilistic formulation of the kernelized matrix factorization problem enables an efficient variational approximation , whereas fully Bayesian treatments are not computationally feasible in the earlier approaches . ( ii ) Multiple side information sources are included , treated as different kernels in multiple kernel learning that additionally reveals which side information sources are informative . Our method outperforms alternatives in predicting drug-protein interactions on two data sets . We then show that our framework can also be used for solving multilabel learning problems by considering samples and labels as the two domains where matrix factorization operates on . Our algorithm obtains the lowest Hamming loss values on 00 out of 00 multilabel classification data sets compared to five state-of-the-art multilabel learning algorithms .
In this paper we study the classification problem in which we have access to easily obtainable surrogate for the true labels , namely complementary labels , which specify classes that observations do \textbf{not} belong to . For example , if one is familiar with monkeys but not meerkats , a meerkat is easily identified as not a monkey , so " monkey " is annotated to the meerkat as a complementary label . Specifically , let $Y$ and $\bar{Y}$ be the true and complementary labels , respectively . We first model the annotation of complementary labels via the transition probabilities $P ( \bar{Y}=i|Y=j ) , i\neq j\in\{0 , \cdots , c\}$ , where $c$ is the number of classes . All the previous methods implicitly assume that the transition probabilities $P ( \bar{Y}=i|Y=j ) $ are identical , which is far from true in practice because humans are biased toward their own experience . For example , if a person is more familiar with monkey than prairie dog when providing complementary labels for meerkats , he/she is more likely to employ " monkey " as a complementary label . We therefore reason that the transition probabilities will be different . In this paper , we address three fundamental problems raised by learning with biased complementary labels . ( 0 ) How to estimate the transition probabilities ? ( 0 ) How to modify the traditional loss functions and extend standard deep neural network classifiers to learn with biased complementary labels ? ( 0 ) Does the classifier learned from examples with complementary labels by our proposed method converge to the optimal one learned from examples with true labels ? Comprehensive experiments on MNIST , CIFAR00 , CIFAR000 , and Tiny ImageNet empirically validate the superiority of the proposed method to the current state-of-the-art methods with accuracy gains of over 00\% .
Multiple Additive Regression Trees ( MART ) , an ensemble model of boosted regression trees , is known to deliver high prediction accuracy for diverse tasks , and it is widely used in practice . However , it suffers an issue which we call over-specialization , wherein trees added at later iterations tend to impact the prediction of only a few instances , and make negligible contribution towards the remaining instances . This negatively affects the performance of the model on unseen data , and also makes the model over-sensitive to the contributions of the few , initially added tress . We show that the commonly used tool to address this issue , that of shrinkage , alleviates the problem only to a certain extent and the fundamental issue of over-specialization still remains . In this work , we explore a different approach to address the problem that of employing dropouts , a tool that has been recently proposed in the context of learning deep neural networks . We propose a novel way of employing dropouts in MART , resulting in the DART algorithm . We evaluate DART on ranking , regression and classification tasks , using large scale , publicly available datasets , and show that DART outperforms MART in each of the tasks , with a significant margin . We also show that DART overcomes the issue of over-specialization to a considerable extent .
We present new excess risk bounds for general unbounded loss functions including log loss and squared loss , where the distribution of the losses may be heavy-tailed . The bounds hold for general estimators , but they are optimized when applied to $\eta$-generalized Bayesian , MDL , and ERM estimators . When applied with log loss , the bounds imply convergence rates for generalized Bayesian inference under misspecification in terms of a generalization of the Hellinger metric as long as the learning rate $\eta$ is set correctly . For general loss functions , our bounds rely on two separate conditions : the $v$-GRIP ( generalized reversed information projection ) conditions , which control the lower tail of the excess loss ; and the newly introduced witness condition , which controls the upper tail . The parameter $v$ in the $v$-GRIP conditions determines the achievable rate and is akin to the exponent in the well-known Tsybakov margin condition and the Bernstein condition for bounded losses , which the $v$-GRIP conditions generalize ; favorable $v$ in combination with small model complexity leads to $\tilde{O} ( 0/n ) $ rates . The witness condition allows us to connect the excess risk to an ' annealed ' version thereof , by which we generalize several previous results connecting Hellinger and R\ ' enyi divergence to KL divergence .
Dimensionality reduction ( DR ) is often used as a preprocessing step in classification , but usually one first fixes the DR mapping , possibly using label information , and then learns a classifier ( a filter approach ) . Best performance would be obtained by optimizing the classification error jointly over DR mapping and classifier ( a wrapper approach ) , but this is a difficult nonconvex problem , particularly with nonlinear DR . Using the method of auxiliary coordinates , we give a simple , efficient algorithm to train a combination of nonlinear DR and a classifier , and apply it to a RBF mapping with a linear SVM . This alternates steps where we train the RBF mapping and a linear SVM as usual regression and classification , respectively , with a closed-form step that coordinates both . The resulting nonlinear low-dimensional classifier achieves classification errors competitive with the state-of-the-art but is fast at training and testing , and allows the user to trade off runtime for classification accuracy easily . We then study the role of nonlinear DR in linear classification , and the interplay between the DR mapping , the number of latent dimensions and the number of classes . When trained jointly , the DR mapping takes an extreme role in eliminating variation : it tends to collapse classes in latent space , erasing all manifold structure , and lay out class centroids so they are linearly separable with maximum margin .
We consider the problem of clustering noisy finite-length observations of stationary ergodic random processes according to their generative models without prior knowledge of the model statistics and the number of generative models . Two algorithms , both using the $L^0$-distance between estimated power spectral densities ( PSDs ) as a measure of dissimilarity , are analyzed . The first one , termed nearest neighbor process clustering ( NNPC ) , relies on partitioning the nearest neighbor graph of the observations via spectral clustering . The second algorithm , simply referred to as $k$-means ( KM ) , consists of a single $k$-means iteration with farthest point initialization and was considered before in the literature , albeit with a different dissimilarity measure . We prove that both algorithms succeed with high probability in the presence of noise and missing entries , and even when the generative process PSDs overlap significantly , all provided that the observation length is sufficiently large . Our results quantify the tradeoff between the overlap of the generative process PSDs , the observation length , the fraction of missing entries , and the noise variance . Finally , we provide extensive numerical results for synthetic and real data and find that NNPC outperforms state-of-the-art algorithms in human motion sequence clustering .
Direct acoustics-to-word ( A0W ) models in the end-to-end paradigm have received increasing attention compared to conventional sub-word based automatic speech recognition models using phones , characters , or context-dependent hidden Markov model states . This is because A0W models recognize words from speech without any decoder , pronunciation lexicon , or externally-trained language model , making training and decoding with such models simple . Prior work has shown that A0W models require orders of magnitude more training data in order to perform comparably to conventional models . Our work also showed this accuracy gap when using the English Switchboard-Fisher data set . This paper describes a recipe to train an A0W model that closes this gap and is at-par with state-of-the-art sub-word based models . We achieve a word error rate of 0 . 0%/00 . 0% on the Hub0-0000 Switchboard/CallHome test sets without any decoder or language model . We find that model initialization , training data order , and regularization have the most impact on the A0W model performance . Next , we present a joint word-character A0W model that learns to first spell the word and then recognize it . This model provides a rich output to the user instead of simple word hypotheses , making it especially useful in the case of words unseen or rarely-seen during training .
The change of two orders of magnitude in the ' new DCF ' of NIST ' s SRE ' 00 , relative to the ' old DCF ' evaluation criterion , posed a difficult challenge for participants and evaluator alike . Initially , participants were at a loss as to how to calibrate their systems , while the evaluator underestimated the required number of evaluation trials . After the fact , it is now obvious that both calibration and evaluation require very large sets of trials . This poses the challenges of ( i ) how to decide what number of trials is enough , and ( ii ) how to process such large data sets with reasonable memory and CPU requirements . After SRE ' 00 , at the BOSARIS Workshop , we built solutions to these problems into the freely available BOSARIS Toolkit . This paper explains the principles and algorithms behind this toolkit . The main contributions of the toolkit are : 0 . The Normalized Bayes Error-Rate Plot , which analyses likelihood- ratio calibration over a wide range of DCF operating points . These plots also help in judging the adequacy of the sizes of calibration and evaluation databases . 0 . Efficient algorithms to compute DCF and minDCF for large score files , over the range of operating points required by these plots . 0 . A new score file format , which facilitates working with very large trial lists . 0 . A faster logistic regression optimizer for fusion and calibration . 0 . A principled way to define EER ( equal error rate ) , which is of practical interest when the absolute error count is small .
Deep learning models can take weeks to train on a single GPU-equipped machine , necessitating scaling out DL training to a GPU-cluster . However , current distributed DL implementations can scale poorly due to substantial parameter synchronization over the network , because the high throughput of GPUs allows more data batches to be processed per unit time than CPUs , leading to more frequent network synchronization . We present Poseidon , an efficient communication architecture for distributed DL on GPUs . Poseidon exploits the layered model structures in DL programs to overlap communication and computation , reducing bursty network communication . Moreover , Poseidon uses a hybrid communication scheme that optimizes the number of bytes required to synchronize each layer , according to layer properties and the number of machines . We show that Poseidon is applicable to different DL frameworks by plugging Poseidon into Caffe and TensorFlow . We show that Poseidon enables Caffe and TensorFlow to achieve 00 . 0x speed-up on 00 single-GPU machines , even with limited bandwidth ( 00GbE ) and the challenging VGG00-00K network for image classification . Moreover , Poseidon-enabled TensorFlow achieves 00 . 0x speed-up with 00 single-GPU machines on Inception-V0 , a 00% improvement over the open-source TensorFlow ( 00x speed-up ) .
Minimizing the rank of a matrix subject to constraints is a challenging problem that arises in many applications in control theory , machine learning , and discrete geometry . This class of optimization problems , known as rank minimization , is NP-HARD , and for most practical problems there are no efficient algorithms that yield exact solutions . A popular heuristic algorithm replaces the rank function with the nuclear norm--equal to the sum of the singular values--of the decision variable . In this paper , we provide a necessary and sufficient condition that quantifies when this heuristic successfully finds the minimum rank solution of a linear constraint set . We additionally provide a probability distribution over instances of the affine rank minimization problem such that instances sampled from this distribution satisfy our conditions for success with overwhelming probability provided the number of constraints is appropriately large . Finally , we give empirical evidence that these probabilistic bounds provide accurate predictions of the heuristic ' s performance in non-asymptotic scenarios .
Use of computational methods to predict gene regulatory networks ( GRNs ) from gene expression data is a challenging task . Many studies have been conducted using unsupervised methods to fulfill the task ; however , such methods usually yield low prediction accuracies due to the lack of training data . In this article , we propose semi-supervised methods for GRN prediction by utilizing two machine learning algorithms , namely support vector machines ( SVM ) and random forests ( RF ) . The semi-supervised methods make use of unlabeled data for training . We investigate inductive and transductive learning approaches , both of which adopt an iterative procedure to obtain reliable negative training data from the unlabeled data . We then apply our semi-supervised methods to gene expression data of Escherichia coli and Saccharomyces cerevisiae , and evaluate the performance of our methods using the expression data . Our analysis indicated that the transductive learning approach outperformed the inductive learning approach for both organisms . However , there was no conclusive difference identified in the performance of SVM and RF . Experimental results also showed that the proposed semi-supervised methods performed better than existing supervised methods for both organisms .
We study the value of information in sequential compressed sensing by characterizing the performance of sequential information guided sensing in practical scenarios when information is inaccurate . In particular , we assume the signal distribution is parameterized through Gaussian or Gaussian mixtures with estimated mean and covariance matrices , and we can measure compressively through a noisy linear projection or using one-sparse vectors , i . e . , observing one entry of the signal each time . We establish a set of performance bounds for the bias and variance of the signal estimator via posterior mean , by capturing the conditional entropy ( which is also related to the size of the uncertainty ) , and the additional power required due to inaccurate information to reach a desired precision . Based on this , we further study how to estimate covariance based on direct samples or covariance sketching . Numerical examples also demonstrate the superior performance of Info-Greedy Sensing algorithms compared with their random and non-adaptive counterparts .
Multi-task feature learning aims to identity the shared features among tasks to improve generalization . It has been shown that by minimizing non-convex learning models , a better solution than the convex alternatives can be obtained . Therefore , a non-convex model based on the capped-$\ell_{0} , \ell_{0}$ regularization was proposed in \cite{Gong0000} , and a corresponding efficient multi-stage multi-task feature learning algorithm ( MSMTFL ) was presented . However , this algorithm harnesses a prescribed fixed threshold in the definition of the capped-$\ell_{0} , \ell_{0}$ regularization and the lack of adaptivity might result in suboptimal performance . In this paper we propose to employ an adaptive threshold in the capped-$\ell_{0} , \ell_{0}$ regularized formulation , where the corresponding variant of MSMTFL will incorporate an additional component to adaptively determine the threshold value . This variant is expected to achieve a better feature selection performance over the original MSMTFL algorithm . In particular , the embedded adaptive threshold component comes from our previously proposed iterative support detection ( ISD ) method \cite{Wang0000} . Empirical studies on both synthetic and real-world data sets demonstrate the effectiveness of this new variant over the original MSMTFL .
We present the collaborative Kalman filter ( CKF ) , a dynamic model for collaborative filtering and related factorization models . Using the matrix factorization approach to collaborative filtering , the CKF accounts for time evolution by modeling each low-dimensional latent embedding as a multidimensional Brownian motion . Each observation is a random variable whose distribution is parameterized by the dot product of the relevant Brownian motions at that moment in time . This is naturally interpreted as a Kalman filter with multiple interacting state space vectors . We also present a method for learning a dynamically evolving drift parameter for each location by modeling it as a geometric Brownian motion . We handle posterior intractability via a mean-field variational approximation , which also preserves tractability for downstream calculations in a manner similar to the Kalman filter . We evaluate the model on several large datasets , providing quantitative evaluation on the 00 million Movielens and 000 million Netflix datasets and qualitative evaluation on a set of 00 million stock returns divided across roughly 0 , 000 companies from the years 0000-0000 .
We consider neural network training , in applications in which there are many possible classes , but at test-time , the task is to identify only whether the given example belongs to a specific class , which can be different in different applications of the classifier . For instance , this is the case in an image search engine . We consider the Single Logit Classification ( SLC ) task : training the network so that at test-time , it would be possible to accurately identify if the example belongs to a given class , based only on the output logit for this class . We propose a natural principle , the Principle of Logit Separation , as a guideline for choosing and designing losses suitable for the SLC . We show that the cross-entropy loss function is not aligned with the Principle of Logit Separation . In contrast , there are known loss functions , as well as novel batch loss functions that we propose , which are aligned with this principle . In total , we study seven loss functions . Our experiments show that indeed in almost all cases , losses that are aligned with Principle of Logit Separation obtain a 00%-00% relative performance improvement in the SLC task , compared to losses that are not aligned with it . We therefore conclude that the Principle of Logit Separation sheds light on an important property of the most common loss functions used by neural network classifiers . Tensorflow code for optimizing the new batch losses is publicly available in https : //github . com/cruvadom/Logit_Separation .
This paper introduces a novel approach to in-painting where the identity of the object to remove or change is preserved and accounted for at inference time : Exemplar GANs ( ExGANs ) . ExGANs are a type of conditional GAN that utilize exemplar information to produce high-quality , personalized in painting results . We propose using exemplar information in the form of a reference image of the region to in-paint , or a perceptual code describing that object . Unlike previous conditional GAN formulations , this extra information can be inserted at multiple points within the adversarial network , thus increasing its descriptive power . We show that ExGANs can produce photo-realistic personalized in-painting results that are both perceptually and semantically plausible by applying them to the task of closed to-open eye in-painting in natural pictures . A new benchmark dataset is also introduced for the task of eye in-painting for future comparisons .
We present an approach for polarimetric Synthetic Aperture Radar ( SAR ) image region boundary detection based on the use of B-Spline active contours and a new model for polarimetric SAR data : the GHP distribution . In order to detect the boundary of a region , initial B-Spline curves are specified , either automatically or manually , and the proposed algorithm uses a deformable contours technique to find the boundary . In doing this , the parameters of the polarimetric GHP model for the data are estimated , in order to find the transition points between the region being segmented and the surrounding area . This is a local algorithm since it works only on the region to be segmented . Results of its performance are presented .
Hyperspectral remote sensing images ( HSIs ) are characterized by having a low spatial resolution and a high spectral resolution , whereas multispectral images ( MSIs ) are characterized by low spectral and high spatial resolutions . These complementary characteristics have stimulated active research in the inference of images with high spatial and spectral resolutions from HSI-MSI pairs . In this paper , we formulate this data fusion problem as the minimization of a convex objective function containing two data-fitting terms and an edge-preserving regularizer . The data-fitting terms are quadratic and account for blur , different spatial resolutions , and additive noise ; the regularizer , a form of vector Total Variation , promotes aligned discontinuities across the reconstructed hyperspectral bands . The optimization described above is rather hard , owing to its non-diagonalizable linear operators , to the non-quadratic and non-smooth nature of the regularizer , and to the very large size of the image to be inferred . We tackle these difficulties by tailoring the Split Augmented Lagrangian Shrinkage Algorithm ( SALSA ) ---an instance of the Alternating Direction Method of Multipliers ( ADMM ) ---to this optimization problem . By using a convenient variable splitting and by exploiting the fact that HSIs generally " live " in a low-dimensional subspace , we obtain an effective algorithm that yields state-of-the-art results , as illustrated by experiments .
Recently , deep neural networks ( DNNs ) have been regarded as the state-of-the-art classification methods in a wide range of applications , especially in image classification . Despite the success , the huge number of parameters blocks its deployment to situations with light computing resources . Researchers resort to the redundancy in the weights of DNNs and attempt to find how fewer parameters can be chosen while preserving the accuracy at the same time . Although several promising results have been shown along this research line , most existing methods either fail to significantly compress a well-trained deep network or require a heavy fine-tuning process for the compressed network to regain the original performance . In this paper , we propose the \textit{Block Term} networks ( BT-nets ) in which the commonly used fully-connected layers ( FC-layers ) are replaced with block term layers ( BT-layers ) . In BT-layers , the inputs and the outputs are reshaped into two low-dimensional high-order tensors , then block-term decomposition is applied as tensor operators to connect them . We conduct extensive experiments on benchmark datasets to demonstrate that BT-layers can achieve a very large compression ratio on the number of parameters while preserving the representation power of the original FC-layers as much as possible . Specifically , we can get a higher performance while requiring fewer parameters compared with the tensor train method .
Finding sparse solutions of underdetermined systems of linear equations is a fundamental problem in signal processing and statistics which has become a subject of interest in recent years . In general , these systems have infinitely many solutions . However , it may be shown that sufficiently sparse solutions may be identified uniquely . In other words , the corresponding linear transformation will be invertible if we restrict its domain to sufficiently sparse vectors . This property may be used , for example , to solve the underdetermined Blind Source Separation ( BSS ) problem , or to find sparse representation of a signal in an `overcomplete ' dictionary of primitive elements ( i . e . , the so-called atomic decomposition ) . The main drawback of current methods of finding sparse solutions is their computational complexity . In this paper , we will show that by detecting `active ' components of the ( potential ) solution , i . e . , those components having a considerable value , a framework for fast solution of the problem may be devised . The idea leads to a family of algorithms , called `Iterative Detection-Estimation ( IDE ) ' , which converge to the solution by successive detection and estimation of its active part . Comparing the performance of IDE ( s ) with one of the most successful method to date , which is based on Linear Programming ( LP ) , an improvement in speed of about two to three orders of magnitude is observed .
The discovery of causal relationships from purely observational data is a fundamental problem in science . The most elementary form of such a causal discovery problem is to decide whether X causes Y or , alternatively , Y causes X , given joint observations of two variables X , Y . An example is to decide whether altitude causes temperature , or vice versa , given only joint measurements of both variables . Even under the simplifying assumptions of no confounding , no feedback loops , and no selection bias , such bivariate causal discovery problems are challenging . Nevertheless , several approaches for addressing those problems have been proposed in recent years . We review two families of such methods : Additive Noise Methods ( ANM ) and Information Geometric Causal Inference ( IGCI ) . We present the benchmark CauseEffectPairs that consists of data for 000 different cause-effect pairs selected from 00 datasets from various domains ( e . g . , meteorology , biology , medicine , engineering , economy , etc . ) and motivate our decisions regarding the " ground truth " causal directions of all pairs . We evaluate the performance of several bivariate causal discovery methods on these real-world benchmark data and in addition on artificially simulated data . Our empirical results on real-world data indicate that certain methods are indeed able to distinguish cause from effect using only purely observational data , although more benchmark data would be needed to obtain statistically significant conclusions . One of the best performing methods overall is the additive-noise method originally proposed by Hoyer et al . ( 0000 ) , which obtains an accuracy of 00+-00 % and an AUC of 0 . 00+-0 . 00 on the real-world benchmark . As the main theoretical contribution of this work we prove the consistency of that method .
Generative adversarial networks ( GANs ) are successful deep generative models . GANs are based on a two-player minimax game . However , the objective function derived in the original motivation is changed to obtain stronger gradients when learning the generator . We propose a novel algorithm that repeats the density ratio estimation and f-divergence minimization . Our algorithm offers a new perspective toward the understanding of GANs and is able to make use of multiple viewpoints obtained in the research of density ratio estimation , e . g . what divergence is stable and relative density ratio is useful .
We study the classical problem of maximizing a monotone submodular function subject to a cardinality constraint k , with two additional twists : ( i ) elements arrive in a streaming fashion , and ( ii ) m items from the algorithm ' s memory are removed after the stream is finished . We develop a robust submodular algorithm STAR-T . It is based on a novel partitioning structure and an exponentially decreasing thresholding rule . STAR-T makes one pass over the data and retains a short but robust summary . We show that after the removal of any m elements from the obtained summary , a simple greedy algorithm STAR-T-GREEDY that runs on the remaining elements achieves a constant-factor approximation guarantee . In two different data summarization tasks , we demonstrate that it matches or outperforms existing greedy and streaming methods , even if they are allowed the benefit of knowing the removed subset in advance .
We show a principled way of deriving online learning algorithms from a minimax analysis . Various upper bounds on the minimax value , previously thought to be non-constructive , are shown to yield algorithms . This allows us to seamlessly recover known methods and to derive new ones . Our framework also captures such " unorthodox " methods as Follow the Perturbed Leader and the R^0 forecaster . We emphasize that understanding the inherent complexity of the learning problem leads to the development of algorithms . We define local sequential Rademacher complexities and associated algorithms that allow us to obtain faster rates in online learning , similarly to statistical learning theory . Based on these localized complexities we build a general adaptive method that can take advantage of the suboptimality of the observed sequence . We present a number of new algorithms , including a family of randomized methods that use the idea of a " random playout " . Several new versions of the Follow-the-Perturbed-Leader algorithms are presented , as well as methods based on the Littlestone ' s dimension , efficient methods for matrix completion with trace norm , and algorithms for the problems of transductive learning and prediction with static experts .
Over the past few years , the multi-armed bandit model has become increasingly popular in the machine learning community , partly because of applications including online content optimization . This paper reviews two different sequential learning tasks that have been considered in the bandit literature ; they can be formulated as ( sequentially ) learning which distribution has the highest mean among a set of distributions , with some constraints on the learning process . For both of them ( regret minimization and best arm identification ) we present recent , asymptotically optimal algorithms . We compare the behaviors of the sampling rule of each algorithm as well as the complexity terms associated to each problem .
Ideas from the image processing literature have recently motivated a new set of clustering algorithms that rely on the concept of total variation . While these algorithms perform well for bi-partitioning tasks , their recursive extensions yield unimpressive results for multiclass clustering tasks . This paper presents a general framework for multiclass total variation clustering that does not rely on recursion . The results greatly outperform previous total variation algorithms and compare well with state-of-the-art NMF approaches .
In this paper , we present a framework for fitting multivariate Hawkes processes for large-scale problems both in the number of events in the observed history $n$ and the number of event types $d$ ( i . e . dimensions ) . The proposed Low-Rank Hawkes Process ( LRHP ) framework introduces a low-rank approximation of the kernel matrix that allows to perform the nonparametric learning of the $d^0$ triggering kernels using at most $O ( ndr^0 ) $ operations , where $r$ is the rank of the approximation ( $r \ll d , n$ ) . This comes as a major improvement to the existing state-of-the-art inference algorithms that are in $O ( nd^0 ) $ . Furthermore , the low-rank approximation allows LRHP to learn representative patterns of interaction between event types , which may be valuable for the analysis of such complex processes in real world datasets . The efficiency and scalability of our approach is illustrated with numerical experiments on simulated as well as real datasets .
The binary symmetric stochastic block model deals with a random graph of $n$ vertices partitioned into two equal-sized clusters , such that each pair of vertices is connected independently with probability $p$ within clusters and $q$ across clusters . In the asymptotic regime of $p=a \log n/n$ and $q=b \log n/n$ for fixed $a , b$ and $n \to \infty$ , we show that the semidefinite programming relaxation of the maximum likelihood estimator achieves the optimal threshold for exactly recovering the partition from the graph with probability tending to one , resolving a conjecture of Abbe et al . \cite{Abbe00} . Furthermore , we show that the semidefinite programming relaxation also achieves the optimal recovery threshold in the planted dense subgraph model containing a single cluster of size proportional to $n$ .
An ensemble of models ( EM ) , where each model is constructed on a diverse subset of feature variables , is proposed to rank rare class items ahead of majority class items in a highly unbalanced two class problem . The proposed ensemble relies on an algorithm to group the feature variables into subsets where the variables in a subset work better together in a model and the variables in different subsets work better in separate models . The strength of the EM depends on the algorithm ' s ability to identify strong and diverse subsets of feature variables . A second phase of ensembling is achieved by aggregating several EMs each optimized on a diverse evaluation metric . The resulting ensemble is called ensemble of models and metrics ( EMM ) . Here , the diverse/complementary evaluation metrics ensure increased diversity among EMs to aggregate . The ensembles are applied to the protein homology data , downloaded from the 0000 KDD cup competition website , to rank proteins in such a way that the rare homologous proteins are found ahead of the majority non-homologous proteins . The ensembles are constructed using feature variables which are various scores from sequence alignments of amino acids in a candidate protein and three dimensional descriptions of a native protein representing functional and structural similarity of proteins . While prediction performances of the EMs are better than the contemporary state-of-the-art ensembles and competitive to the winning procedures of the $0000$ KDD cup competition , the performances of the EMM are found on the top of all . In this application , we have two diverse EMs constructed on two complementary evaluation metrics average precision and rank last , where the former is robust against ranking close homologs and the latter is robust against ranking distant homologs . The advantage of using EMM is that it is robust against both close and distant homologs .
Joint sparsity offers powerful structural cues for feature selection , especially for variables that are expected to demonstrate a " grouped " behavior . Such behavior is commonly modeled via group-lasso , multitask lasso , and related methods where feature selection is effected via mixed-norms . Several mixed-norm based sparse models have received substantial attention , and for some cases efficient algorithms are also available . Surprisingly , several constrained sparse models seem to be lacking scalable algorithms . We address this deficiency by presenting batch and online ( stochastic-gradient ) optimization methods , both of which rely on efficient projections onto mixed-norm balls . We illustrate our methods by applying them to the multitask lasso . We conclude by mentioning some open problems .
Taobao , as the largest online retail platform in the world , provides billions of online display advertising impressions for millions of advertisers every day . For commercial purposes , the advertisers bid for specific spots and target crowds to compete for business traffic . The platform chooses the most suitable ads to display in tens of milliseconds . Common pricing methods include cost per mille ( CPM ) and cost per click ( CPC ) . Traditional advertising systems target certain traits of users and ad placements with fixed bids , essentially regarded as coarse-grained matching of bid and traffic quality . However , the fixed bids set by the advertisers competing for different quality requests cannot fully optimize the advertisers ' key requirements . Moreover , the platform has to be responsible for the business revenue and user experience . Thus , we proposed a bid optimizing strategy called optimized cost per click ( OCPC ) which automatically adjusts the bid to achieve finer matching of bid and traffic quality of page view ( PV ) request granularity . Our approach optimizes advertisers ' demands , platform business revenue and user experience and as a whole improves traffic allocation efficiency . We have validated our approach in Taobao display advertising system in production . The online A/B test shows our algorithm yields substantially better results than previous fixed bid manner .
We propose an adversarial training procedure for learning a causal implicit generative model for a given causal graph . We show that adversarial training can be used to learn a generative model with true observational and interventional distributions if the generator architecture is consistent with the given causal graph . We consider the application of generating faces based on given binary labels where the dependency structure between the labels is preserved with a causal graph . This problem can be seen as learning a causal implicit generative model for the image and labels . We devise a two-stage procedure for this problem . First we train a causal implicit generative model over binary labels using a neural network consistent with a causal graph as the generator . We empirically show that WassersteinGAN can be used to output discrete labels . Later , we propose two new conditional GAN architectures , which we call CausalGAN and CausalBEGAN . We show that the optimal generator of the CausalGAN , given the labels , samples from the image distributions conditioned on these labels . The conditional GAN combined with a trained causal implicit generative model for the labels is then a causal implicit generative model over the labels and the generated image . We show that the proposed architectures can be used to sample from observational and interventional image distributions , even for interventions which do not naturally occur in the dataset .
Using sparse-inducing norms to learn robust models has received increasing attention from many fields for its attractive properties . Projection-based methods have been widely applied to learning tasks constrained by such norms . As a key building block of these methods , an efficient operator for Euclidean projection onto the intersection of $\ell_0$ and $\ell_{0 , q}$ norm balls $ ( q=0\text{or}\infty ) $ is proposed in this paper . We prove that the projection can be reduced to finding the root of an auxiliary function which is piecewise smooth and monotonic . Hence , a bisection algorithm is sufficient to solve the problem . We show that the time complexity of our solution is $O ( n+g\log g ) $ for $q=0$ and $O ( n\log n ) $ for $q=\infty$ , where $n$ is the dimensionality of the vector to be projected and $g$ is the number of disjoint groups ; we confirm this complexity by experimentation . Empirical study reveals that our method achieves significantly better performance than classical methods in terms of running time and memory usage . We further show that embedded with our efficient projection operator , projection-based algorithms can solve regression problems with composite norm constraints more efficiently than other methods and give superior accuracy .
Problems in machine learning ( ML ) can involve noisy input data , and ML classification methods have reached limiting accuracies when based on standard ML data sets consisting of feature vectors and their classes . Greater accuracy will require incorporation of prior structural information on data into learning . We study methods to regularize feature vectors ( unsupervised regularization methods ) , analogous to supervised regularization for estimating functions in ML . We study regularization ( denoising ) of ML feature vectors using Tikhonov and other regularization methods for functions on ${\bf R}^n$ . A feature vector ${\bf x}= ( x_0 , \ldots , x_n ) =\{x_q\}_{q=0}^n$ is viewed as a function of its index $q$ , and smoothed using prior information on its structure . This can involve a penalty functional on feature vectors analogous to those in statistical learning , or use of proximity ( e . g . graph ) structure on the set of indices . Such feature vector regularization inherits a property from function denoising on ${\bf R}^n$ , in that accuracy is non-monotonic in the denoising ( regularization ) parameter $\alpha$ . Under some assumptions about the noise level and the data structure , we show that the best reconstruction accuracy also occurs at a finite positive $\alpha$ in index spaces with graph structures . We adapt two standard function denoising methods used on ${\bf R}^n$ , local averaging and kernel regression . In general the index space can be any discrete set with a notion of proximity , e . g . a metric space , a subset of ${\bf R}^n$ , or a graph/network , with feature vectors as functions with some notion of continuity . We show this improves feature vector recovery , and thus the subsequent classification or regression done on them . We give an example in gene expression analysis for cancer classification with the genome as an index space and network structure based protein-protein interactions .
Determinantal Point Processes ( DPPs ) are probabilistic models that arise in quantum physics and random matrix theory and have recently found numerous applications in computer science . DPPs define distributions over subsets of a given ground set , they exhibit interesting properties such as negative correlation , and , unlike other models , have efficient algorithms for sampling . When applied to kernel methods in machine learning , DPPs favor subsets of the given data with more diverse features . However , many real-world applications require efficient algorithms to sample from DPPs with additional constraints on the subset , e . g . , partition or matroid constraints that are important to ensure priors , resource or fairness constraints on the sampled subset . Whether one can efficiently sample from DPPs in such constrained settings is an important problem that was first raised in a survey of DPPs by \cite{KuleszaTaskar00} and studied in some recent works in the machine learning literature . The main contribution of our paper is the first resolution of the complexity of sampling from DPPs with constraints . We give exact efficient algorithms for sampling from constrained DPPs when their description is in unary . Furthermore , we prove that when the constraints are specified in binary , this problem is #P-hard via a reduction from the problem of computing mixed discriminants implying that it may be unlikely that there is an FPRAS . Our results benefit from viewing the constrained sampling problem via the lens of polynomials . Consequently , we obtain a few algorithms of independent interest : 0 ) to count over the base polytope of regular matroids when there are additional ( succinct ) budget constraints and , 0 ) to evaluate and compute the mixed characteristic polynomials , that played a central role in the resolution of the Kadison-Singer problem , for certain special cases .
Collecting labeled data is costly and thus a critical bottleneck in real-world classification tasks . To mitigate this problem , we propose a novel setting , namely learning from complementary labels for multi-class classification . A complementary label specifies a class that a pattern does not belong to . Collecting complementary labels would be less laborious than collecting ordinary labels , since users do not have to carefully choose the correct class from a long list of candidate classes . However , complementary labels are less informative than ordinary labels and thus a suitable approach is needed to better learn from them . In this paper , we show that an unbiased estimator to the classification risk can be obtained only from complementarily labeled data , if a loss function satisfies a particular symmetric condition . We derive estimation error bounds for the proposed method and prove that the optimal parametric convergence rate is achieved . We further show that learning from complementary labels can be easily combined with learning from ordinary labels ( i . e . , ordinary supervised learning ) , providing a highly practical implementation of the proposed method . Finally , we experimentally demonstrate the usefulness of the proposed methods .
Pattern sampling has been proposed as a potential solution to the infamous pattern explosion . Instead of enumerating all patterns that satisfy the constraints , individual patterns are sampled proportional to a given quality measure . Several sampling algorithms have been proposed , but each of them has its limitations when it comes to 0 ) flexibility in terms of quality measures and constraints that can be used , and/or 0 ) guarantees with respect to sampling accuracy . We therefore present Flexics , the first flexible pattern sampler that supports a broad class of quality measures and constraints , while providing strong guarantees regarding sampling accuracy . To achieve this , we leverage the perspective on pattern mining as a constraint satisfaction problem and build upon the latest advances in sampling solutions in SAT as well as existing pattern mining algorithms . Furthermore , the proposed algorithm is applicable to a variety of pattern languages , which allows us to introduce and tackle the novel task of sampling sets of patterns . We introduce and empirically evaluate two variants of Flexics : 0 ) a generic variant that addresses the well-known itemset sampling task and the novel pattern set sampling task as well as a wide range of expressive constraints within these tasks , and 0 ) a specialized variant that exploits existing frequent itemset techniques to achieve substantial speed-ups . Experiments show that Flexics is both accurate and efficient , making it a useful tool for pattern-based data exploration .
Recurrent Neural Networks ( RNNs ) , which are a powerful scheme for modeling temporal and sequential data need to capture long-term dependencies on datasets and represent them in hidden layers with a powerful model to capture more information from inputs . For modeling long-term dependencies in a dataset , the gating mechanism concept can help RNNs remember and forget previous information . Representing the hidden layers of an RNN with more expressive operations ( i . e . , tensor products ) helps it learn a more complex relationship between the current input and the previous hidden layer information . These ideas can generally improve RNN performances . In this paper , we proposed a novel RNN architecture that combine the concepts of gating mechanism and the tensor product into a single model . By combining these two concepts into a single RNN , our proposed models learn long-term dependencies by modeling with gating units and obtain more expressive and direct interaction between input and hidden layers using a tensor product on 0-dimensional array ( tensor ) weight parameters . We use Long Short Term Memory ( LSTM ) RNN and Gated Recurrent Unit ( GRU ) RNN and combine them with a tensor product inside their formulations . Our proposed RNNs , which are called a Long-Short Term Memory Recurrent Neural Tensor Network ( LSTMRNTN ) and Gated Recurrent Unit Recurrent Neural Tensor Network ( GRURNTN ) , are made by combining the LSTM and GRU RNN models with the tensor product . We conducted experiments with our proposed models on word-level and character-level language modeling tasks and revealed that our proposed models significantly improved their performance compared to our baseline models .
We investigate the systematic mechanism for designing fast mixing Markov chain Monte Carlo algorithms to sample from discrete point processes under the Dobrushin uniqueness condition for Gibbs measures . Discrete point processes are defined as probability distributions $\mu ( S ) \propto \exp ( \beta f ( S ) ) $ over all subsets $S\in 0^V$ of a finite set $V$ through a bounded set function $f : 0^V\rightarrow \mathbb{R}$ and a parameter $\beta>0$ . A subclass of discrete point processes characterized by submodular functions ( which include log-submodular distributions , submodular point processes , and determinantal point processes ) has recently gained a lot of interest in machine learning and shown to be effective for modeling diversity and coverage . We show that if the set function ( not necessarily submodular ) displays a natural notion of decay of correlation , then , for $\beta$ small enough , it is possible to design fast mixing Markov chain Monte Carlo methods that yield error bounds on marginal approximations that do not depend on the size of the set $V$ . The sufficient conditions that we derive involve a control on the ( discrete ) Hessian of set functions , a quantity that has not been previously considered in the literature . We specialize our results for submodular functions , and we discuss canonical examples where the Hessian can be easily controlled .
The problem of detecting communities in a graph is maybe one the most studied inference problems , given its simplicity and widespread diffusion among several disciplines . A very common benchmark for this problem is the stochastic block model or planted partition problem , where a phase transition takes place in the detection of the planted partition by changing the signal-to-noise ratio . Optimal algorithms for the detection exist which are based on spectral methods , but we show these are extremely sensible to slight modification in the generative model . Recently Javanmard , Montanari and Ricci-Tersenghi ( arXiv : 0000 . 00000 ) have used statistical physics arguments , and numerical simulations to show that finding communities in the stochastic block model via semidefinite programming is quasi optimal . Further , the resulting semidefinite relaxation can be solved efficiently , and is very robust with respect to changes in the generative model . In this paper we study in detail several practical aspects of this new algorithm based on semidefinite programming for the detection of the planted partition . The algorithm turns out to be very fast , allowing the solution of problems with $O ( 00^0 ) $ variables in few second on a laptop computer .
Variable ( feature , gene , model , which we use interchangeably ) selections for regression with high-dimensional BIGDATA have found many applications in bioinformatics , computational biology , image processing , and engineering . One appealing approach is the L0 regularized regression which penalizes the number of nonzero features in the model directly . L0 is known as the most essential sparsity measure and has nice theoretical properties , while the popular L0 regularization is only a best convex relaxation of L0 . Therefore , it is natural to expect that L0 regularized regression performs better than LASSO . However , it is well-known that L0 optimization is NP-hard and computationally challenging . Instead of solving the L0 problems directly , most publications so far have tried to solve an approximation problem that closely resembles L0 regularization . In this paper , we propose an efficient EM algorithm ( L0EM ) that directly solves the L0 optimization problem . $L_0$EM is efficient with high dimensional data . It also provides a natural solution to all Lp p in [0 , 0] problems . The regularized parameter can be either determined through cross-validation or AIC and BIC . Theoretical properties of the L0-regularized estimator are given under mild conditions that permit the number of variables to be much larger than the sample size . We demonstrate our methods through simulation and high-dimensional genomic data . The results indicate that L0 has better performance than LASSO and L0 with AIC or BIC has similar performance as computationally intensive cross-validation . The proposed algorithms are efficient in identifying the non-zero variables with less-bias and selecting biologically important genes and pathways with high dimensional BIGDATA .
The diagnosis of Alzheimer ' s disease ( AD ) in routine clinical practice is most commonly based on subjective clinical interpretations . Quantitative electroencephalography ( QEEG ) measures have been shown to reflect neurodegenerative processes in AD and might qualify as affordable and thereby widely available markers to facilitate the objectivization of AD assessment . Here , we present a novel framework combining Riemannian tangent space mapping and elastic net regression for the development of brain atrophy markers . While most AD QEEG studies are based on small sample sizes and psychological test scores as outcome measures , here we train and test our models using data of one of the largest prospective EEG AD trials ever conducted , including MRI biomarkers of brain atrophy .
Biclustering techniques have been widely used to identify homogeneous subgroups within large data matrices , such as subsets of genes similarly expressed across subsets of patients . Mining a max-sum sub-matrix is a related but distinct problem for which one looks for a ( non-necessarily contiguous ) rectangular sub-matrix with a maximal sum of its entries . Le Van et al . ( Ranked Tiling , 0000 ) already illustrated its applicability to gene expression analysis and addressed it with a constraint programming ( CP ) approach combined with large neighborhood search ( CP-LNS ) . In this work , we exhibit some key properties of this NP-hard problem and define a bounding function such that larger problems can be solved in reasonable time . Two different algorithms are proposed in order to exploit the highlighted characteristics of the problem : a CP approach with a global constraint ( CPGC ) and mixed integer linear programming ( MILP ) . Practical experiments conducted both on synthetic and real gene expression data exhibit the characteristics of these approaches and their relative benefits over the original CP-LNS method . Overall , the CPGC approach tends to be the fastest to produce a good solution . Yet , the MILP formulation is arguably the easiest to formulate and can also be competitive .
The question of how to incorporate curvature information in stochastic approximation methods is challenging . The direct application of classical quasi- Newton updating techniques for deterministic optimization leads to noisy curvature estimates that have harmful effects on the robustness of the iteration . In this paper , we propose a stochastic quasi-Newton method that is efficient , robust and scalable . It employs the classical BFGS update formula in its limited memory form , and is based on the observation that it is beneficial to collect curvature information pointwise , and at regular intervals , through ( sub-sampled ) Hessian-vector products . This technique differs from the classical approach that would compute differences of gradients , and where controlling the quality of the curvature estimates can be difficult . We present numerical results on problems arising in machine learning that suggest that the proposed method shows much promise .
We propose a Conditional Density Filtering ( C-DF ) algorithm for efficient online Bayesian inference . C-DF adapts MCMC sampling to the online setting , sampling from approximations to conditional posterior distributions obtained by propagating surrogate conditional sufficient statistics ( a function of data and parameter estimates ) as new data arrive . These quantities eliminate the need to store or process the entire dataset simultaneously and offer a number of desirable features . Often , these include a reduction in memory requirements and runtime and improved mixing , along with state-of-the-art parameter inference and prediction . These improvements are demonstrated through several illustrative examples including an application to high dimensional compressed regression . Finally , we show that C-DF samples converge to the target posterior distribution asymptotically as sampling proceeds and more data arrives .
This paper introduces hierarchical quasi-clustering methods , a generalization of hierarchical clustering for asymmetric networks where the output structure preserves the asymmetry of the input data . We show that this output structure is equivalent to a finite quasi-ultrametric space and study admissibility with respect to two desirable properties . We prove that a modified version of single linkage is the only admissible quasi-clustering method . Moreover , we show stability of the proposed method and we establish invariance properties fulfilled by it . Algorithms are further developed and the value of quasi-clustering analysis is illustrated with a study of internal migration within United States .
We solve the compressive sensing problem via convolutional factor analysis , where the convolutional dictionaries are learned {\em in situ} from the compressed measurements . An alternating direction method of multipliers ( ADMM ) paradigm for compressive sensing inversion based on convolutional factor analysis is developed . The proposed algorithm provides reconstructed images as well as features , which can be directly used for recognition ( $e . g . $ , classification ) tasks . When a deep ( multilayer ) model is constructed , a stochastic unpooling process is employed to build a generative model . During reconstruction and testing , we project the upper layer dictionary to the data level and only a single layer deconvolution is required . We demonstrate that using $\sim00\%$ ( relative to pixel numbers ) compressed measurements , the proposed model achieves the classification accuracy comparable to the original data on MNIST . We also observe that when the compressed measurements are very limited ( $e . g . $ , $<00\%$ ) , the upper layer dictionary can provide better reconstruction results than the bottom layer .
The modified Cholesky decomposition is commonly used for inverse covariance matrix estimation given a specified order of random variables . However , the order of variables is often not available or cannot be pre-determined . Hence , we propose a novel estimator to address the variable order issue in the modified Cholesky decomposition to estimate the sparse inverse covariance matrix . The key idea is to effectively combine a set of estimates obtained from multiple permutations of variable orders , and to efficiently encourage the sparse structure for the resultant estimate by the use of thresholding technique on the combined Cholesky factor matrix . The consistent property of the proposed estimate is established under some weak regularity conditions . Simulation studies show the superior performance of the proposed method in comparison with several existing approaches . We also apply the proposed method into the linear discriminant analysis for analyzing real-data examples for classification .
Feature selection and regularization are becoming increasingly prominent tools in the efforts of the reinforcement learning ( RL ) community to expand the reach and applicability of RL . One approach to the problem of feature selection is to impose a sparsity-inducing form of regularization on the learning method . Recent work on $L_0$ regularization has adapted techniques from the supervised learning literature for use with RL . Another approach that has received renewed attention in the supervised learning community is that of using a simple algorithm that greedily adds new features . Such algorithms have many of the good properties of the $L_0$ regularization methods , while also being extremely efficient and , in some cases , allowing theoretical guarantees on recovery of the true form of a sparse target function from sampled data . This paper considers variants of orthogonal matching pursuit ( OMP ) applied to reinforcement learning . The resulting algorithms are analyzed and compared experimentally with existing $L_0$ regularized approaches . We demonstrate that perhaps the most natural scenario in which one might hope to achieve sparse recovery fails ; however , one variant , OMP-BRM , provides promising theoretical guarantees under certain assumptions on the feature dictionary . Another variant , OMP-TD , empirically outperforms prior methods both in approximation accuracy and efficiency on several benchmark problems .
The recently introduced dropout training criterion for neural networks has been the subject of much attention due to its simplicity and remarkable effectiveness as a regularizer , as well as its interpretation as a training procedure for an exponentially large ensemble of networks that share parameters . In this work we empirically investigate several questions related to the efficacy of dropout , specifically as it concerns networks employing the popular rectified linear activation function . We investigate the quality of the test time weight-scaling inference procedure by evaluating the geometric average exactly in small models , as well as compare the performance of the geometric mean to the arithmetic mean more commonly employed by ensemble techniques . We explore the effect of tied weights on the ensemble interpretation by training ensembles of masked networks without tied weights . Finally , we investigate an alternative criterion based on a biased estimator of the maximum likelihood ensemble gradient .
In this paper , we consider formal series associated with events , profiles derived from events , and statistical models that make predictions about events . We prove theorems about realizations for these formal series using the language and tools of Hopf algebras .
This paper is concerned with the problem of top-$K$ ranking from pairwise comparisons . Given a collection of $n$ items and a few pairwise binary comparisons across them , one wishes to identify the set of $K$ items that receive the highest ranks . To tackle this problem , we adopt the logistic parametric model---the Bradley-Terry-Luce model , where each item is assigned a latent preference score , and where the outcome of each pairwise comparison depends solely on the relative scores of the two items involved . Recent works have made significant progress towards characterizing the performance ( e . g . the mean square error for estimating the scores ) of several classical methods , including the spectral method and the maximum likelihood estimator ( MLE ) . However , where they stand regarding top-$K$ ranking remains unsettled . We demonstrate that under a random sampling model , the spectral method alone , or the regularized MLE alone , is minimax optimal in terms of the sample complexity---the number of paired comparisons needed to ensure exact top-$K$ identification . This is accomplished via optimal control of the entrywise error of the score estimates . We complement our theoretical studies by numerical experiments , confirming that both methods yield low entrywise errors for estimating the underlying scores . Our theory is established based on a novel leave-one-out trick , which proves effective for analyzing both iterative and non-iterative optimization procedures . Along the way , we derive an elementary eigenvector perturbation bound for probability transition matrices , which parallels the Davis-Kahan $\sin\Theta$ theorem for symmetric matrices . This further allows us to close the gap between the $\ell_0$ error upper bound for the spectral method and the minimax lower limit .
An incremental/online state dynamic learning method is proposed for identification of the nonlinear Gaussian state space models . The method embeds the stochastic variational sparse Gaussian process as the probabilistic state dynamic model inside a particle filter framework . Model updating is done at measurement sample rate using stochastic gradient descent based optimization implemented in the state estimation filtering loop . The performance of the proposed method is compared with state-of-the-art Gaussian process based batch learning methods . Finally , it is shown that the state estimation performance significantly improves due to the online learning of state dynamics .
In big data image/video analytics , we encounter the problem of learning an overcomplete dictionary for sparse representation from a large training dataset , which can not be processed at once because of storage and computational constraints . To tackle the problem of dictionary learning in such scenarios , we propose an algorithm for parallel dictionary learning . The fundamental idea behind the algorithm is to learn a sparse representation in two phases . In the first phase , the whole training dataset is partitioned into small non-overlapping subsets , and a dictionary is trained independently on each small database . In the second phase , the dictionaries are merged to form a global dictionary . We show that the proposed algorithm is efficient in its usage of memory and computational complexity , and performs on par with the standard learning strategy operating on the entire data at a time . As an application , we consider the problem of image denoising . We present a comparative analysis of our algorithm with the standard learning techniques , that use the entire database at a time , in terms of training and denoising performance . We observe that the split-and-merge algorithm results in a remarkable reduction of training time , without significantly affecting the denoising performance .
In this paper , we propose new efficient algorithms to verify the null space condition in compressed sensing ( CS ) . Given an $ ( n-m ) \times n$ ( $m>0$ ) CS matrix $A$ and a positive $k$ , we are interested in computing $\displaystyle \alpha_k = \max_{\{z : Az=0 , z\neq 0\}}\max_{\{K : |K|\leq k\}}$ ${\|z_K \|_{0}}{\|z\|_{0}}$ , where $K$ represents subsets of $\{0 , 0 , . . . , n\}$ , and $|K|$ is the cardinality of $K$ . In particular , we are interested in finding the maximum $k$ such that $\alpha_k < {0}{0}$ . However , computing $\alpha_k$ is known to be extremely challenging . In this paper , we first propose a series of new polynomial-time algorithms to compute upper bounds on $\alpha_k$ . Based on these new polynomial-time algorithms , we further design a new sandwiching algorithm , to compute the \emph{exact} $\alpha_k$ with greatly reduced complexity . When needed , this new sandwiching algorithm also achieves a smooth tradeoff between computational complexity and result accuracy . Empirical results show the performance improvements of our algorithm over existing known methods ; and our algorithm outputs precise values of $\alpha_k$ , with much lower complexity than exhaustive search .
First-order methods play a central role in large-scale machine learning . Even though many variations exist , each suited to a particular problem , almost all such methods fundamentally rely on two types of algorithmic steps : gradient descent , which yields primal progress , and mirror descent , which yields dual progress . We observe that the performances of gradient and mirror descent are complementary , so that faster algorithms can be designed by LINEARLY COUPLING the two . We show how to reconstruct Nesterov ' s accelerated gradient methods using linear coupling , which gives a cleaner interpretation than Nesterov ' s original proofs . We also discuss the power of linear coupling by extending it to many other settings that Nesterov ' s methods cannot apply to .
We present a new similarity measure based on information theoretic measures which is superior than Normalized Compression Distance for clustering problems and inherits the useful properties of conditional Kolmogorov complexity . We show that Normalized Compression Dictionary Size and Normalized Compression Dictionary Entropy are computationally more efficient , as the need to perform the compression itself is eliminated . Also they scale linearly with exponential vector size growth and are content independent . We show that normalized compression dictionary distance is compressor independent , if limited to lossless compressors , which gives space for optimizations and implementation speed improvement for real-time and big data applications . The introduced measure is applicable for machine learning tasks of parameter-free unsupervised clustering , supervised learning such as classification and regression , feature selection , and is applicable for big data problems with order of magnitude speed increase .
Computational results demonstrate that posterior sampling for reinforcement learning ( PSRL ) dramatically outperforms algorithms driven by optimism , such as UCRL0 . We provide insight into the extent of this performance boost and the phenomenon that drives it . We leverage this insight to establish an $\tilde{O} ( H\sqrt{SAT} ) $ Bayesian expected regret bound for PSRL in finite-horizon episodic Markov decision processes , where $H$ is the horizon , $S$ is the number of states , $A$ is the number of actions and $T$ is the time elapsed . This improves upon the best previous bound of $\tilde{O} ( H S \sqrt{AT} ) $ for any reinforcement learning algorithm .
A fundamental aspect of biological information processing is the ubiquity of sequence-function relationships -- functions that map the sequence of DNA , RNA , or protein to a biochemically relevant activity . Most sequence-function relationships in biology are quantitative , but only recently have experimental techniques for effectively measuring these relationships been developed . The advent of such " massively parallel " experiments presents an exciting opportunity for the concepts and methods of statistical physics to inform the study of biological systems . After reviewing these recent experimental advances , we focus on the problem of how to infer parametric models of sequence-function relationships from the data produced by these experiments . Specifically , we retrace and extend recent theoretical work showing that inference based on mutual information , not the standard likelihood-based approach , is often necessary for accurately learning the parameters of these models . Closely connected with this result is the emergence of " diffeomorphic modes " -- directions in parameter space that are far less constrained by data than likelihood-based inference would suggest . Analogous to Goldstone modes in physics , diffeomorphic modes arise from an arbitrarily broken symmetry of the inference problem . An analytically tractable model of a massively parallel experiment is then described , providing an explicit demonstration of these fundamental aspects of statistical inference . This paper concludes with an outlook on the theoretical and computational challenges currently facing studies of quantitative sequence-function relationships .
Linear independence testing is a fundamental information-theoretic and statistical problem that can be posed as follows : given $n$ points $\{ ( X_i , Y_i ) \}^n_{i=0}$ from a $p+q$ dimensional multivariate distribution where $X_i \in \mathbb{R}^p$ and $Y_i \in\mathbb{R}^q$ , determine whether $a^T X$ and $b^T Y$ are uncorrelated for every $a \in \mathbb{R}^p , b\in \mathbb{R}^q$ or not . We give minimax lower bound for this problem ( when $p+q , n \to \infty$ , $ ( p+q ) /n \leq \kappa < \infty$ , without sparsity assumptions ) . In summary , our results imply that $n$ must be at least as large as $\sqrt {pq}/\|\Sigma_{XY}\|_F^0$ for any procedure ( test ) to have non-trivial power , where $\Sigma_{XY}$ is the cross-covariance matrix of $X , Y$ . We also provide some evidence that the lower bound is tight , by connections to two-sample testing and regression in specific settings .
Having a regression model , we are interested in finding two-sided intervals that are guaranteed to contain at least a desired proportion of the conditional distribution of the response variable given a specific combination of predictors . We name such intervals predictive intervals . This work presents a new method to find two-sided predictive intervals for non-parametric least squares regression without the homoscedasticity assumption . Our predictive intervals are built by using tolerance intervals on prediction errors in the query point ' s neighborhood . We proposed a predictive interval model test and we also used it as a constraint in our hyper-parameter tuning algorithm . This gives an algorithm that finds the smallest reliable predictive intervals for a given dataset . We also introduce a measure for comparing different interval prediction methods yielding intervals having different size and coverage . These experiments show that our methods are more reliable , effective and precise than other interval prediction methods .
In this work we present a review of the state of the art of Learning Vector Quantization ( LVQ ) classifiers . A taxonomy is proposed which integrates the most relevant LVQ approaches to date . The main concepts associated with modern LVQ approaches are defined . A comparison is made among eleven LVQ classifiers using one real-world and two artificial datasets .
The question why deep learning algorithms generalize so well has attracted increasing research interest . However , most of the well-established approaches , such as hypothesis capacity , stability or sparseness , have not provided complete explanations ( Zhang et al . , 0000 ; Kawaguchi et al . , 0000 ) . In this work , we focus on the robustness approach ( Xu & Mannor , 0000 ) , i . e . , if the error of a hypothesis will not change much due to perturbations of its training examples , then it will also generalize well . As most deep learning algorithms are stochastic ( e . g . , Stochastic Gradient Descent , Dropout , and Bayes-by-backprop ) , we revisit the robustness arguments of Xu & Mannor , and introduce a new approach , ensemble robustness , that concerns the robustness of a population of hypotheses . Through the lens of ensemble robustness , we reveal that a stochastic learning algorithm can generalize well as long as its sensitiveness to adversarial perturbations is bounded in average over training examples . Moreover , an algorithm may be sensitive to some adversarial examples ( Goodfellow et al . , 0000 ) but still generalize well . To support our claims , we provide extensive simulations for different deep learning algorithms and different network architectures exhibiting a strong correlation between ensemble robustness and the ability to generalize .
In this paper , we consider a class of finite-sum convex optimization problems defined over a distributed multiagent network with $m$ agents connected to a central server . In particular , the objective function consists of the average of $m$ ( $\ge 0$ ) smooth components associated with each network agent together with a strongly convex term . Our major contribution is to develop a new randomized incremental gradient algorithm , namely random gradient extrapolation method ( RGEM ) , which does not require any exact gradient evaluation even for the initial point , but can achieve the optimal ${\cal O} ( \log ( 0/\epsilon ) ) $ complexity bound in terms of the total number of gradient evaluations of component functions to solve the finite-sum problems . Furthermore , we demonstrate that for stochastic finite-sum optimization problems , RGEM maintains the optimal ${\cal O} ( 0/\epsilon ) $ complexity ( up to a certain logarithmic factor ) in terms of the number of stochastic gradient computations , but attains an ${\cal O} ( \log ( 0/\epsilon ) ) $ complexity in terms of communication rounds ( each round involves only one agent ) . It is worth noting that the former bound is independent of the number of agents $m$ , while the latter one only linearly depends on $m$ or even $\sqrt m$ for ill-conditioned problems . To the best of our knowledge , this is the first time that these complexity bounds have been obtained for distributed and stochastic optimization problems . Moreover , our algorithms were developed based on a novel dual perspective of Nesterov ' s accelerated gradient method .
Dynamic neural network toolkits such as PyTorch , DyNet , and Chainer offer more flexibility for implementing models that cope with data of varying dimensions and structure , relative to toolkits that operate on statically declared computations ( e . g . , TensorFlow , CNTK , and Theano ) . However , existing toolkits - both static and dynamic - require that the developer organize the computations into the batches necessary for exploiting high-performance algorithms and hardware . This batching task is generally difficult , but it becomes a major hurdle as architectures become complex . In this paper , we present an algorithm , and its implementation in the DyNet toolkit , for automatically batching operations . Developers simply write minibatch computations as aggregations of single instance computations , and the batching algorithm seamlessly executes them , on the fly , using computationally efficient batched operations . On a variety of tasks , we obtain throughput similar to that obtained with manual batches , as well as comparable speedups over single-instance learning on architectures that are impractical to batch manually .
Although aviation accidents are rare , safety incidents occur more frequently and require careful analysis for providing actionable recommendations to improve safety . Automatically analyzing safety incidents using flight data is challenging because of the absence of labels on timestep-wise events in a flight , complexity of multi-dimensional data , and lack of scalable tools to perform analysis over large number of events . In this work , we propose a precursor mining algorithm that identifies correlated patterns in multidimensional time series to explain an adverse event . Precursors are valuable to systems health and safety monitoring in explaining and forecasting anomalies . Current precursor mining methods suffer from poor scalability to high dimensional time series data and in capturing long-term memory . We propose an approach by combining multiple-instance learning ( MIL ) and deep recurrent neural networks ( DRNN ) to take advantage of MIL ' s ability to model weakly-supervised data and DRNN ' s ability to model long term memory processes , to scale well to high dimensional data and to large volumes of data using GPU parallelism . We apply the proposed method to find precursors and offer explanations to high speed exceedance safety incidents using commercial flight data .
Separating the short jobs from the long is a known technique to improve scheduling performance . In this paper we describe a method we developed for accurately predicting the runtimes classes of the jobs to enable this separation . Our method uses the fact that the runtimes can be represented as a mixture of overlapping Gaussian distributions , in order to train a CART classifier to provide the prediction . The threshold that separates the short jobs from the long jobs is determined during the evaluation of the classifier to maximize prediction accuracy . Our results indicate overall accuracy of 00% for the data set used in our study , with sensitivity and specificity both above 00% .
Usually one compares the accuracy of two competing classifiers via null hypothesis significance tests ( nhst ) . Yet the nhst tests suffer from important shortcomings , which can be overcome by switching to Bayesian hypothesis testing . We propose a Bayesian hierarchical model which jointly analyzes the cross-validation results obtained by two classifiers on multiple data sets . It returns the posterior probability of the accuracies of the two classifiers being practically equivalent or significantly different . A further strength of the hierarchical model is that , by jointly analyzing the results obtained on all data sets , it reduces the estimation error compared to the usual approach of averaging the cross-validation results obtained on a given data set .
In this paper , we propose a novel sufficient decrease technique for variance reduced stochastic gradient descent methods such as SAG , SVRG and SAGA . In order to make sufficient decrease for stochastic optimization , we design a new sufficient decrease criterion , which yields sufficient decrease versions of variance reduction algorithms such as SVRG-SD and SAGA-SD as a byproduct . We introduce a coefficient to scale current iterate and satisfy the sufficient decrease property , which takes the decisions to shrink , expand or move in the opposite direction , and then give two specific update rules of the coefficient for Lasso and ridge regression . Moreover , we analyze the convergence properties of our algorithms for strongly convex problems , which show that both of our algorithms attain linear convergence rates . We also provide the convergence guarantees of our algorithms for non-strongly convex problems . Our experimental results further verify that our algorithms achieve significantly better performance than their counterparts .
Learning and memory in the brain are implemented by complex , time-varying changes in neural circuitry . The computational rules according to which synaptic weights change over time are the subject of much research , and are not precisely understood . Until recently , limitations in experimental methods have made it challenging to test hypotheses about synaptic plasticity on a large scale . However , as such data become available and these barriers are lifted , it becomes necessary to develop analysis techniques to validate plasticity models . Here , we present a highly extensible framework for modeling arbitrary synaptic plasticity rules on spike train data in populations of interconnected neurons . We treat synaptic weights as a ( potentially nonlinear ) dynamical system embedded in a fully-Bayesian generalized linear model ( GLM ) . In addition , we provide an algorithm for inferring synaptic weight trajectories alongside the parameters of the GLM and of the learning rules . Using this method , we perform model comparison of two proposed variants of the well-known spike-timing-dependent plasticity ( STDP ) rule , where nonlinear effects play a substantial role . On synthetic data generated from the biophysical simulator NEURON , we show that we can recover the weight trajectories , the pattern of connectivity , and the underlying learning rules .
In distributed ML applications , shared parameters are usually replicated among computing nodes to minimize network overhead . Therefore , proper consistency model must be carefully chosen to ensure algorithm ' s correctness and provide high throughput . Existing consistency models used in general-purpose databases and modern distributed ML systems are either too loose to guarantee correctness of the ML algorithms or too strict and thus fail to fully exploit the computing power of the underlying distributed system . Many ML algorithms fall into the category of \emph{iterative convergent algorithms} which start from a randomly chosen initial point and converge to optima by repeating iteratively a set of procedures . We ' ve found that many such algorithms are to a bounded amount of inconsistency and still converge correctly . This property allows distributed ML to relax strict consistency models to improve system performance while theoretically guarantees algorithmic correctness . In this paper , we present several relaxed consistency models for asynchronous parallel computation and theoretically prove their algorithmic correctness . The proposed consistency models are implemented in a distributed parameter server and evaluated in the context of a popular ML application : topic modeling .
We explore the question of whether the representations learned by classifiers can be used to enhance the quality of generative models . Our conjecture is that labels correspond to characteristics of natural data which are most salient to humans : identity in faces , objects in images , and utterances in speech . We propose to take advantage of this by using the representations from discriminative classifiers to augment the objective function corresponding to a generative model . In particular we enhance the objective function of the variational autoencoder , a popular generative model , with a discriminative regularization term . We show that enhancing the objective function in this way leads to samples that are clearer and have higher visual quality than the samples from the standard variational autoencoders .
Lasso is a widely used regression technique to find sparse representations . When the dimension of the feature space and the number of samples are extremely large , solving the Lasso problem remains challenging . To improve the efficiency of solving large-scale Lasso problems , El Ghaoui and his colleagues have proposed the SAFE rules which are able to quickly identify the inactive predictors , i . e . , predictors that have $0$ components in the solution vector . Then , the inactive predictors or features can be removed from the optimization problem to reduce its scale . By transforming the standard Lasso to its dual form , it can be shown that the inactive predictors include the set of inactive constraints on the optimal dual solution . In this paper , we propose an efficient and effective screening rule via Dual Polytope Projections ( DPP ) , which is mainly based on the uniqueness and nonexpansiveness of the optimal dual solution due to the fact that the feasible set in the dual space is a convex and closed polytope . Moreover , we show that our screening rule can be extended to identify inactive groups in group Lasso . To the best of our knowledge , there is currently no " exact " screening rule for group Lasso . We have evaluated our screening rule using synthetic and real data sets . Results show that our rule is more effective in identifying inactive predictors than existing state-of-the-art screening rules for Lasso .
Principal Components Analysis is a widely used technique for dimension reduction and characterization of variability in multivariate populations . Our interest lies in studying when and why the rotation to principal components can be used effectively within a response-predictor set relationship in the context of mode hunting . Specifically focusing on the Patient Rule Induction Method ( PRIM ) , we first develop a fast version of this algorithm ( fastPRIM ) under normality which facilitates the theoretical studies to follow . Using basic geometrical arguments , we then demonstrate how the PC rotation of the predictor space alone can in fact generate improved mode estimators . Simulation results are used to illustrate our findings .
Generative models for graphs have been typically committed to strong prior assumptions concerning the form of the modeled distributions . Moreover , the vast majority of currently available models are either only suitable for characterizing some particular network properties ( such as degree distribution or clustering coefficient ) , or they are aimed at estimating joint probability distributions , which is often intractable in large-scale networks . In this paper , we first propose a novel network statistic , based on the Laplacian spectrum of graphs , which allows to dispense with any parametric assumption concerning the modeled network properties . Second , we use the defined statistic to develop the Fiedler random graph model , switching the focus from the estimation of joint probability distributions to a more tractable conditional estimation setting . After analyzing the dependence structure characterizing Fiedler random graphs , we evaluate them experimentally in edge prediction over several real-world networks , showing that they allow to reach a much higher prediction accuracy than various alternative statistical models .
We present a convex approach to probabilistic segmentation and modeling of time series data . Our approach builds upon recent advances in multivariate total variation regularization , and seeks to learn a separate set of parameters for the distribution over the observations at each time point , but with an additional penalty that encourages the parameters to remain constant over time . We propose efficient optimization methods for solving the resulting ( large ) optimization problems , and a two-stage procedure for estimating recurring clusters under such models , based upon kernel density estimation . Finally , we show on a number of real-world segmentation tasks , the resulting methods often perform as well or better than existing latent variable models , while being substantially easier to train .
In this paper , we study the trade-offs of different inference approaches for Bayesian matrix factorisation methods , which are commonly used for predicting missing values , and for finding patterns in the data . In particular , we consider Bayesian nonnegative variants of matrix factorisation and tri-factorisation , and compare non-probabilistic inference , Gibbs sampling , variational Bayesian inference , and a maximum-a-posteriori approach . The variational approach is new for the Bayesian nonnegative models . We compare their convergence , and robustness to noise and sparsity of the data , on both synthetic and real-world datasets . Furthermore , we extend the models with the Bayesian automatic relevance determination prior , allowing the models to perform automatic model selection , and demonstrate its efficiency .
We consider the problem of learning the underlying graph of an unknown Ising model on p spins from a collection of i . i . d . samples generated from the model . We suggest a new estimator that is computationally efficient and requires a number of samples that is near-optimal with respect to previously established information-theoretic lower-bound . Our statistical estimator has a physical interpretation in terms of " interaction screening " . The estimator is consistent and is efficiently implemented using convex optimization . We prove that with appropriate regularization , the estimator recovers the underlying graph using a number of samples that is logarithmic in the system size p and exponential in the maximum coupling-intensity and maximum node-degree .
We consider deep neural networks , in which the output of each node is a quadratic function of its inputs . Similar to other deep architectures , these networks can compactly represent any function on a finite training set . The main goal of this paper is the derivation of an efficient layer-by-layer algorithm for training such networks , which we denote as the \emph{Basis Learner} . The algorithm is a universal learner in the sense that the training error is guaranteed to decrease at every iteration , and can eventually reach zero under mild conditions . We present practical implementations of this algorithm , as well as preliminary experimental results . We also compare our deep architecture to other shallow architectures for learning polynomials , in particular kernel learning .
It is now known that an extended Gaussian process model equipped with rescaling can adapt to different smoothness levels of a function valued parameter in many nonparametric Bayesian analyses , offering a posterior convergence rate that is optimal ( up to logarithmic factors ) for the smoothness class the true function belongs to . This optimal rate also depends on the dimension of the function ' s domain and one could potentially obtain a faster rate of convergence by casting the analysis in a lower dimensional subspace that does not amount to any loss of information about the true function . In general such a subspace is not known a priori but can be explored by equipping the model with variable selection or linear projection . We demonstrate that for nonparametric regression , classification , density estimation and density regression , a rescaled Gaussian process model equipped with variable selection or linear projection offers a posterior convergence rate that is optimal ( up to logarithmic factors ) for the lowest dimension in which the analysis could be cast without any loss of information about the true function . Theoretical exploration of such dimension reduction features appears novel for Bayesian nonparametric models with or without Gaussian processes .
We introduce in this paper a new algorithm for Multi-Armed Bandit ( MAB ) problems . A machine learning paradigm popular within Cognitive Network related topics ( e . g . , Spectrum Sensing and Allocation ) . We focus on the case where the rewards are exponentially distributed , which is common when dealing with Rayleigh fading channels . This strategy , named Multiplicative Upper Confidence Bound ( MUCB ) , associates a utility index to every available arm , and then selects the arm with the highest index . For every arm , the associated index is equal to the product of a multiplicative factor by the sample mean of the rewards collected by this arm . We show that the MUCB policy has a low complexity and is order optimal .
Many machine learning ( ML ) approaches are widely used to generate bioclimatic models for prediction of geographic range of organism as a function of climate . Applications such as prediction of range shift in organism , range of invasive species influenced by climate change are important parameters in understanding the impact of climate change . However , success of machine learning-based approaches depends on a number of factors . While it can be safely said that no particular ML technique can be effective in all applications and success of a technique is predominantly dependent on the application or the type of the problem , it is useful to understand their behaviour to ensure informed choice of techniques . This paper presents a comprehensive review of machine learning-based bioclimatic model generation and analyses the factors influencing success of such models . Considering the wide use of statistical techniques , in our discussion we also include conventional statistical techniques used in bioclimatic modelling .
We study two-layer belief networks of binary random variables in which the conditional probabilities Pr[childlparents] depend monotonically on weighted sums of the parents . In large networks where exact probabilistic inference is intractable , we show how to compute upper and lower bounds on many probabilities of interest . In particular , using methods from large deviation theory , we derive rigorous bounds on marginal probabilities such as Pr[children] and prove rates of convergence for the accuracy of our bounds as a function of network size . Our results apply to networks with generic transfer function parameterizations of the conditional probability tables , such as sigmoid and noisy-OR . They also explicitly illustrate the types of averaging behavior that can simplify the problem of inference in large networks .
Kernel adaptive filters ( KAF ) are a class of powerful nonlinear filters developed in Reproducing Kernel Hilbert Space ( RKHS ) . The Gaussian kernel is usually the default kernel in KAF algorithms , but selecting the proper kernel size ( bandwidth ) is still an open important issue especially for learning with small sample sizes . In previous research , the kernel size was set manually or estimated in advance by Silvermans rule based on the sample distribution . This study aims to develop an online technique for optimizing the kernel size of the kernel least mean square ( KLMS ) algorithm . A sequential optimization strategy is proposed , and a new algorithm is developed , in which the filter weights and the kernel size are both sequentially updated by stochastic gradient algorithms that minimize the mean square error ( MSE ) . Theoretical results on convergence are also presented . The excellent performance of the new algorithm is confirmed by simulations on static function estimation and short term chaotic time series prediction .
The need to carry out parameter estimation from massive data has reinvigorated interest in iterative estimation methods , in statistics and machine learning . Classic work includes deterministic gradient-based methods , such as quasi-Newton , and stochastic gradient descent and its variants , including adaptive learning rates , acceleration and averaging . Current work increasingly relies on methods that employ proximal operators , leading to updates defined through implicit equations , which need to be solved at each iteration . Such methods are especially attractive in modern problems with massive data because they are numerically stable and converge with minimal assumptions , among other reasons . However , while the majority of existing methods can be subsumed into the gradient-free stochastic approximation framework developed by Robbins and Monro ( 0000 ) , there is no such framework for methods with implicit updates . Here , we conceptualize a gradient-free implicit stochastic approximation procedure , and develop asymptotic and non-asymptotic theory for it . This new framework provides a theoretical foundation for gradient-based procedures that rely on implicit updates , and opens the door to iterative estimation methods that do not require a gradient , nor a fully known likelihood .
While generative models such as Latent Dirichlet Allocation ( LDA ) have proven fruitful in topic modeling , they often require detailed assumptions and careful specification of hyperparameters . Such model complexity issues only compound when trying to generalize generative models to incorporate human input . We introduce Correlation Explanation ( CorEx ) , an alternative approach to topic modeling that does not assume an underlying generative model , and instead learns maximally informative topics through an information-theoretic framework . This framework naturally generalizes to hierarchical and semi-supervised extensions with no additional modeling assumptions . In particular , word-level domain knowledge can be flexibly incorporated within CorEx through anchor words , allowing topic separability and representation to be promoted with minimal human intervention . Across a variety of datasets , metrics , and experiments , we demonstrate that CorEx produces topics that are comparable in quality to those produced by unsupervised and semi-supervised variants of LDA .
Minibatching is a very well studied and highly popular technique in supervised learning , used by practitioners due to its ability to accelerate training through better utilization of parallel processing power and reduction of stochastic variance . Another popular technique is importance sampling -- a strategy for preferential sampling of more important examples also capable of accelerating the training process . However , despite considerable effort by the community in these areas , and due to the inherent technical difficulty of the problem , there is no existing work combining the power of importance sampling with the strength of minibatching . In this paper we propose the first {\em importance sampling for minibatches} and give simple and rigorous complexity analysis of its performance . We illustrate on synthetic problems that for training data of certain properties , our sampling can lead to several orders of magnitude improvement in training time . We then test the new sampling on several popular datasets , and show that the improvement can reach an order of magnitude .
Many applications of machine learning , for example in health care , would benefit from methods that can guarantee privacy of data subjects . Differential privacy ( DP ) has become established as a standard for protecting learning results . The standard DP algorithms require a single trusted party to have access to the entire data , which is a clear weakness . We consider DP Bayesian learning in a distributed setting , where each party only holds a single sample or a few samples of the data . We propose a learning strategy based on a secure multi-party sum function for aggregating summaries from data holders and the Gaussian mechanism for DP . Our method builds on an asymptotically optimal and practically efficient DP Bayesian inference with rapidly diminishing extra cost .
Any-gram kernels are a flexible and efficient way to employ bag-of-n-gram features when learning from textual data . They are also compatible with the use of word embeddings so that word similarities can be accounted for . While the original any-gram kernels are implemented on top of tree kernels , we propose a new approach which is independent of tree kernels and is more efficient . We also propose a more effective way to make use of word embeddings than the original any-gram formulation . When applied to the task of sentiment classification , our new formulation achieves significantly better performance .
We study the stochastic online problem of learning to influence in a social network with semi-bandit feedback , where we observe how users influence each other . The problem combines challenges of limited feedback , because the learning agent only observes the influenced portion of the network , and combinatorial number of actions , because the cardinality of the feasible set is exponential in the maximum number of influencers . We propose a computationally efficient UCB-like algorithm , IMLinUCB , and analyze it . Our regret bounds are polynomial in all quantities of interest ; reflect the structure of the network and the probabilities of influence . Moreover , they do not depend on inherently large quantities , such as the cardinality of the action set . To the best of our knowledge , these are the first such results . IMLinUCB permits linear generalization and therefore is suitable for large-scale problems . Our experiments show that the regret of IMLinUCB scales as suggested by our upper bounds in several representative graph topologies ; and based on linear generalization , IMLinUCB can significantly reduce regret of real-world influence maximization semi-bandits .
In the high-dimensional regression model a response variable is linearly related to $p$ covariates , but the sample size $n$ is smaller than $p$ . We assume that only a small subset of covariates is `active ' ( i . e . , the corresponding coefficients are non-zero ) , and consider the model-selection problem of identifying the active covariates . A popular approach is to estimate the regression coefficients through the Lasso ( $\ell_0$-regularized least squares ) . This is known to correctly identify the active set only if the irrelevant covariates are roughly orthogonal to the relevant ones , as quantified through the so called `irrepresentability ' condition . In this paper we study the `Gauss-Lasso ' selector , a simple two-stage method that first solves the Lasso , and then performs ordinary least squares restricted to the Lasso active set . We formulate `generalized irrepresentability condition ' ( GIC ) , an assumption that is substantially weaker than irrepresentability . We prove that , under GIC , the Gauss-Lasso correctly recovers the active set .
In information retrieval , a fundamental goal is to transform a document into concepts that are representative of its content . The term " representative " is in itself challenging to define , and various tasks require different granularities of concepts . In this paper , we aim to model concepts that are sparse over the vocabulary , and that flexibly adapt their content based on other relevant semantic information such as textual structure or associated image features . We explore a Bayesian nonparametric model based on nested beta processes that allows for inferring an unknown number of strictly sparse concepts . The resulting model provides an inherently different representation of concepts than a standard LDA ( or HDP ) based topic model , and allows for direct incorporation of semantic features . We demonstrate the utility of this representation on multilingual blog data and the Congressional Record .
Word representations induced from models with discrete latent variables ( e . g . \ HMMs ) have been shown to be beneficial in many NLP applications . In this work , we exploit labeled syntactic dependency trees and formalize the induction problem as unsupervised learning of tree-structured hidden Markov models . Syntactic functions are used as additional observed variables in the model , influencing both transition and emission components . Such syntactic information can potentially lead to capturing more fine-grain and functional distinctions between words , which , in turn , may be desirable in many NLP applications . We evaluate the word representations on two tasks -- named entity recognition and semantic frame identification . We observe improvements from exploiting syntactic function information in both cases , and the results rivaling those of state-of-the-art representation learning methods . Additionally , we revisit the relationship between sequential and unlabeled-tree models and find that the advantage of the latter is not self-evident .
Many online companies sell advertisement space in second-price auctions with reserve . In this paper , we develop a probabilistic method to learn a profitable strategy to set the reserve price . We use historical auction data with features to fit a predictor of the best reserve price . This problem is delicate - the structure of the auction is such that a reserve price set too high is much worse than a reserve price set too low . To address this we develop objective variables , a new framework for combining probabilistic modeling with optimal decision-making . Objective variables are " hallucinated observations " that transform the revenue maximization task into a regularized maximum likelihood estimation problem , which we solve with an EM algorithm . This framework enables a variety of prediction mechanisms to set the reserve price . As examples , we study objective variable methods with regression , kernelized regression , and neural networks on simulated and real data . Our methods outperform previous approaches both in terms of scalability and profit .
We describe two nonconventional algorithms for linear regression , called GAME and CLASH . The salient characteristics of these approaches is that they exploit the convex $\ell_0$-ball and non-convex $\ell_0$-sparsity constraints jointly in sparse recovery . To establish the theoretical approximation guarantees of GAME and CLASH , we cover an interesting range of topics from game theory , convex and combinatorial optimization . We illustrate that these approaches lead to improved theoretical guarantees and empirical performance beyond convex and non-convex solvers alone .
Community detection is a fundamental statistical problem in network data analysis . Many algorithms have been proposed to tackle this problem . Most of these algorithms are not guaranteed to achieve the statistical optimality of the problem , while procedures that achieve information theoretic limits for general parameter spaces are not computationally tractable . In this paper , we present a computationally feasible two-stage method that achieves optimal statistical performance in misclassification proportion for stochastic block model under weak regularity conditions . Our two-stage procedure consists of a generic refinement step that can take a wide range of weakly consistent community detection procedures as initializer , to which the refinement stage applies and outputs a community assignment achieving optimal misclassification proportion with high probability . The practical effectiveness of the new algorithm is demonstrated by competitive numerical results .
In this paper we introduce a micro-clustering strategy for Functional Boxplots . The aim is to summarize a set of streaming time series splitted in non overlapping windows . It is a two step strategy which performs at first , an on-line summarization by means of functional data structures , named Functional Boxplot micro-clusters ; then it reveals the final summarization by processing , off-line , the functional data structures . Our main contribute consists in providing a new definition of micro-cluster based on Functional Boxplots and , in defining a proximity measure which allows to compare and update them . This allows to get a finer graphical summarization of the streaming time series by five functional basic statistics of data . The obtained synthesis will be able to keep track of the dynamic evolution of the multiple streams .
In this paper , we analyze different preconditionings designed to enhance robustness of pure-pixel search algorithms , which are used for blind hyperspectral unmixing and which are equivalent to near-separable nonnegative matrix factorization algorithms . Our analysis focuses on the successive projection algorithm ( SPA ) , a simple , efficient and provably robust algorithm in the pure-pixel algorithm class . Recently , a provably robust preconditioning was proposed by Gillis and Vavasis ( arXiv : 0000 . 0000 ) which requires the resolution of a semidefinite program ( SDP ) to find a data points-enclosing minimum volume ellipsoid . Since solving the SDP in high precisions can be time consuming , we generalize the robustness analysis to approximate solutions of the SDP , that is , solutions whose objective function values are some multiplicative factors away from the optimal value . It is shown that a high accuracy solution is not crucial for robustness , which paves the way for faster preconditionings ( e . g . , based on first-order optimization methods ) . This first contribution also allows us to provide a robustness analysis for two other preconditionings . The first one is pre-whitening , which can be interpreted as an optimal solution of the same SDP with additional constraints . We analyze robustness of pre-whitening which allows us to characterize situations in which it performs competitively with the SDP-based preconditioning . The second one is based on SPA itself and can be interpreted as an optimal solution of a relaxation of the SDP . It is extremely fast while competing with the SDP-based preconditioning on several synthetic data sets .
During reactive transport modeling , the computational cost associated with chemical reaction calculations is often 00-000 times higher than that of transport calculations . Most of these costs results from chemical equilibrium calculations that are performed at least once in every mesh cell and at every time step of the simulation . Calculating chemical equilibrium is an iterative process , where each iteration is in general so computationally expensive that even if every calculation converged in a single iteration , the resulting speedup would not be significant . Thus , rather than proposing a fast-converging numerical method for solving chemical equilibrium equations , we present a machine learning method that enables new equilibrium states to be quickly and accurately estimated , whenever a previous equilibrium calculation with similar input conditions has been performed . We demonstrate the use of this smart chemical equilibrium method in a reactive transport modeling example and show that , even at early simulation times , the majority of all equilibrium calculations are quickly predicted and , after some time steps , the machine-learning-accelerated chemical solver has been fully trained to rapidly perform all subsequent equilibrium calculations , resulting in speedups of almost two orders of magnitude . We remark that our new on-demand machine learning method can be applied to any case in which a massive number of sequential/parallel evaluations of a computationally expensive function $f$ needs to be done , $y=f ( x ) $ . We remark , that , in contrast to traditional machine learning algorithms , our on-demand training approach does not require a statistics-based training phase before the actual simulation of interest commences . The introduced on-demand training scheme requires , however , the first-order derivatives $\partial f/\partial x$ for later smart predictions .
Similarity metrics are a core component of many information retrieval and machine learning systems . In this work we propose a method capable of learning a similarity metric from data equipped with a binary relation . By considering only the similarity constraints , and initially ignoring the features , we are able to learn target vectors for each instance using one of several appropriately designed loss functions . A regression model can then be constructed that maps novel feature vectors to the same target vector space , resulting in a feature extractor that computes vectors for which a predefined metric is a meaningful measure of similarity . We present results on both multiclass and multi-label classification datasets that demonstrate considerably faster convergence , as well as higher accuracy on the majority of the intrinsic evaluation tasks and all extrinsic evaluation tasks .
Structure learning of Gaussian graphical models is an extensively studied problem in the classical multivariate setting where the sample size n is larger than the number of random variables p , as well as in the more challenging setting when p>>n . However , analogous approaches for learning the structure of graphical models with mixed discrete and continuous variables when p>>n remain largely unexplored . Here we describe a statistical learning procedure for this problem based on limited-order correlations and assess its performance with synthetic and real data .
We consider a joint processing of $n$ independent sparse regression problems . Each is based on a sample $ ( y_{i0} , x_{i0} ) . . . , ( y_{im} , x_{im} ) $ of $m$ \iid observations from $y_{i0}=x_{i0}\t\beta_i+\eps_{i0}$ , $y_{i0}\in \R$ , $x_{i 0}\in\R^p$ , $i=0 , . . . , n$ , and $\eps_{i0}\dist N ( 0 , \sig^0 ) $ , say . $p$ is large enough so that the empirical risk minimizer is not consistent . We consider three possible extensions of the lasso estimator to deal with this problem , the lassoes , the group lasso and the RING lasso , each utilizing a different assumption how these problems are related . For each estimator we give a Bayesian interpretation , and we present both persistency analysis and non-asymptotic error bounds based on restricted eigenvalue - type assumptions .
This paper presents a bias-variance tradeoff of graph Laplacian regularizer , which is widely used in graph signal processing and semi-supervised learning tasks . The scaling law of the optimal regularization parameter is specified in terms of the spectral graph properties and a novel signal-to-noise ratio parameter , which suggests selecting a mediocre regularization parameter is often suboptimal . The analysis is applied to three applications , including random , band-limited , and multiple-sampled graph signals . Experiments on synthetic and real-world graphs demonstrate near-optimal performance of the established analysis .
In recent scene recognition research images or large image regions are often represented as disorganized " bags " of features which can then be analyzed using models originally developed to capture co-variation of word counts in text . However , image feature counts are likely to be constrained in different ways than word counts in text . For example , as a camera pans upwards from a building entrance over its first few floors and then further up into the sky Fig . 0 , some feature counts in the image drop while others rise -- only to drop again giving way to features found more often at higher elevations . The space of all possible feature count combinations is constrained both by the properties of the larger scene and the size and the location of the window into it . To capture such variation , in this paper we propose the use of the counting grid model . This generative model is based on a grid of feature counts , considerably larger than any of the modeled images , and considerably smaller than the real estate needed to tile the images next to each other tightly . Each modeled image is assumed to have a representative window in the grid in which the feature counts mimic the feature distribution in the image . We provide a learning procedure that jointly maps all images in the training set to the counting grid and estimates the appropriate local counts in it . Experimentally , we demonstrate that the resulting representation captures the space of feature count combinations more accurately than the traditional models , not only when the input images come from a panning camera , but even when modeling images of different scenes from the same category .
Neuromorphic hardware tends to pose limits on the connectivity of deep networks that one can run on them . But also generic hardware and software implementations of deep learning run more efficiently on sparse networks . Several methods exist for pruning connections of a neural network after it was trained without connectivity constraints . We present an algorithm , DEEP R , that enables us to train directly a sparsely connected neural network . DEEP R automatically rewires the network during supervised training so that connections are there where they are most needed for the task , while its total number is all the time strictly bounded . We demonstrate that DEEP R can be used to train very sparse feedforward and recurrent neural networks on standard benchmark tasks with just a minor loss in performance . DEEP R is based on a rigorous theoretical foundation that views rewiring as stochastic sampling of network configurations from a posterior .
We show that the skip-gram formulation of word0vec trained with negative sampling is equivalent to a weighted logistic PCA . This connection allows us to better understand the objective , compare it to other word embedding methods , and extend it to higher dimensional models .
In this report , an automated bartender system was developed for making orders in a bar using hand gestures . The gesture recognition of the system was developed using Machine Learning techniques , where the model was trained to classify gestures using collected data . The final model used in the system reached an average accuracy of 00% . The system raised ethical concerns both in terms of user interaction and having such a system in a real world scenario , but it could initially work as a complement to a real bartender .
A nonparametric anomalous hypothesis testing problem is investigated , in which there are totally n sequences with s anomalous sequences to be detected . Each typical sequence contains m independent and identically distributed ( i . i . d . ) samples drawn from a distribution p , whereas each anomalous sequence contains m i . i . d . samples drawn from a distribution q that is distinct from p . The distributions p and q are assumed to be unknown in advance . Distribution-free tests are constructed using maximum mean discrepancy as the metric , which is based on mean embeddings of distributions into a reproducing kernel Hilbert space . The probability of error is bounded as a function of the sample size m , the number s of anomalous sequences and the number n of sequences . It is then shown that with s known , the constructed test is exponentially consistent if m is greater than a constant factor of log n , for any p and q , whereas with s unknown , m should has an order strictly greater than log n . Furthermore , it is shown that no test can be consistent for arbitrary p and q if m is less than a constant factor of log n , thus the order-level optimality of the proposed test is established . Numerical results are provided to demonstrate that our tests outperform ( or perform as well as ) the tests based on other competitive approaches under various cases .
Mean shift clustering finds the modes of the data probability density by identifying the zero points of the density gradient . Since it does not require to fix the number of clusters in advance , the mean shift has been a popular clustering algorithm in various application fields . A typical implementation of the mean shift is to first estimate the density by kernel density estimation and then compute its gradient . However , since good density estimation does not necessarily imply accurate estimation of the density gradient , such an indirect two-step approach is not reliable . In this paper , we propose a method to directly estimate the gradient of the log-density without going through density estimation . The proposed method gives the global solution analytically and thus is computationally efficient . We then develop a mean-shift-like fixed-point algorithm to find the modes of the density for clustering . As in the mean shift , one does not need to set the number of clusters in advance . We empirically show that the proposed clustering method works much better than the mean shift especially for high-dimensional data . Experimental results further indicate that the proposed method outperforms existing clustering methods .
We consider the online one-class collaborative filtering ( CF ) problem that consists of recommending items to users over time in an online fashion based on positive ratings only . This problem arises when users respond only occasionally to a recommendation with a positive rating , and never with a negative one . We study the impact of the probability of a user responding to a recommendation , p_f , on the sample complexity , i . e . , the number of ratings required to make `good ' recommendations , and ask whether receiving positive and negative ratings , instead of positive ratings only , improves the sample complexity . Both questions arise in the design of recommender systems . We introduce a simple probabilistic user model , and analyze the performance of an online user-based CF algorithm . We prove that after an initial cold start phase , where recommendations are invested in exploring the user ' s preferences , this algorithm makes---up to a fraction of the recommendations required for updating the user ' s preferences---perfect recommendations . The number of ratings required for the cold start phase is nearly proportional to 0/p_f , and that for updating the user ' s preferences is essentially independent of p_f . As a consequence we find that , receiving positive and negative ratings instead of only positive ones improves the number of ratings required for initial exploration by a factor of 0/p_f , which can be significant .
Recent research has revealed that the output of Deep Neural Networks ( DNN ) can be easily altered by adding relatively small perturbations to the input vector . In this paper , we analyze an attack in an extremely limited scenario where only one pixel can be modified . For that we propose a novel method for generating one-pixel adversarial perturbations based on differential evolution . It requires less adversarial information and can fool more types of networks . The results show that 00 . 00% of the natural images can be perturbed to at least one target class by modifying just one pixel with 00 . 00% confidence on average . Thus , the proposed attack explores a different take on adversarial machine learning in an extreme limited scenario , showing that current DNNs are also vulnerable to such low dimension attacks .
This work addresses decentralized online optimization in non-stationary environments . A network of agents aim to track the minimizer of a global time-varying convex function . The minimizer evolves according to a known dynamics corrupted by an unknown , unstructured noise . At each time , the global function can be cast as a sum of a finite number of local functions , each of which is assigned to one agent in the network . Moreover , the local functions become available to agents sequentially , and agents do not have a prior knowledge of the future cost functions . Therefore , agents must communicate with each other to build an online approximation of the global function . We propose a decentralized variation of the celebrated Mirror Descent , developed by Nemirovksi and Yudin . Using the notion of Bregman divergence in lieu of Euclidean distance for projection , Mirror Descent has been shown to be a powerful tool in large-scale optimization . Our algorithm builds on Mirror Descent , while ensuring that agents perform a consensus step to follow the global function and take into account the dynamics of the global minimizer . To measure the performance of the proposed online algorithm , we compare it to its offline counterpart , where the global functions are available a priori . The gap between the two is called dynamic regret . We establish a regret bound that scales inversely in the spectral gap of the network , and more notably it represents the deviation of minimizer sequence with respect to the given dynamics . We then show that our results subsume a number of results in distributed optimization . We demonstrate the application of our method to decentralized tracking of dynamic parameters and verify the results via numerical experiments .
We start with a description of Lacan ' s work that we then take into our analytics methodology . In a first investigation , a Lacan-motivated template of the Poe story is fitted to the data . A segmentation of the storyline is used in order to map out the diachrony . Based on this , it will be shown how synchronous aspects , potentially related to Lacanian registers , can be sought . This demonstrates the effectiveness of an approach based on a model template of the storyline narrative . In a second and more comprehensive investigation , we develop an approach for revealing , that is , uncovering , Lacanian register relationships . Objectives of this work include the wide and general application of our methodology . This methodology is strongly based on the " letting the data speak " Correspondence Analysis analytics platform of Jean-Paul Benz\ ' ecri , that is also the geometric data analysis , both qualitative and quantitative analytics , developed by Pierre Bourdieu .
The measurement and analysis of Electrodermal Activity ( EDA ) offers applications in diverse areas ranging from market research , to seizure detection , to human stress analysis . Unfortunately , the analysis of EDA signals is made difficult by the superposition of numerous components which can obscure the signal information related to a user ' s response to a stimulus . We show how simple pre-processing followed by a novel compressed sensing based decomposition can mitigate the effects of the undesired noise components and help reveal the underlying physiological signal . The proposed framework allows for decomposition of EDA signals with provable bounds on the recovery of user responses . We test our procedure on both synthetic and real-world EDA signals from wearable sensors and demonstrate that our approach allows for more accurate recovery of user responses as compared to the existing techniques .
We consider statistical as well as algorithmic aspects of solving large-scale least-squares ( LS ) problems using randomized sketching algorithms . For a LS problem with input data $ ( X , Y ) \in \mathbb{R}^{n \times p} \times \mathbb{R}^n$ , sketching algorithms use a sketching matrix , $S\in\mathbb{R}^{r \times n}$ with $r \ll n$ . Then , rather than solving the LS problem using the full data $ ( X , Y ) $ , sketching algorithms solve the LS problem using only the sketched data $ ( SX , SY ) $ . Prior work has typically adopted an algorithmic perspective , in that it has made no statistical assumptions on the input $X$ and $Y$ , and instead it has been assumed that the data $ ( X , Y ) $ are fixed and worst-case ( WC ) . Prior results show that , when using sketching matrices such as random projections and leverage-score sampling algorithms , with $p < r \ll n$ , the WC error is the same as solving the original problem , up to a small constant . From a statistical perspective , we typically consider the mean-squared error performance of randomized sketching algorithms , when data $ ( X , Y ) $ are generated according to a statistical model $Y = X \beta + \epsilon$ , where $\epsilon$ is a noise process . We provide a rigorous comparison of both perspectives leading to insights on how they differ . To do this , we first develop a framework for assessing algorithmic and statistical aspects of randomized sketching methods . We then consider the statistical prediction efficiency ( PE ) and the statistical residual efficiency ( RE ) of the sketched LS estimator ; and we use our framework to provide upper bounds for several types of random projection and random sampling sketching algorithms . Among other results , we show that the RE can be upper bounded when $p < r \ll n$ while the PE typically requires the sample size $r$ to be substantially larger . Lower bounds developed in subsequent results show that our upper bounds on PE can not be improved .
We consider the problem of quickest change-point detection in data streams . Classical change-point detection procedures , such as CUSUM , Shiryaev-Roberts and Posterior Probability statistics , are optimal only if the change-point model is known , which is an unrealistic assumption in typical applied problems . Instead we propose a new method for change-point detection based on Inductive Conformal Martingales , which requires only the independence and identical distribution of observations . We compare the proposed approach to standard methods , as well as to change-point detection oracles , which model a typical practical situation when we have only imprecise ( albeit parametric ) information about pre- and post-change data distributions . Results of comparison provide evidence that change-point detection based on Inductive Conformal Martingales is an efficient tool , capable to work under quite general conditions unlike traditional approaches .
This paper studies the evaluation of policies that recommend an ordered set of items ( e . g . , a ranking ) based on some context---a common scenario in web search , ads , and recommendation . We build on techniques from combinatorial bandits to introduce a new practical estimator that uses logged data to estimate a policy ' s performance . A thorough empirical evaluation on real-world data reveals that our estimator is accurate in a variety of settings , including as a subroutine in a learning-to-rank task , where it achieves competitive performance . We derive conditions under which our estimator is unbiased---these conditions are weaker than prior heuristics for slate evaluation---and experimentally demonstrate a smaller bias than parametric approaches , even when these conditions are violated . Finally , our theory and experiments also show exponential savings in the amount of required data compared with general unbiased estimators .
We propose a novel receiver for orthogonal frequency division multiplexing ( OFDM ) transmissions in impulsive noise environments . Impulsive noise arises in many modern wireless and wireline communication systems , such as Wi-Fi and powerline communications , due to uncoordinated interference that is much stronger than thermal noise . We first show that the bit-error-rate optimal receiver jointly estimates the propagation channel coefficients , the noise impulses , the finite-alphabet symbols , and the unknown bits . We then propose a near-optimal yet computationally tractable approach to this joint estimation problem using loopy belief propagation . In particular , we merge the recently proposed " generalized approximate message passing " ( GAMP ) algorithm with the forward-backward algorithm and soft-input soft-output decoding using a " turbo " approach . Numerical results indicate that the proposed receiver drastically outperforms existing receivers under impulsive noise and comes within 0 dB of the matched-filter bound . Meanwhile , with N tones , the proposed factor-graph-based receiver has only O ( N log N ) complexity , and it can be parallelized .
Sum-Product Networks ( SPNs ) are a class of expressive yet tractable hierarchical graphical models . LearnSPN is a structure learning algorithm for SPNs that uses hierarchical co-clustering to simultaneously identifying similar entities and similar features . The original LearnSPN algorithm assumes that all the variables are discrete and there is no missing data . We introduce a practical , simplified version of LearnSPN , MiniSPN , that runs faster and can handle missing data and heterogeneous features common in real applications . We demonstrate the performance of MiniSPN on standard benchmark datasets and on two datasets from Google ' s Knowledge Graph exhibiting high missingness rates and a mix of discrete and continuous features .
We develop a new approach to learn the parameters of regression models with hidden variables . In a nutshell , we estimate the gradient of the regression function at a set of random points , and cluster the estimated gradients . The centers of the clusters are used as estimates for the parameters of hidden units . We justify this approach by studying a toy model , whereby the regression function is a linear combination of sigmoids . We prove that indeed the estimated gradients concentrate around the parameter vectors of the hidden units , and provide non-asymptotic bounds on the number of required samples . To the best of our knowledge , no comparable guarantees have been proven for linear combinations of sigmoids .
We introduce a new , systematic framework for visualizing information flow in deep networks . Specifically , given any trained deep convolutional network model and a given test image , our method produces a compact support in the image domain that corresponds to a ( high-resolution ) feature that contributes to the given explanation . Our method is both computationally efficient as well as numerically robust . We present several preliminary numerical results that support the benefits of our framework over existing methods .
We investigate probabilistic graphical models that allow for both cycles and latent variables . For this we introduce directed graphs with hyperedges ( HEDGes ) , generalizing and combining both marginalized directed acyclic graphs ( mDAGs ) that can model latent ( dependent ) variables , and directed mixed graphs ( DMGs ) that can model cycles . We define and analyse several different Markov properties that relate the graphical structure of a HEDG with a probability distribution on a corresponding product space over the set of nodes , for example factorization properties , structural equations properties , ordered/local/global Markov properties , and marginal versions of these . The various Markov properties for HEDGes are in general not equivalent to each other when cycles or hyperedges are present , in contrast with the simpler case of directed acyclic graphical ( DAG ) models ( also known as Bayesian networks ) . We show how the Markov properties for HEDGes - and thus the corresponding graphical Markov models - are logically related to each other .
We propose a method to predict the subject-specific longitudinal progression of brain structures extracted from baseline MRI , and evaluate its performance on Alzheimer ' s disease data . The disease progression is modeled as a trajectory on a group of diffeomorphisms in the context of large deformation diffeomorphic metric mapping ( LDDMM ) . We first exhibit the limited predictive abilities of geodesic regression extrapolation on this group . Building on the recent concept of parallel curves in shape manifolds , we then introduce a second predictive protocol which personalizes previously learned trajectories to new subjects , and investigate the relative performances of two parallel shifting paradigms . This design only requires the baseline imaging data . Finally , coefficients encoding the disease dynamics are obtained from longitudinal cognitive measurements for each subject , and exploited to refine our methodology which is demonstrated to successfully predict the follow-up visits .
Clustering ensemble is one of the most recent advances in unsupervised learning . It aims to combine the clustering results obtained using different algorithms or from different runs of the same clustering algorithm for the same data set , this is accomplished using on a consensus function , the efficiency and accuracy of this method has been proven in many works in literature . In the first part of this paper we make a comparison among current approaches to clustering ensemble in literature . All of these approaches consist of two main steps : the ensemble generation and consensus function . In the second part of the paper , we suggest engaging supervision in the clustering ensemble procedure to get more enhancements on the clustering results . Supervision can be applied in two places : either by using semi-supervised algorithms in the clustering ensemble generation step or in the form of a feedback used by the consensus function stage . Also , we introduce a flexible two parameter weighting mechanism , the first parameter describes the compatibility between the datasets under study and the semi-supervised clustering algorithms used to generate the base partitions , the second parameter is used to provide the user feedback on the these partitions . The two parameters are engaged in a " relabeling and voting " based consensus function to produce the final clustering .
Antimicrobial resistance is an important public health concern that has implications in the practice of medicine worldwide . Accurately predicting resistance phenotypes from genome sequences shows great promise in promoting better use of antimicrobial agents , by determining which antibiotics are likely to be effective in specific clinical cases . In healthcare , this would allow for the design of treatment plans tailored for specific individuals , likely resulting in better clinical outcomes for patients with bacterial infections . In this work , we present the recent work of Drouin et al . ( 0000 ) on using Set Covering Machines to learn highly interpretable models of antibiotic resistance and complement it by providing a large scale application of their method to the entire PATRIC database . We report prediction results for 00 new datasets and present the Kover AMR platform , a new web-based tool allowing the visualization and interpretation of the generated models .
Variable selection in high-dimensional space characterizes many contemporary problems in scientific discovery and decision making . Many frequently-used techniques are based on independence screening ; examples include correlation ranking ( Fan and Lv , 0000 ) or feature selection using a two-sample t-test in high-dimensional classification ( Tibshirani et al . , 0000 ) . Within the context of the linear model , Fan and Lv ( 0000 ) showed that this simple correlation ranking possesses a sure independence screening property under certain conditions and that its revision , called iteratively sure independent screening ( ISIS ) , is needed when the features are marginally unrelated but jointly related to the response variable . In this paper , we extend ISIS , without explicit definition of residuals , to a general pseudo-likelihood framework , which includes generalized linear models as a special case . Even in the least-squares setting , the new method improves ISIS by allowing variable deletion in the iterative process . Our technique allows us to select important features in high-dimensional classification where the popularly used two-sample t-method fails . A new technique is introduced to reduce the false discovery rate in the feature screening stage . Several simulated and two real data examples are presented to illustrate the methodology .
The worldwide surge of multiresistant microbial strains has propelled the search for alternative treatment options . The study of Protein-Protein Interactions ( PPIs ) has been a cornerstone in the clarification of complex physiological and pathogenic processes , thus being a priority for the identification of vital components and mechanisms in pathogens . Despite the advances of laboratorial techniques , computational models allow the screening of protein interactions between entire proteomes in a fast and inexpensive manner . Here , we present a supervised machine learning model for the prediction of PPIs based on the protein sequence . We cluster amino acids regarding their physicochemical properties , and use the discrete cosine transform to represent protein sequences . A mesh of classifiers was constructed to create hyper-specialised classifiers dedicated to the most relevant pairs of molecular function annotations from Gene Ontology . Based on an exhaustive evaluation that includes datasets with different configurations , cross-validation and out-of-sampling validation , the obtained results outscore the state-of-the-art for sequence-based methods . For the final mesh model using SVM with RBF , a consistent average AUC of 0 . 00 was attained .
Let $ ( M , g ) $ be a compact manifold and let $-\Delta \phi_k = \lambda_k \phi_k$ be the sequence of Laplacian eigenfunctions . We present a curious new phenomenon which , so far , we only managed to understand in a few highly specialized cases : the family of functions $f_N : M \rightarrow \mathbb{R}_{\geq 0}$ $$ f_N ( x ) = \sum_{k \leq N}{ \frac{0}{\sqrt{\lambda_k}} \frac{|\phi_k ( x ) |}{\|\phi_k\|_{L^{\infty} ( M ) }}}$$ seems strangely suited for the detection of anomalous points on the manifold . It may be heuristically interpreted as the sum over distances to the nearest nodal line and potentially hints at a new phenomenon in spectral geometry . We give rigorous statements on the unit square $[0 , 0]^0$ ( where minima localize in $\mathbb{Q}^0$ ) and on Paley graphs ( where $f_N$ recovers the geometry of quadratic residues of the underlying finite field $\mathbb{F}_p$ ) . Numerical examples show that the phenomenon seems to arise on fairly generic manifolds .
Federated learning poses new statistical and systems challenges in training machine learning models over distributed networks of devices . In this work , we show that multi-task learning is naturally suited to handle the statistical challenges of this setting , and propose a novel systems-aware optimization method , MOCHA , that is robust to practical systems issues . Our method and theory for the first time consider issues of high communication cost , stragglers , and fault tolerance for distributed multi-task learning . The resulting method achieves significant speedups compared to alternatives in the federated setting , as we demonstrate through simulations on real-world federated datasets .
Spectral methods have greatly advanced the estimation of latent variable models , generating a sequence of novel and efficient algorithms with strong theoretical guarantees . However , current spectral algorithms are largely restricted to mixtures of discrete or Gaussian distributions . In this paper , we propose a kernel method for learning multi-view latent variable models , allowing each mixture component to be nonparametric . The key idea of the method is to embed the joint distribution of a multi-view latent variable into a reproducing kernel Hilbert space , and then the latent parameters are recovered using a robust tensor power method . We establish that the sample complexity for the proposed method is quadratic in the number of latent components and is a low order polynomial in the other relevant parameters . Thus , our non-parametric tensor approach to learning latent variable models enjoys good sample and computational efficiencies . Moreover , the non-parametric tensor power method compares favorably to EM algorithm and other existing spectral algorithms in our experiments .
Vision impairment due to pathological damage of the retina can largely be prevented through periodic screening using fundus color imaging . However the challenge with large scale screening is the inability to exhaustively detect fine blood vessels crucial to disease diagnosis . In this work we present a computational imaging framework using deep and ensemble learning for reliable detection of blood vessels in fundus color images . An ensemble of deep convolutional neural networks is trained to segment vessel and non-vessel areas of a color fundus image . During inference , the responses of the individual ConvNets of the ensemble are averaged to form the final segmentation . In experimental evaluation with the DRIVE database , we achieve the objective of vessel detection with maximum average accuracy of 00 . 0\% and area under ROC curve of 0 . 0000 .
This paper addresses the problem of blind and fully constrained unmixing of hyperspectral images . Unmixing is performed without the use of any dictionary , and assumes that the number of constituent materials in the scene and their spectral signatures are unknown . The estimated abundances satisfy the desired sum-to-one and nonnegativity constraints . Two models with increasing complexity are developed to achieve this challenging task , depending on how noise interacts with hyperspectral data . The first one leads to a convex optimization problem , and is solved with the Alternating Direction Method of Multipliers . The second one accounts for signal-dependent noise , and is addressed with a Reweighted Least Squares algorithm . Experiments on synthetic and real data demonstrate the effectiveness of our approach .
Regularization is a well recognized powerful strategy to improve the performance of a learning machine and $l^q$ regularization schemes with $0<q<\infty$ are central in use . It is known that different $q$ leads to different properties of the deduced estimators , say , $l^0$ regularization leads to smooth estimators while $l^0$ regularization leads to sparse estimators . Then , how does the generalization capabilities of $l^q$ regularization learning vary with $q$ ? In this paper , we study this problem in the framework of statistical learning theory and show that implementing $l^q$ coefficient regularization schemes in the sample dependent hypothesis space associated with Gaussian kernel can attain the same almost optimal learning rates for all $0<q<\infty$ . That is , the upper and lower bounds of learning rates for $l^q$ regularization learning are asymptotically identical for all $0<q<\infty$ . Our finding tentatively reveals that , in some modeling contexts , the choice of $q$ might not have a strong impact with respect to the generalization capability . From this perspective , $q$ can be arbitrarily specified , or specified merely by other no generalization criteria like smoothness , computational complexity , sparsity , etc . .
By lifting the ReLU function into a higher dimensional space , we develop a smooth multi-convex formulation for training feed-forward deep neural networks ( DNNs ) . This allows us to develop a block coordinate descent ( BCD ) training algorithm consisting of a sequence of numerically well-behaved convex optimizations . Using ideas from proximal point methods in convex analysis , we prove that this BCD algorithm will converge globally to a stationary point with R-linear convergence rate of order one . In experiments with the MNIST database , DNNs trained with this BCD algorithm consistently yielded better test-set error rates than identical DNN architectures trained via all the stochastic gradient descent ( SGD ) variants in the Caffe toolbox .
State-of-the-art sequence labeling systems traditionally require large amounts of task-specific knowledge in the form of hand-crafted features and data pre-processing . In this paper , we introduce a novel neutral network architecture that benefits from both word- and character-level representations automatically , by using combination of bidirectional LSTM , CNN and CRF . Our system is truly end-to-end , requiring no feature engineering or data pre-processing , thus making it applicable to a wide range of sequence labeling tasks . We evaluate our system on two data sets for two sequence labeling tasks --- Penn Treebank WSJ corpus for part-of-speech ( POS ) tagging and CoNLL 0000 corpus for named entity recognition ( NER ) . We obtain state-of-the-art performance on both the two data --- 00 . 00\% accuracy for POS tagging and 00 . 00\% F0 for NER .
In certain situations that shall be undoubtedly more and more common in the Big Data era , the datasets available are so massive that computing statistics over the full sample is hardly feasible , if not unfeasible . A natural approach in this context consists in using survey schemes and substituting the " full data " statistics with their counterparts based on the resulting random samples , of manageable size . It is the main purpose of this paper to investigate the impact of survey sampling with unequal inclusion probabilities on stochastic gradient descent-based M-estimation methods in large-scale statistical and machine-learning problems . Precisely , we prove that , in presence of some a priori information , one may significantly increase asymptotic accuracy when choosing appropriate first order inclusion probabilities , without affecting complexity . These striking results are described here by limit theorems and are also illustrated by numerical experiments .
For semi-supervised techniques to be applied safely in practice we at least want methods to outperform their supervised counterparts . We study this question for classification using the well-known quadratic surrogate loss function . Using a projection of the supervised estimate onto a set of constraints imposed by the unlabeled data , we find we can safely improve over the supervised solution in terms of this quadratic loss . Unlike other approaches to semi-supervised learning , the procedure does not rely on assumptions that are not intrinsic to the classifier at hand . It is theoretically demonstrated that , measured on the labeled and unlabeled training data , this semi-supervised procedure never gives a lower quadratic loss than the supervised alternative . To our knowledge this is the first approach that offers such strong , albeit conservative , guarantees for improvement over the supervised solution . The characteristics of our approach are explicated using benchmark datasets to further understand the similarities and differences between the quadratic loss criterion used in the theoretical results and the classification accuracy often considered in practice .
In support vector machine ( SVM ) applications with unreliable data that contains a portion of outliers , non-robustness of SVMs often causes considerable performance deterioration . Although many approaches for improving the robustness of SVMs have been studied , two major challenges remain in robust SVM learning . First , robust learning algorithms are essentially formulated as non-convex optimization problems . It is thus important to develop a non-convex optimization method for robust SVM that can find a good local optimal solution . The second practical issue is how one can tune the hyperparameter that controls the balance between robustness and efficiency . Unfortunately , due to the non-convexity , robust SVM solutions with slightly different hyper-parameter values can be significantly different , which makes model selection highly unstable . In this paper , we address these two issues simultaneously by introducing a novel homotopy approach to non-convex robust SVM learning . Our basic idea is to introduce parametrized formulations of robust SVM which bridge the standard SVM and fully robust SVM via the parameter that represents the influence of outliers . We characterize the necessary and sufficient conditions of the local optimal solutions of robust SVM , and develop an algorithm that can trace a path of local optimal solutions when the influence of outliers is gradually decreased . An advantage of our homotopy approach is that it can be interpreted as simulated annealing , a common approach for finding a good local optimal solution in non-convex optimization problems . In addition , our homotopy method allows stable and efficient model selection based on the path of local optimal solutions . Empirical performances of the proposed approach are demonstrated through intensive numerical experiments both on robust classification and regression problems .
We consider the task of estimating a Gaussian graphical model in the high-dimensional setting . The graphical lasso , which involves maximizing the Gaussian log likelihood subject to an l0 penalty , is a well-studied approach for this task . We begin by introducing a surprising connection between the graphical lasso and hierarchical clustering : the graphical lasso in effect performs a two-step procedure , in which ( 0 ) single linkage hierarchical clustering is performed on the variables in order to identify connected components , and then ( 0 ) an l0-penalized log likelihood is maximized on the subset of variables within each connected component . In other words , the graphical lasso determines the connected components of the estimated network via single linkage clustering . Unfortunately , single linkage clustering is known to perform poorly in certain settings . Therefore , we propose the cluster graphical lasso , which involves clustering the features using an alternative to single linkage clustering , and then performing the graphical lasso on the subset of variables within each cluster . We establish model selection consistency for this technique , and demonstrate its improved performance relative to the graphical lasso in a simulation study , as well as in applications to an equities data set , a university webpage data set , and a gene expression data set .
We introduce Clique Matrices as an alternative representation of undirected graphs , being a generalisation of the incidence matrix representation . Here we use clique matrices to decompose a graph into a set of possibly overlapping clusters , de ned as well-connected subsets of vertices . The decomposition is based on a statistical description which encourages clusters to be well connected and few in number . Inference is carried out using a variational approximation . Clique matrices also play a natural role in parameterising positive de nite matrices under zero constraints on elements of the matrix . We show that clique matrices can parameterise all positive de nite matrices restricted according to a decomposable graph and form a structured Factor Analysis approximation in the non-decomposable case .
A typical viral marketing model identifies influential users in a social network to maximize a single product adoption assuming unlimited user attention , campaign budgets , and time . In reality , multiple products need campaigns , users have limited attention , convincing users incurs costs , and advertisers have limited budgets and expect the adoptions to be maximized soon . Facing these user , monetary , and timing constraints , we formulate the problem as a submodular maximization task in a continuous-time diffusion model under the intersection of a matroid and multiple knapsack constraints . We propose a randomized algorithm estimating the user influence in a network ( $|\mathcal{V}|$ nodes , $|\mathcal{E}|$ edges ) to an accuracy of $\epsilon$ with $n=\mathcal{O} ( 0/\epsilon^0 ) $ randomizations and $\tilde{\mathcal{O}} ( n|\mathcal{E}|+n|\mathcal{V}| ) $ computations . By exploiting the influence estimation algorithm as a subroutine , we develop an adaptive threshold greedy algorithm achieving an approximation factor $k_a/ ( 0+0 k ) $ of the optimal when $k_a$ out of the $k$ knapsack constraints are active . Extensive experiments on networks of millions of nodes demonstrate that the proposed algorithms achieve the state-of-the-art in terms of effectiveness and scalability .
The reparameterization gradient has become a widely used method to obtain Monte Carlo gradients to optimize the variational objective . However , this technique does not easily apply to commonly used distributions such as beta or gamma without further approximations , and most practical applications of the reparameterization gradient fit Gaussian distributions . In this paper , we introduce the generalized reparameterization gradient , a method that extends the reparameterization gradient to a wider class of variational distributions . Generalized reparameterizations use invertible transformations of the latent variables which lead to transformed distributions that weakly depend on the variational parameters . This results in new Monte Carlo gradients that combine reparameterization gradients and score function gradients . We demonstrate our approach on variational inference for two complex probabilistic models . The generalized reparameterization is effective : even a single sample from the variational distribution is enough to obtain a low-variance gradient .
Stochastic gradient descent in continuous time ( SGDCT ) provides a computationally efficient method for the statistical learning of continuous-time models , which are widely used in science , engineering , and finance . The SGDCT algorithm follows a ( noisy ) descent direction along a continuous stream of data . SGDCT performs an online parameter update in continuous time , with the parameter updates $\theta_t$ satisfying a stochastic differential equation . We prove that $\lim_{t \rightarrow \infty} \nabla \bar g ( \theta_t ) = 0$ where $\bar g$ is a natural objective function for the estimation of the continuous-time dynamics . The convergence proof leverages ergodicity by using an appropriate Poisson equation to help describe the evolution of the parameters for large times . SGDCT can also be used to solve continuous-time optimization problems , such as American options . For certain continuous-time problems , SGDCT has some promising advantages compared to a traditional stochastic gradient descent algorithm . As an example application , SGDCT is combined with a deep neural network to price high-dimensional American options ( up to 000 dimensions ) .
X in R^D has mean zero and finite second moments . We show that there is a precise sense in which almost all linear projections of X into R^d ( for d < D ) look like a scale-mixture of spherical Gaussians -- specifically , a mixture of distributions N ( 0 , sigma^0 I_d ) where the weight of the particular sigma component is P ( | X |^0 = sigma^0 D ) . The extent of this effect depends upon the ratio of d to D , and upon a particular coefficient of eccentricity of X ' s distribution . We explore this result in a variety of experiments .
Recommender systems problems witness a growing interest for finding better learning algorithms for personalized information . Matrix factorization that estimates the user liking for an item by taking an inner product on the latent features of users and item have been widely studied owing to its better accuracy and scalability . However , it is possible that the mapping between the latent features learned from these and the original features contains rather complex nonlinear hierarchical information , that classical linear matrix factorization can not capture . In this paper , we aim to propose a novel multilayer non-linear approach to a variant of nonnegative matrix factorization ( NMF ) to learn such factors from the incomplete ratings matrix . Firstly , we construct a user-item matrix with explicit ratings , secondly we learn latent factors for representations of users and items from the designed nonlinear multi-layer approach . Further , the architecture is built with different nonlinearities using adaptive gradient optimizer to better learn the latent factors in this space . We show that by doing so , our model is able to learn low-dimensional representations that are better suited for recommender systems on several benchmark datasets .
Social media provide a platform for users to express their opinions and share information . Understanding public health opinions on social media , such as Twitter , offers a unique approach to characterizing common health issues such as diabetes , diet , exercise , and obesity ( DDEO ) , however , collecting and analyzing a large scale conversational public health data set is a challenging research task . The goal of this research is to analyze the characteristics of the general public ' s opinions in regard to diabetes , diet , exercise and obesity ( DDEO ) as expressed on Twitter . A multi-component semantic and linguistic framework was developed to collect Twitter data , discover topics of interest about DDEO , and analyze the topics . From the extracted 0 . 0 million tweets , 0% of tweets discussed diabetes , 00 . 0% diet , 00 . 0% exercise , and 00 . 0% obesity . The strongest correlation among the topics was determined between exercise and obesity . Other notable correlations were : diabetes and obesity , and diet and obesity DDEO terms were also identified as subtopics of each of the DDEO topics . The frequent subtopics discussed along with Diabetes , excluding the DDEO terms themselves , were blood pressure , heart attack , yoga , and Alzheimer . The non-DDEO subtopics for Diet included vegetarian , pregnancy , celebrities , weight loss , religious , and mental health , while subtopics for Exercise included computer games , brain , fitness , and daily plan . Non-DDEO subtopics for Obesity included Alzheimer , cancer , and children . With 0 . 00 billion social media users in 0000 , publicly available data such as Twitter posts can be utilized to support clinical providers , public health experts , and social scientists in better understanding common public opinions in regard to diabetes , diet , exercise , and obesity .
The output scores of a neural network classifier are converted to probabilities via normalizing over the scores of all competing categories . Computing this partition function , $Z$ , is then linear in the number of categories , which is problematic as real-world problem sets continue to grow in categorical types , such as in visual object recognition or discriminative language modeling . We propose three approaches for sublinear estimation of the partition function , based on approximate nearest neighbor search and kernel feature maps and compare the performance of the proposed approaches empirically .
A low-cost , robust , and simple mechanism to measure hemoglobin would play a critical role in the modern health infrastructure . Consistent sample acquisition has been a long-standing technical hurdle for photometer-based portable hemoglobin detectors which rely on micro cuvettes and dry chemistry . Any particulates ( e . g . intact red blood cells ( RBCs ) , microbubbles , etc . ) in a cuvette ' s sensing area drastically impact optical absorption profile , and commercial hemoglobinometers lack the ability to automatically detect faulty samples . We present the ground-up development of a portable , low-cost and open platform with equivalent accuracy to medical-grade devices , with the addition of CNN-based image processing for rapid sample viability prechecks . The developed platform has demonstrated precision to the nearest $0 . 00[g/dL]$ of hemoglobin , an R^0 = 0 . 000 correlation to hemoglobin absorption curves reported in literature , and a 00% detection accuracy of poorly-prepared samples . We see the developed hemoglobin device/ML platform having massive implications in rural medicine , and consider it an excellent springboard for robust deep learning optical spectroscopy : a currently untapped source of data for detection of countless analytes .
OBJECTIVE : We aim to extract and denoise the attended speaker in a noisy , two-speaker acoustic scenario , relying on microphone array recordings from a binaural hearing aid , which are complemented with electroencephalography ( EEG ) recordings to infer the speaker of interest . METHODS : In this study , we propose a modular processing flow that first extracts the two speech envelopes from the microphone recordings , then selects the attended speech envelope based on the EEG , and finally uses this envelope to inform a multi-channel speech separation and denoising algorithm . RESULTS : Strong suppression of interfering ( unattended ) speech and background noise is achieved , while the attended speech is preserved . Furthermore , EEG-based auditory attention detection ( AAD ) is shown to be robust to the use of noisy speech signals . CONCLUSIONS : Our results show that AAD-based speaker extraction from microphone array recordings is feasible and robust , even in noisy acoustic environments , and without access to the clean speech signals to perform EEG-based AAD . SIGNIFICANCE : Current research on AAD always assumes the availability of the clean speech signals , which limits the applicability in real settings . We have extended this research to detect the attended speaker even when only microphone recordings with noisy speech mixtures are available . This is an enabling ingredient for new brain-computer interfaces and effective filtering schemes in neuro-steered hearing prostheses . Here , we provide a first proof of concept for EEG-informed attended speaker extraction and denoising .
Classification and clustering algorithms have been proved to be successful individually in different contexts . Both of them have their own advantages and limitations . For instance , although classification algorithms are more powerful than clustering methods in predicting class labels of objects , they do not perform well when there is a lack of sufficient manually labeled reliable data . On the other hand , although clustering algorithms do not produce label information for objects , they provide supplementary constraints ( e . g . , if two objects are clustered together , it is more likely that the same label is assigned to both of them ) that one can leverage for label prediction of a set of unknown objects . Therefore , systematic utilization of both these types of algorithms together can lead to better prediction performance . In this paper , We propose a novel algorithm , called EC0 that merges classification and clustering together in order to support both binary and multi-class classification . EC0 is based on a principled combination of multiple classification and multiple clustering methods using an optimization function . We theoretically show the convexity and optimality of the problem and solve it by block coordinate descent method . We additionally propose iEC0 , a variant of EC0 that handles imbalanced training data . We perform an extensive experimental analysis by comparing EC0 and iEC0 with 00 baseline methods ( 0 well-known standalone classifiers , 0 ensemble classifiers , and 0 existing methods that merge classification and clustering ) on 00 standard benchmark datasets . We show that our methods outperform other baselines for every single dataset , achieving at most 00% higher AUC . Moreover our methods are faster ( 0 . 00 times faster than the best baseline ) , more resilient to noise and class imbalance than the best baseline method .
Recommendation systems rely on historical user data to provide suggestions . We propose an explicit and simple model for the interaction between users and recommendations provided by a platform , and relate this model to the multi-armed bandit literature . First , we show that this interaction leads to a bias in naive estimators due to selection effects . This bias leads to suboptimal outcomes , which we quantify in terms of linear regret . We end the first part by discussing ways to obtain unbiased estimates . The second part of this work considers exploration of alternatives . We show that although agents are myopic , agents ' heterogeneous preferences ensure that recommendation systems ' learn ' about all alternatives without explicitly incentivizing this exploration . This work provides new and practical insights relevant to a wide range of systems designed to help users make better decisions .
Rejoinder to " Latent variable graphical model selection via convex optimization " by Venkat Chandrasekaran , Pablo A . Parrilo and Alan S . Willsky [arXiv : 0000 . 0000] .
We analyze a plug-in estimator for a large class of integral functionals of one or more continuous probability densities . This class includes important families of entropy , divergence , mutual information , and their conditional versions . For densities on the $d$-dimensional unit cube $[0 , 0]^d$ that lie in a $\beta$-H\ " older smoothness class , we prove our estimator converges at the rate $O \left ( n^{-\frac{\beta}{\beta + d}} \right ) $ . Furthermore , we prove the estimator is exponentially concentrated about its mean , whereas most previous related results have proven only expected error bounds on estimators .
Supervisory signals have the potential to make low-dimensional data representations , like those learned by mixture and topic models , more interpretable and useful . We propose a framework for training latent variable models that explicitly balances two goals : recovery of faithful generative explanations of high-dimensional data , and accurate prediction of associated semantic labels . Existing approaches fail to achieve these goals due to an incomplete treatment of a fundamental asymmetry : the intended application is always predicting labels from data , not data from labels . Our prediction-constrained objective for training generative models coherently integrates loss-based supervisory signals while enabling effective semi-supervised learning from partially labeled data . We derive learning algorithms for semi-supervised mixture and topic models using stochastic gradient descent with automatic differentiation . We demonstrate improved prediction quality compared to several previous supervised topic models , achieving predictions competitive with high-dimensional logistic regression on text sentiment analysis and electronic health records tasks while simultaneously learning interpretable topics .
Neural samplers such as variational autoencoders ( VAEs ) or generative adversarial networks ( GANs ) approximate distributions by transforming samples from a simple random source---the latent space---to samples from a more complex distribution represented by a dataset . While the manifold hypothesis implies that the density induced by a dataset contains large regions of low density , the training criterions of VAEs and GANs will make the latent space densely covered . Consequently points that are separated by low-density regions in observation space will be pushed together in latent space , making stationary distances poor proxies for similarity . We transfer ideas from Riemannian geometry to this setting , letting the distance between two points be the shortest path on a Riemannian manifold induced by the transformation . The method yields a principled distance measure , provides a tool for visual inspection of deep generative models , and an alternative to linear interpolation in latent space . In addition , it can be applied for robot movement generalization using previously learned skills . The method is evaluated on a synthetic dataset with known ground truth ; on a simulated robot arm dataset ; on human motion capture data ; and on a generative model of handwritten digits .
We consider the problem of sequentially making decisions that are rewarded by " successes " and " failures " which can be predicted through an unknown relationship that depends on a partially controllable vector of attributes for each instance . The learner takes an active role in selecting samples from the instance pool . The goal is to maximize the probability of success in either offline ( training ) or online ( testing ) phases . Our problem is motivated by real-world applications where observations are time-consuming and/or expensive . We develop a knowledge gradient policy using an online Bayesian linear classifier to guide the experiment by maximizing the expected value of information of labeling each alternative . We provide a finite-time analysis of the estimated error and show that the maximum likelihood estimator based produced by the KG policy is consistent and asymptotically normal . We also show that the knowledge gradient policy is asymptotically optimal in an offline setting . This work further extends the knowledge gradient to the setting of contextual bandits . We report the results of a series of experiments that demonstrate its efficiency .
There are many forms of feature information present in video data . Principle among them are object identity information which is largely static across multiple video frames , and object pose and style information which continuously transforms from frame to frame . Most existing models confound these two types of representation by mapping them to a shared feature space . In this paper we propose a probabilistic approach for learning separable representations of object identity and pose information using unsupervised video data . Our approach leverages a deep generative model with a factored prior distribution that encodes properties of temporal invariances in the hidden feature set . Learning is achieved via variational inference . We present results of learning identity and pose information on a dataset of moving characters as well as a dataset of rotating 0D objects . Our experimental results demonstrate our model ' s success in factoring its representation , and demonstrate that the model achieves improved performance in transfer learning tasks .
We state the problem of inverse reinforcement learning in terms of preference elicitation , resulting in a principled ( Bayesian ) statistical formulation . This generalises previous work on Bayesian inverse reinforcement learning and allows us to obtain a posterior distribution on the agent ' s preferences , policy and optionally , the obtained reward sequence , from observations . We examine the relation of the resulting approach to other statistical methods for inverse reinforcement learning via analysis and experimental results . We show that preferences can be determined accurately , even if the observed agent ' s policy is sub-optimal with respect to its own preferences . In that case , significantly improved policies with respect to the agent ' s preferences are obtained , compared to both other methods and to the performance of the demonstrated policy .
The problem of topic modeling can be seen as a generalization of the clustering problem , in that it posits that observations are generated due to multiple latent factors ( e . g . , the words in each document are generated as a mixture of several active topics , as opposed to just one ) . This increased representational power comes at the cost of a more challenging unsupervised learning problem of estimating the topic probability vectors ( the distributions over words for each topic ) , when only the words are observed and the corresponding topics are hidden . We provide a simple and efficient learning procedure that is guaranteed to recover the parameters for a wide class of mixture models , including the popular latent Dirichlet allocation ( LDA ) model . For LDA , the procedure correctly recovers both the topic probability vectors and the prior over the topics , using only trigram statistics ( i . e . , third order moments , which may be estimated with documents containing just three words ) . The method , termed Excess Correlation Analysis ( ECA ) , is based on a spectral decomposition of low order moments ( third and fourth order ) via two singular value decompositions ( SVDs ) . Moreover , the algorithm is scalable since the SVD operations are carried out on $k\times k$ matrices , where $k$ is the number of latent factors ( e . g . the number of topics ) , rather than in the $d$-dimensional observed space ( typically $d \gg k$ ) .
Inspired by biophysical principles underlying nonlinear dendritic computation in neural circuits , we develop a scheme to train deep neural networks to make them robust to adversarial attacks . Our scheme generates highly nonlinear , saturated neural networks that achieve state of the art performance on gradient based adversarial examples on MNIST , despite never being exposed to adversarially chosen examples during training . Moreover , these networks exhibit unprecedented robustness to targeted , iterative schemes for generating adversarial examples , including second-order methods . We further identify principles governing how these networks achieve their robustness , drawing on methods from information geometry . We find these networks progressively create highly flat and compressed internal representations that are sensitive to very few input dimensions , while still solving the task . Moreover , they employ highly kurtotic weight distributions , also found in the brain , and we demonstrate how such kurtosis can protect even linear classifiers from adversarial attack .
Gaussian Markov random fields ( GMRFs ) are useful in a broad range of applications . In this paper we tackle the problem of learning a sparse GMRF in a high-dimensional space . Our approach uses the l0-norm as a regularization on the inverse covariance matrix . We utilize a novel projected gradient method , which is faster than previous methods in practice and equal to the best performing of these in asymptotic complexity . We also extend the l0-regularized objective to the problem of sparsifying entire blocks within the inverse covariance matrix . Our methods generalize fairly easily to this case , while other methods do not . We demonstrate that our extensions give better generalization performance on two real domains--biological network analysis and a 0D-shape modeling image task .
An ability to model a generative process and learn a latent representation for speech in an unsupervised fashion will be crucial to process vast quantities of unlabelled speech data . Recently , deep probabilistic generative models such as Variational Autoencoders ( VAEs ) have achieved tremendous success in modeling natural images . In this paper , we apply a convolutional VAE to model the generative process of natural speech . We derive latent space arithmetic operations to disentangle learned latent representations . We demonstrate the capability of our model to modify the phonetic content or the speaker identity for speech segments using the derived operations , without the need for parallel supervisory data .
We propose the Bayesian bridge estimator for regularized regression and classification . Two key mixture representations for the Bayesian bridge model are developed : ( 0 ) a scale mixture of normals with respect to an alpha-stable random variable ; and ( 0 ) a mixture of Bartlett--Fejer kernels ( or triangle densities ) with respect to a two-component mixture of gamma random variables . Both lead to MCMC methods for posterior simulation , and these methods turn out to have complementary domains of maximum efficiency . The first representation is a well known result due to West ( 0000 ) , and is the better choice for collinear design matrices . The second representation is new , and is more efficient for orthogonal problems , largely because it avoids the need to deal with exponentially tilted stable random variables . It also provides insight into the multimodality of the joint posterior distribution , a feature of the bridge model that is notably absent under ridge or lasso-type priors . We prove a theorem that extends this representation to a wider class of densities representable as scale mixtures of betas , and provide an explicit inversion formula for the mixing distribution . The connections with slice sampling and scale mixtures of normals are explored . On the practical side , we find that the Bayesian bridge model outperforms its classical cousin in estimation and prediction across a variety of data sets , both simulated and real . We also show that the MCMC for fitting the bridge model exhibits excellent mixing properties , particularly for the global scale parameter . This makes for a favorable contrast with analogous MCMC algorithms for other sparse Bayesian models . All methods described in this paper are implemented in the R package BayesBridge . An extensive set of simulation results are provided in two supplemental files .
We introduce a new method for sparse principal component analysis , based on the aggregation of eigenvector information from carefully-selected random projections of the sample covariance matrix . Unlike most alternative approaches , our algorithm is non-iterative , so is not vulnerable to a bad choice of initialisation . Our theory provides great detail on the statistical and computational trade-off in our procedure , revealing a subtle interplay between the effective sample size and the number of random projections that are required to achieve the minimax optimal rate . Numerical studies provide further insight into the procedure and confirm its highly competitive finite-sample performance .
Multi-armed bandit problems are receiving a great deal of attention because they adequately formalize the exploration-exploitation trade-offs arising in several industrially relevant applications , such as online advertisement and , more generally , recommendation systems . In many cases , however , these applications have a strong social component , whose integration in the bandit algorithm could lead to a dramatic performance increase . For instance , we may want to serve content to a group of users by taking advantage of an underlying network of social relationships among them . In this paper , we introduce novel algorithmic approaches to the solution of such networked bandit problems . More specifically , we design and analyze a global strategy which allocates a bandit algorithm to each network node ( user ) and allows it to " share " signals ( contexts and payoffs ) with the neghboring nodes . We then derive two more scalable variants of this strategy based on different ways of clustering the graph nodes . We experimentally compare the algorithm and its variants to state-of-the-art methods for contextual bandits that do not use the relational information . Our experiments , carried out on synthetic and real-world datasets , show a marked increase in prediction performance obtained by exploiting the network structure .
This article proposes a novel solution for stretchy polynomial regression learning . The solution comes in primal and dual closed-forms similar to that of ridge regression . Essentially , the proposed solution stretches the covariance computation via a power term thereby compresses or amplifies the estimation . Our experiments on both synthetic data and real-world data show effectiveness of the proposed method for compressive learning .
Conventional decision trees have a number of favorable properties , including interpretability , a small computational footprint and the ability to learn from little training data . However , they lack a key quality that has helped fuel the deep learning revolution : that of being end-to-end trainable , and to learn from scratch those features that best allow to solve a given supervised learning problem . Recent work ( Kontschieder 0000 ) has addressed this deficit , but at the cost of losing a main attractive trait of decision trees : the fact that each sample is routed along a small subset of tree nodes only . We here propose a model and Expectation-Maximization training scheme for decision trees that are fully probabilistic at train time , but after a deterministic annealing process become deterministic at test time . We also analyze the learned oblique split parameters on image datasets and show that Neural Networks can be trained at each split node . In summary , we present the first end-to-end learning scheme for deterministic decision trees and present results on par with or superior to published standard oblique decision tree algorithms .
This paper proposes a method for multi-class classification problems , where the number of classes $K$ is large . The method , referred to as {\em Candidates v . s . Noises Estimation} ( CANE ) , selects a small subset of candidate classes and samples the remaining classes . We show that CANE is always consistent and computationally efficient . Moreover , the resulting estimator has low statistical variance approaching that of the maximum likelihood estimator , when the observed label belongs to the selected candidates with high probability . In practice , we use a tree structure with leaves as classes to promote fast beam search for candidate selection . We also apply the CANE method to estimate word probabilities in neural language models . Experiments show that CANE achieves better prediction accuracy over the Noise-Contrastive Estimation ( NCE ) , its variants and a number of the state-of-the-art tree classifiers , while it gains significant speedup compared to the standard $\mathcal{O} ( K ) $ methods .
The outcome of a functional genomics pipeline is usually a partial list of genomic features , ranked by their relevance in modelling biological phenotype in terms of a classification or regression model . Due to resampling protocols or just within a meta-analysis comparison , instead of one list it is often the case that sets of alternative feature lists ( possibly of different lengths ) are obtained . Here we introduce a method , based on the algebraic theory of symmetric groups , for studying the variability between lists ( " list stability " ) in the case of lists of unequal length . We provide algorithms evaluating stability for lists embedded in the full feature set or just limited to the features occurring in the partial lists . The method is demonstrated first on synthetic data in a gene filtering task and then for finding gene profiles on a recent prostate cancer dataset .
The relationship between statistical dependency and causality lies at the heart of all statistical approaches to causal inference . Recent results in the ChaLearn cause-effect pair challenge have shown that causal directionality can be inferred with good accuracy also in Markov indistinguishable configurations thanks to data driven approaches . This paper proposes a supervised machine learning approach to infer the existence of a directed causal link between two variables in multivariate settings with $n>0$ variables . The approach relies on the asymmetry of some conditional ( in ) dependence relations between the members of the Markov blankets of two variables causally connected . Our results show that supervised learning methods may be successfully used to extract causal information on the basis of asymmetric statistical descriptors also for $n>0$ variate distributions .
We derive fundamental sample complexity bounds for recovering sparse and structured signals for linear and nonlinear observation models including sparse regression , group testing , multivariate regression and problems with missing features . In general , sparse signal processing problems can be characterized in terms of the following Markovian property . We are given a set of $N$ variables $X_0 , X_0 , \ldots , X_N$ , and there is an unknown subset of variables $S \subset \{0 , \ldots , N\}$ that are relevant for predicting outcomes $Y$ . More specifically , when $Y$ is conditioned on $\{X_n\}_{n\in S}$ it is conditionally independent of the other variables , $\{X_n\}_{n \not \in S}$ . Our goal is to identify the set $S$ from samples of the variables $X$ and the associated outcomes $Y$ . We characterize this problem as a version of the noisy channel coding problem . Using asymptotic information theoretic analyses , we establish mutual information formulas that provide sufficient and necessary conditions on the number of samples required to successfully recover the salient variables . These mutual information expressions unify conditions for both linear and nonlinear observations . We then compute sample complexity bounds for the aforementioned models , based on the mutual information expressions in order to demonstrate the applicability and flexibility of our results in general sparse signal processing models .
The main challenges that arise when adopting Gaussian Process priors in probabilistic modeling are how to carry out exact Bayesian inference and how to account for uncertainty on model parameters when making model-based predictions on out-of-sample data . Using probit regression as an illustrative working example , this paper presents a general and effective methodology based on the pseudo-marginal approach to Markov chain Monte Carlo that efficiently addresses both of these issues . The results presented in this paper show improvements over existing sampling methods to simulate from the posterior distribution over the parameters defining the covariance function of the Gaussian Process prior . This is particularly important as it offers a powerful tool to carry out full Bayesian inference of Gaussian Process based hierarchic statistical models in general . The results also demonstrate that Monte Carlo based integration of all model parameters is actually feasible in this class of models providing a superior quantification of uncertainty in predictions . Extensive comparisons with respect to state-of-the-art probabilistic classifiers confirm this assertion .
In this paper , we give a new generalization error bound of Multiple Kernel Learning ( MKL ) for a general class of regularizations , and discuss what kind of regularization gives a favorable predictive accuracy . Our main target in this paper is dense type regularizations including \ellp-MKL . According to the recent numerical experiments , the sparse regularization does not necessarily show a good performance compared with dense type regularizations . Motivated by this fact , this paper gives a general theoretical tool to derive fast learning rates of MKL that is applicable to arbitrary mixed-norm-type regularizations in a unifying manner . This enables us to compare the generalization performances of various types of regularizations . As a consequence , we observe that the homogeneity of the complexities of candidate reproducing kernel Hilbert spaces ( RKHSs ) affects which regularization strategy ( \ell0 or dense ) is preferred . In fact , in homogeneous complexity settings where the complexities of all RKHSs are evenly same , \ell0-regularization is optimal among all isotropic norms . On the other hand , in inhomogeneous complexity settings , dense type regularizations can show better learning rate than sparse \ell0-regularization . We also show that our learning rate achieves the minimax lower bound in homogeneous complexity settings .
This paper presents a novel theoretical study of the general problem of multiple source adaptation using the notion of Renyi divergence . Our results build on our previous work [00] , but significantly broaden the scope of that work in several directions . We extend previous multiple source loss guarantees based on distribution weighted combinations to arbitrary target distributions P , not necessarily mixtures of the source distributions , analyze both known and unknown target distribution cases , and prove a lower bound . We further extend our bounds to deal with the case where the learner receives an approximate distribution for each source instead of the exact one , and show that similar loss guarantees can be achieved depending on the divergence between the approximate and true distributions . We also analyze the case where the labeling functions of the source domains are somewhat different . Finally , we report the results of experiments with both an artificial data set and a sentiment analysis task , showing the performance benefits of the distribution weighted combinations and the quality of our bounds based on the Renyi divergence .
Non-invasive myoelectric prostheses require a long training time to obtain satisfactory control dexterity . These training times could possibly be reduced by leveraging over training efforts by previous subjects . So-called domain adaptation algorithms formalize this strategy and have indeed been shown to significantly reduce the amount of required training data for intact subjects for myoelectric movements classification . It is not clear , however , whether these results extend also to amputees and , if so , whether prior information from amputees and intact subjects is equally useful . To overcome this problem , we evaluated several domain adaptation algorithms on data coming from both amputees and intact subjects . Our findings indicate that : ( 0 ) the use of previous experience from other subjects allows us to reduce the training time by about an order of magnitude ; ( 0 ) this improvement holds regardless of whether an amputee exploits previous information from other amputees or from intact subjects .
We study sparse principal component analysis for high dimensional vector autoregressive time series under a doubly asymptotic framework , which allows the dimension $d$ to scale with the series length $T$ . We treat the transition matrix of time series as a nuisance parameter and directly apply sparse principal component analysis on multivariate time series as if the data are independent . We provide explicit non-asymptotic rates of convergence for leading eigenvector estimation and extend this result to principal subspace estimation . Our analysis illustrates that the spectral norm of the transition matrix plays an essential role in determining the final rates . We also characterize sufficient conditions under which sparse principal component analysis attains the optimal parametric rate . Our theoretical results are backed up by thorough numerical studies .
In crowd labeling , a large amount of unlabeled data instances are outsourced to a crowd of workers . Workers will be paid for each label they provide , but the labeling requester usually has only a limited amount of the budget . Since data instances have different levels of labeling difficulty and workers have different reliability , it is desirable to have an optimal policy to allocate the budget among all instance-worker pairs such that the overall labeling accuracy is maximized . We consider categorical labeling tasks and formulate the budget allocation problem as a Bayesian Markov decision process ( MDP ) , which simultaneously conducts learning and decision making . Using the dynamic programming ( DP ) recurrence , one can obtain the optimal allocation policy . However , DP quickly becomes computationally intractable when the size of the problem increases . To solve this challenge , we propose a computationally efficient approximate policy , called optimistic knowledge gradient policy . Our MDP is a quite general framework , which applies to both pull crowdsourcing marketplaces with homogeneous workers and push marketplaces with heterogeneous workers . It can also incorporate the contextual information of instances when they are available . The experiments on both simulated and real data show that the proposed policy achieves a higher labeling accuracy than other existing policies at the same budget level .
We present a non-parametric Bayesian approach to structure learning with hidden causes . Previous Bayesian treatments of this problem define a prior over the number of hidden causes and use algorithms such as reversible jump Markov chain Monte Carlo to move between solutions . In contrast , we assume that the number of hidden causes is unbounded , but only a finite number influence observable variables . This makes it possible to use a Gibbs sampler to approximate the distribution over causal structures . We evaluate the performance of both approaches in discovering hidden causes in simulated data , and use our non-parametric approach to discover hidden causes in a real medical dataset .
We consider the setting of linear regression in high dimension . We focus on the problem of constructing adaptive and honest confidence sets for the sparse parameter \theta , i . e . we want to construct a confidence set for theta that contains theta with high probability , and that is as small as possible . The l_0 diameter of a such confidence set should depend on the sparsity S of \theta - the larger S , the wider the confidence set . However , in practice , S is unknown . This paper focuses on constructing a confidence set for \theta which contains \theta with high probability , whose diameter is adaptive to the unknown sparsity S , and which is implementable in practice .
We analyze the problem of sequential probability assignment for binary outcomes with side information and logarithmic loss , where regret---or , redundancy---is measured with respect to a ( possibly infinite ) class of experts . We provide upper and lower bounds for minimax regret in terms of sequential complexities of the class . These complexities were recently shown to give matching ( up to logarithmic factors ) upper and lower bounds for sequential prediction with general convex Lipschitz loss functions ( Rakhlin and Sridharan , 0000 ) . To deal with unbounded gradients of the logarithmic loss , we present a new analysis that employs a sequential chaining technique with a Bernstein-type bound . The introduced complexities are intrinsic to the problem of sequential probability assignment , as illustrated by our lower bound . We also consider an example of a large class of experts parametrized by vectors in a high-dimensional Euclidean ball ( or a Hilbert ball ) . The typical discretization approach fails , while our techniques give a non-trivial bound . For this problem we also present an algorithm based on regularization with a self-concordant barrier . This algorithm is of an independent interest , as it requires a bound on the function values rather than gradients .
Consider an unknown smooth function $f : [0 , 0] \rightarrow \mathbb{R}$ , and say we are given $n$ noisy mod 0 samples of $f$ , i . e . , $y_i = ( f ( x_i ) + \eta_i ) \mod 0$ for $x_i \in [0 , 0]$ , where $\eta_i$ denotes noise . Given the samples $ ( x_i , y_i ) _{i=0}^{n}$ , our goal is to recover smooth , robust estimates of the clean samples $f ( x_i ) \bmod 0$ . We formulate a natural approach for solving this problem which works with angular embeddings of the noisy mod 0 samples over the unit complex circle , inspired by the angular synchronization framework . Our approach amounts to solving a quadratically constrained quadratic program ( QCQP ) which is NP-hard in its basic form , and therefore we consider its relaxation which is a trust region sub-problem and hence solvable efficiently . We demonstrate its robustness to noise via extensive numerical simulations on several synthetic examples , along with a detailed theoretical analysis . To the best of our knowledge , we provide the first algorithm for denoising mod 0 samples of a smooth function , which comes with robustness guarantees .
Jump Markov linear models consists of a finite number of linear state space models and a discrete variable encoding the jumps ( or switches ) between the different linear models . Identifying jump Markov linear models makes for a challenging problem lacking an analytical solution . We derive a new expectation maximization ( EM ) type algorithm that produce maximum likelihood estimates of the model parameters . Our development hinges upon recent progress in combining particle filters with Markov chain Monte Carlo methods in solving the nonlinear state smoothing problem inherent in the EM formulation . Key to our development is that we exploit a conditionally linear Gaussian substructure in the model , allowing for an efficient algorithm .
The target of $\mathcal{X}$-armed bandit problem is to find the global maximum of an unknown stochastic function $f$ , given a finite budget of $n$ evaluations . Recently , $\mathcal{X}$-armed bandits have been widely used in many situations . Many of these applications need to deal with large-scale data sets . To deal with these large-scale data sets , we study a distributed setting of $\mathcal{X}$-armed bandits , where $m$ players collaborate to find the maximum of the unknown function . We develop a novel anytime distributed $\mathcal{X}$-armed bandit algorithm . Compared with prior work on $\mathcal{X}$-armed bandits , our algorithm uses a quite different searching strategy so as to fit distributed learning scenarios . Our theoretical analysis shows that our distributed algorithm is $m$ times faster than the classical single-player algorithm . Moreover , the number of communication rounds of our algorithm is only logarithmic in $mn$ . The numerical results show that our method can make effective use of every players to minimize the loss . Thus , our distributed approach is attractive and useful .
Compression and computational efficiency in deep learning have become a problem of great significance . In this work , we argue that the most principled and effective way to attack this problem is by adopting a Bayesian point of view , where through sparsity inducing priors we prune large parts of the network . We introduce two novelties in this paper : 0 ) we use hierarchical priors to prune nodes instead of individual weights , and 0 ) we use the posterior uncertainties to determine the optimal fixed point precision to encode the weights . Both factors significantly contribute to achieving the state of the art in terms of compression rates , while still staying competitive with methods designed to optimize for speed or energy efficiency .
In this paper , we propose an unifying view of several recently proposed structured sparsity-inducing norms . We consider the situation of a model simultaneously ( a ) penalized by a set- function de ned on the support of the unknown parameter vector which represents prior knowledge on supports , and ( b ) regularized in Lp-norm . We show that the natural combinatorial optimization problems obtained may be relaxed into convex optimization problems and introduce a notion , the lower combinatorial envelope of a set-function , that characterizes the tightness of our relaxations . We moreover establish links with norms based on latent representations including the latent group Lasso and block-coding , and with norms obtained from submodular functions .
As technology becomes more advanced , those who design , use and are otherwise affected by it want to know that it will perform correctly , and understand why it does what it does , and how to use it appropriately . In essence they want to be able to trust the systems that are being designed . In this survey we present assurances that are the method by which users can understand how to trust autonomous systems . Trust between humans and autonomy is reviewed , and the implications for the design of assurances are highlighted . A survey of existing research related to assurances is presented . Much of the surveyed research originates from fields such as interpretable , comprehensible , transparent , and explainable machine learning , as well as human-computer interaction , human-robot interaction , and e-commerce . Several key ideas are extracted from this work in order to refine the definition of assurances . The design of assurances is found to be highly dependent not only on the capabilities of the autonomous system , but on the characteristics of the human user , and the appropriate trust-related behaviors . Several directions for future research are identified and discussed .
Learning goal-directed behavior in environments with sparse feedback is a major challenge for reinforcement learning algorithms . The primary difficulty arises due to insufficient exploration , resulting in an agent being unable to learn robust value functions . Intrinsically motivated agents can explore new behavior for its own sake rather than to directly solve problems . Such intrinsic behaviors could eventually help the agent solve tasks posed by the environment . We present hierarchical-DQN ( h-DQN ) , a framework to integrate hierarchical value functions , operating at different temporal scales , with intrinsically motivated deep reinforcement learning . A top-level value function learns a policy over intrinsic goals , and a lower-level function learns a policy over atomic actions to satisfy the given goals . h-DQN allows for flexible goal specifications , such as functions over entities and relations . This provides an efficient space for exploration in complicated environments . We demonstrate the strength of our approach on two problems with very sparse , delayed feedback : ( 0 ) a complex discrete stochastic decision process , and ( 0 ) the classic ATARI game `Montezuma ' s Revenge ' .
Bayesian inference in the presence of an intractable likelihood function is computationally challenging . When following a Markov chain Monte Carlo ( MCMC ) approach to approximate the posterior distribution in this context , one typically either uses MCMC schemes which target the joint posterior of the parameters and some auxiliary latent variables or pseudo-marginal Metropolis-Hastings ( MH ) schemes which mimic a MH algorithm targeting the marginal posterior of the parameters by approximating unbiasedly the intractable likelihood . In scenarios where the parameters and auxiliary variables are strongly correlated under the posterior and/or this posterior is multimodal , Gibbs sampling or Hamiltonian Monte Carlo ( HMC ) will perform poorly and the pseudo-marginal MH algorithm , as any other MH scheme , will be inefficient for high dimensional parameters . We propose here an original MCMC algorithm , termed pseudo-marginal HMC , which approximates the HMC algorithm targeting the marginal posterior of the parameters . We demonstrate through experiments that pseudo-marginal HMC can outperform significantly both standard HMC and pseudo-marginal MH schemes .
We address the problem of parameter estimation in models of systems biology from noisy observations . The models we consider are characterized by simultaneous deterministic nonlinear differential equations whose parameters are either taken from in vitro experiments , or are hand-tuned during the model development process to reproduces observations from the system . We consider the family of algorithms coming under the Bayesian formulation of Approximate Bayesian Computation ( ABC ) , and show that sensitivity analysis could be deployed to quantify the relative roles of different parameters in the system . Parameters to which a system is relatively less sensitive ( known as sloppy parameters ) need not be estimated to high precision , while the values of parameters that are more critical ( stiff parameters ) need to be determined with care . A tradeoff between computational complexity and the accuracy with which the posterior distribution may be probed is an important characteristic of this class of algorithms .
We propose a sample-efficient alternative for importance weighting for situations where one only has sample access to the probability distribution that generates the observations . Our new method , called Geometric Resampling ( GR ) , is described and analyzed in the context of online combinatorial optimization under semi-bandit feedback , where a learner sequentially selects its actions from a combinatorial decision set so as to minimize its cumulative loss . In particular , we show that the well-known Follow-the-Perturbed-Leader ( FPL ) prediction method coupled with Geometric Resampling yields the first computationally efficient reduction from offline to online optimization in this setting . We provide a thorough theoretical analysis for the resulting algorithm , showing that its performance is on par with previous , inefficient solutions . Our main contribution is showing that , despite the relatively large variance induced by the GR procedure , our performance guarantees hold with high probability rather than only in expectation . As a side result , we also improve the best known regret bounds for FPL in online combinatorial optimization with full feedback , closing the perceived performance gap between FPL and exponential weights in this setting .
We show that the spectral norm of a random $n_0\times n_0\times \cdots \times n_K$ tensor ( or higher-order array ) scales as $O\left ( \sqrt{ ( \sum_{k=0}^{K}n_k ) \log ( K ) }\right ) $ under some sub-Gaussian assumption on the entries . The proof is based on a covering number argument . Since the spectral norm is dual to the tensor nuclear norm ( the tightest convex relaxation of the set of rank one tensors ) , the bound implies that the convex relaxation yields sample complexity that is linear in ( the sum of ) the number of dimensions , which is much smaller than other recently proposed convex relaxations of tensor rank that use unfolding .
Particle Metropolis-Hastings enables Bayesian parameter inference in general nonlinear state space models ( SSMs ) . However , in many implementations a random walk proposal is used and this can result in poor mixing if not tuned correctly using tedious pilot runs . Therefore , we consider a new proposal inspired by quasi-Newton algorithms that may achieve similar ( or better ) mixing with less tuning . An advantage compared to other Hessian based proposals , is that it only requires estimates of the gradient of the log-posterior . A possible application is parameter inference in the challenging class of SSMs with intractable likelihoods . We exemplify this application and the benefits of the new proposal by modelling log-returns of future contracts on coffee by a stochastic volatility model with $\alpha$-stable observations .
Feature engineering is a crucial step in the process of predictive modeling . It involves the transformation of given feature space , typically using mathematical functions , with the objective of reducing the modeling error for a given target . However , there is no well-defined basis for performing effective feature engineering . It involves domain knowledge , intuition , and most of all , a lengthy process of trial and error . The human attention involved in overseeing this process significantly influences the cost of model generation . We present a new framework to automate feature engineering . It is based on performance driven exploration of a transformation graph , which systematically and compactly enumerates the space of given options . A highly efficient exploration strategy is derived through reinforcement learning on past examples .
A complex-valued convolutional network ( convnet ) implements the repeated application of the following composition of three operations , recursively applying the composition to an input vector of nonnegative real numbers : ( 0 ) convolution with complex-valued vectors followed by ( 0 ) taking the absolute value of every entry of the resulting vectors followed by ( 0 ) local averaging . For processing real-valued random vectors , complex-valued convnets can be viewed as " data-driven multiscale windowed power spectra , " " data-driven multiscale windowed absolute spectra , " " data-driven multiwavelet absolute values , " or ( in their most general configuration ) " data-driven nonlinear multiwavelet packets . " Indeed , complex-valued convnets can calculate multiscale windowed spectra when the convnet filters are windowed complex-valued exponentials . Standard real-valued convnets , using rectified linear units ( ReLUs ) , sigmoidal ( for example , logistic or tanh ) nonlinearities , max . pooling , etc . , do not obviously exhibit the same exact correspondence with data-driven wavelets ( whereas for complex-valued convnets , the correspondence is much more than just a vague analogy ) . Courtesy of the exact correspondence , the remarkably rich and rigorous body of mathematical analysis for wavelets applies directly to ( complex-valued ) convnets .
This paper focuses on the problem of explaining predictions of psychological attributes such as attractiveness , happiness , confidence and intelligence from face photographs using deep neural networks . Since psychological attribute datasets typically suffer from small sample sizes , we apply transfer learning with two base models to avoid overfitting . These models were trained on an age and gender prediction task , respectively . Using a novel explanation method we extract heatmaps that highlight the parts of the image most responsible for the prediction . We further observe that the explanation method provides important insights into the nature of features of the base model , which allow one to assess the aptitude of the base model for a given transfer learning task . Finally , we observe that the multiclass model is more feature rich than its binary counterpart . The experimental evaluation is performed on the 0000 images from the 00k US faces dataset containing psychological attribute labels as well as on a subset of KDEF images .
( ABRIDGED ) In previous work , two platforms have been developed for testing computer-vision algorithms for robotic planetary exploration ( McGuire et al . 0000b , 0000 ; Bartolo et al . 0000 ) . The wearable-computer platform has been tested at geological and astrobiological field sites in Spain ( Rivas Vaciamadrid and Riba de Santiuste ) , and the phone-camera has been tested at a geological field site in Malta . In this work , we ( i ) apply a Hopfield neural-network algorithm for novelty detection based upon color , ( ii ) integrate a field-capable digital microscope on the wearable computer platform , ( iii ) test this novelty detection with the digital microscope at Rivas Vaciamadrid , ( iv ) develop a Bluetooth communication mode for the phone-camera platform , in order to allow access to a mobile processing computer at the field sites , and ( v ) test the novelty detection on the Bluetooth-enabled phone-camera connected to a netbook computer at the Mars Desert Research Station in Utah . This systems engineering and field testing have together allowed us to develop a real-time computer-vision system that is capable , for example , of identifying lichens as novel within a series of images acquired in semi-arid desert environments . We acquired sequences of images of geologic outcrops in Utah and Spain consisting of various rock types and colors to test this algorithm . The algorithm robustly recognized previously-observed units by their color , while requiring only a single image or a few images to learn colors as familiar , demonstrating its fast learning capability .
An active learner is given a class of models , a large set of unlabeled examples , and the ability to interactively query labels of a subset of these examples ; the goal of the learner is to learn a model in the class that fits the data well . Previous theoretical work has rigorously characterized label complexity of active learning , but most of this work has focused on the PAC or the agnostic PAC model . In this paper , we shift our attention to a more general setting -- maximum likelihood estimation . Provided certain conditions hold on the model class , we provide a two-stage active learning algorithm for this problem . The conditions we require are fairly general , and cover the widely popular class of Generalized Linear Models , which in turn , include models for binary and multi-class classification , regression , and conditional random fields . We provide an upper bound on the label requirement of our algorithm , and a lower bound that matches it up to lower order terms . Our analysis shows that unlike binary classification in the realizable case , just a single extra round of interaction is sufficient to achieve near-optimal performance in maximum likelihood estimation . On the empirical side , the recent work in ~\cite{Zhang00} and~\cite{Zhang00} ( on active linear and logistic regression ) shows the promise of this approach .
We propose the use of incomplete dot products ( IDP ) to dynamically adjust the number of input channels used in each layer of a convolutional neural network during feedforward inference . IDP adds monotonically non-increasing coefficients , referred to as a " profile " , to the channels during training . The profile orders the contribution of each channel in non-increasing order . At inference time , the number of channels used can be dynamically adjusted to trade off accuracy for lowered power consumption and reduced latency by selecting only a beginning subset of channels . This approach allows for a single network to dynamically scale over a computation range , as opposed to training and deploying multiple networks to support different levels of computation scaling . Additionally , we extend the notion to multiple profiles , each optimized for some specific range of computation scaling . We present experiments on the computation and accuracy trade-offs of IDP for popular image classification models and datasets . We demonstrate that , for MNIST and CIFAR-00 , IDP reduces computation significantly , e . g . , by 00% , without significantly compromising accuracy . We argue that IDP provides a convenient and effective means for devices to lower computation costs dynamically to reflect the current computation budget of the system . For example , VGG-00 with 00% IDP ( using only the first 00% of channels ) achieves 00% in accuracy on the CIFAR-00 dataset compared to the standard network which achieves only 00% accuracy when using the reduced channel set .
The article derives some novel independence measures and contrast functions for Blind Source Separation ( BSS ) application . For the $k^{th}$ order differentiable multivariate functions with equal hyper-volumes ( region bounded by hyper-surfaces ) and with a constraint of bounded support for $k>0$ , it proves that equality of any $k^{th}$ order derivatives implies equality of the functions . The difference between product of marginal Probability Density Functions ( PDFs ) and joint PDF of a random vector is defined as Function Difference ( FD ) of a random vector . Assuming the PDFs are $k^{th}$ order differentiable , the results on generalized functions are applied to the independence condition . This brings new sets of independence measures and BSS contrasts based on the $L^p$-Norm , $ p \geq 0$ of - FD , gradient of FD ( GFD ) and Hessian of FD ( HFD ) . Instead of a conventional two stage indirect estimation method for joint PDF based BSS contrast estimation , a single stage direct estimation of the contrasts is desired . The article targets both the efficient estimation of the proposed contrasts and extension of the potential theory for an information field . The potential theory has a concept of reference potential and it is used to derive closed form expression for the relative analysis of potential field . Analogous to it , there are introduced concepts of Reference Information Potential ( RIP ) and Cross Reference Information Potential ( CRIP ) based on the potential due to kernel functions placed at selected sample points as basis in kernel methods . The quantities are used to derive closed form expressions for information field analysis using least squares . The expressions are used to estimate $L^0$-Norm of FD and $L^0$-Norm of GFD based contrasts .
Long Short-Term Memory ( LSTM ) is a recurrent neural network ( RNN ) architecture that has been designed to address the vanishing and exploding gradient problems of conventional RNNs . Unlike feedforward neural networks , RNNs have cyclic connections making them powerful for modeling sequences . They have been successfully used for sequence labeling and sequence prediction tasks , such as handwriting recognition , language modeling , phonetic labeling of acoustic frames . However , in contrast to the deep neural networks , the use of RNNs in speech recognition has been limited to phone recognition in small scale tasks . In this paper , we present novel LSTM based RNN architectures which make more effective use of model parameters to train acoustic models for large vocabulary speech recognition . We train and compare LSTM , RNN and DNN models at various numbers of parameters and configurations . We show that LSTM models converge quickly and give state of the art speech recognition performance for relatively small sized models .
We investigate a generic problem of learning pairwise exponential family graphical models with pairwise sufficient statistics defined by a global mapping function , e . g . , Mercer kernels . This subclass of pairwise graphical models allow us to flexibly capture complex interactions among variables beyond pairwise product . We propose two $\ell_0$-norm penalized maximum likelihood estimators to learn the model parameters from i . i . d . samples . The first one is a joint estimator which estimates all the parameters simultaneously . The second one is a node-wise conditional estimator which estimates the parameters individually for each node . For both estimators , we show that under proper conditions the extra flexibility gained in our model comes at almost no cost of statistical and computational efficiency . We demonstrate the advantages of our model over state-of-the-art methods on synthetic and real datasets .
Motivation : Algorithms that discover variables which are causally related to a target may inform the design of experiments . With observational gene expression data , many methods discover causal variables by measuring each variable ' s degree of statistical dependence with the target using dependence measures ( DMs ) . However , other methods measure each variable ' s ability to explain the statistical dependence between the target and the remaining variables in the data using conditional dependence measures ( CDMs ) , since this strategy is guaranteed to find the target ' s direct causes , direct effects , and direct causes of the direct effects in the infinite sample limit . In this paper , we design a new algorithm in order to systematically compare the relative abilities of DMs and CDMs in discovering causal variables from gene expression data . Results : The proposed algorithm using a CDM is sample efficient , since it consistently outperforms other state-of-the-art local causal discovery algorithms when samples sizes are small . However , the proposed algorithm using a CDM outperforms the proposed algorithm using a DM only when sample sizes are above several hundred . These results suggest that accurate causal discovery from gene expression data using current CDM-based algorithms requires datasets with at least several hundred samples . Availability : The proposed algorithm is freely available at https : //github . com/ericstrobl/DvCD .
Correlation matrices play a key role in many multivariate methods ( e . g . , graphical model estimation and factor analysis ) . The current state-of-the-art in estimating large correlation matrices focuses on the use of Pearson ' s sample correlation matrix . Although Pearson ' s sample correlation matrix enjoys various good properties under Gaussian models , it is not an effective estimator when facing heavy-tailed distributions . As a robust alternative , Han and Liu [J . Am . Stat . Assoc . 000 ( 0000 ) 000-000] advocated the use of a transformed version of the Kendall ' s tau sample correlation matrix in estimating high dimensional latent generalized correlation matrix under the transelliptical distribution family ( or elliptical copula ) . The transelliptical family assumes that after unspecified marginal monotone transformations , the data follow an elliptical distribution . In this paper , we study the theoretical properties of the Kendall ' s tau sample correlation matrix and its transformed version proposed in Han and Liu [J . Am . Stat . Assoc . 000 ( 0000 ) 000-000] for estimating the population Kendall ' s tau correlation matrix and the latent Pearson ' s correlation matrix under both spectral and restricted spectral norms . With regard to the spectral norm , we highlight the role of " effective rank " in quantifying the rate of convergence . With regard to the restricted spectral norm , we for the first time present a " sign sub-Gaussian condition " which is sufficient to guarantee that the rank-based correlation matrix estimator attains the fast rate of convergence . In both cases , we do not need any moment condition .
We consider the problem of learning high-dimensional Gaussian graphical models . The graphical lasso is one of the most popular methods for estimating Gaussian graphical models . However , it does not achieve the oracle rate of convergence . In this paper , we propose the graphical nonconvex optimization for optimal estimation in Gaussian graphical models , which is then approximated by a sequence of convex programs . Our proposal is computationally tractable and produces an estimator that achieves the oracle rate of convergence . The statistical error introduced by the sequential approximation using the convex programs are clearly demonstrated via a contraction property . The rate of convergence can be further improved using the notion of sparsity pattern . The proposed methodology is then extended to semiparametric graphical models . We show through numerical studies that the proposed estimator outperforms other popular methods for estimating Gaussian graphical models .
We propose a method to optimise the parameters of a policy which will be used to safely perform a given task in a data-efficient manner . We train a Gaussian process model to capture the system dynamics , based on the PILCO framework . Our model has useful analytic properties , which allow closed form computation of error gradients and estimating the probability of violating given state space constraints . During training , as well as operation , only policies that are deemed safe are implemented on the real system , minimising the risk of failure .
Support Vector Machine ( SVM ) is powerful classification technique based on the idea of structural risk minimization . Use of kernel function enables curse of dimensionality to be addressed . However , proper kernel function for certain problem is dependent on specific dataset and as such there is no good method on choice of kernel function . In this paper , SVM is used to build empirical models of currency crisis in Argentina . An estimation technique is developed by training model on real life data set which provides reasonably accurate model outputs and helps policy makers to identify situations in which currency crisis may happen . The third and fourth order polynomial kernel is generally best choice to achieve high generalization of classifier performance . SVM has high level of maturity with algorithms that are simple , easy to implement , tolerates curse of dimensionality and good empirical performance . The satisfactory results show that currency crisis situation is properly emulated using only small fraction of database and could be used as an evaluation tool as well as an early warning system . To the best of knowledge this is the first work on SVM approach for currency crisis evaluation of Argentina .
Standard maximum likelihood estimation cannot be applied to discrete energy-based models in the general case because the computation of exact model probabilities is intractable . Recent research has seen the proposal of several new estimators designed specifically to overcome this intractability , but virtually nothing is known about their theoretical properties . In this paper , we present a generalized estimator that unifies many of the classical and recently proposed estimators . We use results from the standard asymptotic theory for M-estimators to derive a generic expression for the asymptotic covariance matrix of our generalized estimator . We apply these results to study the relative statistical efficiency of classical pseudolikelihood and the recently-proposed ratio matching estimator .
The backpropagation algorithm for calculating gradients has been widely used in computation of weights for deep neural networks ( DNNs ) . This method requires derivatives of objective functions and has some difficulties finding appropriate parameters such as learning rate . In this paper , we propose a novel approach for computing weight matrices of fully-connected DNNs by using two types of semi-nonnegative matrix factorizations ( semi-NMFs ) . In this method , optimization processes are performed by calculating weight matrices alternately , and backpropagation ( BP ) is not used . We also present a method to calculate stacked autoencoder using a NMF . The output results of the autoencoder are used as pre-training data for DNNs . The experimental results show that our method using three types of NMFs attains similar error rates to the conventional DNNs with BP .
We develop estimation for potentially high-dimensional additive structural equation models . A key component of our approach is to decouple order search among the variables from feature or edge selection in a directed acyclic graph encoding the causal structure . We show that the former can be done with nonregularized ( restricted ) maximum likelihood estimation while the latter can be efficiently addressed using sparse regression techniques . Thus , we substantially simplify the problem of structure search and estimation for an important class of causal models . We establish consistency of the ( restricted ) maximum likelihood estimator for low- and high-dimensional scenarios , and we also allow for misspecification of the error distribution . Furthermore , we develop an efficient computational algorithm which can deal with many variables , and the new method ' s accuracy and performance is illustrated on simulated and real data .
Multi-scanner Antivirus systems provide insightful information on the nature of a suspect application ; however there is often a lack of consensus and consistency between different Anti-Virus engines . In this article , we analyze more than 000 thousand malware signatures generated by 00 different Anti-Virus engines after analyzing 00 thousand different Android malware applications . We identify 00 different malware classes grouped into three major categories , namely Adware , Harmful Threats and Unknown or Generic signatures . We further investigate the relationships between such 00 classes using community detection algorithms from graph theory to identify similarities between them ; and we finally propose a Structure Equation Model to identify which Anti-Virus engines are more powerful at detecting each macro-category . As an application , we show how such models can help in identifying whether Unknown malware applications are more likely to be of Harmful or Adware type .
Dictionary Learning has proven to be a powerful tool for many image processing tasks , where atoms are typically defined on small image patches . As a drawback , the dictionary only encodes basic structures . In addition , this approach treats patches of different locations in one single set , which means a loss of information when features are well-aligned across signals . This is the case , for instance , in multi-trial magneto- or electroencephalography ( M/EEG ) . Learning the dictionary on the entire signals could make use of the alignement and reveal higher-level features . In this case , however , small missalignements or phase variations of features would not be compensated for . In this paper , we propose an extension to the common dictionary learning framework to overcome these limitations by allowing atoms to adapt their position across signals . The method is validated on simulated and real neuroelectric data .
Visual rendering of graphs is a key task in the mapping of complex network data . Although most graph drawing algorithms emphasize aesthetic appeal , certain applications such as travel-time maps place more importance on visualization of structural network properties . The present paper advocates a graph embedding approach with centrality considerations to comply with node hierarchy . The problem is formulated as one of constrained multi-dimensional scaling ( MDS ) , and it is solved via block coordinate descent iterations with successive approximations and guaranteed convergence to a KKT point . In addition , a regularization term enforcing graph smoothness is incorporated with the goal of reducing edge crossings . Experimental results demonstrate that the algorithm converges , and can be used to efficiently embed large graphs on the order of thousands of nodes .
Objective : Anemia is a frequent comorbidity in hemodialysis patients that can be successfully treated by administering erythropoiesis-stimulating agents ( ESAs ) . ESAs dosing is currently based on clinical protocols that often do not account for the high inter- and intra-individual variability in the patient ' s response . As a result , the hemoglobin level of some patients oscillates around the target range , which is associated with multiple risks and side-effects . This work proposes a methodology based on reinforcement learning ( RL ) to optimize ESA therapy . Methods : RL is a data-driven approach for solving sequential decision-making problems that are formulated as Markov decision processes ( MDPs ) . Computing optimal drug administration strategies for chronic diseases is a sequential decision-making problem in which the goal is to find the best sequence of drug doses . MDPs are particularly suitable for modeling these problems due to their ability to capture the uncertainty associated with the outcome of the treatment and the stochastic nature of the underlying process . The RL algorithm employed in the proposed methodology is fitted Q iteration , which stands out for its ability to make an efficient use of data . Results : The experiments reported here are based on a computational model that describes the effect of ESAs on the hemoglobin level . The performance of the proposed method is evaluated and compared with the well-known Q-learning algorithm and with a standard protocol . Simulation results show that the performance of Q-learning is substantially lower than FQI and the protocol . Conclusion : Although prospective validation is required , promising results demonstrate the potential of RL to become an alternative to current protocols .
Computational models in fields such as computational neuroscience are often evaluated via stochastic simulation or numerical approximation . Fitting these models implies a difficult optimization problem over complex , possibly noisy parameter landscapes . Bayesian optimization ( BO ) has been successfully applied to solving expensive black-box problems in engineering and machine learning . Here we explore whether BO can be applied as a general tool for model fitting . First , we present a novel hybrid BO algorithm , Bayesian adaptive direct search ( BADS ) , that achieves competitive performance with an affordable computational overhead for the running time of typical models . We then perform an extensive benchmark of BADS vs . many common and state-of-the-art nonconvex , derivative-free optimizers , on a set of model-fitting problems with real data and models from six studies in behavioral , cognitive , and computational neuroscience . With default settings , BADS consistently finds comparable or better solutions than other methods , including `vanilla ' BO , showing great promise for advanced BO techniques , and BADS in particular , as a general model-fitting tool .
We consider the class of optimization problems arising from computationally intensive L0-regularized M-estimators , where the function or gradient values are very expensive to compute . A particular instance of interest is the L0-regularized MLE for learning Conditional Random Fields ( CRFs ) , which are a popular class of statistical models for varied structured prediction problems such as sequence labeling , alignment , and classification with label taxonomy . L0-regularized MLEs for CRFs are particularly expensive to optimize since computing the gradient values requires an expensive inference step . In this work , we propose the use of a carefully constructed proximal quasi-Newton algorithm for such computationally intensive M-estimation problems , where we employ an aggressive active set selection technique . In a key contribution of the paper , we show that the proximal quasi-Newton method is provably super-linearly convergent , even in the absence of strong convexity , by leveraging a restricted variant of strong convexity . In our experiments , the proposed algorithm converges considerably faster than current state-of-the-art on the problems of sequence labeling and hierarchical classification .
Sparse modeling is a powerful framework for data analysis and processing . Traditionally , encoding in this framework is performed by solving an L0-regularized linear regression problem , commonly referred to as Lasso or Basis Pursuit . In this work we combine the sparsity-inducing property of the Lasso model at the individual feature level , with the block-sparsity property of the Group Lasso model , where sparse groups of features are jointly encoded , obtaining a sparsity pattern hierarchically structured . This results in the Hierarchical Lasso ( HiLasso ) , which shows important practical modeling advantages . We then extend this approach to the collaborative case , where a set of simultaneously coded signals share the same sparsity pattern at the higher ( group ) level , but not necessarily at the lower ( inside the group ) level , obtaining the collaborative HiLasso model ( C-HiLasso ) . Such signals then share the same active groups , or classes , but not necessarily the same active set . This model is very well suited for applications such as source identification and separation . An efficient optimization procedure , which guarantees convergence to the global optimum , is developed for these new models . The underlying presentation of the new framework and optimization approach is complemented with experimental examples and theoretical results regarding recovery guarantees for the proposed models .
Genetic sequence data are well described by hidden Markov models ( HMMs ) in which latent states correspond to clusters of similar mutation patterns . Theory from statistical genetics suggests that these HMMs are nonhomogeneous ( their transition probabilities vary along the chromosome ) and have large support for self transitions . We develop a new nonparametric model of genetic sequence data , based on the hierarchical Dirichlet process , which supports these self transitions and nonhomogeneity . Our model provides a parameterization of the genetic process that is more parsimonious than other more general nonparametric models which have previously been applied to population genetics . We provide truncation-free MCMC inference for our model using a new auxiliary sampling scheme for Bayesian nonparametric HMMs . In a series of experiments on male X chromosome data from the Thousand Genomes Project and also on data simulated from a population bottleneck we show the benefits of our model over the popular finite model fastPHASE , which can itself be seen as a parametric truncation of our model . We find that the number of HMM states found by our model is correlated with the time to the most recent common ancestor in population bottlenecks . This work demonstrates the flexibility of Bayesian nonparametrics applied to large and complex genetic data .
Submodular functions have many applications . Matchings have many applications . The bitext word alignment problem can be modeled as the problem of maximizing a nonnegative , monotone , submodular function constrained to matchings in a complete bipartite graph where each vertex corresponds to a word in the two input sentences and each edge represents a potential word-to-word translation . We propose a more general problem of maximizing a nonnegative , monotone , submodular function defined on the edge set of a complete graph constrained to matchings ; we call this problem the CSM-Matching problem . CSM-Matching also generalizes the maximum-weight matching problem , which has a polynomial-time algorithm ; however , we show that it is NP-hard to approximate CSM-Matching within a factor of e/ ( e-0 ) by reducing the max k-cover problem to it . Our main result is a simple , greedy , 0-approximation algorithm for CSM-Matching . Then we reduce CSM-Matching to maximizing a nonnegative , monotone , submodular function over two matroids , i . e . , CSM-0-Matroids . CSM-0-Matroids has a ( 0+epsilon ) -approximation algorithm - called LSV0 . We show that we can find a ( 0+epsilon ) -approximate solution to CSM-Matching using LSV0 . We extend this approach to similar problems .
With the advent of kernel methods , automating the task of specifying a suitable kernel has become increasingly important . In this context , the Multiple Kernel Learning ( MKL ) problem of finding a combination of pre-specified base kernels that is suitable for the task at hand has received significant attention from researchers . In this paper we show that Multiple Kernel Learning can be framed as a standard binary classification problem with additional constraints that ensure the positive definiteness of the learned kernel . Framing MKL in this way has the distinct advantage that it makes it easy to leverage the extensive research in binary classification to develop better performing and more scalable MKL algorithms that are conceptually simpler , and , arguably , more accessible to practitioners . Experiments on nine data sets from different domains show that , despite its simplicity , the proposed technique compares favorably with current leading MKL approaches .
Community recovery is a central problem that arises in a wide variety of applications such as network clustering , motion segmentation , face clustering and protein complex detection . The objective of the problem is to cluster data points into distinct communities based on a set of measurements , each of which is associated with the values of a certain number of data points . While most of the prior works focus on a setting in which the number of data points involved in a measurement is two , this work explores a generalized setting in which the number can be more than two . Motivated by applications particularly in machine learning and channel coding , we consider two types of measurements : ( 0 ) homogeneity measurement which indicates whether or not the associated data points belong to the same community ; ( 0 ) parity measurement which denotes the modulo-0 sum of the values of the data points . Such measurements are possibly corrupted by Bernoulli noise . We characterize the fundamental limits on the number of measurements required to reconstruct the communities for the considered models .
We propose a theoretical framework for thinking about score normalization , which confirms that normalization is not needed under ( admittedly fragile ) ideal conditions . If , however , these conditions are not met , e . g . under data-set shift between training and runtime , our theory reveals dependencies between scores that could be exploited by strategies such as score normalization . Indeed , it has been demonstrated over and over experimentally , that various ad-hoc score normalization recipes do work . We present a first attempt at using probability theory to design a generative score-space normalization model which gives similar improvements to ZT-norm on the text-dependent RSR 0000 database .
Feature learning and deep learning have drawn great attention in recent years as a way of transforming input data into more effective representations using learning algorithms . Such interest has grown in the area of music information retrieval ( MIR ) as well , particularly in music audio classification tasks such as auto-tagging . In this paper , we present a two-stage learning model to effectively predict multiple labels from music audio . The first stage learns to project local spectral patterns of an audio track onto a high-dimensional sparse space in an unsupervised manner and summarizes the audio track as a bag-of-features . The second stage successively performs the unsupervised learning on the bag-of-features in a layer-by-layer manner to initialize a deep neural network and finally fine-tunes it with the tag labels . Through the experiment , we rigorously examine training choices and tuning parameters , and show that the model achieves high performance on Magnatagatune , a popularly used dataset in music auto-tagging .
Unknown constraints arise in many types of expensive black-box optimization problems . Several methods have been proposed recently for performing Bayesian optimization with constraints , based on the expected improvement ( EI ) heuristic . However , EI can lead to pathologies when used with constraints . For example , in the case of decoupled constraints---i . e . , when one can independently evaluate the objective or the constraints---EI can encounter a pathology that prevents exploration . Additionally , computing EI requires a current best solution , which may not exist if none of the data collected so far satisfy the constraints . By contrast , information-based approaches do not suffer from these failure modes . In this paper , we present a new information-based method called Predictive Entropy Search with Constraints ( PESC ) . We analyze the performance of PESC and show that it compares favorably to EI-based approaches on synthetic and benchmark problems , as well as several real-world examples . We demonstrate that PESC is an effective algorithm that provides a promising direction towards a unified solution for constrained Bayesian optimization .
The Schatten-$p$ norm ( $0<p<0$ ) has been widely used to replace the nuclear norm for better approximating the rank function . However , existing methods are either 0 ) not scalable for large scale problems due to relying on singular value decomposition ( SVD ) in every iteration , or 0 ) specific to some $p$ values , e . g . , $0/0$ , and $0/0$ . In this paper , we show that for any $p$ , $p_0$ , and $p_0 >0$ satisfying $0/p=0/p_0+0/p_0$ , there is an equivalence between the Schatten-$p$ norm of one matrix and the Schatten-$p_0$ and the Schatten-$p_0$ norms of its two factor matrices . We further extend the equivalence to multiple factor matrices and show that all the factor norms can be convex and smooth for any $p>0$ . In contrast , the original Schatten-$p$ norm for $0<p<0$ is non-convex and non-smooth . As an example we conduct experiments on matrix completion . To utilize the convexity of the factor matrix norms , we adopt the accelerated proximal alternating linearized minimization algorithm and establish its sequence convergence . Experiments on both synthetic and real datasets exhibit its superior performance over the state-of-the-art methods . Its speed is also highly competitive .
In this paper , we study and analyze the mini-batch version of StochAstic Recursive grAdient algoritHm ( SARAH ) , a method employing the stochastic recursive gradient , for solving empirical loss minimization for the case of nonconvex losses . We provide a sublinear convergence rate ( to stationary points ) for general nonconvex functions and a linear convergence rate for gradient dominated functions , both of which have some advantages compared to other modern stochastic gradient algorithms for nonconvex losses .
We study revenue optimization learning algorithms for repeated posted-price auctions where a seller interacts with a single strategic buyer that holds a fixed private valuation for a good and seeks to maximize his cumulative discounted surplus . For this setting , first , we propose a novel algorithm that never decreases offered prices and has a tight strategic regret bound in $\Theta ( \log\log T ) $ under some mild assumptions on the buyer surplus discounting . This result closes the open research question on the existence of a no-regret horizon-independent weakly consistent pricing . The proposed algorithm is inspired by our observation that a double decrease of offered prices in a weakly consistent algorithm is enough to cause a linear regret . This motivates us to construct a novel transformation that maps a right-consistent algorithm to a weakly consistent one that never decreases offered prices . Second , we outperform the previously known strategic regret upper bound of the algorithm PRRFES , where the improvement is achieved by means of a finer constant factor $C$ of the principal term $C\log\log T$ in this upper bound . Finally , we generalize results on strategic regret previously known for geometric discounting of the buyer ' s surplus to discounting of other types , namely : the optimality of the pricing PRRFES to the case of geometrically concave decreasing discounting ; and linear lower bound on the strategic regret of a wide range of horizon-independent weakly consistent algorithms to the case of arbitrary discounts .
State-space models have been successfully used for more than fifty years in different areas of science and engineering . We present a procedure for efficient variational Bayesian learning of nonlinear state-space models based on sparse Gaussian processes . The result of learning is a tractable posterior over nonlinear dynamical systems . In comparison to conventional parametric models , we offer the possibility to straightforwardly trade off model capacity and computational cost whilst avoiding overfitting . Our main algorithm uses a hybrid inference approach combining variational Bayes and sequential Monte Carlo . We also present stochastic variational inference and online learning approaches for fast learning with long time series .
Low-rank matrix is desired in many machine learning and computer vision problems . Most of the recent studies use the nuclear norm as a convex surrogate of the rank operator . However , all singular values are simply added together by the nuclear norm , and thus the rank may not be well approximated in practical problems . In this paper , we propose to use a log-determinant ( LogDet ) function as a smooth and closer , though non-convex , approximation to rank for obtaining a low-rank representation in subspace clustering . Augmented Lagrange multipliers strategy is applied to iteratively optimize the LogDet-based non-convex objective function on potentially large-scale data . By making use of the angular information of principal directions of the resultant low-rank representation , an affinity graph matrix is constructed for spectral clustering . Experimental results on motion segmentation and face clustering data demonstrate that the proposed method often outperforms state-of-the-art subspace clustering algorithms .
To effectively connect animal behaviors to activities and patterns in the nervous system , it is ideal have a precise , accurate , and complete description of stereotyped modules and their dynamics in behaviors . In case of rodent behaviors , observers have identified and described several stereotyped behaviors , such as grooming and lateral threat . Discovering behavioral repertoires in this way is imprecise , slow and contaminated with biases and individual differences . As a replacement , we propose a framework for unbiased , efficient and precise investigation of rat locomotor activities . We propose that locomotion possesses multiscale dynamics that can be well approximated by multiple Markov processes running in parallel at different spatial-temporal scales . To capture motifs and transition dynamics on multiple scales , we developed a segmentation-decomposition procedure , which imposes explicit constraints on timescales on parallel Hidden Markov Models ( HMM ) . Each HMM describes the motifs and transition dynamics at its respective timescale . We showed that the motifs discovered across timescales have experimental significance and space-dependent heterogeneity . Through statistical tests , we show that locomotor dynamics largely conforms with Markov property across scales . Finally , using layered HMMs , we showed that motif assembly is strongly constrained to a few fixed sequences . The motifs potentially reflect outputs of canonical underlying behavioral output motifs . Our approach and results for the first time capture behavioral dynamics at different spatial-temporal scales , painting a more complete picture of how behaviors are organized .
We examine the effect of the Group Lasso ( gLasso ) regularizer in selecting the salient nodes of Deep Neural Network ( DNN ) hidden layers by applying a DNN-HMM hybrid speech recognizer to TED Talks speech data . We test two types of gLasso regularization , one for outgoing weight vectors and another for incoming weight vectors , as well as two sizes of DNNs : 0000 hidden layer nodes and 0000 nodes . Furthermore , we compare gLasso and L0 regularizers . Our experiment results demonstrate that our DNN training , in which the gLasso regularizer was embedded , successfully selected the hidden layer nodes that are necessary and sufficient for achieving high classification power .
Chow and Liu ( 0000 ) studied the problem of learning a maximumlikelihood Markov tree . We generalize their work to more complexMarkov networks by considering the problem of learning a maximumlikelihood Markov network of bounded complexity . We discuss howtree-width is in many ways the appropriate measure of complexity andthus analyze the problem of learning a maximum likelihood Markovnetwork of bounded tree-width . Similar to the work of Chow and Liu , we are able to formalize thelearning problem as a combinatorial optimization problem on graphs . Weshow that learning a maximum likelihood Markov network of boundedtree-width is equivalent to finding a maximum weight hypertree . Thisequivalence gives rise to global , integer-programming based , approximation algorithms with provable performance guarantees , for thelearning problem . This contrasts with heuristic local-searchalgorithms which were previously suggested ( e . g . by Malvestuto 0000 ) . The equivalence also allows us to study the computational hardness ofthe learning problem . We show that learning a maximum likelihoodMarkov network of bounded tree-width is NP-hard , and discuss thehardness of approximation .
We study the sample complexity of learning neural networks , by providing new bounds on their Rademacher complexity assuming norm constraints on the parameter matrix of each layer . Compared to previous work , these complexity bounds have improved dependence on the network depth , and under some additional assumptions , are fully independent of the network size ( both depth and width ) . These results are derived using some novel techniques , which may be of independent interest .
We consider the problem of Graphical lasso with an additional $\ell_{\infty}$ element-wise norm constraint on the precision matrix . This problem has applications in high-dimensional covariance decomposition such as in \citep{Janzamin-00} . We propose an ADMM algorithm to solve this problem . We also use a continuation strategy on the penalty parameter to have a fast implemenation of the algorithm .
We present a novel Newton-type method for distributed optimization , which is particularly well suited for stochastic optimization and learning problems . For quadratic objectives , the method enjoys a linear rate of convergence which provably \emph{improves} with the data size , requiring an essentially constant number of iterations under reasonable assumptions . We provide theoretical and empirical evidence of the advantages of our method compared to other approaches , such as one-shot parameter averaging and ADMM .
This paper describes a recursive estimation procedure for multivariate binary densities ( probability distributions of vectors of Bernoulli random variables ) using orthogonal expansions . For $d$ covariates , there are $0^d$ basis coefficients to estimate , which renders conventional approaches computationally prohibitive when $d$ is large . However , for a wide class of densities that satisfy a certain sparsity condition , our estimator runs in probabilistic polynomial time and adapts to the unknown sparsity of the underlying density in two key ways : ( 0 ) it attains near-minimax mean-squared error for moderate sample sizes , and ( 0 ) the computational complexity is lower for sparser densities . Our method also allows for flexible control of the trade-off between mean-squared error and computational complexity .
Controlled interventions provide the most direct source of information for learning causal effects . In particular , a dose-response curve can be learned by varying the treatment level and observing the corresponding outcomes . However , interventions can be expensive and time-consuming . Observational data , where the treatment is not controlled by a known mechanism , is sometimes available . Under some strong assumptions , observational data allows for the estimation of dose-response curves . Estimating such curves nonparametrically is hard : sample sizes for controlled interventions may be small , while in the observational case a large number of measured confounders may need to be marginalized . In this paper , we introduce a hierarchical Gaussian process prior that constructs a distribution over the dose-response curve by learning from observational data , and reshapes the distribution with a nonparametric affine transform learned from controlled interventions . This function composition from different sources is shown to speed-up learning , which we demonstrate with a thorough sensitivity analysis and an application to modeling the effect of therapy on cognitive skills of premature infants .
The adaptability of the convolutional neural network ( CNN ) technique for aerodynamic meta-modeling tasks is probed in this work . The primary objective is to develop suitable CNN architecture for variable flow conditions and object geometry , in addition to identifying a sufficient data preparation process . Multiple CNN structures were trained to learn the lift coefficients of the airfoils with a variety of shapes in multiple flow Mach numbers , Reynolds numbers , and diverse angles of attack . This is conducted to illustrate the concept of the technique . A multi-layered perceptron ( MLP ) is also used for the training sets . The MLP results are compared with that of the CNN results . The newly proposed meta-modeling concept has been found to be comparable with the MLP in learning capability ; and more importantly , our CNN model exhibits a competitive prediction accuracy with minimal constraints in a geometric representation .
The multivariate linear regression model with shuffled data and additive Gaussian noise arises in various correspondence estimation and matching problems . Focusing on the denoising aspect of this problem , we provide a characterization the minimax error rate that is sharp up to logarithmic factors . We also analyze the performance of two versions of a computationally efficient estimator , and establish their consistency for a large range of input parameters . Finally , we provide an exact algorithm for the noiseless problem and demonstrate its performance on an image point-cloud matching task . Our analysis also extends to datasets with outliers .
We demonstrate how quantum computation can provide non-trivial improvements in the computational and statistical complexity of the perceptron model . We develop two quantum algorithms for perceptron learning . The first algorithm exploits quantum information processing to determine a separating hyperplane using a number of steps sublinear in the number of data points $N$ , namely $O ( \sqrt{N} ) $ . The second algorithm illustrates how the classical mistake bound of $O ( \frac{0}{\gamma^0} ) $ can be further improved to $O ( \frac{0}{\sqrt{\gamma}} ) $ through quantum means , where $\gamma$ denotes the margin . Such improvements are achieved through the application of quantum amplitude amplification to the version space interpretation of the perceptron model .
In this paper we use information-theoretic measures to provide a theory and tools to analyze the flow of information from a discrete , multivariate source of information $\overline X$ to a discrete , multivariate sink of information $\overline Y$ joined by a distribution $P_{\overline X \overline Y}$ . The first contribution is a decomposition of the maximal potential entropy of $ ( \overline X , \overline Y ) $ that we call a balance equation , that can also be split into decompositions for the entropies of $\overline X$ and $\overline Y$ respectively . Such balance equations accept normalizations that allow them to be represented in de Finetti entropy diagrams , our second contribution . The most important of these , the aggregate Channel Multivariate Entropy Triangle CMET is an exploratory tool to assess the efficiency of multivariate channels . We also present a practical contribution in the application of these balance equations and diagrams to the assessment of information transfer efficiency for PCA and ICA as feature transformation and selection procedures in machine learning applications .
We introduce a doubly stochastic proximal gradient algorithm for optimizing a finite average of smooth convex functions , whose gradients depend on numerically expensive expectations . Our main motivation is the acceleration of the optimization of the regularized Cox partial-likelihood ( the core model used in survival analysis ) , but our algorithm can be used in different settings as well . The proposed algorithm is doubly stochastic in the sense that gradient steps are done using stochastic gradient descent ( SGD ) with variance reduction , where the inner expectations are approximated by a Monte-Carlo Markov-Chain ( MCMC ) algorithm . We derive conditions on the MCMC number of iterations guaranteeing convergence , and obtain a linear rate of convergence under strong convexity and a sublinear rate without this assumption . We illustrate the fact that our algorithm improves the state-of-the-art solver for regularized Cox partial-likelihood on several datasets from survival analysis .
Spectral clustering is widely used to partition graphs into distinct modules or communities . Existing methods for spectral clustering use the eigenvalues and eigenvectors of the graph Laplacian , an operator that is closely associated with random walks on graphs . We propose a new spectral partitioning method that exploits the properties of epidemic diffusion . An epidemic is a dynamic process that , unlike the random walk , simultaneously transitions to all the neighbors of a given node . We show that the replicator , an operator describing epidemic diffusion , is equivalent to the symmetric normalized Laplacian of a reweighted graph with edges reweighted by the eigenvector centralities of their incident nodes . Thus , more weight is given to edges connecting more central nodes . We describe a method that partitions the nodes based on the componentwise ratio of the replicator ' s second eigenvector to the first , and compare its performance to traditional spectral clustering techniques on synthetic graphs with known community structure . We demonstrate that the replicator gives preference to dense , clique-like structures , enabling it to more effectively discover communities that may be obscured by dense intercommunity linking .
Almost all of the work in graphical models for game theory has mirrored previous work in probabilistic graphical models . Our work considers the opposite direction : Taking advantage of recent advances in equilibrium computation for probabilistic inference . We present formulations of inference problems in Markov random fields ( MRFs ) as computation of equilibria in a certain class of game-theoretic graphical models . We concretely establishes the precise connection between variational probabilistic inference in MRFs and correlated equilibria . No previous work exploits recent theoretical and empirical results from the literature on algorithmic and computational game theory on the tractable , polynomial-time computation of exact or approximate correlated equilibria in graphical games with arbitrary , loopy graph structure . We discuss how to design new algorithms with equally tractable guarantees for the computation of approximate variational inference in MRFs . Also , inspired by a previously stated game-theoretic view of state-of-the-art tree-reweighed ( TRW ) message-passing techniques for belief inference as zero-sum game , we propose a different , general-sum potential game to design approximate fictitious-play techniques . We perform synthetic experiments evaluating our proposed approximation algorithms with standard methods and TRW on several classes of classical Ising models ( i . e . , with binary random variables ) . We also evaluate the algorithms using Ising models learned from the MNIST dataset . Our experiments show that our global approach is competitive , particularly shinning in a class of Ising models with constant , " highly attractive " edge-weights , in which it is often better than all other alternatives we evaluated . With a notable exception , our more local approach was not as effective . Yet , in fairness , almost all of the alternatives are often no better than a simple baseline : estimate 0 . 0 .
The discriminative approach to classification using deep neural networks has become the de-facto standard in various fields . Complementing recent reservations about safety against adversarial examples , we show that conventional discriminative methods can easily be fooled to provide incorrect labels with very high confidence to out of distribution examples . We posit that a generative approach is the natural remedy for this problem , and propose a method for classification using generative models . At training time , we learn a generative model for each class , while at test time , given an example to classify , we query each generator for its most similar generation , and select the class corresponding to the most similar one . Our approach is general and can be used with expressive models such as GANs and VAEs . At test time , our method accurately " knows when it does not know , " and provides resilience to out of distribution examples while maintaining competitive performance for standard examples .
Modern statistical applications involving large data sets have focused attention on statistical methodologies which are both efficient computationally and able to deal with the screening of large numbers of different candidate models . Here we consider computationally efficient variational Bayes approaches to inference in high-dimensional heteroscedastic linear regression , where both the mean and variance are described in terms of linear functions of the predictors and where the number of predictors can be larger than the sample size . We derive a closed form variational lower bound on the log marginal likelihood useful for model selection , and propose a novel fast greedy search algorithm on the model space which makes use of one step optimization updates to the variational lower bound in the current model for screening large numbers of candidate predictor variables for inclusion/exclusion in a computationally thrifty way . We show that the model search strategy we suggest is related to widely used orthogonal matching pursuit algorithms for model search but yields a framework for potentially extending these algorithms to more complex models . The methodology is applied in simulations and in two real examples involving prediction for food constituents using NIR technology and prediction of disease progression in diabetes .
In this paper , a nonparametric maximum likelihood ( ML ) estimator for band-limited ( BL ) probability density functions ( pdfs ) is proposed . The BLML estimator is consistent and computationally efficient . To compute the BLML estimator , three approximate algorithms are presented : a binary quadratic programming ( BQP ) algorithm for medium scale problems , a Trivial algorithm for large-scale problems that yields a consistent estimate if the underlying pdf is strictly positive and BL , and a fast implementation of the Trivial algorithm that exploits the band-limited assumption and the Nyquist sampling theorem ( " BLMLQuick " ) . All three BLML estimators outperform kernel density estimation ( KDE ) algorithms ( adaptive and higher order KDEs ) with respect to the mean integrated squared error for data generated from both BL and infinite-band pdfs . Further , the BLMLQuick estimate is remarkably faster than the KD algorithms . Finally , the BLML method is applied to estimate the conditional intensity function of a neuronal spike train ( point process ) recorded from a rat ' s entorhinal cortex grid cell , for which it outperforms state-of-the-art estimators used in neuroscience .
Binary , or one-bit , representations of data arise naturally in many applications , and are appealing in both hardware implementations and algorithm design . In this work , we study the problem of data classification from binary data and propose a framework with low computation and resource costs . We illustrate the utility of the proposed approach through stylized and realistic numerical experiments , and provide a theoretical analysis for a simple case . We hope that our framework and analysis will serve as a foundation for studying similar types of approaches .
Preserving the privacy of individuals by protecting their sensitive attributes is an important consideration during microdata release . However , it is equally important to preserve the quality or utility of the data for at least some targeted workloads . We propose a novel framework for privacy preservation based on the k-anonymity model that is ideally suited for workloads that require preserving the probability distribution of the quasi-identifier variables in the data . Our framework combines the principles of distribution-preserving quantization and k-member clustering , and we specialize it to two variants that respectively use intra-cluster and Gaussian dithering of cluster centers to achieve distribution preservation . We perform theoretical analysis of the proposed schemes in terms of distribution preservation , and describe their utility in workloads such as covariate shift and transfer learning where such a property is necessary . Using extensive experiments on real-world Medical Expenditure Panel Survey data , we demonstrate the merits of our algorithms over standard k-anonymization for a hallmark health care application where an insurance company wishes to understand the risk in entering a new market . Furthermore , by empirically quantifying the reidentification risk , we also show that the proposed approaches indeed maintain k-anonymity .
A graphical model is a statistical model that is associated to a graph whose nodes correspond to variables of interest . The edges of the graph reflect allowed conditional dependencies among the variables . Graphical models admit computationally convenient factorization properties and have long been a valuable tool for tractable modeling of multivariate distributions . More recently , applications such as reconstructing gene regulatory networks from gene expression data have driven major advances in structure learning , that is , estimating the graph underlying a model . We review some of these advances and discuss methods such as the graphical lasso and neighborhood selection for undirected graphical models ( or Markov random fields ) , and the PC algorithm and score-based search methods for directed graphical models ( or Bayesian networks ) . We further review extensions that account for effects of latent variables and heterogeneous data sources .
Plants sense their environment by producing electrical signals which in essence represent changes in underlying physiological processes . These electrical signals , when monitored , show both stochastic and deterministic dynamics . In this paper , we compute 00 statistical features from the raw non-stationary plant electrical signal time series to classify the stimulus applied ( causing the electrical signal ) . By using different discriminant analysis based classification techniques , we successfully establish that there is enough information in the raw electrical signal to classify the stimuli . In the process , we also propose two standard features which consistently give good classification results for three types of stimuli - Sodium Chloride ( NaCl ) , Sulphuric Acid ( H0SO0 ) and Ozone ( O0 ) . This may facilitate reduction in the complexity involved in computing all the features for online classification of similar external stimuli in future .
When using reinforcement learning ( RL ) algorithms to evaluate a policy it is common , given a large state space , to introduce some form of approximation architecture for the value function ( VF ) . The exact form of this architecture can have a significant effect on the accuracy of the VF estimate , however , and determining a suitable approximation architecture can often be a highly complex task . Consequently there is a large amount of interest in the potential for allowing RL algorithms to adaptively generate ( i . e . to learn ) approximation architectures . We investigate a method of adapting approximation architectures which uses feedback regarding the frequency with which an agent has visited certain states to guide which areas of the state space to approximate with greater detail . We introduce an algorithm based upon this idea which adapts a state aggregation approximation architecture on-line . Assuming $S$ states , we demonstrate theoretically that - provided the following relatively non-restrictive assumptions are satisfied : ( a ) the number of cells $X$ in the state aggregation architecture is of order $\sqrt{S}\ln{S}\log_0{S}$ or greater , ( b ) the policy and transition function are close to deterministic , and ( c ) the prior for the transition function is uniformly distributed - our algorithm can guarantee , assuming we use an appropriate scoring function to measure VF error , error which is arbitrarily close to zero as $S$ becomes large . It is able to do this despite having only $O ( X\log_0{S} ) $ space complexity ( and negligible time complexity ) . We conclude by generating a set of empirical results which support the theoretical results .
In this paper we investigate the problem of estimating the cluster tree for a density $f$ supported on or near a smooth $d$-dimensional manifold $M$ isometrically embedded in $\mathbb{R}^D$ . We analyze a modified version of a $k$-nearest neighbor based algorithm recently proposed by Chaudhuri and Dasgupta . The main results of this paper show that under mild assumptions on $f$ and $M$ , we obtain rates of convergence that depend on $d$ only but not on the ambient dimension $D$ . We also show that similar ( albeit non-algorithmic ) results can be obtained for kernel density estimators . We sketch a construction of a sample complexity lower bound instance for a natural class of manifold oblivious clustering algorithms . We further briefly consider the known manifold case and show that in this case a spatially adaptive algorithm achieves better rates .
This paper presents a general graph representation learning framework called DeepGL for learning deep node and edge representations from large ( attributed ) graphs . In particular , DeepGL begins by deriving a set of base features ( e . g . , graphlet features ) and automatically learns a multi-layered hierarchical graph representation where each successive layer leverages the output from the previous layer to learn features of a higher-order . Contrary to previous work , DeepGL learns relational functions ( each representing a feature ) that generalize across-networks and therefore useful for graph-based transfer learning tasks . Moreover , DeepGL naturally supports attributed graphs , learns interpretable features , and is space-efficient ( by learning sparse feature vectors ) . In addition , DeepGL is expressive , flexible with many interchangeable components , efficient with a time complexity of $\mathcal{O} ( |E| ) $ , and scalable for large networks via an efficient parallel implementation . Compared with the state-of-the-art method , DeepGL is ( 0 ) effective for across-network transfer learning tasks and attributed graph representation learning , ( 0 ) space-efficient requiring up to 0x less memory , ( 0 ) fast with up to 000x speedup in runtime performance , and ( 0 ) accurate with an average improvement of 00% or more on many learning tasks .
Analysis of opinion dynamics in social networks plays an important role in today ' s life . For applications such as predicting users ' political preference , it is particularly important to be able to analyze the dynamics of competing opinions . While observing the evolution of polar opinions of a social network ' s users over time , can we tell when the network " behaved " abnormally ? Furthermore , can we predict how the opinions of the users will change in the future ? Do opinions evolve according to existing network opinion dynamics models ? To answer such questions , it is not sufficient to study individual user behavior , since opinions can spread far beyond users ' egonets . We need a method to analyze opinion dynamics of all network users simultaneously and capture the effect of individuals ' behavior on the global evolution pattern of the social network . In this work , we introduce Social Network Distance ( SND ) - a distance measure that quantifies the " cost " of evolution of one snapshot of a social network into another snapshot under various models of polar opinion propagation . SND has a rich semantics of a transportation problem , yet , is computable in time linear in the number of users , which makes SND applicable to the analysis of large-scale online social networks . In our experiments with synthetic and real-world Twitter data , we demonstrate the utility of our distance measure for anomalous event detection . It achieves a true positive rate of 0 . 00 , twice as high as that of alternatives . When employed for opinion prediction in Twitter , our method ' s accuracy is 00 . 00% , which is 0 . 0% higher than that of the next best method . Source Code : https : //cs . ucsb . edu/~victor/pub/ucsb/dbl/snd/
The OSCAR ( octagonal selection and clustering algorithm for regression ) regularizer consists of a L_0 norm plus a pair-wise L_inf norm ( responsible for its grouping behavior ) and was proposed to encourage group sparsity in scenarios where the groups are a priori unknown . The OSCAR regularizer has a non-trivial proximity operator , which limits its applicability . We reformulate this regularizer as a weighted sorted L_0 norm , and propose its grouping proximity operator ( GPO ) and approximate proximity operator ( APO ) , thus making state-of-the-art proximal splitting algorithms ( PSAs ) available to solve inverse problems with OSCAR regularization . The GPO is in fact the APO followed by additional grouping and averaging operations , which are costly in time and storage , explaining the reason why algorithms with APO are much faster than that with GPO . The convergences of PSAs with GPO are guaranteed since GPO is an exact proximity operator . Although convergence of PSAs with APO is may not be guaranteed , we have experimentally found that APO behaves similarly to GPO when the regularization parameter of the pair-wise L_inf norm is set to an appropriately small value . Experiments on recovery of group-sparse signals ( with unknown groups ) show that PSAs with APO are very fast and accurate .
Topic models are probabilistic models for discovering topical themes in collections of documents . In real world applications , these models provide us with the means of organizing what would otherwise be unstructured collections . They can help us cluster a huge collection into different topics or find a subset of the collection that resembles the topical theme found in an article at hand . The first wave of topic models developed were able to discover the prevailing topics in a big collection of documents spanning a period of time . It was later realized that these time-invariant models were not capable of modeling 0 ) the time varying number of topics they discover and 0 ) the time changing structure of these topics . Few models were developed to address this two deficiencies . The online-hierarchical Dirichlet process models the documents with a time varying number of topics . It varies the structure of the topics over time as well . However , it relies on document order , not timestamps to evolve the model over time . The continuous-time dynamic topic model evolves topic structure in continuous-time . However , it uses a fixed number of topics over time . In this dissertation , I present a model , the continuous-time infinite dynamic topic model , that combines the advantages of these two models 0 ) the online-hierarchical Dirichlet process , and 0 ) the continuous-time dynamic topic model . More specifically , the model I present is a probabilistic topic model that does the following : 0 ) it changes the number of topics over continuous time , and 0 ) it changes the topic structure over continuous-time . I compared the model I developed with the two other models with different setting values . The results obtained were favorable to my model and showed the need for having a model that has a continuous-time varying number of topics and topic structure .
Graphical models have gained a lot of attention recently as a tool for learning and representing dependencies among variables in multivariate data . Often , domain scientists are looking specifically for differences among the dependency networks of different conditions or populations ( e . g . differences between regulatory networks of different species , or differences between dependency networks of diseased versus healthy populations ) . The standard method for finding these differences is to learn the dependency networks for each condition independently and compare them . We show that this approach is prone to high false discovery rates ( low precision ) that can render the analysis useless . We then show that by imposing a bias towards learning similar dependency networks for each condition the false discovery rates can be reduced to acceptable levels , at the cost of finding a reduced number of differences . Algorithms developed in the transfer learning literature can be used to vary the strength of the imposed similarity bias and provide a natural mechanism to smoothly adjust this differential precision-recall tradeoff to cater to the requirements of the analysis conducted . We present real case studies ( oncological and neurological ) where domain experts use the proposed technique to extract useful differential networks that shed light on the biological processes involved in cancer and brain function .
In this work we show that randomized ( block ) coordinate descent methods can be accelerated by parallelization when applied to the problem of minimizing the sum of a partially separable smooth convex function and a simple separable convex function . The theoretical speedup , as compared to the serial method , and referring to the number of iterations needed to approximately solve the problem with high probability , is a simple expression depending on the number of parallel processors and a natural and easily computable measure of separability of the smooth component of the objective function . In the worst case , when no degree of separability is present , there may be no speedup ; in the best case , when the problem is separable , the speedup is equal to the number of processors . Our analysis also works in the mode when the number of blocks being updated at each iteration is random , which allows for modeling situations with busy or unreliable processors . We show that our algorithm is able to solve a LASSO problem involving a matrix with 00 billion nonzeros in 0 hours on a large memory node with 00 cores .
Disease prediction or classification using health datasets involve using well-known predictors associated with the disease as features for the models . This study considers multiple data components of an individual ' s health , using the relationship between variables to generate features that may improve the performance of disease classification models . In order to capture information from different aspects of the data , this project uses a multiview learning approach , using Canonical Correlation Analysis ( CCA ) , a technique that finds projections with maximum correlations between two data views . Data categories collected from the NHANES survey ( 0000-0000 ) are used as views to learn the multiview representations . The usefulness of the representations is demonstrated by applying them as features in a Diabetes classification task .
We adapt tools from information theory to analyze how an observer comes to synchronize with the hidden states of a finitary , stationary stochastic process . We show that synchronization is determined by both the process ' s internal organization and by an observer ' s model of it . We analyze these components using the convergence of state-block and block-state entropies , comparing them to the previously known convergence properties of the Shannon block entropy . Along the way , we introduce a hierarchy of information quantifiers as derivatives and integrals of these entropies , which parallels a similar hierarchy introduced for block entropy . We also draw out the duality between synchronization properties and a process ' s controllability . The tools lead to a new classification of a process ' s alternative representations in terms of minimality , synchronizability , and unifilarity .
Tensor decomposition is an important technique for capturing the high-order interactions among multiway data . Multi-linear tensor composition methods , such as the Tucker decomposition and the CANDECOMP/PARAFAC ( CP ) , assume that the complex interactions among objects are multi-linear , and are thus insufficient to represent nonlinear relationships in data . Another assumption of these methods is that a predefined rank should be known . However , the rank of tensors is hard to estimate , especially for cases with missing values . To address these issues , we design a Bayesian generative model for tensor decomposition . Different from the traditional Bayesian methods , the high-order interactions of tensor entries are modeled with variational auto-encoder . The proposed model takes advantages of Neural Networks and nonparametric Bayesian models , by replacing the multi-linear product in traditional Bayesian tensor decomposition with a complex nonlinear function ( via Neural Networks ) whose parameters can be learned from data . Experimental results on synthetic data and real-world chemometrics tensor data have demonstrated that our new model can achieve significantly higher prediction performance than the state-of-the-art tensor decomposition approaches .
The inference of correlated signal fields with unknown correlation structures is of high scientific and technological relevance , but poses significant conceptual and numerical challenges . To address these , we develop the correlated signal inference ( CSI ) algorithm within information field theory ( IFT ) and discuss its numerical implementation . To this end , we introduce the free energy exploration ( FrEE ) strategy for numerical information field theory ( NIFTy ) applications . The FrEE strategy is to let the mathematical structure of the inference problem determine the dynamics of the numerical solver . FrEE uses the Gibbs free energy formalism for all involved unknown fields and correlation structures without marginalization of nuisance quantities . It thereby avoids the complexity marginalization often impose to IFT equations . FrEE simultaneously solves for the mean and the uncertainties of signal , nuisance , and auxiliary fields , while exploiting any analytically calculable quantity . Finally , FrEE uses a problem specific and self-tuning exploration strategy to swiftly identify the optimal field estimates as well as their uncertainty maps . For all estimated fields , properly weighted posterior samples drawn from their exact , fully non-Gaussian distributions can be generated . Here , we develop the FrEE strategies for the CSI of a normal , a log-normal , and a Poisson log-normal IFT signal inference problem and demonstrate their performances via their NIFTy implementations .
We introduce a new dynamical system for sequentially observed multivariate count data . This model is based on the gamma--Poisson construction---a natural choice for count data---and relies on a novel Bayesian nonparametric prior that ties and shrinks the model parameters , thus avoiding overfitting . We present an efficient MCMC inference algorithm that advances recent work on augmentation schemes for inference in negative binomial models . Finally , we demonstrate the model ' s inductive bias using a variety of real-world data sets , showing that it exhibits superior predictive performance over other models and infers highly interpretable latent structure .
Convolutional sparse representations are a form of sparse representation with a dictionary that has a structure that is equivalent to convolution with a set of linear filters . While effective algorithms have recently been developed for the convolutional sparse coding problem , the corresponding dictionary learning problem is substantially more challenging . Furthermore , although a number of different approaches have been proposed , the absence of thorough comparisons between them makes it difficult to determine which of them represents the current state of the art . The present work both addresses this deficiency and proposes some new approaches that outperform existing ones in certain contexts . A thorough set of performance comparisons indicates a very wide range of performance differences among the existing and proposed methods , and clearly identifies those that are the most effective .
Developments in deep generative models have allowed for tractable learning of high-dimensional data distributions . While the employed learning procedures typically assume that training data is drawn i . i . d . from the distribution of interest , it may be desirable to model distinct distributions which are observed sequentially , such as when different classes are encountered over time . Although conditional variations of deep generative models permit multiple distributions to be modeled by a single network in a disentangled fashion , they are susceptible to catastrophic forgetting when the distributions are encountered sequentially . In this paper , we adapt recent work in reducing catastrophic forgetting to the task of training generative adversarial networks on a sequence of distinct distributions , enabling continual generative modeling .
Screening rules allow to early discard irrelevant variables from the optimization in Lasso problems , or its derivatives , making solvers faster . In this paper , we propose new versions of the so-called $\textit{safe rules}$ for the Lasso . Based on duality gap considerations , our new rules create safe test regions whose diameters converge to zero , provided that one relies on a converging solver . This property helps screening out more variables , for a wider range of regularization parameter values . In addition to faster convergence , we prove that we correctly identify the active sets ( supports ) of the solutions in finite time . While our proposed strategy can cope with any solver , its performance is demonstrated using a coordinate descent algorithm particularly adapted to machine learning use cases . Significant computing time reductions are obtained with respect to previous safe rules .
A Hilbert space embedding for probability measures has recently been proposed , wherein any probability measure is represented as a mean element in a reproducing kernel Hilbert space ( RKHS ) . Such an embedding has found applications in homogeneity testing , independence testing , dimensionality reduction , etc . , with the requirement that the reproducing kernel is characteristic , i . e . , the embedding is injective . In this paper , we generalize this embedding to finite signed Borel measures , wherein any finite signed Borel measure is represented as a mean element in an RKHS . We show that the proposed embedding is injective if and only if the kernel is universal . This therefore , provides a novel characterization of universal kernels , which are proposed in the context of achieving the Bayes risk by kernel-based classification/regression algorithms . By exploiting this relation between universality and the embedding of finite signed Borel measures into an RKHS , we establish the relation between universal and characteristic kernels .
Bayesian optimization ( BO ) has become an effective approach for black-box function optimization problems when function evaluations are expensive and the optimum can be achieved within a relatively small number of queries . However , many cases , such as the ones with high-dimensional inputs , may require a much larger number of observations for optimization . Despite an abundance of observations thanks to parallel experiments , current BO techniques have been limited to merely a few thousand observations . In this paper , we propose ensemble Bayesian optimization ( EBO ) to address three current challenges in BO simultaneously : ( 0 ) large-scale observations ; ( 0 ) high dimensional input spaces ; and ( 0 ) selections of batch queries that balance quality and diversity . The key idea of EBO is to operate on an ensemble of additive Gaussian process models , each of which possesses a randomized strategy to divide and conquer . We show unprecedented , previously impossible results of scaling up BO to tens of thousands of observations within minutes of computation .
User interfaces provide an interactive window between physical and virtual environments . A new concept in the field of human-computer interaction is a soft user interface ; a compliant surface that facilitates touch interaction through deformation . Despite the potential of these interfaces , they currently lack a signal processing framework that can efficiently extract information from their deformation . Here we present OrbTouch , a device that uses statistical learning algorithms , based on convolutional neural networks , to map deformations from human touch to categorical labels ( i . e . , gestures ) and touch location using stretchable capacitor signals as inputs . We demonstrate this approach by using the device to control the popular game Tetris . OrbTouch provides a modular , robust framework to interpret deformation in soft media , laying a foundation for new modes of human computer interaction through shape changing solids .
We introduce a recursive adaptive group lasso algorithm for real-time penalized least squares prediction that produces a time sequence of optimal sparse predictor coefficient vectors . At each time index the proposed algorithm computes an exact update of the optimal $\ell_{0 , \infty}$-penalized recursive least squares ( RLS ) predictor . Each update minimizes a convex but nondifferentiable function optimization problem . We develop an online homotopy method to reduce the computational complexity . Numerical simulations demonstrate that the proposed algorithm outperforms the $\ell_0$ regularized RLS algorithm for a group sparse system identification problem and has lower implementation complexity than direct group lasso solvers .
In this paper , we analyze energy-harvesting adaptive diffusion networks for a distributed estimation problem . In order to wisely manage the available energy resources , we propose a scheme where a censoring algorithm is jointly applied over the diffusion strategy . An energy-aware variation of a diffusion algorithm is used , and a new way of measuring the relevance of the estimates in diffusion networks is proposed in order to apply a subsequent censoring mechanism . Simulation results show the potential benefit of integrating censoring schemes in energy-constrained diffusion networks .
Solving inverse problems is central to geosciences and remote sensing . Radiative transfer models ( RTMs ) represent mathematically the physical laws which govern the phenomena in remote sensing applications ( forward models ) . The numerical inversion of the RTM equations is a challenging and computationally demanding problem , and for this reason , often the application of a nonlinear statistical regression is preferred . In general , regression models predict the biophysical parameter of interest from the corresponding received radiance . However , this approach does not employ the physical information encoded in the RTMs . An alternative strategy , which attempts to include the physical knowledge , consists in learning a regression model trained using data simulated by an RTM code . In this work , we introduce a nonlinear nonparametric regression model which combines the benefits of the two aforementioned approaches . The inversion is performed taking into account jointly both real observations and RTM-simulated data . The proposed Joint Gaussian Process ( JGP ) provides a solid framework for exploiting the regularities between the two types of data . The JGP automatically detects the relative quality of the simulated and real data , and combines them accordingly . This occurs by learning an additional hyper-parameter w . r . t . a standard GP model , and fitting parameters through maximizing the pseudo-likelihood of the real observations . The resulting scheme is both simple and robust , i . e . , capable of adapting to different scenarios . The advantages of the JGP method compared to benchmark strategies are shown considering RTM-simulated and real observations in different experiments . Specifically , we consider leaf area index ( LAI ) retrieval from Landsat data combined with simulated data generated by the PROSAIL model .
This work centers on the problem of stochastic filtering for systems that yield complex beliefs . The main contribution is GP-SUM , a filtering algorithm for dynamic systems expressed as Gaussian Processes ( GP ) , that does not rely on linearizations or Gaussian approximations of the belief . The algorithm can be seen as a combination of a sampling-based filter and a probabilistic Bayes filter . GP-SUM operates by sampling the state distribution and propagating each sample through the dynamic system and observation models . Both , the sampling of the state and its propagation , are made possible by relying on the GP form of the system . In practice , the belief has the form of a weighted sum of Gaussians . We evaluate the performance of the algorithm with favorable comparisons against multiple versions of GP-Bayes filters on a standard synthetic problem . We also illustrate its practical use in a pushing task , and demonstrate that GP-SUM can predict heteroscedasticity , i . e . , different amounts of uncertainty , and multi-modality when naturally occurring in pushing .
The alignment of a set of objects by means of transformations plays an important role in computer vision . Whilst the case for only two objects can be solved globally , when multiple objects are considered usually iterative methods are used . In practice the iterative methods perform well if the relative transformations between any pair of objects are free of noise . However , if only noisy relative transformations are available ( e . g . due to missing data or wrong correspondences ) the iterative methods may fail . Based on the observation that the underlying noise-free transformations can be retrieved from the null space of a matrix that can directly be obtained from pairwise alignments , this paper presents a novel method for the synchronisation of pairwise transformations such that they are transitively consistent . Simulations demonstrate that for noisy transformations , a large proportion of missing data and even for wrong correspondence assignments the method delivers encouraging results .
Nowadays , with the unprecedented penetration of renewable distributed energy resources ( DERs ) , the necessity of an efficient energy forecasting model is more demanding than before . Generally , forecasting models are trained using observed weather data while the trained models are applied for energy forecasting using forecasted weather data . In this study , the performance of several commonly used forecasting methods in the presence of weather predictors with uncertainty is assessed and compared . Accordingly , both observed and forecasted weather data are collected , then the influential predictors for solar PV generation forecasting model are selected using several measures . Using observed and forecasted weather data , an analysis on the uncertainty of weather variables is represented by MAE and bootstrapping . The energy forecasting model is trained using observed weather data , and finally , the performance of several commonly used forecasting methods in solar energy forecasting is simulated and compared for a real case study .
Data science models , although successful in a number of commercial domains , have had limited applicability in scientific problems involving complex physical phenomena . Theory-guided data science ( TGDS ) is an emerging paradigm that aims to leverage the wealth of scientific knowledge for improving the effectiveness of data science models in enabling scientific discovery . The overarching vision of TGDS is to introduce scientific consistency as an essential component for learning generalizable models . Further , by producing scientifically interpretable models , TGDS aims to advance our scientific understanding by discovering novel domain insights . Indeed , the paradigm of TGDS has started to gain prominence in a number of scientific disciplines such as turbulence modeling , material discovery , quantum chemistry , bio-medical science , bio-marker discovery , climate science , and hydrology . In this paper , we formally conceptualize the paradigm of TGDS and present a taxonomy of research themes in TGDS . We describe several approaches for integrating domain knowledge in different research themes using illustrative examples from different disciplines . We also highlight some of the promising avenues of novel research for realizing the full potential of theory-guided data science .
This note presents in a technical though hopefully pedagogical way the three most common forms of neural network architectures : Feedforward , Convolutional and Recurrent . For each network , their fundamental building blocks are detailed . The forward pass and the update rules for the backpropagation algorithm are then derived in full .
Spectral clustering is sensitive to how graphs are constructed from data particularly when proximal and imbalanced clusters are present . We show that Ratio-Cut ( RCut ) or normalized cut ( NCut ) objectives are not tailored to imbalanced data since they tend to emphasize cut sizes over cut values . We propose a graph partitioning problem that seeks minimum cut partitions under minimum size constraints on partitions to deal with imbalanced data . Our approach parameterizes a family of graphs , by adaptively modulating node degrees on a fixed node set , to yield a set of parameter dependent cuts reflecting varying levels of imbalance . The solution to our problem is then obtained by optimizing over these parameters . We present rigorous limit cut analysis results to justify our approach . We demonstrate the superiority of our method through unsupervised and semi-supervised experiments on synthetic and real data sets .
Estimating the log-likelihood gradient with respect to the parameters of a Restricted Boltzmann Machine ( RBM ) typically requires sampling using Markov Chain Monte Carlo ( MCMC ) techniques . To save computation time , the Markov chains are only run for a small number of steps , which leads to a biased estimate . This bias can cause RBM training algorithms such as Contrastive Divergence ( CD ) learning to deteriorate . We adopt the idea behind Population Monte Carlo ( PMC ) methods to devise a new RBM training algorithm termed Population-Contrastive-Divergence ( pop-CD ) . Compared to CD , it leads to a consistent estimate and may have a significantly lower bias . Its computational overhead is negligible compared to CD . However , the variance of the gradient estimate increases . We experimentally show that pop-CD can significantly outperform CD . In many cases , we observed a smaller bias and achieved higher log-likelihood values . However , when the RBM distribution has many hidden neurons , the consistent estimate of pop-CD may still have a considerable bias and the variance of the gradient estimate requires a smaller learning rate . Thus , despite its superior theoretical properties , it is not advisable to use pop-CD in its current form on large problems .
In this paper we introduce a new feature selection algorithm to remove the irrelevant or redundant features in the data sets . In this algorithm the importance of a feature is based on its fitting to the Catastrophe model . Akaike information crite- rion value is used for ranking the features in the data set . The proposed algorithm is compared with well-known RELIEF feature selection algorithm . Breast Cancer , Parkinson Telemonitoring data and Slice locality data sets are used to evaluate the model .
We introduce a framework to leverage knowledge acquired from a repository of ( heterogeneous ) supervised datasets to new unsupervised datasets . Our perspective avoids the subjectivity inherent in unsupervised learning by reducing it to supervised learning , and provides a principled way to evaluate unsupervised algorithms . We demonstrate the versatility of our framework via simple agnostic bounds on unsupervised problems . In the context of clustering , our approach can help choose the number of clusters , the clustering algorithm , and provably circumvents Kleinberg ' s impossibility result . Experimental results across hundreds of problems demonstrate improved performance on unsupervised data with simple algorithms , despite the fact problems come from different domains . Additionally , a deep learning algorithm learns common features from many small datasets across multiple domains .
We introduce a kernel method for manifold alignment ( KEMA ) and domain adaptation that can match an arbitrary number of data sources without needing corresponding pairs , just few labeled examples in all domains . KEMA has interesting properties : 0 ) it generalizes other manifold alignment methods , 0 ) it can align manifolds of very different complexities , performing a sort of manifold unfolding plus alignment , 0 ) it can define a domain-specific metric to cope with multimodal specificities , 0 ) it can align data spaces of different dimensionality , 0 ) it is robust to strong nonlinear feature deformations , and 0 ) it is closed-form invertible which allows transfer across-domains and data synthesis . We also present a reduced-rank version for computational efficiency and discuss the generalization performance of KEMA under Rademacher principles of stability . KEMA exhibits very good performance over competing methods in synthetic examples , visual object recognition and recognition of facial expressions tasks .
Global convergence of an online ( stochastic ) limited memory version of the Broyden-Fletcher- Goldfarb-Shanno ( BFGS ) quasi-Newton method for solving optimization problems with stochastic objectives that arise in large scale machine learning is established . Lower and upper bounds on the Hessian eigenvalues of the sample functions are shown to suffice to guarantee that the curvature approximation matrices have bounded determinants and traces , which , in turn , permits establishing convergence to optimal arguments with probability 0 . Numerical experiments on support vector machines with synthetic data showcase reductions in convergence time relative to stochastic gradient descent algorithms as well as reductions in storage and computation relative to other online quasi-Newton methods . Experimental evaluation on a search engine advertising problem corroborates that these advantages also manifest in practical applications .
The feature map obtained from the denoising autoencoder ( DAE ) is investigated by determining transportation dynamics of the DAE , which is a cornerstone for deep learning . Despite the rapid development in its application , deep neural networks remain analytically unexplained , because the feature maps are nested and parameters are not faithful . In this paper , we address the problem of the formulation of nested complex of parameters by regarding the feature map as a transport map . Even when a feature map has different dimensions between input and output , we can regard it as a transportation map by considering that both the input and output spaces are embedded in a common high-dimensional space . In addition , the trajectory is a geometric object and thus , is independent of parameterization . In this manner , transportation can be regarded as a universal character of deep neural networks . By determining and analyzing the transportation dynamics , we can understand the behavior of a deep neural network . In this paper , we investigate a fundamental case of deep neural networks : the DAE . We derive the transport map of the DAE , and reveal that the infinitely deep DAE transports mass to decrease a certain quantity , such as entropy , of the data distribution . These results though analytically simple , shed light on the correspondence between deep neural networks and the Wasserstein gradient flows .
Reinforcement learning is widely used for dialogue policy optimization where the reward function often consists of more than one component , e . g . , the dialogue success and the dialogue length . In this work , we propose a structured method for finding a good balance between these components by searching for the optimal reward component weighting . To render this search feasible , we use multi-objective reinforcement learning to significantly reduce the number of training dialogues required . We apply our proposed method to find optimized component weights for six domains and compare them to a default baseline .
The random forest algorithm , proposed by L . Breiman in 0000 , has been extremely successful as a general-purpose classification and regression method . The approach , which combines several randomized decision trees and aggregates their predictions by averaging , has shown excellent performance in settings where the number of variables is much larger than the number of observations . Moreover , it is versatile enough to be applied to large-scale problems , is easily adapted to various ad-hoc learning tasks , and returns measures of variable importance . The present article reviews the most recent theoretical and methodological developments for random forests . Emphasis is placed on the mathematical forces driving the algorithm , with special attention given to the selection of parameters , the resampling mechanism , and variable importance measures . This review is intended to provide non-experts easy access to the main ideas .
Map matching of the GPS trajectory serves the purpose of recovering the original route on a road network from a sequence of noisy GPS observations . It is a fundamental technique to many Location Based Services . However , map matching of a low sampling rate on urban road network is still a challenging task . In this paper , the characteristics of Conditional Random Fields with regard to inducing many contextual features and feature selection are explored for the map matching of the GPS trajectories at a low sampling rate . Experiments on a taxi trajectory dataset show that our method may achieve competitive results along with the success of reducing model complexity for computation-limited applications .
Minimizing the empirical risk is a popular training strategy , but for learning tasks where the data may be noisy or heavy-tailed , one may require many observations in order to generalize well . To achieve better performance under less stringent requirements , we introduce a procedure which constructs a robust approximation of the risk gradient for use in an iterative learning routine . We provide high-probability bounds on the excess risk of this algorithm , by showing that it does not deviate far from the ideal gradient-based update . Empirical tests show that in diverse settings , the proposed procedure can learn more efficiently , using less resources ( iterations and observations ) while generalizing better .
We present a Kalman smoothing framework based on modeling errors using the heavy tailed Student ' s t distribution , along with algorithms , convergence theory , open-source general implementation , and several important applications . The computational effort per iteration grows linearly with the length of the time series , and all smoothers allow nonlinear process and measurement models . Robust smoothers form an important subclass of smoothers within this framework . These smoothers work in situations where measurements are highly contaminated by noise or include data unexplained by the forward model . Highly robust smoothers are developed by modeling measurement errors using the Student ' s t distribution , and outperform the recently proposed L0-Laplace smoother in extreme situations with data containing 00% or more outliers . A second special application we consider in detail allows tracking sudden changes in the state . It is developed by modeling process noise using the Student ' s t distribution , and the resulting smoother can track sudden changes in the state . These features can be used separately or in tandem , and we present a general smoother algorithm and open source implementation , together with convergence analysis that covers a wide range of smoothers . A key ingredient of our approach is a technique to deal with the non-convexity of the Student ' s t loss function . Numerical results for linear and nonlinear models illustrate the performance of the new smoothers for robust and tracking applications , as well as for mixed problems that have both types of features .
Traditional Recurrent Neural Networks assume vectorized data as inputs . However many data from modern science and technology come in certain structures such as tensorial time series data . To apply the recurrent neural networks for this type of data , a vectorisation process is necessary , while such a vectorisation leads to the loss of the precise information of the spatial or longitudinal dimensions . In addition , such a vectorized data is not an optimum solution for learning the representation of the longitudinal data . In this paper , we propose a new variant of tensorial neural networks which directly take tensorial time series data as inputs . We call this new variant as Tensorial Recurrent Neural Network ( TRNN ) . The proposed TRNN is based on tensor Tucker decomposition .
We consider the problem of learning mixtures of generalized linear models ( GLM ) which arise in classification and regression problems . Typical learning approaches such as expectation maximization ( EM ) or variational Bayes can get stuck in spurious local optima . In contrast , we present a tensor decomposition method which is guaranteed to correctly recover the parameters . The key insight is to employ certain feature transformations of the input , which depend on the input generative model . Specifically , we employ score function tensors of the input and compute their cross-correlation with the response variable . We establish that the decomposition of this tensor consistently recovers the parameters , under mild non-degeneracy conditions . We demonstrate that the computational and sample complexity of our method is a low order polynomial of the input and the latent dimensions .
We propose a novel adaptive learning algorithm based on iterative orthogonal projections in the Cartesian product of multiple reproducing kernel Hilbert spaces ( RKHSs ) . The task is estimating/tracking nonlinear functions which are supposed to contain multiple components such as ( i ) linear and nonlinear components , ( ii ) high- and low- frequency components etc . In this case , the use of multiple RKHSs permits a compact representation of multicomponent functions . The proposed algorithm is where two different methods of the author meet : multikernel adaptive filtering and the algorithm of hyperplane projection along affine subspace ( HYPASS ) . In a certain particular case , the sum space of the RKHSs is isomorphic to the product space and hence the proposed algorithm can also be regarded as an iterative projection method in the sum space . The efficacy of the proposed algorithm is shown by numerical examples .
While statistical learning methods have proved powerful tools for predictive modeling , the black-box nature of the models they produce can severely limit their interpretability and the ability to conduct formal inference . However , the natural structure of ensemble learners like bagged trees and random forests has been shown to admit desirable asymptotic properties when base learners are built with proper subsamples . In this work , we demonstrate that by defining an appropriate grid structure on the covariate space , we may carry out formal hypothesis tests for both variable importance and underlying additive model structure . To our knowledge , these tests represent the first statistical tools for investigating the underlying regression structure in a context such as random forests . We develop notions of total and partial additivity and further demonstrate that testing can be carried out at no additional computational cost by estimating the variance within the process of constructing the ensemble . Furthermore , we propose a novel extension of these testing procedures utilizing random projections in order to allow for computationally efficient testing procedures that retain high power even when the grid size is much larger than that of the training set .
Deep learning has gained great popularity due to its widespread success on many inference problems . We consider the application of deep learning to the sparse linear inverse problem encountered in compressive sensing , where one seeks to recover a sparse signal from a small number of noisy linear measurements . In this paper , we propose a novel neural-network architecture that decouples prediction errors across layers in the same way that the approximate message passing ( AMP ) algorithm decouples them across iterations : through Onsager correction . Numerical experiments suggest that our " learned AMP " network significantly improves upon Gregor and LeCun ' s " learned ISTA " network in both accuracy and complexity .
Recent machine learning methods make it possible to model potential energy of atomic configurations with chemical-level accuracy ( as calculated from ab-initio calculations ) and at speeds suitable for molecular dynam- ics simulation . Best performance is achieved when the known physical constraints are encoded in the machine learning models . For example , the atomic energy is invariant under global translations and rotations , it is also invariant to permutations of same-species atoms . Although simple to state , these symmetries are complicated to encode into machine learning algorithms . In this paper , we present a machine learning approach based on graph theory that naturally incorporates translation , rotation , and permutation symmetries . Specifically , we use a random walk graph kernel to measure the similarity of two adjacency matrices , each of which represents a local atomic environment . This Graph Approximated Energy ( GRAPE ) approach is flexible and admits many possible extensions . We benchmark a simple version of GRAPE by predicting atomization energies on a standard dataset of organic molecules .
Analysis of non-asymptotic estimation error and structured statistical recovery based on norm regularized regression , such as Lasso , needs to consider four aspects : the norm , the loss function , the design matrix , and the noise model . This paper presents generalizations of such estimation error analysis on all four aspects compared to the existing literature . We characterize the restricted error set where the estimation error vector lies , establish relations between error sets for the constrained and regularized problems , and present an estimation error bound applicable to any norm . Precise characterizations of the bound is presented for isotropic as well as anisotropic subGaussian design matrices , subGaussian noise models , and convex loss functions , including least squares and generalized linear models . Generic chaining and associated results play an important role in the analysis . A key result from the analysis is that the sample complexity of all such estimators depends on the Gaussian width of a spherical cap corresponding to the restricted error set . Further , once the number of samples $n$ crosses the required sample complexity , the estimation error decreases as $\frac{c}{\sqrt{n}}$ , where $c$ depends on the Gaussian width of the unit norm ball .
The Matrix Factorization models , sometimes called the latent factor models , are a family of methods in the recommender system research area to ( 0 ) generate the latent factors for the users and the items and ( 0 ) predict users ' ratings on items based on their latent factors . However , current Matrix Factorization models presume that all the latent factors are equally weighted , which may not always be a reasonable assumption in practice . In this paper , we propose a new model , called Weighted-SVD , to integrate the linear regression model with the SVD model such that each latent factor accompanies with a corresponding weight parameter . This mechanism allows the latent factors have different weights to influence the final ratings . The complexity of the Weighted-SVD model is slightly larger than the SVD model but much smaller than the SVD++ model . We compared the Weighted-SVD model with several latent factor models on five public datasets based on the Root-Mean-Squared-Errors ( RMSEs ) . The results show that the Weighted-SVD model outperforms the baseline methods in all the experimental datasets under almost all settings .
Classification in the dissimilarity space has become a very active research area since it provides a possibility to learn from data given in the form of pairwise non-metric dissimilarities , which otherwise would be difficult to cope with . The selection of prototypes is a key step for the further creation of the space . However , despite previous efforts to find good prototypes , how to select the best representation set remains an open issue . In this paper we proposed scalable methods to select the set of prototypes out of very large datasets . The methods are based on genetic algorithms , dissimilarity-based hashing , and two different unsupervised and supervised scalable criteria . The unsupervised criterion is based on the Minimum Spanning Tree of the graph created by the prototypes as nodes and the dissimilarities as edges . The supervised criterion is based on counting matching labels of objects and their closest prototypes . The suitability of these type of algorithms is analyzed for the specific case of dissimilarity representations . The experimental results showed that the methods select good prototypes taking advantage of the large datasets , and they do so at low runtimes .
We consider two variables that are related to each other by an invertible function . While it has previously been shown that the dependence structure of the noise can provide hints to determine which of the two variables is the cause , we presently show that even in the deterministic ( noise-free ) case , there are asymmetries that can be exploited for causal inference . Our method is based on the idea that if the function and the probability density of the cause are chosen independently , then the distribution of the effect will , in a certain sense , depend on the function . We provide a theoretical analysis of this method , showing that it also works in the low noise regime , and link it to information geometry . We report strong empirical results on various real-world data sets from different domains .
High-resolution satellite imagery have been increasingly used on remote sensing classification problems . One of the main factors is the availability of this kind of data . Even though , very little effort has been placed on the zebra crossing classification problem . In this letter , crowdsourcing systems are exploited in order to enable the automatic acquisition and annotation of a large-scale satellite imagery database for crosswalks related tasks . Then , this dataset is used to train deep-learning-based models in order to accurately classify satellite images that contains or not zebra crossings . A novel dataset with more than 000 , 000 images from 0 continents , 0 countries and more than 00 cities was used in the experiments . Experimental results showed that freely available crowdsourcing data can be used to accurately ( 00 . 00% ) train robust models to perform crosswalk classification on a global scale .
Learning policies that generalize across multiple tasks is an important and challenging research topic in reinforcement learning and robotics . Training individual policies for every single potential task is often impractical , especially for continuous task variations , requiring more principled approaches to share and transfer knowledge among similar tasks . We present a novel approach for learning a nonlinear feedback policy that generalizes across multiple tasks . The key idea is to define a parametrized policy as a function of both the state and the task , which allows learning a single policy that generalizes across multiple known and unknown tasks . Applications of our novel approach to reinforcement and imitation learning in real-robot experiments are shown .
We introduce the speculate-correct method to derive error bounds for local classifiers . Using it , we show that k nearest neighbor classifiers , in spite of their famously fractured decision boundaries , have exponential error bounds with O ( sqrt ( ( k + ln n ) / n ) ) error bound range for n in-sample examples .
We develop a general class of two-step algorithms for heterogeneous treatment effect estimation in observational studies . We first estimate marginal effects and treatment propensities to form an objective function that isolates the heterogeneous treatment effects , and then optimize the learned objective . This approach has several advantages over existing methods . From a practical perspective , our method is very flexible and easy to use : In both steps , we can use any method of our choice , e . g . , penalized regression , a deep net , or boosting ; moreover , these methods can be fine-tuned by cross-validating on the learned objective . Meanwhile , in the case of penalized kernel regression , we show that our method has a quasi-oracle property , whereby even if our pilot estimates for marginal effects and treatment propensities are not particularly accurate , we achieve the same regret bounds as an oracle who has a-priori knowledge of these nuisance components . We implement variants of our method based on both penalized regression and convolutional neural networks , and find promising performance relative to existing baselines .
We investigate the problem of sequentially predicting the binary labels on the nodes of an arbitrary weighted graph . We show that , under a suitable parametrization of the problem , the optimal number of prediction mistakes can be characterized ( up to logarithmic factors ) by the cutsize of a random spanning tree of the graph . The cutsize is induced by the unknown adversarial labeling of the graph nodes . In deriving our characterization , we obtain a simple randomized algorithm achieving in expectation the optimal mistake bound on any polynomially connected weighted graph . Our algorithm draws a random spanning tree of the original graph and then predicts the nodes of this tree in constant expected amortized time and linear space . Experiments on real-world datasets show that our method compares well to both global ( Perceptron ) and local ( label propagation ) methods , while being generally faster in practice .
We consider the problem of approximate joint triangularization of a set of noisy jointly diagonalizable real matrices . Approximate joint triangularizers are commonly used in the estimation of the joint eigenstructure of a set of matrices , with applications in signal processing , linear algebra , and tensor decomposition . By assuming the input matrices to be perturbations of noise-free , simultaneously diagonalizable ground-truth matrices , the approximate joint triangularizers are expected to be perturbations of the exact joint triangularizers of the ground-truth matrices . We provide a priori and a posteriori perturbation bounds on the `distance ' between an approximate joint triangularizer and its exact counterpart . The a priori bounds are theoretical inequalities that involve functions of the ground-truth matrices and noise matrices , whereas the a posteriori bounds are given in terms of observable quantities that can be computed from the input matrices . From a practical perspective , the problem of finding the best approximate joint triangularizer of a set of noisy matrices amounts to solving a nonconvex optimization problem . We show that , under a condition on the noise level of the input matrices , it is possible to find a good initial triangularizer such that the solution obtained by any local descent-type algorithm has certain global guarantees . Finally , we discuss the application of approximate joint matrix triangularization to canonical tensor decomposition and we derive novel estimation error bounds .
Empirical risk minimization ( ERM ) is a fundamental learning rule for statistical learning problems where the data is generated according to some unknown distribution $\mathsf{P}$ and returns a hypothesis $f$ chosen from a fixed class $\mathcal{F}$ with small loss $\ell$ . In the parametric setting , depending upon $ ( \ell , \mathcal{F} , \mathsf{P} ) $ ERM can have slow $ ( 0/\sqrt{n} ) $ or fast $ ( 0/n ) $ rates of convergence of the excess risk as a function of the sample size $n$ . There exist several results that give sufficient conditions for fast rates in terms of joint properties of $\ell$ , $\mathcal{F}$ , and $\mathsf{P}$ , such as the margin condition and the Bernstein condition . In the non-statistical prediction with expert advice setting , there is an analogous slow and fast rate phenomenon , and it is entirely characterized in terms of the mixability of the loss $\ell$ ( there being no role there for $\mathcal{F}$ or $\mathsf{P}$ ) . The notion of stochastic mixability builds a bridge between these two models of learning , reducing to classical mixability in a special case . The present paper presents a direct proof of fast rates for ERM in terms of stochastic mixability of $ ( \ell , \mathcal{F} , \mathsf{P} ) $ , and in so doing provides new insight into the fast-rates phenomenon . The proof exploits an old result of Kemperman on the solution to the general moment problem . We also show a partial converse that suggests a characterization of fast rates for ERM in terms of stochastic mixability is possible .
This paper considers the problem of robust subspace recovery : given a set of $N$ points in $\mathbb{R}^D$ , if many lie in a $d$-dimensional subspace , then can we recover the underlying subspace ? We show that Tyler ' s M-estimator can be used to recover the underlying subspace , if the percentage of the inliers is larger than $d/D$ and the data points lie in general position . Empirically , Tyler ' s M-estimator compares favorably with other convex subspace recovery algorithms in both simulations and experiments on real data sets .
In machine learning , the domain adaptation problem arrives when the test ( target ) and the train ( source ) data are generated from different distributions . A key applied issue is thus the design of algorithms able to generalize on a new distribution , for which we have no label information . We focus on learning classification models defined as a weighted majority vote over a set of real-val ued functions . In this context , Germain et al . ( 0000 ) have shown that a measure of disagreement between these functions is crucial to control . The core of this measure is a theoretical bound--the C-bound ( Lacasse et al . , 0000 ) --which involves the disagreement and leads to a well performing majority vote learning algorithm in usual non-adaptative supervised setting : MinCq . In this work , we propose a framework to extend MinCq to a domain adaptation scenario . This procedure takes advantage of the recent perturbed variation divergence between distributions proposed by Harel and Mannor ( 0000 ) . Justified by a theoretical bound on the target risk of the vote , we provide to MinCq a target sample labeled thanks to a perturbed variation-based self-labeling focused on the regions where the source and target marginals appear similar . We also study the influence of our self-labeling , from which we deduce an original process for tuning the hyperparameters . Finally , our framework called PV-MinCq shows very promising results on a rotation and translation synthetic problem .
Blind source separation ( BSS ) is a very popular technique to analyze multichannel data . In this context , the data are modeled as the linear combination of sources to be retrieved . For that purpose , standard BSS methods all rely on some discrimination principle , whether it is statistical independence or morphological diversity , to distinguish between the sources . However , dealing with real-world data reveals that such assumptions are rarely valid in practice : the signals of interest are more likely partially correlated , which generally hampers the performances of standard BSS methods . In this article , we introduce a novel sparsity-enforcing BSS method coined Adaptive Morphological Component Analysis ( AMCA ) , which is designed to retrieve sparse and partially correlated sources . More precisely , it makes profit of an adaptive re-weighting scheme to favor/penalize samples based on their level of correlation . Extensive numerical experiments have been carried out which show that the proposed method is robust to the partial correlation of sources while standard BSS techniques fail . The AMCA algorithm is evaluated in the field of astrophysics for the separation of physical components from microwave data .
Adaptive gradient methods have become recently very popular , in particular as they have been shown to be useful in the training of deep neural networks . In this paper we have analyzed RMSProp , originally proposed for the training of deep neural networks , in the context of online convex optimization and show $\sqrt{T}$-type regret bounds . Moreover , we propose two variants SC-Adagrad and SC-RMSProp for which we show logarithmic regret bounds for strongly convex functions . Finally , we demonstrate in the experiments that these new variants outperform other adaptive gradient techniques or stochastic gradient descent in the optimization of strongly convex functions as well as in training of deep neural networks .
We consider empirical risk minimization of linear predictors with convex loss functions . Such problems can be reformulated as convex-concave saddle point problems , and thus are well suitable for primal-dual first-order algorithms . However , primal-dual algorithms often require explicit strongly convex regularization in order to obtain fast linear convergence , and the required dual proximal mapping may not admit closed-form or efficient solution . In this paper , we develop both batch and randomized primal-dual algorithms that can exploit strong convexity from data adaptively and are capable of achieving linear convergence even without regularization . We also present dual-free variants of the adaptive primal-dual algorithms that do not require computing the dual proximal mapping , which are especially suitable for logistic regression .
Recent studies have revealed the vulnerability of deep neural networks - A small adversarial perturbation that is imperceptible to human can easily make a well-trained deep neural network mis-classify . This makes it unsafe to apply neural networks in security-critical applications . In this paper , we propose a new defensive algorithm called Random Self-Ensemble ( RSE ) by combining two important concepts : ${\bf randomness}$ and ${\bf ensemble}$ . To protect a targeted model , RSE adds random noise layers to the neural network to prevent from state-of-the-art gradient-based attacks , and ensembles the prediction over random noises to stabilize the performance . We show that our algorithm is equivalent to ensemble an infinite number of noisy models $f_\epsilon$ without any additional memory overhead , and the proposed training procedure based on noisy stochastic gradient descent can ensure the ensemble model has good predictive capability . Our algorithm significantly outperforms previous defense techniques on real datasets . For instance , on CIFAR-00 with VGG network ( which has $00\%$ accuracy without any attack ) , under the state-of-the-art C&W attack within a certain distortion tolerance , the accuracy of unprotected model drops to less than $00\%$ , the best previous defense technique has $00\%$ accuracy , while our method still has $00\%$ prediction accuracy under the same level of attack . Finally , our method is simple and easy to integrate into any neural network .
We develop a highly scalable optimization method called " hierarchical group-thresholding " for solving a multi-task regression model with complex structured sparsity constraints on both input and output spaces . Despite the recent emergence of several efficient optimization algorithms for tackling complex sparsity-inducing regularizers , true scalability in practical high-dimensional problems where a huge amount ( e . g . , millions ) of sparsity patterns need to be enforced remains an open challenge , because all existing algorithms must deal with ALL such patterns exhaustively in every iteration , which is computationally prohibitive . Our proposed algorithm addresses the scalability problem by screening out multiple groups of coefficients simultaneously and systematically . We employ a hierarchical tree representation of group constraints to accelerate the process of removing irrelevant constraints by taking advantage of the inclusion relationships between group sparsities , thereby avoiding dealing with all constraints in every optimization step , and necessitating optimization operation only on a small number of outstanding coefficients . In our experiments , we demonstrate the efficiency of our method on simulation datasets , and in an application of detecting genetic variants associated with gene expression traits .
We present a novel algorithm , Westfall-Young light , for detecting patterns , such as itemsets and subgraphs , which are statistically significantly enriched in one of two classes . Our method corrects rigorously for multiple hypothesis testing and correlations between patterns through the Westfall-Young permutation procedure , which empirically estimates the null distribution of pattern frequencies in each class via permutations . In our experiments , Westfall-Young light dramatically outperforms the current state-of-the-art approach in terms of both runtime and memory efficiency on popular real-world benchmark datasets for pattern mining . The key to this efficiency is that unlike all existing methods , our algorithm neither needs to solve the underlying frequent itemset mining problem anew for each permutation nor needs to store the occurrence list of all frequent patterns . Westfall-Young light opens the door to significant pattern mining on large datasets that previously led to prohibitive runtime or memory costs .
We introduce a technique to compute probably approximately correct ( PAC ) bounds on precision and recall for matching algorithms . The bounds require some verified matches , but those matches may be used to develop the algorithms . The bounds can be applied to network reconciliation or entity resolution algorithms , which identify nodes in different networks or values in a data set that correspond to the same entity . For network reconciliation , the bounds do not require knowledge of the network generation process .
BayesPy is an open-source Python software package for performing variational Bayesian inference . It is based on the variational message passing framework and supports conjugate exponential family models . By removing the tedious task of implementing the variational Bayesian update equations , the user can construct models faster and in a less error-prone way . Simple syntax , flexible model construction and efficient inference make BayesPy suitable for both average and expert Bayesian users . It also supports some advanced methods such as stochastic and collapsed variational inference .
The seminal paper of Caponnetto and de Vito ( 0000 ) provides minimax-optimal rates for kernel ridge regression in a very general setting . Its proof , however , contains an error in its bound on the effective dimensionality . In this note , we explain the mistake , provide a correct bound , and show that the main theorem remains true .
Diffusion maps are a nonlinear manifold learning technique based on harmonic analysis of a diffusion process over the data . Out-of-sample extensions with computational complexity $\mathcal{O} ( N ) $ , where $N$ is the number of points comprising the manifold , frustrate applications to online learning applications requiring rapid embedding of high-dimensional data streams . We propose landmark diffusion maps ( L-dMaps ) to reduce the complexity to $\mathcal{O} ( M ) $ , where $M \ll N$ is the number of landmark points selected using pruned spanning trees or k-medoids . Offering $ ( N/M ) $ speedups in out-of-sample extension , L-dMaps enables the application of diffusion maps to high-volume and/or high-velocity streaming data . We illustrate our approach on three datasets : the Swiss roll , molecular simulations of a C$_{00}$H$_{00}$ polymer chain , and biomolecular simulations of alanine dipeptide . We demonstrate up to 00-fold speedups in out-of-sample extension for the molecular systems with less than 0% errors in manifold reconstruction fidelity relative to calculations over the full dataset .
We consider the problem of learning from a similarity matrix ( such as spectral clustering and lowd imensional embedding ) , when computing pairwise similarities are costly , and only a limited number of entries can be observed . We provide a theoretical analysis using standard notions of graph approximation , significantly generalizing previous results ( which focused on spectral clustering with two clusters ) . We also propose a new algorithmic approach based on adaptive sampling , which experimentally matches or improves on previous methods , while being considerably more general and computationally cheaper .
The rise of Big Data has led to new demands for Machine Learning ( ML ) systems to learn complex models with millions to billions of parameters , that promise adequate capacity to digest massive datasets and offer powerful predictive analytics thereupon . In order to run ML algorithms at such scales , on a distributed cluster with 00s to 0000s of machines , it is often the case that significant engineering efforts are required --- and one might fairly ask if such engineering truly falls within the domain of ML research or not . Taking the view that Big ML systems can benefit greatly from ML-rooted statistical and algorithmic insights --- and that ML researchers should therefore not shy away from such systems design --- we discuss a series of principles and strategies distilled from our recent efforts on industrial-scale ML solutions . These principles and strategies span a continuum from application , to engineering , and to theoretical research and development of Big ML systems and architectures , with the goal of understanding how to make them efficient , generally-applicable , and supported with convergence and scaling guarantees . They concern four key questions which traditionally receive little attention in ML research : How to distribute an ML program over a cluster ? How to bridge ML computation with inter-machine communication ? How to perform such communication ? What should be communicated between machines ? By exposing underlying statistical and algorithmic characteristics unique to ML programs but not typically seen in traditional computer programs , and by dissecting successful cases to reveal how we have harnessed these principles to design and develop both high-performance distributed ML software as well as general-purpose ML frameworks , we present opportunities for ML researchers and practitioners to further shape and grow the area that lies between ML and systems .
Markov chain Monte Carlo ( MCMC ) algorithms have become powerful tools for Bayesian inference . However , they do not scale well to large-data problems . Divide-and-conquer strategies , which split the data into batches and , for each batch , run independent MCMC algorithms targeting the corresponding subposterior , can spread the computational burden across a number of separate workers . The challenge with such strategies is in recombining the subposteriors to approximate the full posterior . By creating a Gaussian-process approximation for each log-subposterior density we create a tractable approximation for the full posterior . This approximation is exploited through three methodologies : firstly a Hamiltonian Monte Carlo algorithm targeting the expectation of the posterior density provides a sample from an approximation to the posterior ; secondly , evaluating the true posterior at the sampled points leads to an importance sampler that , asymptotically , targets the true posterior expectations ; finally , an alternative importance sampler uses the full Gaussian-process distribution of the approximation to the log-posterior density to re-weight any initial sample and provide both an estimate of the posterior expectation and a measure of the uncertainty in it .
Nonparametric Bayesian approaches to clustering , information retrieval , language modeling and object recognition have recently shown great promise as a new paradigm for unsupervised data analysis . Most contributions have focused on the Dirichlet process mixture models or extensions thereof for which efficient Gibbs samplers exist . In this paper we explore Gibbs samplers for infinite complexity mixture models in the stick breaking representation . The advantage of this representation is improved modeling flexibility . For instance , one can design the prior distribution over cluster sizes or couple multiple infinite mixture models ( e . g . over time ) at the level of their parameters ( i . e . the dependent Dirichlet process model ) . However , Gibbs samplers for infinite mixture models ( as recently introduced in the statistics literature ) seem to mix poorly over cluster labels . Among others issues , this can have the adverse effect that labels for the same cluster in coupled mixture models are mixed up . We introduce additional moves in these samplers to improve mixing over cluster labels and to bring clusters into correspondence . An application to modeling of storm trajectories is used to illustrate these ideas .
In this article , we study spectral methods for community detection based on $ \alpha$-parametrized normalized modularity matrix hereafter called $ {\bf L}_\alpha $ in heterogeneous graph models . We show , in a regime where community detection is not asymptotically trivial , that $ {\bf L}_\alpha $ can be well approximated by a more tractable random matrix which falls in the family of spiked random matrices . The analysis of this equivalent spiked random matrix allows us to improve spectral methods for community detection and assess their performances in the regime under study . In particular , we prove the existence of an optimal value $ \alpha_{\rm opt} $ of the parameter $ \alpha $ for which the detection of communities is best ensured and we provide an on-line estimation of $ \alpha_{\rm opt} $ only based on the knowledge of the graph adjacency matrix . Unlike classical spectral methods for community detection where clustering is performed on the eigenvectors associated with extreme eigenvalues , we show through our theoretical analysis that a regularization should instead be performed on those eigenvectors prior to clustering in heterogeneous graphs . Finally , through a deeper study of the regularized eigenvectors used for clustering , we assess the performances of our new algorithm for community detection . Numerical simulations in the course of the article show that our methods outperform state-of-the-art spectral methods on dense heterogeneous graphs .
We present two algorithms for learning the structure of a Markov network from data : GSMN* and GSIMN . Both algorithms use statistical independence tests to infer the structure by successively constraining the set of structures consistent with the results of these tests . Until very recently , algorithms for structure learning were based on maximum likelihood estimation , which has been proved to be NP-hard for Markov networks due to the difficulty of estimating the parameters of the network , needed for the computation of the data likelihood . The independence-based approach does not require the computation of the likelihood , and thus both GSMN* and GSIMN can compute the structure efficiently ( as shown in our experiments ) . GSMN* is an adaptation of the Grow-Shrink algorithm of Margaritis and Thrun for learning the structure of Bayesian networks . GSIMN extends GSMN* by additionally exploiting Pearls well-known properties of the conditional independence relation to infer novel independences from known ones , thus avoiding the performance of statistical tests to estimate them . To accomplish this efficiently GSIMN uses the Triangle theorem , also introduced in this work , which is a simplified version of the set of Markov axioms . Experimental comparisons on artificial and real-world data sets show GSIMN can yield significant savings with respect to GSMN* , while generating a Markov network with comparable or in some cases improved quality . We also compare GSIMN to a forward-chaining implementation , called GSIMN-FCH , that produces all possible conditional independences resulting from repeatedly applying Pearls theorems on the known conditional independence tests . The results of this comparison show that GSIMN , by the sole use of the Triangle theorem , is nearly optimal in terms of the set of independences tests that it infers .
We describe the Customer LifeTime Value ( CLTV ) prediction system deployed at ASOS . com , a global online fashion retailer . CLTV prediction is an important problem in e-commerce where an accurate estimate of future value allows retailers to effectively allocate marketing spend , identify and nurture high value customers and mitigate exposure to losses . The system at ASOS provides daily estimates of the future value of every customer and is one of the cornerstones of the personalised shopping experience . The state of the art in this domain uses large numbers of handcrafted features and ensemble regressors to forecast value , predict churn and evaluate customer loyalty . Recently , domains including language , vision and speech have shown dramatic advances by replacing handcrafted features with features that are learned automatically from data . We detail the system deployed at ASOS and show that learning feature representations is a promising extension to the state of the art in CLTV modelling . We propose a novel way to generate embeddings of customers , which addresses the issue of the ever changing product catalogue and obtain a significant improvement over an exhaustive set of handcrafted features .
The estimation of dependencies between multiple variables is a central problem in the analysis of financial time series . A common approach is to express these dependencies in terms of a copula function . Typically the copula function is assumed to be constant but this may be inaccurate when there are covariates that could have a large influence on the dependence structure of the data . To account for this , a Bayesian framework for the estimation of conditional copulas is proposed . In this framework the parameters of a copula are non-linearly related to some arbitrary conditioning variables . We evaluate the ability of our method to predict time-varying dependencies on several equities and currencies and observe consistent performance gains compared to static copula models and other time-varying copula methods .
Many sensors , such as range , sonar , radar , GPS and visual devices , produce measurements which are contaminated by outliers . This problem can be addressed by using fat-tailed sensor models , which account for the possibility of outliers . Unfortunately , all estimation algorithms belonging to the family of Gaussian filters ( such as the widely-used extended Kalman filter and unscented Kalman filter ) are inherently incompatible with such fat-tailed sensor models . The contribution of this paper is to show that any Gaussian filter can be made compatible with fat-tailed sensor models by applying one simple change : Instead of filtering with the physical measurement , we propose to filter with a pseudo measurement obtained by applying a feature function to the physical measurement . We derive such a feature function which is optimal under some conditions . Simulation results show that the proposed method can effectively handle measurement outliers and allows for robust filtering in both linear and nonlinear systems .
This paper applies machine learning techniques to student modeling . It presents a method for discovering high-level student behaviors from a very large set of low-level traces corresponding to problem-solving actions in a learning environment . Basic actions are encoded into sets of domain-dependent attribute-value patterns called cases . Then a domain-independent hierarchical clustering identifies what we call general attitudes , yielding automatic diagnosis expressed in natural language , addressed in principle to teachers . The method can be applied to individual students or to entire groups , like a class . We exhibit examples of this system applied to thousands of students ' actions in the domain of algebraic transformations .
In this paper , the problem of road friction prediction from a fleet of connected vehicles is investigated . A framework is proposed to predict the road friction level using both historical friction data from the connected cars and data from weather stations , and comparative results from different methods are presented . The problem is formulated as a classification task where the available data is used to train three machine learning models including logistic regression , support vector machine , and neural networks to predict the friction class ( slippery or non-slippery ) in the future for specific road segments . In addition to the friction values , which are measured by moving vehicles , additional parameters such as humidity , temperature , and rainfall are used to obtain a set of descriptive feature vectors as input to the classification methods . The proposed prediction models are evaluated for different prediction horizons ( 0 to 000 minutes in the future ) where the evaluation shows that the neural networks method leads to more stable results in different conditions .
A new iterative low complexity algorithm has been presented for computing the Walsh-Hadamard transform ( WHT ) of an $N$ dimensional signal with a $K$-sparse WHT , where $N$ is a power of two and $K = O ( N^\alpha ) $ , scales sub-linearly in $N$ for some $0 < \alpha < 0$ . Assuming a random support model for the non-zero transform domain components , the algorithm reconstructs the WHT of the signal with a sample complexity $O ( K \log_0 ( \frac{N}{K} ) ) $ , a computational complexity $O ( K\log_0 ( K ) \log_0 ( \frac{N}{K} ) ) $ and with a very high probability asymptotically tending to 0 . The approach is based on the subsampling ( aliasing ) property of the WHT , where by a carefully designed subsampling of the time domain signal , one can induce a suitable aliasing pattern in the transform domain . By treating the aliasing patterns as parity-check constraints and borrowing ideas from erasure correcting sparse-graph codes , the recovery of the non-zero spectral values has been formulated as a belief propagation ( BP ) algorithm ( peeling decoding ) over a sparse-graph code for the binary erasure channel ( BEC ) . Tools from coding theory are used to analyze the asymptotic performance of the algorithm in the very sparse ( $\alpha\in ( 0 , \frac{0}{0}]$ ) and the less sparse ( $\alpha\in ( \frac{0}{0} , 0 ) $ ) regime .
Training model to generate data has increasingly attracted research attention and become important in modern world applications . We propose in this paper a new geometry-based optimization approach to address this problem . Orthogonal to current state-of-the-art density-based approaches , most notably VAE and GAN , we present a fresh new idea that borrows the principle of minimal enclosing ball to train a generator G\left ( \bz\right ) in such a way that both training and generated data , after being mapped to the feature space , are enclosed in the same sphere . We develop theory to guarantee that the mapping is bijective so that its inverse from feature space to data space results in expressive nonlinear contours to describe the data manifold , hence ensuring data generated are also lying on the data manifold learned from training data . Our model enjoys a nice geometric interpretation , hence termed Geometric Enclosing Networks ( GEN ) , and possesses some key advantages over its rivals , namely simple and easy-to-control optimization formulation , avoidance of mode collapsing and efficiently learn data manifold representation in a completely unsupervised manner . We conducted extensive experiments on synthesis and real-world datasets to illustrate the behaviors , strength and weakness of our proposed GEN , in particular its ability to handle multi-modal data and quality of generated data .
The goal of this thesis is to investigate the potential of predictive modelling for football injuries . This work was conducted in close collaboration with Tottenham Hotspurs FC ( THFC ) , the PGA European tour and the participation of Wolverhampton Wanderers ( WW ) . Three investigations were conducted : 0 . Predicting the recovery time of football injuries using the UEFA injury recordings : The UEFA recordings is a common standard for recording injuries in professional football . For this investigation , three datasets of UEFA injury recordings were available . Different machine learning algorithms were used in order to build a predictive model . The performance of the machine learning models is then improved by using feature selection conducted through correlation-based subset feature selection and random forests . 0 . Predicting injuries in professional football using exposure records : The relationship between exposure ( in training hours and match hours ) in professional football athletes and injury incidence was studied . A common problem in football is understanding how the training schedule of an athlete can affect the chance of him getting injured . The task was to predict the number of days a player can train before he gets injured . 0 . Predicting intrinsic injury incidence using in-training GPS measurements : A significant percentage of football injuries can be attributed to overtraining and fatigue . GPS data collected during training sessions might provide indicators of fatigue , or might be used to detect very intense training sessions which can lead to overtraining . This research used GPS data gathered during training sessions of the first team of THFC , in order to predict whether an injury would take place during a week .
We introduce a new neural architecture to learn the conditional probability of an output sequence with elements that are discrete tokens corresponding to positions in an input sequence . Such problems cannot be trivially addressed by existent approaches such as sequence-to-sequence and Neural Turing Machines , because the number of target classes in each step of the output depends on the length of the input , which is variable . Problems such as sorting variable sized sequences , and various combinatorial optimization problems belong to this class . Our model solves the problem of variable size output dictionaries using a recently proposed mechanism of neural attention . It differs from the previous attention attempts in that , instead of using attention to blend hidden units of an encoder to a context vector at each decoder step , it uses attention as a pointer to select a member of the input sequence as the output . We call this architecture a Pointer Net ( Ptr-Net ) . We show Ptr-Nets can be used to learn approximate solutions to three challenging geometric problems -- finding planar convex hulls , computing Delaunay triangulations , and the planar Travelling Salesman Problem -- using training examples alone . Ptr-Nets not only improve over sequence-to-sequence with input attention , but also allow us to generalize to variable size output dictionaries . We show that the learnt models generalize beyond the maximum lengths they were trained on . We hope our results on these tasks will encourage a broader exploration of neural learning for discrete problems .
In multivariate regression , a $K$-dimensional response vector is regressed upon a common set of $p$ covariates , with a matrix $B^*\in\mathbb{R}^{p\times K}$ of regression coefficients . We study the behavior of the multivariate group Lasso , in which block regularization based on the $\ell_0/\ell_0$ norm is used for support union recovery , or recovery of the set of $s$ rows for which $B^*$ is nonzero . Under high-dimensional scaling , we show that the multivariate group Lasso exhibits a threshold for the recovery of the exact row pattern with high probability over the random design and noise that is specified by the sample complexity parameter $\theta ( n , p , s ) : =n/[0\psi ( B^* ) \log ( p-s ) ]$ . Here $n$ is the sample size , and $\psi ( B^* ) $ is a sparsity-overlap function measuring a combination of the sparsities and overlaps of the $K$-regression coefficient vectors that constitute the model . We prove that the multivariate group Lasso succeeds for problem sequences $ ( n , p , s ) $ such that $\theta ( n , p , s ) $ exceeds a critical level $\theta_u$ , and fails for sequences such that $\theta ( n , p , s ) $ lies below a critical level $\theta_{\ell}$ . For the special case of the standard Gaussian ensemble , we show that $\theta_{\ell}=\theta_u$ so that the characterization is sharp . The sparsity-overlap function $\psi ( B^* ) $ reveals that , if the design is uncorrelated on the active rows , $\ell_0/\ell_0$ regularization for multivariate regression never harms performance relative to an ordinary Lasso approach and can yield substantial improvements in sample complexity ( up to a factor of $K$ ) when the coefficient vectors are suitably orthogonal . For more general designs , it is possible for the ordinary Lasso to outperform the multivariate group Lasso . We complement our analysis with simulations that demonstrate the sharpness of our theoretical results , even for relatively small problems .
Adaptive optimization methods , which perform local optimization with a metric constructed from the history of iterates , are becoming increasingly popular for training deep neural networks . Examples include AdaGrad , RMSProp , and Adam . We show that for simple overparameterized problems , adaptive methods often find drastically different solutions than gradient descent ( GD ) or stochastic gradient descent ( SGD ) . We construct an illustrative binary classification problem where the data is linearly separable , GD and SGD achieve zero test error , and AdaGrad , Adam , and RMSProp attain test errors arbitrarily close to half . We additionally study the empirical generalization capability of adaptive methods on several state-of-the-art deep learning models . We observe that the solutions found by adaptive methods generalize worse ( often significantly worse ) than SGD , even when these solutions have better training performance . These results suggest that practitioners should reconsider the use of adaptive methods to train neural networks .
A parametric point process model is developed , with modeling based on the assumption that sequential observations often share latent phenomena , while also possessing idiosyncratic effects . An alternating optimization method is proposed to learn a " registered " point process that accounts for shared structure , as well as " warping " functions that characterize idiosyncratic aspects of each observed sequence . Under reasonable constraints , in each iteration we update the sample-specific warping functions by solving a set of constrained nonlinear programming problems in parallel , and update the model by maximum likelihood estimation . The justifiability , complexity and robustness of the proposed method are investigated in detail . Experiments on both synthetic and real-world data demonstrate that the method yields explainable point process models , achieving encouraging results compared to state-of-the-art methods .
Many datasets can be viewed as a noisy sampling of an underlying space , and tools from topological data analysis can characterize this structure for the purpose of knowledge discovery . One such tool is persistent homology , which provides a multiscale description of the homological features within a dataset . A useful representation of this homological information is a persistence diagram ( PD ) . Efforts have been made to map PDs into spaces with additional structure valuable to machine learning tasks . We convert a PD to a finite-dimensional vector representation which we call a persistence image ( PI ) , and prove the stability of this transformation with respect to small perturbations in the inputs . The discriminatory power of PIs is compared against existing methods , showing significant performance gains . We explore the use of PIs with vector-based machine learning tools , such as linear sparse support vector machines , which identify features containing discriminating topological information . Finally , high accuracy inference of parameter values from the dynamic output of a discrete dynamical system ( the linked twist map ) and a partial differential equation ( the anisotropic Kuramoto-Sivashinsky equation ) provide a novel application of the discriminatory power of PIs .
This paper studies the problem of learning clusters which are consistently present in different ( continuously valued ) representations of observed data . Our setup differs slightly from the standard approach of ( co- ) clustering as we use the fact that some form of `labeling ' becomes available in this setup : a cluster is only interesting if it has a counterpart in the alternative representation . The contribution of this paper is twofold : ( i ) the problem setting is explored and an analysis in terms of the PAC-Bayesian theorem is presented , ( ii ) a practical kernel-based algorithm is derived exploiting the inherent relation to Canonical Correlation Analysis ( CCA ) , as well as its extension to multiple views . A content based information retrieval ( CBIR ) case study is presented on the multi-lingual aligned Europal document dataset which supports the above findings .
Phylogenetic tree reconstruction is traditionally based on multiple sequence alignments ( MSAs ) and heavily depends on the validity of this information bottleneck . With increasing sequence divergence , the quality of MSAs decays quickly . Alignment-free methods , on the other hand , are based on abstract string comparisons and avoid potential alignment problems . However , in general they are not biologically motivated and ignore our knowledge about the evolution of sequences . Thus , it is still a major open question how to define an evolutionary distance metric between divergent sequences that makes use of indel information and known substitution models without the need for a multiple alignment . Here we propose a new evolutionary distance metric to close this gap . It uses finite-state transducers to create a biologically motivated similarity score which models substitutions and indels , and does not depend on a multiple sequence alignment . The sequence similarity score is defined in analogy to pairwise alignments and additionally has the positive semi-definite property . We describe its derivation and show in simulation studies and real-world examples that it is more accurate in reconstructing phylogenies than competing methods . The result is a new and accurate way of determining evolutionary distances in and beyond the twilight zone of sequence alignments that is suitable for large datasets .
The last decade has seen huge progress in the development of advanced machine learning models ; however , those models are powerless unless human users can interpret them . Here we show how the mind ' s construction of concepts and meaning can be used to create more interpretable machine learning models . By proposing a novel method of classifying concepts , in terms of ' form ' and ' function ' , we elucidate the nature of meaning and offer proposals to improve model understandability . As machine learning begins to permeate daily life , interpretable models may serve as a bridge between domain-expert authors and non-expert users .
We consider the problem of constructing diffusion operators high dimensional data $X$ to address counterfactual functions $F$ , such as individualized treatment effectiveness . We propose and construct a new diffusion metric $K_F$ that captures both the local geometry of $X$ and the directions of variance of $F$ . The resulting diffusion metric is then used to define a localized filtration of $F$ and answer counterfactual questions pointwise , particularly in situations such as drug trials where an individual patient ' s outcomes cannot be studied long term both taking and not taking a medication . We validate the model on synthetic and real world clinical trials , and create individualized notions of benefit from treatment .
Bayesian matrix factorization ( BMF ) is a powerful tool for producing low-rank representations of matrices , and giving principled predictions of missing values . However , scaling up MCMC samplers to large matrices has proven to be difficult with parallel algorithms that require communication between MCMC iterations . On the other hand , designing communication-free algorithms is challenging due to the inherent unidentifiability of BMF solutions . We propose posterior propagation , an embarrassingly parallel inference procedure , which hierarchically introduces dependencies between data subsets and thus alleviates the unidentifiability problem .
Understanding player behavior is fundamental in game data science . Video games evolve as players interact with the game , so being able to foresee player experience would help to ensure a successful game development . In particular , game developers need to evaluate beforehand the impact of in-game events . Simulation optimization of these events is crucial to increase player engagement and maximize monetization . We present an experimental analysis of several methods to forecast game-related variables , with two main aims : to obtain accurate predictions of in-app purchases and playtime in an operational production environment , and to perform simulations of in-game events in order to maximize sales and playtime . Our ultimate purpose is to take a step towards the data-driven development of games . The results suggest that , even though the performance of traditional approaches such as ARIMA is still better , the outcomes of state-of-the-art techniques like deep learning are promising . Deep learning comes up as a well-suited general model that could be used to forecast a variety of time series with different dynamic behaviors .
Many practical machine learning tasks employ very deep convolutional neural networks . Such large depths pose formidable computational challenges in training and operating the network . It is therefore important to understand how fast the energy contained in the propagated signals ( a . k . a . feature maps ) decays across layers . In addition , it is desirable that the feature extractor generated by the network be informative in the sense of the only signal mapping to the all-zeros feature vector being the zero input signal . This " trivial null-space " property can be accomplished by asking for " energy conservation " in the sense of the energy in the feature vector being proportional to that of the corresponding input signal . This paper establishes conditions for energy conservation ( and thus for a trivial null-space ) for a wide class of deep convolutional neural network-based feature extractors and characterizes corresponding feature map energy decay rates . Specifically , we consider general scattering networks employing the modulus non-linearity and we find that under mild analyticity and high-pass conditions on the filters ( which encompass , inter alia , various constructions of Weyl-Heisenberg filters , wavelets , ridgelets , ( $\alpha$ ) -curvelets , and shearlets ) the feature map energy decays at least polynomially fast . For broad families of wavelets and Weyl-Heisenberg filters , the guaranteed decay rate is shown to be exponential . Moreover , we provide handy estimates of the number of layers needed to have at least $ ( ( 0-\varepsilon ) \cdot 000 ) \%$ of the input signal energy be contained in the feature vector .
Recently , considerable research efforts have been devoted to the design of methods to learn from data overcomplete dictionaries for sparse coding . However , learned dictionaries require the solution of an optimization problem for coding new data . In order to overcome this drawback , we propose an algorithm aimed at learning both a dictionary and its dual : a linear mapping directly performing the coding . By leveraging on proximal methods , our algorithm jointly minimizes the reconstruction error of the dictionary and the coding error of its dual ; the sparsity of the representation is induced by an $\ell_0$-based penalty on its coefficients . The results obtained on synthetic data and real images show that the algorithm is capable of recovering the expected dictionaries . Furthermore , on a benchmark dataset , we show that the image features obtained from the dual matrix yield state-of-the-art classification performance while being much less computational intensive .
We consider the scenario where one observes an outcome variable and sets of features from multiple assays , all measured on the same set of samples . One approach that has been proposed for dealing with this type of data is ``sparse multiple canonical correlation analysis ' ' ( sparse mCCA ) . All of the current sparse mCCA techniques are biconvex and thus have no guarantees about reaching a global optimum . We propose a method for performing sparse supervised canonical correlation analysis ( sparse sCCA ) , a specific case of sparse mCCA when one of the datasets is a vector . Our proposal for sparse sCCA is convex and thus does not face the same difficulties as the other methods . We derive efficient algorithms for this problem , and illustrate their use on simulated and real data .
In this paper , we consider a novel machine learning problem , that is , learning a classifier from noisy label distributions . In this problem , each instance with a feature vector belongs to at least one group . Then , instead of the true label of each instance , we observe the label distribution of the instances associated with a group , where the label distribution is distorted by an unknown noise . Our goals are to ( 0 ) estimate the true label of each instance , and ( 0 ) learn a classifier that predicts the true label of a new instance . We propose a probabilistic model that considers true label distributions of groups and parameters that represent the noise as hidden variables . The model can be learned based on a variational Bayesian method . In numerical experiments , we show that the proposed model outperforms existing methods in terms of the estimation of the true labels of instances .
Stochastic variational inference allows for fast posterior inference in complex Bayesian models . However , the algorithm is prone to local optima which can make the quality of the posterior approximation sensitive to the choice of hyperparameters and initialization . We address this problem by replacing the natural gradient step of stochastic varitional inference with a trust-region update . We show that this leads to generally better results and reduced sensitivity to hyperparameters . We also describe a new strategy for variational inference on streaming data and show that here our trust-region method is crucial for getting good performance .
In this paper , we consider solving a class of nonconvex and nonsmooth problems frequently appearing in signal processing and machine learning research . The traditional alternating direction method of multipliers encounter troubles in both mathematics and computations in solving the nonconvex and nonsmooth subproblem . In view of this , we propose a reweighted alternating direction method of multipliers . In this algorithm , all subproblems are convex and easy to calculate . We also provide several guarantees for the convergence and prove that the algorithm globally converges to a critical point of an auxiliary function with the help of the Kurdyka- Lojasiewicz property . Several numerical results are presented to demonstrate the efficiency of the proposed algorithm .
Poisson likelihood models have been prevalently used in imaging , social networks , and time series analysis . We propose fast , simple , theoretically-grounded , and versatile , optimization algorithms for Poisson likelihood modeling . The Poisson log-likelihood is concave but not Lipschitz-continuous . Since almost all gradient-based optimization algorithms rely on Lipschitz-continuity , optimizing Poisson likelihood models with a guarantee of convergence can be challenging , especially for large-scale problems . We present a new perspective allowing to efficiently optimize a wide range of penalized Poisson likelihood objectives . We show that an appropriate saddle point reformulation enjoys a favorable geometry and a smooth structure . Therefore , we can design a new gradient-based optimization algorithm with $O ( 0/t ) $ convergence rate , in contrast to the usual $O ( 0/\sqrt{t} ) $ rate of non-smooth minimization alternatives . Furthermore , in order to tackle problems with large samples , we also develop a randomized block-decomposition variant that enjoys the same convergence rate yet more efficient iteration cost . Experimental results on several point process applications including social network estimation and temporal recommendation show that the proposed algorithm and its randomized block variant outperform existing methods both on synthetic and real-world datasets .
Due to physiological variation , patients diagnosed with the same condition may exhibit divergent , but related , responses to the same treatments . Hidden Parameter Markov Decision Processes ( HiP-MDPs ) tackle this transfer-learning problem by embedding these tasks into a low-dimensional space . However , the original formulation of HiP-MDP had a critical flaw : the embedding uncertainty was modeled independently of the agent ' s state uncertainty , requiring an unnatural training procedure in which all tasks visited every part of the state space---possible for robots that can be moved to a particular location , impossible for human patients . We update the HiP-MDP framework and extend it to more robustly develop personalized medicine strategies for HIV treatment .
Deep Neural Network ( DNN ) acoustic models have yielded many state-of-the-art results in Automatic Speech Recognition ( ASR ) tasks . More recently , Recurrent Neural Network ( RNN ) models have been shown to outperform DNNs counterparts . However , state-of-the-art DNN and RNN models tend to be impractical to deploy on embedded systems with limited computational capacity . Traditionally , the approach for embedded platforms is to either train a small DNN directly , or to train a small DNN that learns the output distribution of a large DNN . In this paper , we utilize a state-of-the-art RNN to transfer knowledge to small DNN . We use the RNN model to generate soft alignments and minimize the Kullback-Leibler divergence against the small DNN . The small DNN trained on the soft RNN alignments achieved a 0 . 00 WER on the Wall Street Journal ( WSJ ) eval00 task compared to a baseline 0 . 00 WER or more than 00% relative improvement .
Computational paralinguistic analysis is increasingly being used in a wide range of applications , including security-sensitive applications such as speaker verification , deceptive speech detection , and medical diagnosis . While state-of-the-art machine learning techniques , such as deep neural networks , can provide robust and accurate speech analysis , they are susceptible to adversarial attacks . In this work , we propose a novel end-to-end scheme to generate adversarial examples by perturbing directly the raw waveform of an audio recording rather than specific acoustic features . Our experiments show that the proposed adversarial perturbation can lead to a significant performance drop of state-of-the-art deep neural networks , while only minimally impairing the audio quality .
Approximate inference in high-dimensional , discrete probabilistic models is a central problem in computational statistics and machine learning . This paper describes discrete particle variational inference ( DPVI ) , a new approach that combines key strengths of Monte Carlo , variational and search-based techniques . DPVI is based on a novel family of particle-based variational approximations that can be fit using simple , fast , deterministic search techniques . Like Monte Carlo , DPVI can handle multiple modes , and yields exact results in a well-defined limit . Like unstructured mean-field , DPVI is based on optimizing a lower bound on the partition function ; when this quantity is not of intrinsic interest , it facilitates convergence assessment and debugging . Like both Monte Carlo and combinatorial search , DPVI can take advantage of factorization , sequential structure , and custom search operators . This paper defines DPVI particle-based approximation family and partition function lower bounds , along with the sequential DPVI and local DPVI algorithm templates for optimizing them . DPVI is illustrated and evaluated via experiments on lattice Markov Random Fields , nonparametric Bayesian mixtures and block-models , and parametric as well as non-parametric hidden Markov models . Results include applications to real-world spike-sorting and relational modeling problems , and show that DPVI can offer appealing time/accuracy trade-offs as compared to multiple alternatives .
We consider a generalization of low-rank matrix completion to the case where the data belongs to an algebraic variety , i . e . each data point is a solution to a system of polynomial equations . In this case the original matrix is possibly high-rank , but it becomes low-rank after mapping each column to a higher dimensional space of monomial features . Many well-studied extensions of linear models , including affine subspaces and their union , can be described by a variety model . In addition , varieties can be used to model a richer class of nonlinear quadratic and higher degree curves and surfaces . We study the sampling requirements for matrix completion under a variety model with a focus on a union of affine subspaces . We also propose an efficient matrix completion algorithm that minimizes a convex or non-convex surrogate of the rank of the matrix of monomial features . Our algorithm uses the well-known " kernel trick " to avoid working directly with the high-dimensional monomial matrix . We show the proposed algorithm is able to recover synthetically generated data up to the predicted sampling complexity bounds . The proposed algorithm also outperforms standard low rank matrix completion and subspace clustering techniques in experiments with real data .
We consider Bayesian optimization of an expensive-to-evaluate black-box objective function , where we also have access to cheaper approximations of the objective . In general , such approximations arise in applications such as reinforcement learning , engineering , and the natural sciences , and are subject to an inherent , unknown bias . This model discrepancy is caused by an inadequate internal model that deviates from reality and can vary over the domain , making the utilization of these approximations a non-trivial task . We present a novel algorithm that provides a rigorous mathematical treatment of the uncertainties arising from model discrepancies and noisy observations . Its optimization decisions rely on a value of information analysis that extends the Knowledge Gradient factor to the setting of multiple information sources that vary in cost : each sampling decision maximizes the predicted benefit per unit cost . We conduct an experimental evaluation that demonstrates that the method consistently outperforms other state-of-the-art techniques : it finds designs of considerably higher objective value and additionally inflicts less cost in the exploration process .
Consumer Demand Response ( DR ) is an important research and industry problem , which seeks to categorize , predict and modify consumer ' s energy consumption . Unfortunately , traditional clustering methods have resulted in many hundreds of clusters , with a given consumer often associated with several clusters , making it difficult to classify consumers into stable representative groups and to predict individual energy consumption patterns . In this paper , we present a shape-based approach that better classifies and predicts consumer energy consumption behavior at the household level . The method is based on Dynamic Time Warping . DTW seeks an optimal alignment between energy consumption patterns reflecting the effect of hidden patterns of regular consumer behavior . Using real consumer 00-hour load curves from Opower Corporation , our method results in a 00% reduction in the number of representative groups and an improvement in prediction accuracy measured under DTW distance . We extend the approach to estimate which electrical devices will be used and in which hours .
Computation of moments of transformed random variables is a problem appearing in many engineering applications . The current methods for moment transformation are mostly based on the classical quadrature rules which cannot account for the approximation errors . Our aim is to design a method for moment transformation for Gaussian random variables which accounts for the error in the numerically computed mean . We employ an instance of Bayesian quadrature , called Gaussian process quadrature ( GPQ ) , which allows us to treat the integral itself as a random variable , where the integral variance informs about the incurred integration error . Experiments on the coordinate transformation and nonlinear filtering examples show that the proposed GPQ moment transform performs better than the classical transforms .
Distributed algorithms are often beset by the straggler effect , where the slowest compute nodes in the system dictate the overall running time . Coding-theoretic techniques have been recently proposed to mitigate stragglers via algorithmic redundancy . Prior work in coded computation and gradient coding has mainly focused on exact recovery of the desired output . However , slightly inexact solutions can be acceptable in applications that are robust to noise , such as model training via gradient-based algorithms . In this work , we present computationally simple gradient codes based on sparse graphs that guarantee fast and approximately accurate distributed computation . We demonstrate that sacrificing a small amount of accuracy can significantly increase algorithmic robustness to stragglers .
Bayesian network models with latent variables are widely used in statistics and machine learning . In this paper we provide a complete algebraic characterization of Bayesian network models with latent variables when the observed variables are discrete and no assumption is made about the state-space of the latent variables . We show that it is algebraically equivalent to the so-called nested Markov model , meaning that the two are the same up to inequality constraints on the joint probabilities . In particular these two models have the same dimension . The nested Markov model is therefore the best possible description of the latent variable model that avoids consideration of inequalities , which are extremely complicated in general . A consequence of this is that the constraint finding algorithm of Tian and Pearl ( UAI 0000 , pp000-000 ) is complete for finding equality constraints . Latent variable models suffer from difficulties of unidentifiable parameters and non-regular asymptotics ; in contrast the nested Markov model is fully identifiable , represents a curved exponential family of known dimension , and can easily be fitted using an explicit parameterization .
In recent years , deep neural networks ( DNN ) have demonstrated significant business impact in large scale analysis and classification tasks such as speech recognition , visual object detection , pattern extraction , etc . Training of large DNNs , however , is universally considered as time consuming and computationally intensive task that demands datacenter-scale computational resources recruited for many days . Here we propose a concept of resistive processing unit ( RPU ) devices that can potentially accelerate DNN training by orders of magnitude while using much less power . The proposed RPU device can store and update the weight values locally thus minimizing data movement during training and allowing to fully exploit the locality and the parallelism of the training algorithm . We identify the RPU device and system specifications for implementation of an accelerator chip for DNN training in a realistic CMOS-compatible technology . For large DNNs with about 0 billion weights this massively parallel RPU architecture can achieve acceleration factors of 00 , 000X compared to state-of-the-art microprocessors while providing power efficiency of 00 , 000 GigaOps/s/W . Problems that currently require days of training on a datacenter-size cluster with thousands of machines can be addressed within hours on a single RPU accelerator . A system consisted of a cluster of RPU accelerators will be able to tackle Big Data problems with trillions of parameters that is impossible to address today like , for example , natural speech recognition and translation between all world languages , real-time analytics on large streams of business and scientific data , integration and analysis of multimodal sensory data flows from massive number of IoT ( Internet of Things ) sensors .
We introduce a novel stochastic version of the non-reversible , rejection-free Bouncy Particle Sampler ( BPS ) , a Markov process whose sample trajectories are piecewise linear . The algorithm is based on simulating first arrival times in a doubly stochastic Poisson process using the thinning method , and allows efficient sampling of Bayesian posteriors in big datasets . We prove that in the BPS no bias is introduced by noisy evaluations of the log-likelihood gradient . On the other hand , we argue that efficiency considerations favor a small , controllable bias in the construction of the thinning proposals , in exchange for faster mixing . We introduce a simple regression-based proposal intensity for the thinning method that controls this trade-off . We illustrate the algorithm in several examples in which it outperforms both unbiased , but slowly mixing stochastic versions of BPS , as well as biased stochastic gradient-based samplers .
We consider parallel asynchronous Markov Chain Monte Carlo ( MCMC ) sampling for problems where we can leverage ( stochastic ) gradients to define continuous dynamics which explore the target distribution . We outline a solution strategy for this setting based on stochastic gradient Hamiltonian Monte Carlo sampling ( SGHMC ) which we alter to include an elastic coupling term that ties together multiple MCMC instances . The proposed strategy turns inherently sequential HMC algorithms into asynchronous parallel versions . First experiments empirically show that the resulting parallel sampler significantly speeds up exploration of the target distribution , when compared to standard SGHMC , and is less prone to the harmful effects of stale gradients than a naive parallelization approach .
This paper presents novel Gaussian process decentralized data fusion algorithms exploiting the notion of agent-centric support sets for distributed cooperative perception of large-scale environmental phenomena . To overcome the limitations of scale in existing works , our proposed algorithms allow every mobile sensing agent to choose a different support set and dynamically switch to another during execution for encapsulating its own data into a local summary that , perhaps surprisingly , can still be assimilated with the other agents ' local summaries ( i . e . , based on their current choices of support sets ) into a globally consistent summary to be used for predicting the phenomenon . To achieve this , we propose a novel transfer learning mechanism for a team of agents capable of sharing and transferring information encapsulated in a summary based on a support set to that utilizing a different support set with some loss that can be theoretically bounded and analyzed . To alleviate the issue of information loss accumulating over multiple instances of transfer learning , we propose a new information sharing mechanism to be incorporated into our algorithms in order to achieve memory-efficient lazy transfer learning . Empirical evaluation on real-world datasets show that our algorithms outperform the state-of-the-art methods .
Many real-world analytics problems involve two significant challenges : prediction and optimization . Due to the typically complex nature of each challenge , the standard paradigm is to predict , then optimize . By and large , machine learning tools are intended to minimize prediction error and do not account for how the predictions will be used in a downstream optimization problem . In contrast , we propose a new and very general framework , called Smart " Predict , then Optimize " ( SPO ) , which directly leverages the optimization problem structure , i . e . , its objective and constraints , for designing successful analytics tools . A key component of our framework is the SPO loss function , which measures the quality of a prediction by comparing the objective values of the solutions generated using the predicted and observed parameters , respectively . Training a model with respect to the SPO loss is computationally challenging , and therefore we also develop a surrogate loss function , called the SPO+ loss , which upper bounds the SPO loss , has desirable convexity properties , and is statistically consistent under mild conditions . We also propose a stochastic gradient descent algorithm which allows for situations in which the number of training samples is large , model regularization is desired , and/or the optimization problem of interest is nonlinear or integer . Finally , we perform computational experiments to empirically verify the success of our SPO framework in comparison to the standard predict-then-optimize approach .
This paper presents a framework to tackle combinatorial optimization problems using neural networks and reinforcement learning . We focus on the traveling salesman problem ( TSP ) and train a recurrent network that , given a set of city coordinates , predicts a distribution over different city permutations . Using negative tour length as the reward signal , we optimize the parameters of the recurrent network using a policy gradient method . We compare learning the network parameters on a set of training graphs against learning them on individual test graphs . Despite the computational expense , without much engineering and heuristic designing , Neural Combinatorial Optimization achieves close to optimal results on 0D Euclidean graphs with up to 000 nodes . Applied to the KnapSack , another NP-hard problem , the same method obtains optimal solutions for instances with up to 000 items .
A data filtering method for cluster analysis is proposed , based on minimizing a least squares function with a weighted $\ell_0$-norm penalty . To overcome the discontinuity of the objective function , smooth non-convex functions are employed to approximate the $\ell_0$-norm . The convergence of the global minimum points of the approximating problems towards global minimum points of the original problem is stated . The proposed method also exploits a suitable technique to choose the penalty parameter . Numerical results on synthetic and real data sets are finally provided , showing how some existing clustering methods can take advantages from the proposed filtering strategy .
Model-based collaborative filtering analyzes user-item interactions to infer latent factors that represent user preferences and item characteristics in order to predict future interactions . Most collaborative filtering algorithms assume that these latent factors are static , although it has been shown that user preferences and item perceptions drift over time . In this paper , we propose a conjugate and numerically stable dynamic matrix factorization ( DCPF ) based on compound Poisson matrix factorization that models the smoothly drifting latent factors using Gamma-Markov chains . We propose a numerically stable Gamma chain construction , and then present a stochastic variational inference approach to estimate the parameters of our model . We apply our model to time-stamped ratings data sets : Netflix , Yelp , and Last . fm , where DCPF achieves a higher predictive accuracy than state-of-the-art static and dynamic factorization models .
ConvNets and Imagenet have driven the recent success of deep learning for image classification . However , the marked slowdown in performance improvement , the recent studies on the lack of robustness of neural networks to adversarial examples and their tendency to exhibit undesirable biases ( e . g racial biases ) questioned the reliability and the sustained development of these methods . This work investigates these questions from the perspective of the end-user by using human subject studies and explanations . We experimentally demonstrate that the accuracy and robustness of ConvNets measured on Imagenet are underestimated . We show that explanations can mitigate the impact of misclassified adversarial examples from the perspective of the end-user and we introduce a novel tool for uncovering the undesirable biases learned by a model . These contributions also show that explanations are a promising tool for improving our understanding of ConvNets ' predictions and for designing more reliable models
Ultrahigh-dimensional variable selection plays an increasingly important role in contemporary scientific discoveries and statistical research . Among others , Fan and Lv [J . R . Stat . Soc . Ser . B Stat . Methodol . 00 ( 0000 ) 000-000] propose an independent screening framework by ranking the marginal correlations . They showed that the correlation ranking procedure possesses a sure independence screening property within the context of the linear model with Gaussian covariates and responses . In this paper , we propose a more general version of the independent learning with ranking the maximum marginal likelihood estimates or the maximum marginal likelihood itself in generalized linear models . We show that the proposed methods , with Fan and Lv [J . R . Stat . Soc . Ser . B Stat . Methodol . 00 ( 0000 ) 000-000] as a very special case , also possess the sure screening property with vanishing false selection rate . The conditions under which the independence learning possesses a sure screening is surprisingly simple . This justifies the applicability of such a simple method in a wide spectrum . We quantify explicitly the extent to which the dimensionality can be reduced by independence screening , which depends on the interactions of the covariance matrix of covariates and true parameters . Simulation studies are used to illustrate the utility of the proposed approaches . In addition , we establish an exponential inequality for the quasi-maximum likelihood estimator which is useful for high-dimensional statistical learning .
An important goal in visual recognition is to devise image representations that are invariant to particular transformations . In this paper , we address this goal with a new type of convolutional neural network ( CNN ) whose invariance is encoded by a reproducing kernel . Unlike traditional approaches where neural networks are learned either to represent data or for solving a classification task , our network learns to approximate the kernel feature map on training data . Such an approach enjoys several benefits over classical ones . First , by teaching CNNs to be invariant , we obtain simple network architectures that achieve a similar accuracy to more complex ones , while being easy to train and robust to overfitting . Second , we bridge a gap between the neural network literature and kernels , which are natural tools to model invariance . We evaluate our methodology on visual recognition tasks where CNNs have proven to perform well , e . g . , digit recognition with the MNIST dataset , and the more challenging CIFAR-00 and STL-00 datasets , where our accuracy is competitive with the state of the art .
Optimization problems with rank constraints appear in many diverse fields such as control , machine learning and image analysis . Since the rank constraint is non-convex , these problems are often approximately solved via convex relaxations . Nuclear norm regularization is the prevailing convexifying technique for dealing with these types of problem . This paper introduces a family of low-rank inducing norms and regularizers which includes the nuclear norm as a special case . A posteriori guarantees on solving an underlying rank constrained optimization problem with these convex relaxations are provided . We evaluate the performance of the low-rank inducing norms on three matrix completion problems . In all examples , the nuclear norm heuristic is outperformed by convex relaxations based on other low-rank inducing norms . For two of the problems there exist low-rank inducing norms that succeed in recovering the partially unknown matrix , while the nuclear norm fails . These low-rank inducing norms are shown to be representable as semi-definite programs and to have cheaply computable proximal mappings . The latter makes it possible to also solve problems of large size with the help of scalable first-order methods . Finally , it is proven that our findings extend to the more general class of atomic norms . In particular , this allows us to solve corresponding vector-valued problems , as well as problems with other non-convex constraints .
We generalize Newton-type methods for minimizing smooth functions to handle a sum of two convex functions : a smooth function and a nonsmooth function with a simple proximal mapping . We show that the resulting proximal Newton-type methods inherit the desirable convergence behavior of Newton-type methods for minimizing smooth functions , even when search directions are computed inexactly . Many popular methods tailored to problems arising in bioinformatics , signal processing , and statistical learning are special cases of proximal Newton-type methods , and our analysis yields new convergence results for some of these methods .
Dropout has been witnessed with great success in training deep neural networks by independently zeroing out the outputs of neurons at random . It has also received a surge of interest for shallow learning , e . g . , logistic regression . However , the independent sampling for dropout could be suboptimal for the sake of convergence . In this paper , we propose to use multinomial sampling for dropout , i . e . , sampling features or neurons according to a multinomial distribution with different probabilities for different features/neurons . To exhibit the optimal dropout probabilities , we analyze the shallow learning with multinomial dropout and establish the risk bound for stochastic optimization . By minimizing a sampling dependent factor in the risk bound , we obtain a distribution-dependent dropout with sampling probabilities dependent on the second order statistics of the data distribution . To tackle the issue of evolving distribution of neurons in deep learning , we propose an efficient adaptive dropout ( named \textbf{evolutional dropout} ) that computes the sampling probabilities on-the-fly from a mini-batch of examples . Empirical studies on several benchmark datasets demonstrate that the proposed dropouts achieve not only much faster convergence and but also a smaller testing error than the standard dropout . For example , on the CIFAR-000 data , the evolutional dropout achieves relative improvements over 00\% on the prediction performance and over 00\% on the convergence speed compared to the standard dropout .
Concave regularization methods provide natural procedures for sparse recovery . However , they are difficult to analyze in the high dimensional setting . Only recently a few sparse recovery results have been established for some specific local solutions obtained via specialized numerical procedures . Still , the fundamental relationship between these solutions such as whether they are identical or their relationship to the global minimizer of the underlying nonconvex formulation is unknown . The current paper fills this conceptual gap by presenting a general theoretical framework showing that under appropriate conditions , the global solution of nonconvex regularization leads to desirable recovery performance ; moreover , under suitable conditions , the global solution corresponds to the unique sparse local solution , which can be obtained via different numerical procedures . Under this unified framework , we present an overview of existing results and discuss their connections . The unified view of this work leads to a more satisfactory treatment of concave high dimensional sparse estimation procedures , and serves as guideline for developing further numerical procedures for concave regularization .
We study the $K$-armed dueling bandit problem , a variation of the standard stochastic bandit problem where the feedback is limited to relative comparisons of a pair of arms . We introduce a tight asymptotic regret lower bound that is based on the information divergence . An algorithm that is inspired by the Deterministic Minimum Empirical Divergence algorithm ( Honda and Takemura , 0000 ) is proposed , and its regret is analyzed . The proposed algorithm is found to be the first one with a regret upper bound that matches the lower bound . Experimental comparisons of dueling bandit algorithms show that the proposed algorithm significantly outperforms existing ones .
Community detection in graphs has been extensively studied both in theory and in applications . However , detecting communities in hypergraphs is more challenging . In this paper , we propose a tensor decomposition approach for guaranteed learning of communities in a special class of hypergraphs modeling social tagging systems or folksonomies . A folksonomy is a tripartite 0-uniform hypergraph consisting of ( user , tag , resource ) hyperedges . We posit a probabilistic mixed membership community model , and prove that the tensor method consistently learns the communities under efficient sample complexity and separation requirements .
The problem of low-rank matrix estimation recently received a lot of attention due to challenging applications . A lot of work has been done on rank-penalized methods and convex relaxation , both on the theoretical and applied sides . However , only a few papers considered Bayesian estimation . In this paper , we review the different type of priors considered on matrices to favour low-rank . We also prove that the obtained Bayesian estimators , under suitable assumptions , enjoys the same optimality properties as the ones based on penalization .
We propose a particularly structured Boltzmann machine , which we refer to as a dynamic Boltzmann machine ( DyBM ) , as a stochastic model of a multi-dimensional time-series . The DyBM can have infinitely many layers of units but allows exact and efficient inference and learning when its parameters have a proposed structure . This proposed structure is motivated by postulates and observations , from biological neural networks , that the synaptic weight is strengthened or weakened , depending on the timing of spikes ( i . e . , spike-timing dependent plasticity or STDP ) . We show that the learning rule of updating the parameters of the DyBM in the direction of maximizing the likelihood of given time-series can be interpreted as STDP with long term potentiation and long term depression . The learning rule has a guarantee of convergence and can be performed in a distributed matter ( i . e . , local in space ) with limited memory ( i . e . , local in time ) .
Long short-term memory ( LSTM ) recurrent neural networks are renowned for being uninterpretable " black boxes " . In the medical domain where LSTMs have shown promise , this is specifically concerning because it is imperative to understand the decisions made by machine learning models in such acute situations . This study employs techniques used in the convolutional neural network domain to elucidate the inputs that are important when LSTMs classify electrocardiogram signals . Of the various techniques available to determine input feature saliency , it was found that learning an occlusion mask is the most effective .
We consider the problem of clustering noisy finite-length observations of stationary ergodic random processes according to their nonparametric generative models without prior knowledge of the model statistics and the number of generative models . Two algorithms , both using the L0-distance between estimated power spectral densities ( PSDs ) as a measure of dissimilarity , are analyzed . The first algorithm , termed nearest neighbor process clustering ( NNPC ) , to the best of our knowledge , is new and relies on partitioning the nearest neighbor graph of the observations via spectral clustering . The second algorithm , simply referred to as k-means ( KM ) , consists of a single k-means iteration with farthest point initialization and was considered before in the literature , albeit with a different measure of dissimilarity and with asymptotic performance results only . We show that both NNPC and KM succeed with high probability under noise and even when the generative process PSDs overlap significantly , all provided that the observation length is sufficiently large . Our results quantify the tradeoff between the overlap of the generative process PSDs , the noise variance , and the observation length . Finally , we present numerical performance results for synthetic and real data .
This paper deals with sparse feature selection and grouping for classification and regression . The classification or regression problems under consideration consists in minimizing a convex empirical risk function subject to an $\ell^0$ constraint , a pairwise $\ell^\infty$ constraint , or a pairwise $\ell^0$ constraint . Existing work , such as the Lasso formulation , has focused mainly on Lagrangian penalty approximations , which often require ad hoc or computationally expensive procedures to determine the penalization parameter . We depart from this approach and address the constrained problem directly via a splitting method . The structure of the method is that of the classical gradient-projection algorithm , which alternates a gradient step on the objective and a projection step onto the lower level set modeling the constraint . The novelty of our approach is that the projection step is implemented via an outer approximation scheme in which the constraint set is approximated by a sequence of simple convex sets consisting of the intersection of two half-spaces . Convergence of the iterates generated by the algorithm is established for a general smooth convex minimization problem with inequality constraints . Experiments on both synthetic and biological data show that our method outperforms penalty methods .
We propose a Bayesian nonparametric prior for time-varying networks . To each node of the network is associated a positive parameter , modeling the sociability of that node . Sociabilities are assumed to evolve over time , and are modeled via a dynamic point process model . The model is able to ( a ) capture smooth evolution of the interaction between nodes , allowing edges to appear/disappear over time ( b ) capture long term evolution of the sociabilities of the nodes ( c ) and yield sparse graphs , where the number of edges grows subquadratically with the number of nodes . The evolution of the sociabilities is described by a tractable time-varying gamma process . We provide some theoretical insights into the model and apply it to three real world datasets .
We design iterative receiver schemes for a generic wireless communication system by treating channel estimation and information decoding as an inference problem in graphical models . We introduce a recently proposed inference framework that combines belief propagation ( BP ) and the mean field ( MF ) approximation and includes these algorithms as special cases . We also show that the expectation propagation and expectation maximization algorithms can be embedded in the BP-MF framework with slight modifications . By applying the considered inference algorithms to our probabilistic model , we derive four different message-passing receiver schemes . Our numerical evaluation demonstrates that the receiver based on the BP-MF framework and its variant based on BP-EM yield the best compromise between performance , computational complexity and numerical stability among all candidate algorithms .
We propose a mini-batching scheme for improving the theoretical complexity and practical performance of semi-stochastic gradient descent applied to the problem of minimizing a strongly convex composite function represented as the sum of an average of a large number of smooth convex functions , and simple nonsmooth convex function . Our method first performs a deterministic step ( computation of the gradient of the objective function at the starting point ) , followed by a large number of stochastic steps . The process is repeated a few times with the last iterate becoming the new starting point . The novelty of our method is in introduction of mini-batching into the computation of stochastic steps . In each step , instead of choosing a single function , we sample $b$ functions , compute their gradients , and compute the direction based on this . We analyze the complexity of the method and show that the method benefits from two speedup effects . First , we prove that as long as $b$ is below a certain threshold , we can reach predefined accuracy with less overall work than without mini-batching . Second , our mini-batching scheme admits a simple parallel implementation , and hence is suitable for further acceleration by parallelization .
A number of modern learning tasks involve estimation from heterogeneous information sources . This includes classification with labeled and unlabeled data as well as other problems with analogous structure such as competitive ( game theoretic ) problems . The associated estimation problems can be typically reduced to solving a set of fixed point equations ( consistency conditions ) . We introduce a general method for combining a preferred information source with another in this setting by evolving continuous paths of fixed points at intermediate allocations . We explicitly identify critical points along the unique paths to either increase the stability of estimation or to ensure a significant departure from the initial source . The homotopy continuation approach is guaranteed to terminate at the second source , and involves no combinatorial effort . We illustrate the power of these ideas both in classification tasks with labeled and unlabeled data , as well as in the context of a competitive ( min-max ) formulation of DNA sequence motif discovery .
Regularization is one of the crucial ingredients of deep learning , yet the term regularization has various definitions , and regularization methods are often studied separately from each other . In our work we present a systematic , unifying taxonomy to categorize existing methods . We distinguish methods that affect data , network architectures , error terms , regularization terms , and optimization procedures . We do not provide all details about the listed methods ; instead , we present an overview of how the methods can be sorted into meaningful categories and sub-categories . This helps revealing links and fundamental similarities between them . Finally , we include practical recommendations both for users and for developers of new regularization methods .
In this paper we introduce the deep kernelized autoencoder , a neural network model that allows an explicit approximation of ( i ) the mapping from an input space to an arbitrary , user-specified kernel space and ( ii ) the back-projection from such a kernel space to input space . The proposed method is based on traditional autoencoders and is trained through a new unsupervised loss function . During training , we optimize both the reconstruction accuracy of input samples and the alignment between a kernel matrix given as prior and the inner products of the hidden representations computed by the autoencoder . Kernel alignment provides control over the hidden representation learned by the autoencoder . Experiments have been performed to evaluate both reconstruction and kernel alignment performance . Additionally , we applied our method to emulate kPCA on a denoising task obtaining promising results .
We propose an approach to reduce the bias of ridge regression and regularization kernel network . When applied to a single data set the new algorithms have comparable learning performance with the original ones . When applied to incremental learning with block wise streaming data the new algorithms are more efficient due to bias reduction . Both theoretical characterizations and simulation studies are used to verify the effectiveness of these new algorithms .
This paper presents a stochastic behavior analysis of a kernel-based stochastic restricted-gradient descent method . The restricted gradient gives a steepest ascent direction within the so-called dictionary subspace . The analysis provides the transient and steady state performance in the mean squared error criterion . It also includes stability conditions in the mean and mean-square sense . The present study is based on the analysis of the kernel normalized least mean square ( KNLMS ) algorithm initially proposed by Chen et al . Simulation results validate the analysis .
Learning and understanding the typical patterns in the daily activities and routines of people from low-level sensory data is an important problem in many application domains such as building smart environments , or providing intelligent assistance . Traditional approaches to this problem typically rely on supervised learning and generative models such as the hidden Markov models and its extensions . While activity data can be readily acquired from pervasive sensors , e . g . in smart environments , providing manual labels to support supervised training is often extremely expensive . In this paper , we propose a new approach based on semi-supervised training of partially hidden discriminative models such as the conditional random field ( CRF ) and the maximum entropy Markov model ( MEMM ) . We show that these models allow us to incorporate both labeled and unlabeled data for learning , and at the same time , provide us with the flexibility and accuracy of the discriminative framework . Our experimental results in the video surveillance domain illustrate that these models can perform better than their generative counterpart , the partially hidden Markov model , even when a substantial amount of labels are unavailable .
The use of distributions and high-level features from deep architecture has become commonplace in modern computer vision . Both of these methodologies have separately achieved a great deal of success in many computer vision tasks . However , there has been little work attempting to leverage the power of these to methodologies jointly . To this end , this paper presents the Deep Mean Maps ( DMMs ) framework , a novel family of methods to non-parametrically represent distributions of features in convolutional neural network models . DMMs are able to both classify images using the distribution of top-level features , and to tune the top-level features for performing this task . We show how to implement DMMs using a special mean map layer composed of typical CNN operations , making both forward and backward propagation simple . We illustrate the efficacy of DMMs at analyzing distributional patterns in image data in a synthetic data experiment . We also show that we extending existing deep architectures with DMMs improves the performance of existing CNNs on several challenging real-world datasets .
Deep learning , in the form of artificial neural networks , has achieved remarkable practical success in recent years , for a variety of difficult machine learning applications . However , a theoretical explanation for this remains a major open problem , since training neural networks involves optimizing a highly non-convex objective function , and is known to be computationally hard in the worst case . In this work , we study the \emph{geometric} structure of the associated non-convex objective function , in the context of ReLU networks and starting from a random initialization of the network parameters . We identify some conditions under which it becomes more favorable to optimization , in the sense of ( i ) High probability of initializing at a point from which there is a monotonically decreasing path to a global minimum ; and ( ii ) High probability of initializing at a basin ( suitably defined ) with a small minimal objective value . A common theme in our results is that such properties are more likely to hold for larger ( " overspecified " ) networks , which accords with some recent empirical and theoretical observations .
Feature interactions can contribute to a large proportion of variation in many prediction models . In the era of big data , the coexistence of high dimensionality in both responses and covariates poses unprecedented challenges in identifying important interactions . In this paper , we suggest a two-stage interaction identification method , called the interaction pursuit via distance correlation ( IPDC ) , in the setting of high-dimensional multi-response interaction models that exploits feature screening applied to transformed variables with distance correlation followed by feature selection . Such a procedure is computationally efficient , generally applicable beyond the heredity assumption , and effective even when the number of responses diverges with the sample size . Under mild regularity conditions , we show that this method enjoys nice theoretical properties including the sure screening property , support union recovery , and oracle inequalities in prediction and estimation for both interactions and main effects . The advantages of our method are supported by several simulation studies and real data analysis .
An important step in speaker verification is extracting features that best characterize the speaker voice . This paper investigates a front-end processing that aims at improving the performance of speaker verification based on the SVMs classifier , in text independent mode . This approach combines features based on conventional Mel-cepstral Coefficients ( MFCCs ) and Line Spectral Frequencies ( LSFs ) to constitute robust multivariate feature vectors . To reduce the high dimensionality required for training these feature vectors , we use a dimension reduction method called principal component analysis ( PCA ) . In order to evaluate the robustness of these systems , different noisy environments have been used . The obtained results using TIMIT database showed that , using the paradigm that combines these spectral cues leads to a significant improvement in verification accuracy , especially with PCA reduction for low signal-to-noise ratio noisy environment .
The widely used genetic pleiotropic analysis of multiple phenotypes are often designed for examining the relationship between common variants and a few phenotypes . They are not suited for both high dimensional phenotypes and high dimensional genotype ( next-generation sequencing ) data . To overcome these limitations , we develop sparse structural equation models ( SEMs ) as a general framework for a new paradigm of genetic analysis of multiple phenotypes . To incorporate both common and rare variants into the analysis , we extend the traditional multivariate SEMs to sparse functional SEMs . To deal with high dimensional phenotype and genotype data , we employ functional data analysis and the alternative direction methods of multiplier ( ADMM ) techniques to reduce data dimension and improve computational efficiency . Using large scale simulations we showed that the proposed methods have higher power to detect true causal genetic pleiotropic structure than other existing methods . Simulations also demonstrate that the gene-based pleiotropic analysis has higher power than the single variant-based pleiotropic analysis . The proposed method is applied to exome sequence data from the NHLBI Exome Sequencing Project ( ESP ) with 00 phenotypes , which identifies a network with 000 genes connected to 00 phenotypes and 000 edges . Among them , 000 genes showed pleiotropic genetic effects and 00 genes were reported to be associated with phenotypes in the analysis or other cardiovascular disease ( CVD ) related phenotypes in the literature .
In online social media systems users are not only posting , consuming , and resharing content , but also creating new and destroying existing connections in the underlying social network . While each of these two types of dynamics has individually been studied in the past , much less is known about the connection between the two . How does user information posting and seeking behavior interact with the evolution of the underlying social network structure ? Here , we study ways in which network structure reacts to users posting and sharing content . We examine the complete dynamics of the Twitter information network , where users post and reshare information while they also create and destroy connections . We find that the dynamics of network structure can be characterized by steady rates of change , interrupted by sudden bursts . Information diffusion in the form of cascades of post re-sharing often creates such sudden bursts of new connections , which significantly change users ' local network structure . These bursts transform users ' networks of followers to become structurally more cohesive as well as more homogenous in terms of follower interests . We also explore the effect of the information content on the dynamics of the network and find evidence that the appearance of new topics and real-world events can lead to significant changes in edge creations and deletions . Lastly , we develop a model that quantifies the dynamics of the network and the occurrence of these bursts as a function of the information spreading through the network . The model can successfully predict which information diffusion events will lead to bursts in network dynamics .
In this paper , we propose an efficient and scalable low rank matrix completion algorithm . The key idea is to extend orthogonal matching pursuit method from the vector case to the matrix case . We further propose an economic version of our algorithm by introducing a novel weight updating rule to reduce the time and storage complexity . Both versions are computationally inexpensive for each matrix pursuit iteration , and find satisfactory results in a few iterations . Another advantage of our proposed algorithm is that it has only one tunable parameter , which is the rank . It is easy to understand and to use by the user . This becomes especially important in large-scale learning problems . In addition , we rigorously show that both versions achieve a linear convergence rate , which is significantly better than the previous known results . We also empirically compare the proposed algorithms with several state-of-the-art matrix completion algorithms on many real-world datasets , including the large-scale recommendation dataset Netflix as well as the MovieLens datasets . Numerical results show that our proposed algorithm is more efficient than competing algorithms while achieving similar or better prediction performance .
We present an extension of sparse Canonical Correlation Analysis ( CCA ) designed for finding multiple-to-multiple linear correlations within a single set of variables . Unlike CCA , which finds correlations between two sets of data where the rows are matched exactly but the columns represent separate sets of variables , the method proposed here , Canonical Autocorrelation Analysis ( CAA ) , finds multivariate correlations within just one set of variables . This can be useful when we look for hidden parsimonious structures in data , each involving only a small subset of all features . In addition , the discovered correlations are highly interpretable as they are formed by pairs of sparse linear combinations of the original features . We show how CAA can be of use as a tool for anomaly detection when the expected structure of correlations is not followed by anomalous data . We illustrate the utility of CAA in two application domains where single-class and unsupervised learning of correlation structures are particularly relevant : breast cancer diagnosis and radiation threat detection . When applied to the Wisconsin Breast Cancer data , single-class CAA is competitive with supervised methods used in literature . On the radiation threat detection task , unsupervised CAA performs significantly better than an unsupervised alternative prevalent in the domain , while providing valuable additional insights for threat analysis .
There is tremendous interest in precision medicine as a means to improve patient outcomes by tailoring treatment to individual characteristics . An individualized treatment rule formalizes precision medicine as a map from patient information to a recommended treatment . A regime is defined to be optimal if it maximizes the mean of a scalar outcome in a population of interest , e . g . , symptom reduction . However , clinical and intervention scientists often must balance multiple and possibly competing outcomes , e . g . , symptom reduction and the risk of an adverse event . One approach to precision medicine in this setting is to elicit a composite outcome which balances all competing outcomes ; unfortunately , eliciting a composite outcome directly from patients is difficult without a high-quality instrument and an expert-derived composite outcome may not account for heterogeneity in patient preferences . We consider estimation of composite outcomes using observational data under the assumption that clinicians are approximately ( i . e . , imperfectly ) making decisions to maximize individual patient utility . Estimated composite outcomes are subsequently used to construct an estimator of an individualized treatment rule that maximizes the mean of patient-specific composite outcomes . Furthermore , the estimated composite outcomes and estimated optimal individualized treatment rule can provide new insights into patient preference heterogeneity , clinician behavior , and the value of precision medicine in a given domain . We prove that the proposed estimators are consistent under mild conditions and demonstrate their finite sample performance through a suite of simulation experiments and an illustrative application to data from a study of bipolar depression .
We present a Bayesian model selection approach to estimate the intrinsic dimensionality of a high-dimensional dataset . To this end , we introduce a novel formulation of the probabilisitic principal component analysis model based on a normal-gamma prior distribution . In this context , we exhibit a closed-form expression of the marginal likelihood which allows to infer an optimal number of components . We also propose a heuristic based on the expected shape of the marginal likelihood curve in order to choose the hyperparameters . In non-asymptotic frameworks , we show on simulated data that this exact dimensionality selection approach is competitive with both Bayesian and frequentist state-of-the-art methods .
Approximate Bayesian computation ( ABC ) methods provide an elaborate approach to Bayesian inference on complex models , including model choice . Both theoretical arguments and simulation experiments indicate , however , that model posterior probabilities may be poorly evaluated by standard ABC techniques . We propose a novel approach based on a machine learning tool named random forests to conduct selection among the highly complex models covered by ABC algorithms . We thus modify the way Bayesian model selection is both understood and operated , in that we rephrase the inferential goal as a classification problem , first predicting the model that best fits the data with random forests and postponing the approximation of the posterior probability of the predicted MAP for a second stage also relying on random forests . Compared with earlier implementations of ABC model choice , the ABC random forest approach offers several potential improvements : ( i ) it often has a larger discriminative power among the competing models , ( ii ) it is more robust against the number and choice of statistics summarizing the data , ( iii ) the computing effort is drastically reduced ( with a gain in computation efficiency of at least fifty ) , and ( iv ) it includes an approximation of the posterior probability of the selected model . The call to random forests will undoubtedly extend the range of size of datasets and complexity of models that ABC can handle . We illustrate the power of this novel methodology by analyzing controlled experiments as well as genuine population genetics datasets . The proposed methodologies are implemented in the R package abcrf available on the CRAN .
We develop in this article a penalized likelihood method to estimate sparse Bayesian networks from categorical data . The structure of a Bayesian network is represented by a directed acyclic graph ( DAG ) . We model the conditional distribution of a node given its parents by multi-logit regression and estimate the structure of a DAG via maximizing a regularized likelihood . The adaptive group Lasso penalty is employed to encourage sparsity by selecting grouped dummy variables encoding the level of a factor . We develop a blockwise coordinate descent algorithm to solve the penalized likelihood problem subject to the acyclicity constraint of a DAG . When intervention data are available , our method may construct a causal network , in which a directed edge represents a causal relation . We apply our method to various simulated networks and a real biological network . The results show that our method is very competitive , compared to other existing methods , in DAG estimation from both interventional and high-dimensional observational data . We also establish consistency in parameter and structure estimation for our method when the number of nodes is fixed .
We address the problem of acoustic source separation in a deep learning framework we call " deep clustering . " Rather than directly estimating signals or masking functions , we train a deep network to produce spectrogram embeddings that are discriminative for partition labels given in training data . Previous deep network approaches provide great advantages in terms of learning power and speed , but previously it has been unclear how to use them to separate signals in a class-independent way . In contrast , spectral clustering approaches are flexible with respect to the classes and number of items to be segmented , but it has been unclear how to leverage the learning power and speed of deep networks . To obtain the best of both worlds , we use an objective function that to train embeddings that yield a low-rank approximation to an ideal pairwise affinity matrix , in a class-independent way . This avoids the high cost of spectral factorization and instead produces compact clusters that are amenable to simple clustering methods . The segmentations are therefore implicitly encoded in the embeddings , and can be " decoded " by clustering . Preliminary experiments show that the proposed method can separate speech : when trained on spectrogram features containing mixtures of two speakers , and tested on mixtures of a held-out set of speakers , it can infer masking functions that improve signal quality by around 0dB . We show that the model can generalize to three-speaker mixtures despite training only on two-speaker mixtures . The framework can be used without class labels , and therefore has the potential to be trained on a diverse set of sound types , and to generalize to novel sources . We hope that future work will lead to segmentation of arbitrary sounds , with extensions to microphone array methods as well as image segmentation and other domains .
We propose a new Bayesian tracking and parameter learning algorithm for non-linear non-Gaussian multiple target tracking ( MTT ) models . We design a Markov chain Monte Carlo ( MCMC ) algorithm to sample from the posterior distribution of the target states , birth and death times , and association of observations to targets , which constitutes the solution to the tracking problem , as well as the model parameters . In the numerical section , we present performance comparisons with several competing techniques and demonstrate significant performance improvements in all cases .
A good measure of similarity between data points is crucial to many tasks in machine learning . Similarity and metric learning methods learn such measures automatically from data , but they do not scale well respect to the dimensionality of the data . In this paper , we propose a method that can learn efficiently similarity measure from high-dimensional sparse data . The core idea is to parameterize the similarity measure as a convex combination of rank-one matrices with specific sparsity structures . The parameters are then optimized with an approximate Frank-Wolfe procedure to maximally satisfy relative similarity constraints on the training data . Our algorithm greedily incorporates one pair of features at a time into the similarity measure , providing an efficient way to control the number of active features and thus reduce overfitting . It enjoys very appealing convergence guarantees and its time and memory complexity depends on the sparsity of the data instead of the dimension of the feature space . Our experiments on real-world high-dimensional datasets demonstrate its potential for classification , dimensionality reduction and data exploration .
One of the most tedious tasks in the application of machine learning is model selection , i . e . hyperparameter selection . Fortunately , recent progress has been made in the automation of this process , through the use of sequential model-based optimization ( SMBO ) methods . This can be used to optimize a cross-validation performance of a learning algorithm over the value of its hyperparameters . However , it is well known that ensembles of learned models almost consistently outperform a single model , even if properly selected . In this paper , we thus propose an extension of SMBO methods that automatically constructs such ensembles . This method builds on a recently proposed ensemble construction paradigm known as agnostic Bayesian learning . In experiments on 00 regression and 00 classification data sets , we confirm the success of this proposed approach , which is able to outperform model selection with SMBO .
We introduce the adversarially learned inference ( ALI ) model , which jointly learns a generation network and an inference network using an adversarial process . The generation network maps samples from stochastic latent variables to the data space while the inference network maps training examples in data space to the space of latent variables . An adversarial game is cast between these two networks and a discriminative network is trained to distinguish between joint latent/data-space samples from the generative network and joint samples from the inference network . We illustrate the ability of the model to learn mutually coherent inference and generation networks through the inspections of model samples and reconstructions and confirm the usefulness of the learned representations by obtaining a performance competitive with state-of-the-art on the semi-supervised SVHN and CIFAR00 tasks .
We introduce a novel Entropy-driven Monte Carlo ( EdMC ) strategy to efficiently sample solutions of random Constraint Satisfaction Problems ( CSPs ) . First , we extend a recent result that , using a large-deviation analysis , shows that the geometry of the space of solutions of the Binary Perceptron Learning Problem ( a prototypical CSP ) , contains regions of very high-density of solutions . Despite being sub-dominant , these regions can be found by optimizing a local entropy measure . Building on these results , we construct a fast solver that relies exclusively on a local entropy estimate , and can be applied to general CSPs . We describe its performance not only for the Perceptron Learning Problem but also for the random $K$-Satisfiabilty Problem ( another prototypical CSP with a radically different structure ) , and show numerically that a simple zero-temperature Metropolis search in the smooth local entropy landscape can reach sub-dominant clusters of optimal solutions in a small number of steps , while standard Simulated Annealing either requires extremely long cooling procedures or just fails . We also discuss how the EdMC can heuristically be made even more efficient for the cases we studied .
We describe a methodology for modeling the performance of decision-level data fusion between different sensor configurations , implemented as part of the JIEDDO Analytic Decision Engine ( JADE ) . We first discuss a Bayesian network formulation of classical probabilistic data fusion , which allows elementary fusion structures to be stacked and analyzed efficiently . We then present an extension of the Wald sequential test for combining the outputs of the Bayesian network over time . We discuss an algorithm to compute its performance statistics and illustrate the approach on some examples . This variant of the sequential test involves multiple , distinct stages , where the evidence accumulated from each stage is carried over into the next one , and is motivated by a need to keep certain sensors in the network inactive unless triggered by other sensors .
How many samples are sufficient to guarantee that the eigenvectors and eigenvalues of the sample covariance matrix are close to those of the actual covariance matrix ? For a wide family of distributions , including distributions with finite second moment and distributions supported in a centered Euclidean ball , we prove that the inner product between eigenvectors of the sample and actual covariance matrices decreases proportionally to the respective eigenvalue distance . Our findings imply non-asymptotic concentration bounds for eigenvectors , eigenspaces , and eigenvalues . They also provide conditions for distinguishing principal components based on a constant number of samples .
We consider the problem of estimating the latent structure of a social network based on observational data on information diffusion processes , or {\it cascades} . Here for a given cascade , we only observe the time a node/agent is infected but not the source of infection . Existing literature has focused on estimating network diffusion matrix without any underlying assumptions on the structure of the network . We propose a novel model for inferring network diffusion matrix based on the intuition that an information datum is more likely to propagate among two nodes if they are interested in similar topics , which are common with the information . In particular , our model endows each node with an influence vector ( how authoritative they are on each topic ) and a receptivity vector ( how susceptible they are on each topic ) . We show how this node-topic structure can be estimated from observed cascades . The estimated model can be used to build recommendation system based on the receptivity vectors , as well as for marketing based on the influence vectors .
We present a simple , yet effective , approach to Semi-Supervised Learning . Our approach is based on estimating density-based distances ( DBD ) using a shortest path calculation on a graph . These Graph-DBD estimates can then be used in any distance-based supervised learning method , such as Nearest Neighbor methods and SVMs with RBF kernels . In order to apply the method to very large data sets , we also present a novel algorithm which integrates nearest neighbor computations into the shortest path search and can find exact shortest paths even in extremely large dense graphs . Significant runtime improvement over the commonly used Laplacian regularization method is then shown on a large scale dataset .
This paper describes an implementation of the L-BFGS method designed to deal with two adversarial situations . The first occurs in distributed computing environments where some of the computational nodes devoted to the evaluation of the function and gradient are unable to return results on time . A similar challenge occurs in a multi-batch approach in which the data points used to compute function and gradients are purposely changed at each iteration to accelerate the learning process . Difficulties arise because L-BFGS employs gradient differences to update the Hessian approximations , and when these gradients are computed using different data points the updating process can be unstable . This paper shows how to perform stable quasi-Newton updating in the multi-batch setting , studies the convergence properties for both convex and nonconvex functions , and illustrates the behavior of the algorithm in a distributed computing platform on binary classification logistic regression and neural network training problems that arise in machine learning .
Kernel ridge regression is used to approximate the kinetic energy of non-interacting fermions in a one-dimensional box as a functional of their density . The properties of different kernels and methods of cross-validation are explored , and highly accurate energies are achieved . Accurate {\em constrained optimal densities} are found via a modified Euler-Lagrange constrained minimization of the total energy . A projected gradient descent algorithm is derived using local principal component analysis . Additionally , a sparse grid representation of the density can be used without degrading the performance of the methods . The implications for machine-learned density functional approximations are discussed .
The machine learning community has recently devoted much attention to the problem of inferring causal relationships from statistical data . Most of this work has focused on uncovering connections among scalar random variables . We generalize existing methods to apply to collections of multi-dimensional random vectors , focusing on techniques applicable to linear models . The performance of the resulting algorithms is evaluated and compared in simulations , which show that our methods can , in many cases , provide useful information on causal relationships even for relatively small sample sizes .
Mechanical devices such as engines , vehicles , aircrafts , etc . , are typically instrumented with numerous sensors to capture the behavior and health of the machine . However , there are often external factors or variables which are not captured by sensors leading to time-series which are inherently unpredictable . For instance , manual controls and/or unmonitored environmental conditions or load may lead to inherently unpredictable time-series . Detecting anomalies in such scenarios becomes challenging using standard approaches based on mathematical models that rely on stationarity , or prediction models that utilize prediction errors to detect anomalies . We propose a Long Short Term Memory Networks based Encoder-Decoder scheme for Anomaly Detection ( EncDec-AD ) that learns to reconstruct ' normal ' time-series behavior , and thereafter uses reconstruction error to detect anomalies . We experiment with three publicly available quasi predictable time-series datasets : power demand , space shuttle , and ECG , and two real-world engine datasets with both predictive and unpredictable behavior . We show that EncDec-AD is robust and can detect anomalies from predictable , unpredictable , periodic , aperiodic , and quasi-periodic time-series . Further , we show that EncDec-AD is able to detect anomalies from short time-series ( length as small as 00 ) as well as long time-series ( length as large as 000 ) .
Discrete choice models are commonly used by applied statisticians in numerous fields , such as marketing , economics , finance , and operations research . When agents in discrete choice models are assumed to have differing preferences , exact inference is often intractable . Markov chain Monte Carlo techniques make approximate inference possible , but the computational cost is prohibitive on the large data sets now becoming routinely available . Variational methods provide a deterministic alternative for approximation of the posterior distribution . We derive variational procedures for empirical Bayes and fully Bayesian inference in the mixed multinomial logit model of discrete choice . The algorithms require only that we solve a sequence of unconstrained optimization problems , which are shown to be convex . Extensive simulations demonstrate that variational methods achieve accuracy competitive with Markov chain Monte Carlo , at a small fraction of the computational cost . Thus , variational methods permit inferences on data sets that otherwise could not be analyzed without bias-inducing modifications to the underlying model .
Hypernetworks are neural networks that transform a random input vector into weights for a specified target neural network . We formulate the hypernetwork training objective as a compromise between accuracy and diversity , where the diversity takes into account trivial symmetry transformations of the target network . We show that this formulation naturally arises as a relaxation of an optimistic probability distribution objective for the generated networks , and we explain how it is related to variational inference . We use multi-layered perceptrons to form the mapping from the low dimensional input random vector to the high dimensional weight space , and demonstrate how to reduce the number of parameters in this mapping by weight sharing . We perform experiments on a four layer convolutional target network which classifies MNIST images , and show that the generated weights are diverse and have interesting distributions .
We introduce a class of network models that insert edges by connecting the starting and terminal vertices of a random walk on the network graph . Within the taxonomy of statistical network models , this class is distinguished by permitting the location of a new edge to explicitly depend on the structure of the graph , but being nonetheless statistically and computationally tractable . In the limit of infinite walk length , the model converges to an extension of the preferential attachment model---in this sense , it can be motivated alternatively by asking what preferential attachment is an approximation to . Theoretical properties , including the limiting degree sequence , are studied analytically . If the entire history of the graph is observed , parameters can be estimated by maximum likelihood . If only the final graph is available , its history can be imputed using MCMC . We develop a class of sequential Monte Carlo algorithms that are more generally applicable to sequential random graph models , and may be of interest in their own right . The model parameters can be recovered from a single graph generated by the model . Applications to data clarify the role of the random walk length as a length scale of interactions within the graph .
Segmental structure is a common pattern in many types of sequences such as phrases in human languages . In this paper , we present a probabilistic model for sequences via their segmentations . The probability of a segmented sequence is calculated as the product of the probabilities of all its segments , where each segment is modeled using existing tools such as recurrent neural networks . Since the segmentation of a sequence is usually unknown in advance , we sum over all valid segmentations to obtain the final probability for the sequence . An efficient dynamic programming algorithm is developed for forward and backward computations without resorting to any approximation . We demonstrate our approach on text segmentation and speech recognition tasks . In addition to quantitative results , we also show that our approach can discover meaningful segments in their respective application contexts .
Parameter estimation for model-based clustering using a finite mixture of normal inverse Gaussian ( NIG ) distributions is achieved through variational Bayes approximations . Univariate NIG mixtures and multivariate NIG mixtures are considered . The use of variational Bayes approximations here is a substantial departure from the traditional EM approach and alleviates some of the associated computational complexities and uncertainties . Our variational algorithm is applied to simulated and real data . The paper concludes with discussion and suggestions for future work .
Learning structured outputs with general structures is computationally challenging , except for tree-structured models . Thus we propose an efficient boosting-based algorithm AdaBoost . MRF for this task . The idea is based on the realization that a graph is a superimposition of trees . Different from most existing work , our algorithm can handle partial labelling , and thus is particularly attractive in practice where reliable labels are often sparsely observed . In addition , our method works exclusively on trees and thus is guaranteed to converge . We apply the AdaBoost . MRF algorithm to an indoor video surveillance scenario , where activities are modelled at multiple levels .
This article is devoted to the problem of predicting the value taken by a random permutation $\Sigma$ , describing the preferences of an individual over a set of numbered items $\{0 , \ ; \ldots , \ ; n\}$ say , based on the observation of an input/explanatory r . v . $X$ e . g . characteristics of the individual ) , when error is measured by the Kendall $\tau$ distance . In the probabilistic formulation of the ' Learning to Order ' problem we propose , which extends the framework for statistical Kemeny ranking aggregation developped in \citet{CKS00} , this boils down to recovering conditional Kemeny medians of $\Sigma$ given $X$ from i . i . d . training examples $ ( X_0 , \Sigma_0 ) , \ ; \ldots , \ ; ( X_N , \Sigma_N ) $ . For this reason , this statistical learning problem is referred to as \textit{ranking median regression} here . Our contribution is twofold . We first propose a probabilistic theory of ranking median regression : the set of optimal elements is characterized , the performance of empirical risk minimizers is investigated in this context and situations where fast learning rates can be achieved are also exhibited . Next we introduce the concept of local consensus/median , in order to derive efficient methods for ranking median regression . The major advantage of this local learning approach lies in its close connection with the widely studied Kemeny aggregation problem . From an algorithmic perspective , this permits to build predictive rules for ranking median regression by implementing efficient techniques for ( approximate ) Kemeny median computations at a local level in a tractable manner . In particular , versions of $k$-nearest neighbor and tree-based methods , tailored to ranking median regression , are investigated . Accuracy of piecewise constant ranking median regression rules is studied under a specific smoothness assumption for $\Sigma$ ' s conditional distribution given $X$ .
This study presents a novel end-to-end architecture that learns hierarchical representations from raw EEG data using fully convolutional deep neural networks for the task of neonatal seizure detection . The deep neural network acts as both feature extractor and classifier , allowing for end-to-end optimization of the seizure detector . The designed system is evaluated on a large dataset of continuous unedited multi-channel neonatal EEG totaling 000 hours and comprising of 0000 seizures . The proposed deep architecture , with sample-level filters , achieves an accuracy that is comparable to the state-of-the-art SVM-based neonatal seizure detector , which operates on a set of carefully designed hand-crafted features . The fully convolutional architecture allows for the localization of EEG waveforms and patterns that result in high seizure probabilities for further clinical examination .
We find lower and upper bounds for the risk of estimating a manifold in Hausdorff distance under several models . We also show that there are close connections between manifold estimation and the problem of deconvolving a singular measure .
Stochastic gradient descent~ ( SGD ) and its variants have become more and more popular in machine learning due to their efficiency and effectiveness . To handle large-scale problems , researchers have recently proposed several parallel SGD methods for multicore systems . However , existing parallel SGD methods cannot achieve satisfactory performance in real applications . In this paper , we propose a fast asynchronous parallel SGD method , called AsySVRG , by designing an asynchronous strategy to parallelize the recently proposed SGD variant called stochastic variance reduced gradient~ ( SVRG ) . Both theoretical and empirical results show that AsySVRG can outperform existing state-of-the-art parallel SGD methods like Hogwild ! in terms of convergence rate and computation cost .
One of the major hurdles preventing the full exploitation of information from online communities is the widespread concern regarding the quality and credibility of user-contributed content . Prior works in this domain operate on a static snapshot of the community , making strong assumptions about the structure of the data ( e . g . , relational tables ) , or consider only shallow features for text classification . To address the above limitations , we propose probabilistic graphical models that can leverage the joint interplay between multiple factors in online communities --- like user interactions , community dynamics , and textual content --- to automatically assess the credibility of user-contributed online content , and the expertise of users and their evolution with user-interpretable explanation . To this end , we devise new models based on Conditional Random Fields for different settings like incorporating partial expert knowledge for semi-supervised learning , and handling discrete labels as well as numeric ratings for fine-grained analysis . This enables applications such as extracting reliable side-effects of drugs from user-contributed posts in healthforums , and identifying credible content in news communities . Online communities are dynamic , as users join and leave , adapt to evolving trends , and mature over time . To capture this dynamics , we propose generative models based on Hidden Markov Model , Latent Dirichlet Allocation , and Brownian Motion to trace the continuous evolution of user expertise and their language model over time . This allows us to identify expert users and credible content jointly over time , improving state-of-the-art recommender systems by explicitly considering the maturity of users . This also enables applications such as identifying helpful product reviews , and detecting fake and anomalous reviews with limited information .
Solving inverse problems with iterative algorithms is popular , especially for large data . Due to time constraints , the number of possible iterations is usually limited , potentially limiting the achievable accuracy . Given an error one is willing to tolerate , an important question is whether it is possible to modify the original iterations to obtain faster convergence to a minimizer achieving the allowed error without increasing the computational cost of each iteration considerably . Relying on recent recovery techniques developed for settings in which the desired signal belongs to some low-dimensional set , we show that using a coarse estimate of this set may lead to a faster convergence at the cost of an additional error in the reconstruction related to the accuracy of the set approximation . Our theory ties to recent advances in sparse recovery , compressed sensing , and deep learning . Particularly , it may provide a possible explanation to the successful approximation of the l_0-minimization solution by neural networks with layers representing iterations , as practiced in the learned iterative shrinkage-thresholding algorithm ( LISTA ) .
Tweedie Compound Poisson models are heavily used for modelling non-negative continuous data with a discrete probability spike at zero . An important practice is the modelling of the aggregate claim loss for insurance policies in actuarial science . However , the intractable density function and the unknown variance function have presented considerable challenges for Tweedie regression models . Previous studies are focused on numerical approximations to the density function . In this study , we tackle the Bayesian Tweedie regression problem via a Variational approach . In particular , we empower the posterior approximation by an implicit model trained in the adversarial setting , introduce the hyper prior by making the parameters of the prior distribution trainable , and integrate out one local latent variable in Tweedie model to reduce the variance . Our method is evaluated on the application of predicting the losses for auto insurance policies . Results show that the proposed method enjoys a state-of-the-art performance among traditional inference methods , while having a richer estimation of the variance function .
The Wasserstein distance received a lot of attention recently in the community of machine learning , especially for its principled way of comparing distributions . It has found numerous applications in several hard problems , such as domain adaptation , dimensionality reduction or generative models . However , its use is still limited by a heavy computational cost . Our goal is to alleviate this problem by providing an approximation mechanism that allows to break its inherent complexity . It relies on the search of an embedding where the Euclidean distance mimics the Wasserstein distance . We show that such an embedding can be found with a siamese architecture associated with a decoder network that allows to move from the embedding space back to the original input space . Once this embedding has been found , computing optimization problems in the Wasserstein space ( e . g . barycenters , principal directions or even archetypes ) can be conducted extremely fast . Numerical experiments supporting this idea are conducted on image datasets , and show the wide potential benefits of our method .
Link prediction in large knowledge graphs has received a lot of attention recently because of its importance for inferring missing relations and for completing and improving noisily extracted knowledge graphs . Over the years a number of machine learning researchers have presented various models for predicting the presence of missing relations in a knowledge base . Although all the previous methods are presented with empirical results that show high performance on select datasets , there is almost no previous work on understanding the connection between properties of a knowledge base and the performance of a model . In this paper we analyze the RESCAL method and prove that it can not encode asymmetric transitive relations in knowledge bases .
We present a class of models that , via a simple construction , enables exact , incremental , non-parametric , polynomial-time , Bayesian inference of conditional measures . The approach relies upon creating a sequence of covers on the conditioning variable and maintaining a different model for each set within a cover . Inference remains tractable by specifying the probabilistic model in terms of a random walk within the sequence of covers . We demonstrate the approach on problems of conditional density estimation , which , to our knowledge is the first closed-form , non-parametric Bayesian approach to this problem .
McCullagh and Yang ( 0000 ) suggest a family of classification algorithms based on Cox processes . We further investigate the log Gaussian variant which has a number of appealing properties . Conditioned on the covariates , the distribution over labels is given by a type of conditional Markov random field . In the supervised case , computation of the predictive probability of a single test point scales linearly with the number of training points and the multiclass generalization is straightforward . We show new links between the supervised method and classical nonparametric methods . We give a detailed analysis of the pairwise graph representable Markov random field , which we use to extend the model to semi-supervised learning problems , and propose an inference method based on graph min-cuts . We give the first experimental analysis on supervised and semi-supervised datasets and show good empirical performance .
We apply the OSCAR ( octagonal selection and clustering algorithms for regression ) in recovering group-sparse matrices ( two-dimensional---0D---arrays ) from compressive measurements . We propose a 0D version of OSCAR ( 0OSCAR ) consisting of the $\ell_0$ norm and the pair-wise $\ell_{\infty}$ norm , which is convex but non-differentiable . We show that the proximity operator of 0OSCAR can be computed based on that of OSCAR . The 0OSCAR problem can thus be efficiently solved by state-of-the-art proximal splitting algorithms . Experiments on group-sparse 0D array recovery show that 0OSCAR regularization solved by the SpaRSA algorithm is the fastest choice , while the PADMM algorithm ( with debiasing ) yields the most accurate results .
The efficiency of deep machine learning for automatic delineation of tumor areas has been demonstrated for intraoperative neuronavigation using active IR-mapping with the use of the cold test . The proposed approach employs a matrix IR-imager to remotely register the space-time distribution of surface temperature pattern , which is determined by the dynamics of local cerebral blood flow . The advantages of this technique are non-invasiveness , zero risks for the health of patients and medical staff , low implementation and operational costs , ease and speed of use . Traditional IR-diagnostic technique has a crucial limitation - it involves a diagnostician who determines the boundaries of tumor areas , which gives rise to considerable uncertainty , which can lead to diagnosis errors that are difficult to control . The current study demonstrates that implementing deep learning algorithms allows to eliminate the explained drawback .
We propose a novel method to directly learn a stochastic transition operator whose repeated application provides generated samples . Traditional undirected graphical models approach this problem indirectly by learning a Markov chain model whose stationary distribution obeys detailed balance with respect to a parameterized energy function . The energy function is then modified so the model and data distributions match , with no guarantee on the number of steps required for the Markov chain to converge . Moreover , the detailed balance condition is highly restrictive : energy based models corresponding to neural networks must have symmetric weights , unlike biological neural circuits . In contrast , we develop a method for directly learning arbitrarily parameterized transition operators capable of expressing non-equilibrium stationary distributions that violate detailed balance , thereby enabling us to learn more biologically plausible asymmetric neural networks and more general non-energy based dynamical systems . The proposed training objective , which we derive via principled variational methods , encourages the transition operator to " walk back " in multi-step trajectories that start at data-points , as quickly as possible back to the original data points . We present a series of experimental results illustrating the soundness of the proposed approach , Variational Walkback ( VW ) , on the MNIST , CIFAR-00 , SVHN and CelebA datasets , demonstrating superior samples compared to earlier attempts to learn a transition operator . We also show that although each rapid training trajectory is limited to a finite but variable number of steps , our transition operator continues to generate good samples well past the length of such trajectories , thereby demonstrating the match of its non-equilibrium stationary distribution to the data distribution . Source Code : http : //github . com/anirudh0000/walkback_nips00
By drawing on ideas from optimisation theory , artificial neural networks ( ANN ) , graph embeddings and sparse representations , I develop a novel technique , termed SENNS ( Sparse Extraction Neural NetworkS ) , aimed at addressing the feature extraction problem . The proposed method uses ( preferably deep ) ANNs for projecting input attribute vectors to an output space wherein pairwise distances are maximized for vectors belonging to different classes , but minimized for those belonging to the same class , while simultaneously enforcing sparsity on the ANN outputs . The vectors that result from the projection can then be used as features in any classifier of choice . Mathematically , I formulate the proposed method as the minimisation of an objective function which can be interpreted , in the ANN output space , as a negative factor of the sum of the squares of the pair-wise distances between output vectors belonging to different classes , added to a positive factor of the sum of squares of the pair-wise distances between output vectors belonging to the same classes , plus sparsity and weight decay terms . To derive an algorithm for minimizing the objective function via gradient descent , I use the multi-variate version of the chain rule to obtain the partial derivatives of the function with respect to ANN weights and biases , and find that each of the required partial derivatives can be expressed as a sum of six terms . As it turns out , four of those six terms can be computed using the standard back propagation algorithm ; the fifth can be computed via a slight modification of the standard backpropagation algorithm ; while the sixth one can be computed via simple arithmetic . Finally , I propose experiments on the ARABASE Arabic corpora of digits and letters , the CMU PIE database of faces , the MNIST digits database , and other standard machine learning databases .
It is well known that Markov chain Monte Carlo ( MCMC ) methods scale poorly with dataset size . A popular class of methods for solving this issue is stochastic gradient MCMC . These methods use a noisy estimate of the gradient of the log posterior , which reduces the per iteration computational cost of the algorithm . Despite this , there are a number of results suggesting that stochastic gradient Langevin dynamics ( SGLD ) , probably the most popular of these methods , still has computational cost proportional to the dataset size . We suggest an alternative log posterior gradient estimate for stochastic gradient MCMC , which uses control variates to reduce the variance . We analyse SGLD using this gradient estimate , and show that , under log-concavity assumptions on the target distribution , the computational cost required for a given level of accuracy is independent of the dataset size . Next we show that a different control variate technique , known as zero variance control variates can be applied to SGMCMC algorithms for free . This post-processing step improves the inference of the algorithm by reducing the variance of the MCMC output . Zero variance control variates rely on the gradient of the log posterior ; we explore how the variance reduction is affected by replacing this with the noisy gradient estimate calculated by SGMCMC .
Estimating multiple sparse Gaussian Graphical Models ( sGGMs ) jointly for many related tasks ( large $K$ ) under a high-dimensional ( large $p$ ) situation is an important task . Most previous studies for the joint estimation of multiple sGGMs rely on penalized log-likelihood estimators that involve expensive and difficult non-smooth optimizations . We propose a novel approach , FASJEM for \underline{fa}st and \underline{s}calable \underline{j}oint structure-\underline{e}stimation of \underline{m}ultiple sGGMs at a large scale . As the first study of joint sGGM using the M-estimator framework , our work has three major contributions : ( 0 ) We solve FASJEM through an entry-wise manner which is parallelizable . ( 0 ) We choose a proximal algorithm to optimize FASJEM . This improves the computational efficiency from $O ( Kp^0 ) $ to $O ( Kp^0 ) $ and reduces the memory requirement from $O ( Kp^0 ) $ to $O ( K ) $ . ( 0 ) We theoretically prove that FASJEM achieves a consistent estimation with a convergence rate of $O ( \log ( Kp ) /n_{tot} ) $ . On several synthetic and four real-world datasets , FASJEM shows significant improvements over baselines on accuracy , computational complexity and memory costs .
We study the problem of causal structure learning over a set of random variables when the experimenter is allowed to perform at most $M$ experiments in a non-adaptive manner . We consider the optimal learning strategy in terms of minimizing the portions of the structure that remains unknown given the limited number of experiments in both Bayesian and minimax setting . We characterize the theoretical optimal solution and propose an algorithm , which designs the experiments efficiently in terms of time complexity . We show that for bounded degree graphs , in the minimax case and in the Bayesian case with uniform priors , our proposed algorithm is a $\rho$-approximation algorithm , where $\rho$ is independent of the order of the underlying graph . Simulations on both synthetic and real data show that the performance of our algorithm is very close to the optimal solution .
The introduction of convolutional layers greatly advanced the performance of neural networks on image tasks due to innately capturing a way of encoding and learning translation-invariant operations , matching one of the underlying symmetries of the image domain . In comparison , there are a number of problems in which there are a number of different inputs which are all ' of the same type ' --- multiple particles , multiple agents , multiple stock prices , etc . The corresponding symmetry to this is permutation symmetry , in that the algorithm should not depend on the specific ordering of the input data . We discuss a permutation-invariant neural network layer in analogy to convolutional layers , and show the ability of this architecture to learn to predict the motion of a variable number of interacting hard discs in 0D . In the same way that convolutional layers can generalize to different image sizes , the permutation layer we describe generalizes to different numbers of objects .
Community detection is a central problem of network data analysis . Given a network , the goal of community detection is to partition the network nodes into a small number of clusters , which could often help reveal interesting structures . The present paper studies community detection in Degree-Corrected Block Models ( DCBMs ) . We first derive asymptotic minimax risks of the problem for a misclassification proportion loss under appropriate conditions . The minimax risks are shown to depend on degree-correction parameters , community sizes , and average within and between community connectivities in an intuitive and interpretable way . In addition , we propose a polynomial time algorithm to adaptively perform consistent and even asymptotically optimal community detection in DCBMs .
We adapt the ideas underlying the success of Deep Q-Learning to the continuous action domain . We present an actor-critic , model-free algorithm based on the deterministic policy gradient that can operate over continuous action spaces . Using the same learning algorithm , network architecture and hyper-parameters , our algorithm robustly solves more than 00 simulated physics tasks , including classic problems such as cartpole swing-up , dexterous manipulation , legged locomotion and car driving . Our algorithm is able to find policies whose performance is competitive with those found by a planning algorithm with full access to the dynamics of the domain and its derivatives . We further demonstrate that for many of the tasks the algorithm can learn policies end-to-end : directly from raw pixel inputs .
This paper proposes a new family of algorithms for training neural networks ( NNs ) . These are based on recent developments in the field of non-convex optimization , going under the general name of successive convex approximation ( SCA ) techniques . The basic idea is to iteratively replace the original ( non-convex , highly dimensional ) learning problem with a sequence of ( strongly convex ) approximations , which are both accurate and simple to optimize . Differently from similar ideas ( e . g . , quasi-Newton algorithms ) , the approximations can be constructed using only first-order information of the neural network function , in a stochastic fashion , while exploiting the overall structure of the learning problem for a faster convergence . We discuss several use cases , based on different choices for the loss function ( e . g . , squared loss and cross-entropy loss ) , and for the regularization of the NN ' s weights . We experiment on several medium-sized benchmark problems , and on a large-scale dataset involving simulated physical data . The results show how the algorithm outperforms state-of-the-art techniques , providing faster convergence to a better minimum . Additionally , we show how the algorithm can be easily parallelized over multiple computational units without hindering its performance . In particular , each computational unit can optimize a tailored surrogate function defined on a randomly assigned subset of the input variables , whose dimension can be selected depending entirely on the available computational power .
Sensor data has been playing an important role in machine learning tasks , complementary to the human-annotated data that is usually rather costly . However , due to systematic or accidental mis-operations , sensor data comes very often with a variety of missing values , resulting in considerable difficulties in the follow-up analysis and visualization . Previous work imputes the missing values by interpolating in the observational feature space , without consulting any latent ( hidden ) dynamics . In contrast , our model captures the latent complex temporal dynamics by summarizing each observation ' s context with a novel Iterative Imputing Network , thus significantly outperforms previous work on the benchmark Beijing air quality and meteorological dataset . Our model also yields consistent superiority over other methods in cases of different missing rates .
We present a theoretically grounded approach to train deep neural networks , including recurrent networks , subject to class-dependent label noise . We propose two procedures for loss correction that are agnostic to both application domain and network architecture . They simply amount to at most a matrix inversion and multiplication , provided that we know the probability of each class being corrupted into another . We further show how one can estimate these probabilities , adapting a recent technique for noise estimation to the multi-class setting , and thus providing an end-to-end framework . Extensive experiments on MNIST , IMDB , CIFAR-00 , CIFAR-000 and a large scale dataset of clothing images employing a diversity of architectures --- stacking dense , convolutional , pooling , dropout , batch normalization , word embedding , LSTM and residual layers --- demonstrate the noise robustness of our proposals . Incidentally , we also prove that , when ReLU is the only non-linearity , the loss curvature is immune to class-dependent label noise .
We consider the problem of covariance matrix estimation in the presence of latent variables . Under suitable conditions , it is possible to learn the marginal covariance matrix of the observed variables via a tractable convex program , where the concentration matrix of the observed variables is decomposed into a sparse matrix ( representing the graphical structure of the observed variables ) and a low rank matrix ( representing the marginalization effect of latent variables ) . We present an efficient first-order method based on split Bregman to solve the convex problem . The algorithm is guaranteed to converge under mild conditions . We show that our algorithm is significantly faster than the state-of-the-art algorithm on both artificial and real-world data . Applying the algorithm to a gene expression data involving thousands of genes , we show that most of the correlation between observed variables can be explained by only a few dozen latent factors .
Deep learning using multi-layer neural networks ( NNs ) architecture manifests superb power in modern machine learning systems . The trained Deep Neural Networks ( DNNs ) are typically large . The question we would like to address is whether it is possible to simplify the NN during training process to achieve a reasonable performance within an acceptable computational time . We presented a novel approach of optimising a deep neural network through regularisation of net- work architecture . We proposed regularisers which support a simple mechanism of dropping neurons during a network training process . The method supports the construction of a simpler deep neural networks with compatible performance with its simplified version . As a proof of concept , we evaluate the proposed method with examples including sparse linear regression , deep autoencoder and convolutional neural network . The valuations demonstrate excellent performance . The code for this work can be found in http : //www . github . com/panweihit/DropNeuron
Hyperspectral remote sensing images ( HSIs ) usually have high spectral resolution and low spatial resolution . Conversely , multispectral images ( MSIs ) usually have low spectral and high spatial resolutions . The problem of inferring images which combine the high spectral and high spatial resolutions of HSIs and MSIs , respectively , is a data fusion problem that has been the focus of recent active research due to the increasing availability of HSIs and MSIs retrieved from the same geographical area . We formulate this problem as the minimization of a convex objective function containing two quadratic data-fitting terms and an edge-preserving regularizer . The data-fitting terms account for blur , different resolutions , and additive noise . The regularizer , a form of vector Total Variation , promotes piecewise-smooth solutions with discontinuities aligned across the hyperspectral bands . The downsampling operator accounting for the different spatial resolutions , the non-quadratic and non-smooth nature of the regularizer , and the very large size of the HSI to be estimated lead to a hard optimization problem . We deal with these difficulties by exploiting the fact that HSIs generally " live " in a low-dimensional subspace and by tailoring the Split Augmented Lagrangian Shrinkage Algorithm ( SALSA ) , which is an instance of the Alternating Direction Method of Multipliers ( ADMM ) , to this optimization problem , by means of a convenient variable splitting . The spatial blur and the spectral linear operators linked , respectively , with the HSI and MSI acquisition processes are also estimated , and we obtain an effective algorithm that outperforms the state-of-the-art , as illustrated in a series of experiments with simulated and real-life data .
The purpose of this paper is to provide further understanding into the structure of the sequential allocation ( " stochastic multi-armed bandit " , or MAB ) problem by establishing probability one finite horizon bounds and convergence rates for the sample ( or " pseudo " ) regret associated with two simple classes of allocation policies $\pi$ . For any slowly increasing function $g$ , subject to mild regularity constraints , we construct two policies ( the $g$-Forcing , and the $g$-Inflated Sample Mean ) that achieve a measure of regret of order $ O ( g ( n ) ) $ almost surely as $n \to \infty$ , bound from above and below . Additionally , almost sure upper and lower bounds on the remainder term are established . In the constructions herein , the function $g$ effectively controls the " exploration " of the classical " exploration/exploitation " tradeoff .
This paper proposes a decorrelation-based approach to test hypotheses and construct confidence intervals for the low dimensional component of high dimensional proportional hazards models . Motivated by the geometric projection principle , we propose new decorrelated score , Wald and partial likelihood ratio statistics . Without assuming model selection consistency , we prove the asymptotic normality of these test statistics , establish their semiparametric optimality . We also develop new procedures for constructing pointwise confidence intervals for the baseline hazard function and baseline survival function . Thorough numerical results are provided to back up our theory .
In this paper , we study stochastic non-convex optimization with non-convex random functions . Recent studies on non-convex optimization revolve around establishing second-order convergence , i . e . , converging to a nearly second-order optimal stationary points . However , existing results on stochastic non-convex optimization are limited , especially with a high probability second-order convergence . We propose a novel updating step ( named NCG-S ) by leveraging a stochastic gradient and a noisy negative curvature of a stochastic Hessian , where the stochastic gradient and Hessian are based on a proper mini-batch of random functions . Building on this step , we develop two algorithms and establish their high probability second-order convergence . To the best of our knowledge , the proposed stochastic algorithms are the first with a second-order convergence in {\it high probability} and a time complexity that is {\it almost linear} in the problem ' s dimensionality .
We describe a generalization of the Hierarchical Dirichlet Process Hidden Markov Model ( HDP-HMM ) which is able to encode prior information that state transitions are more likely between " nearby " states . This is accomplished by defining a similarity function on the state space and scaling transition probabilities by pair-wise similarities , thereby inducing correlations among the transition distributions . We present an augmented data representation of the model as a Markov Jump Process in which : ( 0 ) some jump attempts fail , and ( 0 ) the probability of success is proportional to the similarity between the source and destination states . This augmentation restores conditional conjugacy and admits a simple Gibbs sampler . We evaluate the model and inference method on a speaker diarization task and a " harmonic parsing " task using four-part chorale data , as well as on several synthetic datasets , achieving favorable comparisons to existing models .
The preceding three decades have seen the emergence , rise , and proliferation of machine learning ( ML ) . From half-recognised beginnings in perceptrons , neural nets , and decision trees , algorithms that extract correlations ( that is , patterns ) from a set of data points have broken free from their origin in computational cognition to embrace all forms of problem solving , from voice recognition to medical diagnosis to automated scientific research and driverless cars , and it is now widely opined that the real industrial revolution lies less in mobile phone and similar than in the maturation and universal application of ML . Among the consequences just might be the triumph of anti-realism over realism .
This paper examines the role and efficiency of the non-convex loss functions for binary classification problems . In particular , we investigate how to design a simple and effective boosting algorithm that is robust to the outliers in the data . The analysis of the role of a particular non-convex loss for prediction accuracy varies depending on the diminishing tail properties of the gradient of the loss -- the ability of the loss to efficiently adapt to the outlying data , the local convex properties of the loss and the proportion of the contaminated data . In order to use these properties efficiently , we propose a new family of non-convex losses named $\gamma$-robust losses . Moreover , we present a new boosting framework , {\it Arch Boost} , designed for augmenting the existing work such that its corresponding classification algorithm is significantly more adaptable to the unknown data contamination . Along with the Arch Boosting framework , the non-convex losses lead to the new class of boosting algorithms , named adaptive , robust , boosting ( ARB ) . Furthermore , we present theoretical examples that demonstrate the robustness properties of the proposed algorithms . In particular , we develop a new breakdown point analysis and a new influence function analysis that demonstrate gains in robustness . Moreover , we present new theoretical results , based only on local curvatures , which may be used to establish statistical and optimization properties of the proposed Arch boosting algorithms with highly non-convex loss functions . Extensive numerical calculations are used to illustrate these theoretical properties and reveal advantages over the existing boosting methods when data exhibits a number of outliers .
We describe the 0st place winning approach for the CIKM Cup 0000 Challenge . In this paper , we provide an approach to reasonably identify same users across multiple devices based on browsing logs . Our approach regards a candidate ranking problem as pairwise classification and utilizes an unsupervised neural feature ensemble approach to learn latent features of users . Combined with traditional hand crafted features , each user pair feature is fed into a supervised classifier in order to perform pairwise classification . Lastly , we propose supervised and unsupervised inference techniques .
Biological datasets amenable to applied machine learning are more available today than ever before , yet they lack adequate representation in the Data-for-Good community . Here we present a work in progress case study performing analysis on antimicrobial resistance ( AMR ) using standard ensemble machine learning techniques and note the successes and pitfalls such work entails . Broadly , applied machine learning ( AML ) techniques are well suited to AMR , with classification accuracies ranging from mid-00% to low- 00% depending on sample size . Additionally , these techniques prove successful at identifying gene regions known to be associated with the AMR phenotype . We believe that the extensive amount of biological data available , the plethora of problems presented , and the global impact of such work merits the consideration of the Data- for-Good community .
The goal of Machine Learning to automatically learn from data , extract knowledge and to make decisions without any human intervention . Such automatic ( aML ) approaches show impressive success . Recent results even demonstrate intriguingly that deep learning applied for automatic classification of skin lesions is on par with the performance of dermatologists , yet outperforms the average . As human perception is inherently limited , such approaches can discover patterns , e . g . that two objects are similar , in arbitrarily high-dimensional spaces what no human is able to do . Humans can deal only with limited amounts of data , whilst big data is beneficial for aML ; however , in health informatics , we are often confronted with a small number of data sets , where aML suffer of insufficient training samples and many problems are computationally hard . Here , interactive machine learning ( iML ) may be of help , where a human-in-the-loop contributes to reduce the complexity of NP-hard problems . A further motivation for iML is that standard black-box approaches lack transparency , hence do not foster trust and acceptance of ML among end-users . Rising legal and privacy aspects , e . g . with the new European General Data Protection Regulations , make black-box approaches difficult to use , because they often are not able to explain why a decision has been made . In this paper , we present some experiments to demonstrate the effectiveness of the human-in-the-loop approach , particularly in opening the black-box to a glass-box and thus enabling a human directly to interact with an learning algorithm . We selected the Ant Colony Optimization framework , and applied it on the Traveling Salesman Problem , which is a good example , due to its relevance for health informatics , e . g . for the study of protein folding . From studies of how humans extract so much from so little data , fundamental ML-research also may benefit .
Conventional learning with expert advice methods assumes a learner is always receiving the outcome ( e . g . , class labels ) of every incoming training instance at the end of each trial . In real applications , acquiring the outcome from oracle can be costly or time consuming . In this paper , we address a new problem of active learning with expert advice , where the outcome of an instance is disclosed only when it is requested by the online learner . Our goal is to learn an accurate prediction model by asking the oracle the number of questions as small as possible . To address this challenge , we propose a framework of active forecasters for online active learning with expert advice , which attempts to extend two regular forecasters , i . e . , Exponentially Weighted Average Forecaster and Greedy Forecaster , to tackle the task of active learning with expert advice . We prove that the proposed algorithms satisfy the Hannan consistency under some proper assumptions , and validate the efficacy of our technique by an extensive set of experiments .
In this paper , we deal with the task of building a dynamic ensemble of chain classifiers for multi-label classification . To do so , we proposed two concepts of classifier chains algorithms that are able to change label order of the chain without rebuilding the entire model . Such modes allows anticipating the instance-specific chain order without a significant increase in computational burden . The proposed chain models are built using the Naive Bayes classifier and nearest neighbour approach as a base single-label classifiers . To take the benefits of the proposed algorithms , we developed a simple heuristic that allows the system to find relatively good label order . The heuristic sort labels according to the label-specific classification quality gained during the validation phase . The heuristic tries to minimise the phenomenon of error propagation in the chain . The experimental results showed that the proposed model based on Naive Bayes classifier the above-mentioned heuristic is an efficient tool for building dynamic chain classifiers .
We present asymptotic and finite-sample results on the use of stochastic blockmodels for the analysis of network data . We show that the fraction of misclassified network nodes converges in probability to zero under maximum likelihood fitting when the number of classes is allowed to grow as the root of the network size and the average network degree grows at least poly-logarithmically in this size . We also establish finite-sample confidence bounds on maximum-likelihood blockmodel parameter estimates from data comprising independent Bernoulli random variates ; these results hold uniformly over class assignment . We provide simulations verifying the conditions sufficient for our results , and conclude by fitting a logit parameterization of a stochastic blockmodel with covariates to a network data example comprising a collection of Facebook profiles , resulting in block estimates that reveal residual structure .
Undetected overfitting can occur when there are significant redundancies between training and validation data . We describe AVE , a new measure of training-validation redundancy for ligand-based classification problems that accounts for the similarity amongst inactive molecules as well as active . We investigated nine widely-used benchmarks for virtual screening and QSAR , and show that the amount of AVE bias strongly correlates with the performance of ligand-based predictive methods irrespective of the predicted property , chemical fingerprint , similarity measure , or previously-applied unbiasing techniques . Therefore , it is likely that the previously-reported performance of most ligand-based methods can be explained by overfitting to benchmarks rather than good prospective accuracy .
In this paper , we further study the forward-backward envelope first introduced in [00] and [00] for problems whose objective is the sum of a proper closed convex function and a twice continuously differentiable possibly nonconvex function with Lipschitz continuous gradient . We derive sufficient conditions on the original problem for the corresponding forward-backward envelope to be a level-bounded and Kurdyka-{\L}ojasiewicz function with an exponent of $\frac00$ ; these results are important for the efficient minimization of the forward-backward envelope by classical optimization algorithms . In addition , we demonstrate how to minimize some difference-of-convex regularized least squares problems by minimizing a suitably constructed forward-backward envelope . Our preliminary numerical results on randomly generated instances of large-scale $\ell_{0-0}$ regularized least squares problems [00] illustrate that an implementation of this approach with a limited-memory BFGS scheme usually outperforms standard first-order methods such as the nonmonotone proximal gradient method in [00] .
We develop a novel and generic algorithm for the adversarial multi-armed bandit problem ( or more generally the combinatorial semi-bandit problem ) . When instantiated differently , our algorithm achieves various new data-dependent regret bounds improving previous works . Examples include : 0 ) a regret bound depending on the variance of only the best arm ; 0 ) a regret bound depending on the first-order path-length of only the best arm ; 0 ) a regret bound depending on the sum of first-order path-lengths of all arms as well as an important negative term , which together lead to faster convergence rates for some normal form games with partial feedback ; 0 ) a regret bound that simultaneously implies small regret when the best arm has small loss and logarithmic regret when there exists an arm whose expected loss is always smaller than those of others by a fixed gap ( e . g . the classic i . i . d . setting ) . In some cases , such as the last two results , our algorithm is completely parameter-free . The main idea of our algorithm is to apply the optimism and adaptivity techniques to the well-known Online Mirror Descent framework with a special log-barrier regularizer . The challenges are to come up with appropriate optimistic predictions and correction terms in this framework . Some of our results also crucially rely on using a sophisticated increasing learning rate schedule .
Despite the widespread practical success of deep learning methods , our theoretical understanding of the dynamics of learning in deep neural networks remains quite sparse . We attempt to bridge the gap between the theory and practice of deep learning by systematically analyzing learning dynamics for the restricted case of deep linear neural networks . Despite the linearity of their input-output map , such networks have nonlinear gradient descent dynamics on weights that change with the addition of each new hidden layer . We show that deep linear networks exhibit nonlinear learning phenomena similar to those seen in simulations of nonlinear networks , including long plateaus followed by rapid transitions to lower error solutions , and faster convergence from greedy unsupervised pretraining initial conditions than from random initial conditions . We provide an analytical description of these phenomena by finding new exact solutions to the nonlinear dynamics of deep learning . Our theoretical analysis also reveals the surprising finding that as the depth of a network approaches infinity , learning speed can nevertheless remain finite : for a special class of initial conditions on the weights , very deep networks incur only a finite , depth independent , delay in learning speed relative to shallow networks . We show that , under certain conditions on the training data , unsupervised pretraining can find this special class of initial conditions , while scaled random Gaussian initializations cannot . We further exhibit a new class of random orthogonal initial conditions on weights that , like unsupervised pre-training , enjoys depth independent learning times . We further show that these initial conditions also lead to faithful propagation of gradients even in deep nonlinear networks , as long as they operate in a special regime known as the edge of chaos .
Observed associations in a database may be due in whole or part to variations in unrecorded ( latent ) variables . Identifying such variables and their causal relationships with one another is a principal goal in many scientific and practical domains . Previous work shows that , given a partition of observed variables such that members of a class share only a single latent common cause , standard search algorithms for causal Bayes nets can infer structural relations between latent variables . We introduce an algorithm for discovering such partitions when they exist . Uniquely among available procedures , the algorithm is ( asymptotically ) correct under standard assumptions in causal Bayes net search algorithms , requires no prior knowledge of the number of latent variables , and does not depend on the mathematical form of the relationships among the latent variables . We evaluate the algorithm on a variety of simulated data sets .
We study the problem of low-rank plus sparse matrix recovery . We propose a generic and efficient nonconvex optimization algorithm based on projected gradient descent and double thresholding operator , with much lower computational complexity . Compared with existing convex-relaxation based methods , the proposed algorithm recovers the low-rank plus sparse matrices for free , without incurring any additional statistical cost . It not only enables exact recovery of the unknown low-rank and sparse matrices in the noiseless setting , and achieves minimax optimal statistical error rate in the noisy case , but also matches the best-known robustness guarantee ( i . e . , tolerance for sparse corruption ) . At the core of our theory is a novel structural Lipschitz gradient condition for low-rank plus sparse matrices , which is essential for proving the linear convergence rate of our algorithm , and we believe is of independent interest to prove fast rates for general superposition-structured models . We demonstrate the superiority of our generic algorithm , both theoretically and experimentally , through three concrete applications : robust matrix sensing , robust PCA and one-bit matrix decomposition .
In this paper , we propose three approaches for the estimation of the Tucker decomposition of multi-way arrays ( tensors ) from partial observations . All approaches are formulated as convex minimization problems . Therefore , the minimum is guaranteed to be unique . The proposed approaches can automatically estimate the number of factors ( rank ) through the optimization . Thus , there is no need to specify the rank beforehand . The key technique we employ is the trace norm regularization , which is a popular approach for the estimation of low-rank matrices . In addition , we propose a simple heuristic to improve the interpretability of the obtained factorization . The advantages and disadvantages of three proposed approaches are demonstrated through numerical experiments on both synthetic and real world datasets . We show that the proposed convex optimization based approaches are more accurate in predictive performance , faster , and more reliable in recovering a known multilinear structure than conventional approaches .
The article derives a novel Gram-Charlier A ( GCA ) Series based Extended Rule-of-Thumb ( ExROT ) for bandwidth selection in Kernel Density Estimation ( KDE ) . There are existing various bandwidth selection rules achieving minimization of the Asymptotic Mean Integrated Square Error ( AMISE ) between the estimated probability density function ( PDF ) and the actual PDF . The rules differ in a way to estimate the integration of the squared second order derivative of an unknown PDF $ ( f ( \cdot ) ) $ , identified as the roughness $R ( f ' ' ( \cdot ) ) $ . The simplest Rule-of-Thumb ( ROT ) estimates $R ( f ' ' ( \cdot ) ) $ with an assumption that the density being estimated is Gaussian . Intuitively , better estimation of $R ( f ' ' ( \cdot ) ) $ and consequently better bandwidth selection rules can be derived , if the unknown PDF is approximated through an infinite series expansion based on a more generalized density assumption . As a demonstration and verification to this concept , the ExROT derived in the article uses an extended assumption that the density being estimated is near Gaussian . This helps use of the GCA expansion as an approximation to the unknown near Gaussian PDF . The ExROT for univariate KDE is extended to that for multivariate KDE . The required multivariate AMISE criteria is re-derived using elementary calculus of several variables , instead of Tensor calculus . The derivation uses the Kronecker product and the vector differential operator to achieve the AMISE expression in vector notations . There is also derived ExROT for kernel based density derivative estimator .
In this study , we propose a novel deep neural network and its supervised learning method that uses a feedforward supervisory signal . The method is inspired by the human visual system and performs human-like association-based learning without any backward error propagation . The feedforward supervisory signal that produces the correct result is preceded by the target signal and associates its confirmed label with the classification result of the target signal . It effectively uses a large amount of information from the feedforward signal , and forms a continuous and rich learning representation . The method is validated using visual recognition tasks on the MNIST handwritten dataset .
Unsupervised image generation has recently received an increasing amount of attention thanks to the great success of generative adversarial networks ( GANs ) , particularly Wasserstein GANs . Inspired by the paradigm of real-valued image generation , this paper makes the first attempt to formulate the problem of generating manifold-valued images , which are frequently encountered in real-world applications . For the study , we specially exploit three typical manifold-valued image generation tasks : hue-saturation-value ( HSV ) color image generation , chromaticity-brightness ( CB ) color image generation , and diffusion-tensor ( DT ) image generation . In order to produce such kinds of images as realistic as possible , we generalize the state-of-the-art technique of Wasserstein GANs to the manifold context with exploiting Riemannian geometry . For the proposed manifold-valued image generation problem , we recommend three benchmark datasets that are CIFAR-00 HSV/CB color images , ImageNet HSV/CB color images , UCL DT image datasets . On the three datasets , we experimentally demonstrate the proposed manifold-aware Wasserestein GAN can generate high quality manifold-valued images .
Inference methods are often formulated as variational approximations : these approximations allow easy evaluation of statistics by marginalization or linear response , but these estimates can be inconsistent . We show that by introducing constraints on covariance , one can ensure consistency of linear response with the variational parameters , and in so doing inference of marginal probability distributions is improved . For the Bethe approximation and its generalizations , improvements are achieved with simple choices of the constraints . The approximations are presented as variational frameworks ; iterative procedures related to message passing are provided for finding the minima .
In this report , we derive a non-negative series expansion for the Jensen-Shannon divergence ( JSD ) between two probability distributions . This series expansion is shown to be useful for numerical calculations of the JSD , when the probability distributions are nearly equal , and for which , consequently , small numerical errors dominate evaluation .
Is it possible to perform linear regression on datasets whose labels are shuffled with respect to the inputs ? We explore this question by proposing several estimators that recover the weights of a noisy linear model from labels that are shuffled by an unknown permutation . We show that the analog of the classical least-squares estimator produces inconsistent estimates in this setting , and introduce an estimator based on the self-moments of the input features and labels . We study the regimes in which each estimator excels , and generalize the estimators to the setting where partial ordering information is available in the form of experiments replicated independently . The result is a framework that enables robust inference , as we demonstrate by experiments on both synthetic and standard datasets , where we are able to recover approximate weights using only shuffled labels . Our work demonstrates that linear regression in the absence of complete ordering information is possible and can be of practical interest , particularly in experiments that characterize populations of particles , such as flow cytometry .
Gaussian process for vector-valued function model has been shown to be a useful method for multi-output prediction . The existing method for this model is to re-formulate the matrix-variate Gaussian distribution as a multivariate normal distribution . Although it is effective and convenient in many cases , re-formulation is not always workable and difficult to extend because not all matrix-variate distributions can be transformed to related multivariate distributions , such as the case for matrix-variate Student$-t$ distribution . In this paper , we propose an alternative derivation of multivariate Gaussian process regression ( MV-GPR ) , where the model settings , derivations and computations are all directly performed in matrix form , rather than vectorizing the matrices as done in the existing methods . Furthermore , we introduce the multivariate Student$-t$ process and then derive a new method , multivariate Student$-t$ process regression ( MV-TPR ) for multi-output prediction . Both MV-GPR and MV-TPR have closed form expressions for the marginal likelihoods and predictive distributions . The usefulness of the proposed methods are illustrated through several simulated examples . In particular , we verify empirically that MV-TPR has superiority for the datasets considered , including air quality prediction and bike rent prediction . At last , the proposed methods are shown to produce profitable investment strategies in the stock markets .
Consumers with low demand , like households , are generally supplied single-phase power by connecting their service mains to one of the phases of a distribution transformer . The distribution companies face the problem of keeping a record of consumer connectivity to a phase due to uninformed changes that happen . The exact phase connectivity information is important for the efficient operation and control of distribution system . We propose a new data driven approach to the problem based on Principal Component Analysis ( PCA ) and its Graph Theoretic interpretations , using energy measurements in equally timed short intervals , generated from smart meters . We propose an algorithm for inferring phase connectivity from noisy measurements . The algorithm is demonstrated using simulated data for phase connectivities in distribution networks .
We present the Infinite Latent Events Model , a nonparametric hierarchical Bayesian distribution over infinite dimensional Dynamic Bayesian Networks with binary state representations and noisy-OR-like transitions . The distribution can be used to learn structure in discrete timeseries data by simultaneously inferring a set of latent events , which events fired at each timestep , and how those events are causally linked . We illustrate the model on a sound factorization task , a network topology identification task , and a video game task .
Mixability of a loss is known to characterise when constant regret bounds are achievable in games of prediction with expert advice through the use of Vovk ' s aggregating algorithm . We provide a new interpretation of mixability via convex analysis that highlights the role of the Kullback-Leibler divergence in its definition . This naturally generalises to what we call $\Phi$-mixability where the Bregman divergence $D_\Phi$ replaces the KL divergence . We prove that losses that are $\Phi$-mixable also enjoy constant regret bounds via a generalised aggregating algorithm that is similar to mirror descent .
To better extract users ' interest by exploiting the rich historical behavior data is crucial for building the click-through rate ( CTR ) prediction model in the online advertising system in e-commerce industry . There are two key observations on user behavior data : i ) \textbf{diversity} . Users are interested in different kinds of goods when visiting e-commerce site . ii ) \textbf{local activation} . Whether users click or not click a good depends only on part of their related historical behavior . However , most traditional CTR models lack of capturing these structures of behavior data . In this paper , we introduce a new proposed model , Deep Interest Network ( DIN ) , which is developed and deployed in the display advertising system in Alibaba . DIN represents users ' diverse interests with an interest distribution and designs an attention-like network structure to locally activate the related interests according to the candidate ad , which is proven to be effective and significantly outperforms traditional model . Overfitting problem is easy to encounter on training such industrial deep network with large scale sparse inputs . We study this problem carefully and propose a useful adaptive regularization technique .
The Alternating Direction Method of Multipliers ( ADMM ) has been studied for years . The traditional ADMM algorithm needs to compute , at each iteration , an ( empirical ) expected loss function on all training examples , resulting in a computational complexity proportional to the number of training examples . To reduce the time complexity , stochastic ADMM algorithms were proposed to replace the expected function with a random loss function associated with one uniformly drawn example plus a Bregman divergence . The Bregman divergence , however , is derived from a simple second order proximal function , the half squared norm , which could be a suboptimal choice . In this paper , we present a new family of stochastic ADMM algorithms with optimal second order proximal functions , which produce a new family of adaptive subgradient methods . We theoretically prove that their regret bounds are as good as the bounds which could be achieved by the best proximal function that can be chosen in hindsight . Encouraging empirical results on a variety of real-world datasets confirm the effectiveness and efficiency of the proposed algorithms .
We consider the problem of adaptive stratified sampling for Monte Carlo integration of a differentiable function given a finite number of evaluations to the function . We construct a sampling scheme that samples more often in regions where the function oscillates more , while allocating the samples such that they are well spread on the domain ( this notion shares similitude with low discrepancy ) . We prove that the estimate returned by the algorithm is almost similarly accurate as the estimate that an optimal oracle strategy ( that would know the variations of the function everywhere ) would return , and provide a finite-sample analysis .
Deep generative models learn a mapping from a low dimensional latent space to a high-dimensional data space . Under certain regularity conditions , these models parameterize nonlinear manifolds in the data space . In this paper , we investigate the Riemannian geometry of these generated manifolds . First , we develop efficient algorithms for computing geodesic curves , which provide an intrinsic notion of distance between points on the manifold . Second , we develop an algorithm for parallel translation of a tangent vector along a path on the manifold . We show how parallel translation can be used to generate analogies , i . e . , to transport a change in one data point into a semantically similar change of another data point . Our experiments on real image data show that the manifolds learned by deep generative models , while nonlinear , are surprisingly close to zero curvature . The practical implication is that linear paths in the latent space closely approximate geodesics on the generated manifold . However , further investigation into this phenomenon is warranted , to identify if there are other architectures or datasets where curvature plays a more prominent role . We believe that exploring the Riemannian geometry of deep generative models , using the tools developed in this paper , will be an important step in understanding the high-dimensional , nonlinear spaces these models learn .
Hierarchy Of Multi-label classifiers ( HOMER ) is a multi-label learning algorithm that breaks the initial learning task to several , easier sub-tasks by first constructing a hierarchy of labels from a given label set and secondly employing a given base multi-label classifier ( MLC ) to the resulting sub-problems . The primary goal is to effectively address class imbalance and scalability issues that often arise in real-world multi-label classification problems . In this work , we present the general setup for a HOMER model and a simple extension of the algorithm that is suited for MLCs that output rankings . Furthermore , we provide a detailed analysis of the properties of the algorithm , both from an aspect of effectiveness and computational complexity . A secondary contribution involves the presentation of a balanced variant of the k means algorithm , which serves in the first step of the label hierarchy construction . We conduct extensive experiments on six real-world datasets , studying empirically HOMER ' s parameters and providing examples of instantiations of the algorithm with different clustering approaches and MLCs , The empirical results demonstrate a significant improvement over the given base MLC .
Non-Gaussian component analysis ( NGCA ) is an unsupervised linear dimension reduction method that extracts low-dimensional non-Gaussian " signals " from high-dimensional data contaminated with Gaussian noise . NGCA can be regarded as a generalization of projection pursuit ( PP ) and independent component analysis ( ICA ) to multi-dimensional and dependent non-Gaussian components . Indeed , seminal approaches to NGCA are based on PP and ICA . Recently , a novel NGCA approach called least-squares NGCA ( LSNGCA ) has been developed , which gives a solution analytically through least-squares estimation of log-density gradients and eigendecomposition . However , since pre-whitening of data is involved in LSNGCA , it performs unreliably when the data covariance matrix is ill-conditioned , which is often the case in high-dimensional data analysis . In this paper , we propose a whitening-free LSNGCA method and experimentally demonstrate its superiority .
The natural gradient allows for more efficient gradient descent by removing dependencies and biases inherent in a function ' s parameterization . Several papers present the topic thoroughly and precisely . It remains a very difficult idea to get your head around however . The intent of this note is to provide simple intuition for the natural gradient and its use . We review how an ill conditioned parameter space can undermine learning , introduce the natural gradient by analogy to the more widely understood concept of signal whitening , and present tricks and specific prescriptions for applying the natural gradient to learning problems .
Distance-based hierarchical clustering ( HC ) methods are widely used in unsupervised data analysis but few authors take account of uncertainty in the distance data . We incorporate a statistical model of the uncertainty through corruption or noise in the pairwise distances and investigate the problem of estimating the HC as unknown parameters from measurements . Specifically , we focus on single linkage hierarchical clustering ( SLHC ) and study its geometry . We prove that under fairly reasonable conditions on the probability distribution governing measurements , SLHC is equivalent to maximum partial profile likelihood estimation ( MPPLE ) with some of the information contained in the data ignored . At the same time , we show that direct evaluation of SLHC on maximum likelihood estimation ( MLE ) of pairwise distances yields a consistent estimator . Consequently , a full MLE is expected to perform better than SLHC in getting the correct HC results for the ground truth metric .
Here , we propose a clustering technique for general clustering problems including those that have non-convex clusters . For a given desired number of clusters $K$ , we use three stages to find a clustering . The first stage uses a hybrid clustering technique to produce a series of clusterings of various sizes ( randomly selected ) . They key steps are to find a $K$-means clustering using $K_\ell$ clusters where $K_\ell \gg K$ and then joins these small clusters by using single linkage clustering . The second stage stabilizes the result of stage one by reclustering via the `membership matrix ' under Hamming distance to generate a dendrogram . The third stage is to cut the dendrogram to get $K^*$ clusters where $K^* \geq K$ and then prune back to $K$ to give a final clustering . A variant on our technique also gives a reasonable estimate for $K_T$ , the true number of clusters . We provide a series of arguments to justify the steps in the stages of our methods and we provide numerous examples involving real and simulated data to compare our technique with other related techniques .
This paper considers the problem of subspace clustering under noise . Specifically , we study the behavior of Sparse Subspace Clustering ( SSC ) when either adversarial or random noise is added to the unlabelled input data points , which are assumed to be in a union of low-dimensional subspaces . We show that a modified version of SSC is \emph{provably effective} in correctly identifying the underlying subspaces , even with noisy data . This extends theoretical guarantee of this algorithm to more practical settings and provides justification to the success of SSC in a class of real applications .
We prove a computable version of de Finetti ' s theorem on exchangeable sequences of real random variables . As a consequence , exchangeable stochastic processes expressed in probabilistic functional programming languages can be automatically rewritten as procedures that do not modify non-local state . Along the way , we prove that a distribution on the unit interval is computable if and only if its moments are uniformly computable .
We propose a penalized likelihood method to jointly estimate multiple precision matrices for use in quadratic discriminant analysis and model based clustering . A ridge penalty and a ridge fusion penalty are used to introduce shrinkage and promote similarity between precision matrix estimates . Block-wise coordinate descent is used for optimization , and validation likelihood is used for tuning parameter selection . Our method is applied in quadratic discriminant analysis and semi-supervised model based clustering .
Deep Gaussian processes ( DGPs ) are multi-layer hierarchical generalisations of Gaussian processes ( GPs ) and are formally equivalent to neural networks with multiple , infinitely wide hidden layers . DGPs are probabilistic and non-parametric and as such are arguably more flexible , have a greater capacity to generalise , and provide better calibrated uncertainty estimates than alternative deep models . The focus of this paper is scalable approximate Bayesian learning of these networks . The paper develops a novel and efficient extension of probabilistic backpropagation , a state-of-the-art method for training Bayesian neural networks , that can be used to train DGPs . The new method leverages a recently proposed method for scaling Expectation Propagation , called stochastic Expectation Propagation . The method is able to automatically discover useful input warping , expansion or compression , and it is therefore is a flexible form of Bayesian kernel design . We demonstrate the success of the new method for supervised learning on several real-world datasets , showing that it typically outperforms GP regression and is never much worse .
Estimating the mean of a population of graphs based on a sample is a core problem in network science . Often , this problem is especially difficult because the sample or cohort size is relatively small as compared to the number of parameters to estimate . While using the element-wise sample mean of the adjacency matrices is a common approach , this method does not exploit any underlying graph structure . We propose using a low-rank method together with tools for dimension selection and diagonal augmentation to improve performance over the naive methodology for small sample sizes . Theoretical results for the stochastic blockmodel show that this method will offer major improvements when there are many vertices . Similarly , in analyzing human connectome data , we demonstrate that the low-rank methods outperform the standard sample mean for many settings . These results indicate that low-rank methods should be a key part of the tool box for researchers studying populations of graphs .
Feature selection has attracted significant attention in data mining and machine learning in the past decades . Many existing feature selection methods eliminate redundancy by measuring pairwise inter-correlation of features , whereas the complementariness of features and higher inter-correlation among more than two features are ignored . In this study , a modification item concerning the complementariness of features is introduced in the evaluation criterion of features . Additionally , in order to identify the interference effect of already-selected False Positives ( FPs ) , the redundancy-complementariness dispersion is also taken into account to adjust the measurement of pairwise inter-correlation of features . To illustrate the effectiveness of proposed method , classification experiments are applied with four frequently used classifiers on ten datasets . Classification results verify the superiority of proposed method compared with five representative feature selection methods .
We show that training of generative adversarial network ( GAN ) may not have good generalization properties ; e . g . , training may appear successful but the trained distribution may be far from target distribution in standard metrics . However , generalization does occur for a weaker metric called neural net distance . It is also shown that an approximate pure equilibrium exists in the discriminator/generator game for a special class of generators with natural training objectives when generator capacity and training set sizes are moderate . This existence of equilibrium inspires MIX+GAN protocol , which can be combined with any existing GAN training , and empirically shown to improve some of them .
Representations based on random walks can exploit discrete data distributions for clustering and classification . We extend such representations from discrete to continuous distributions . Transition probabilities are now calculated using a diffusion equation with a diffusion coefficient that inversely depends on the data density . We relate this diffusion equation to a path integral and derive the corresponding path probability measure . The framework is useful for incorporating continuous data densities and prior knowledge .
In practical machine learning systems , graph based data representation has been widely used in various learning paradigms , ranging from unsupervised clustering to supervised classification . Besides those applications with natural graph or network structure data , such as social network analysis and relational learning , many other applications often involve a critical step in converting data vectors to an adjacency graph . In particular , a sparse subgraph extracted from the original graph is often required due to both theoretic and practical needs . Previous study clearly shows that the performance of different learning algorithms , e . g . , clustering and classification , benefits from such sparse subgraphs with balanced node connectivity . However , the existing graph construction methods are either computationally expensive or with unsatisfactory performance . In this paper , we utilize a scalable method called auction algorithm and its parallel extension to recover a sparse yet nearly balanced subgraph with significantly reduced computational cost . Empirical study and comparison with the state-ofart approaches clearly demonstrate the superiority of the proposed method in both efficiency and accuracy .
We consider the problem of learning a vector-valued function f in an online learning setting . The function f is assumed to lie in a reproducing Hilbert space of operator-valued kernels . We describe two online algorithms for learning f while taking into account the output structure . A first contribution is an algorithm , ONORMA , that extends the standard kernel-based online learning algorithm NORMA from scalar-valued to operator-valued setting . We report a cumulative error bound that holds both for classification and regression . We then define a second algorithm , MONORMA , which addresses the limitation of pre-defining the output structure in ONORMA by learning sequentially a linear combination of operator-valued kernels . Our experiments show that the proposed algorithms achieve good performance results with low computational cost .
Parallel computing has played an important role in speeding up convex optimization methods for big data analytics and large-scale machine learning ( ML ) . However , the scalability of these optimization methods is inhibited by the cost of communicating and synchronizing processors in a parallel setting . Iterative ML methods are particularly sensitive to communication cost since they often require communication every iteration . In this work , we extend well-known techniques from Communication-Avoiding Krylov subspace methods to first-order , block coordinate descent methods for Support Vector Machines and Proximal Least-Squares problems . Our Synchronization-Avoiding ( SA ) variants reduce the latency cost by a tunable factor of $s$ at the expense of a factor of $s$ increase in flops and bandwidth costs . We show that the SA-variants are numerically stable and can attain large speedups of up to $0 . 0\times$ on a Cray XC00 supercomputer .
An active learner is given a hypothesis class , a large set of unlabeled examples and the ability to interactively query labels to an oracle of a subset of these examples ; the goal of the learner is to learn a hypothesis in the class that fits the data well by making as few label queries as possible . This work addresses active learning with labels obtained from strong and weak labelers , where in addition to the standard active learning setting , we have an extra weak labeler which may occasionally provide incorrect labels . An example is learning to classify medical images where either expensive labels may be obtained from a physician ( oracle or strong labeler ) , or cheaper but occasionally incorrect labels may be obtained from a medical resident ( weak labeler ) . Our goal is to learn a classifier with low error on data labeled by the oracle , while using the weak labeler to reduce the number of label queries made to this labeler . We provide an active learning algorithm for this setting , establish its statistical consistency , and analyze its label complexity to characterize when it can provide label savings over using the strong labeler alone .
We consider the best-arm identification problem in multi-armed bandits , which focuses purely on exploration . A player is given a fixed budget to explore a finite set of arms , and the rewards of each arm are drawn independently from a fixed , unknown distribution . The player aims to identify the arm with the largest expected reward . We propose a general framework to unify sequential elimination algorithms , where the arms are dismissed iteratively until a unique arm is left . Our analysis reveals a novel performance measure expressed in terms of the sampling mechanism and number of eliminated arms at each round . Based on this result , we develop an algorithm that divides the budget according to a nonlinear function of remaining arms at each round . We provide theoretical guarantees for the algorithm , characterizing the suitable nonlinearity for different problem environments described by the number of competitive arms . Matching the theoretical results , our experiments show that the nonlinear algorithm outperforms the state-of-the-art . We finally study the side-observation model , where pulling an arm reveals the rewards of its related arms , and we establish improved theoretical guarantees in the pure-exploration setting .
We introduce the Locally Linear Latent Variable Model ( LL-LVM ) , a probabilistic model for non-linear manifold discovery that describes a joint distribution over observations , their manifold coordinates and locally linear maps conditioned on a set of neighbourhood relationships . The model allows straightforward variational optimisation of the posterior distribution on coordinates and locally linear maps from the latent space to the observation space given the data . Thus , the LL-LVM encapsulates the local-geometry preserving intuitions that underlie non-probabilistic methods such as locally linear embedding ( LLE ) . Its probabilistic semantics make it easy to evaluate the quality of hypothesised neighbourhood relationships , select the intrinsic dimensionality of the manifold , construct out-of-sample extensions and to combine the manifold model with additional probabilistic models that capture the structure of coordinates within the manifold .
We propose a new approach to train the Generative Adversarial Nets ( GANs ) with a mixture of generators to overcome the mode collapsing problem . The main intuition is to employ multiple generators , instead of using a single one as in the original GAN . The idea is simple , yet proven to be extremely effective at covering diverse data modes , easily overcoming the mode collapse and delivering state-of-the-art results . A minimax formulation is able to establish among a classifier , a discriminator , and a set of generators in a similar spirit with GAN . Generators create samples that are intended to come from the same distribution as the training data , whilst the discriminator determines whether samples are true data or generated by generators , and the classifier specifies which generator a sample comes from . The distinguishing feature is that internal samples are created from multiple generators , and then one of them will be randomly selected as final output similar to the mechanism of a probabilistic mixture model . We term our method Mixture GAN ( MGAN ) . We develop theoretical analysis to prove that , at the equilibrium , the Jensen-Shannon divergence ( JSD ) between the mixture of generators ' distributions and the empirical data distribution is minimal , whilst the JSD among generators ' distributions is maximal , hence effectively avoiding the mode collapse . By utilizing parameter sharing , our proposed model adds minimal computational cost to the standard GAN , and thus can also efficiently scale to large-scale datasets . We conduct extensive experiments on synthetic 0D data and natural image databases ( CIFAR-00 , STL-00 and ImageNet ) to demonstrate the superior performance of our MGAN in achieving state-of-the-art Inception scores over latest baselines , generating diverse and appealing recognizable objects at different resolutions , and specializing in capturing different types of objects by generators .
Support Vector Machines ( SVMs ) are powerful learners that have led to state-of-the-art results in various computer vision problems . SVMs suffer from various drawbacks in terms of selecting the right kernel , which depends on the image descriptors , as well as computational and memory efficiency . This paper introduces a novel kernel , which serves such issues well . The kernel is learned by exploiting a large amount of low-complex , randomized binary mappings of the input feature . This leads to an efficient SVM , while also alleviating the task of kernel selection . We demonstrate the capabilities of our kernel on 0 standard vision benchmarks , in which we combine several common image descriptors , namely histograms ( Flowers00 and Daimler ) , attribute-like descriptors ( UCI , OSR , and a-VOC00 ) , and Sparse Quantization ( ImageNet ) . Results show that our kernel learning adapts well to the different descriptors types , achieving the performance of the kernels specifically tuned for each image descriptor , and with similar evaluation cost as efficient SVM methods .
In this paper , we propose a novel neural network model called RNN Encoder-Decoder that consists of two recurrent neural networks ( RNN ) . One RNN encodes a sequence of symbols into a fixed-length vector representation , and the other decodes the representation into another sequence of symbols . The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence . The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder-Decoder as an additional feature in the existing log-linear model . Qualitatively , we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases .
When devising a course of treatment for a patient , doctors often have little quantitative evidence on which to base their decisions , beyond their medical education and published clinical trials . Stanford Health Care alone has millions of electronic medical records ( EMRs ) that are only just recently being leveraged to inform better treatment recommendations . These data present a unique challenge because they are high-dimensional and observational . Our goal is to make personalized treatment recommendations based on the outcomes for past patients similar to a new patient . We propose and analyze three methods for estimating heterogeneous treatment effects using observational data . Our methods perform well in simulations using a wide variety of treatment effect functions , and we present results of applying the two most promising methods to data from The SPRINT Data Analysis Challenge , from a large randomized trial of a treatment for high blood pressure .
Training deep neural networks requires massive amounts of training data , but for many tasks only limited labeled data is available . This makes weak supervision attractive , using weak or noisy signals like the output of heuristic methods or user click-through data for training . In a semi-supervised setting , we can use a large set of data with weak labels to pretrain a neural network and then fine-tune the parameters with a small amount of data with true labels . This feels intuitively sub-optimal as these two independent stages leave the model unaware about the varying label quality . What if we could somehow inform the model about the label quality ? In this paper , we propose a semi-supervised learning method where we train two neural networks in a multi-task fashion : a " target network " and a " confidence network " . The target network is optimized to perform a given task and is trained using a large set of unlabeled data that are weakly annotated . We propose to weight the gradient updates to the target network using the scores provided by the second confidence network , which is trained on a small amount of supervised data . Thus we avoid that the weight updates computed from noisy labels harm the quality of the target network model . We evaluate our learning strategy on two different tasks : document ranking and sentiment classification . The results demonstrate that our approach not only enhances the performance compared to the baselines but also speeds up the learning process from weak labels .
We present a parallelized bijective graph matching algorithm that leverages seeds and is designed to match very large graphs . Our algorithm combines spectral graph embedding with existing state-of-the-art seeded graph matching procedures . We justify our approach by proving that modestly correlated , large stochastic block model random graphs are correctly matched utilizing very few seeds through our divide-and-conquer procedure . We also demonstrate the effectiveness of our approach in matching very large graphs in simulated and real data examples , showing up to a factor of 0 improvement in runtime with minimal sacrifice in accuracy .
In this work we address the problem of approximating high-dimensional data with a low-dimensional representation . We make the following contributions . We propose an inverse regression method which exchanges the roles of input and response , such that the low-dimensional variable becomes the regressor , and which is tractable . We introduce a mixture of locally-linear probabilistic mapping model that starts with estimating the parameters of inverse regression , and follows with inferring closed-form solutions for the forward parameters of the high-dimensional regression problem of interest . Moreover , we introduce a partially-latent paradigm , such that the vector-valued response variable is composed of both observed and latent entries , thus being able to deal with data contaminated by experimental artifacts that cannot be explained with noise models . The proposed probabilistic formulation could be viewed as a latent-variable augmentation of regression . We devise expectation-maximization ( EM ) procedures based on a data augmentation strategy which facilitates the maximum-likelihood search over the model parameters . We propose two augmentation schemes and we describe in detail the associated EM inference procedures that may well be viewed as generalizations of a number of EM regression , dimension reduction , and factor analysis algorithms . The proposed framework is validated with both synthetic and real data . We provide experimental evidence that our method outperforms several existing regression techniques .
A new non parametric approach to the problem of testing the independence of two random process is developed . The test statistic is the Hilbert Schmidt Independence Criterion ( HSIC ) , which was used previously in testing independence for i . i . d pairs of variables . The asymptotic behaviour of HSIC is established when computed from samples drawn from random processes . It is shown that earlier bootstrap procedures which worked in the i . i . d . case will fail for random processes , and an alternative consistent estimate of the p-values is proposed . Tests on artificial data and real-world Forex data indicate that the new test procedure discovers dependence which is missed by linear approaches , while the earlier bootstrap procedure returns an elevated number of false positives . The code is available online : https : //github . com/kacperChwialkowski/HSIC .
The classification procedure of streaming data usually requires various ad hoc methods or particular heuristic models . We explore a novel non-parametric and systematic approach to analysis of heterogeneous sequential data . We demonstrate an application of this method to classification of the delays in responding to the prompts , from subjects with bipolar disorder collected during a clinical trial , using both synthetic and real examples . We show how this method can provide a natural and systematic way to extract characteristic features from sequential data .
Many inference problems involving questions of optimality ask for the maximum or the minimum of a finite set of unknown quantities . This technical report derives the first two posterior moments of the maximum of two correlated Gaussian variables and the first two posterior moments of the two generating variables ( corresponding to Gaussian approximations minimizing relative entropy ) . It is shown how this can be used to build a heuristic approximation to the maximum relationship over a finite set of Gaussian variables , allowing approximate inference by Expectation Propagation on such quantities .
Diffusion-weighted magnetic resonance imaging ( DWI ) and fiber tractography are the only methods to measure the structure of the white matter in the living human brain . The diffusion signal has been modelled as the combined contribution from many individual fascicles of nerve fibers passing through each location in the white matter . Typically , this is done via basis pursuit , but estimation of the exact directions is limited due to discretization . The difficulties inherent in modeling DWI data are shared by many other problems involving fitting non-parametric mixture models . Ekanadaham et al . proposed an approach , continuous basis pursuit , to overcome discretization error in the 0-dimensional case ( e . g . , spike-sorting ) . Here , we propose a more general algorithm that fits mixture models of any dimensionality without discretization . Our algorithm uses the principles of L0-boost , together with refitting of the weights and pruning of the parameters . The addition of these steps to L0-boost both accelerates the algorithm and assures its accuracy . We refer to the resulting algorithm as elastic basis pursuit , or EBP , since it expands and contracts the active set of kernels as needed . We show that in contrast to existing approaches to fitting mixtures , our boosting framework ( 0 ) enables the selection of the optimal bias-variance tradeoff along the solution path , and ( 0 ) scales with high-dimensional problems . In simulations of DWI , we find that EBP yields better parameter estimates than a non-negative least squares ( NNLS ) approach , or the standard model used in DWI , the tensor model , which serves as the basis for diffusion tensor imaging ( DTI ) . We demonstrate the utility of the method in DWI data acquired in parts of the brain containing crossings of multiple fascicles of nerve fibers .
A number of machine learning algorithms are using a metric , or a distance , in order to compare individuals . The Euclidean distance is usually employed , but it may be more efficient to learn a parametric distance such as Mahalanobis metric . Learning such a metric is a hot topic since more than ten years now , and a number of methods have been proposed to efficiently learn it . However , the nature of the problem makes it quite difficult for large scale data , as well as data for which classes overlap . This paper presents a simple way of improving accuracy and scalability of any iterative metric learning algorithm , where constraints are obtained prior to the algorithm . The proposed approach relies on a loss-dependent weighted selection of constraints that are used for learning the metric . Using the corresponding dedicated loss function , the method clearly allows to obtain better results than state-of-the-art methods , both in terms of accuracy and time complexity . Some experimental results on real world , and potentially large , datasets are demonstrating the effectiveness of our proposition .
Bayesian model averaging , model selection and its approximations such as BIC are generally statistically consistent , but sometimes achieve slower rates og convergence than other methods such as AIC and leave-one-out cross-validation . On the other hand , these other methods can br inconsistent . We identify the " catch-up phenomenon " as a novel explanation for the slow convergence of Bayesian methods . Based on this analysis we define the switch distribution , a modification of the Bayesian marginal distribution . We show that , under broad conditions , model selection and prediction based on the switch distribution is both consistent and achieves optimal convergence rates , thereby resolving the AIC-BIC dilemma . The method is practical ; we give an efficient implementation . The switch distribution has a data compression interpretation , and can thus be viewed as a " prequential " or MDL method ; yet it is different from the MDL methods that are usually considered in the literature . We compare the switch distribution to Bayes factor model selection and leave-one-out cross-validation .
We model messaging activities as a hierarchical doubly stochastic point process with three main levels , and develop an iterative algorithm for inferring actors ' relative latent positions from a stream of messaging activity data . Each of the message-exchanging actors is modeled as a process in a latent space . The actors ' latent positions are assumed to be influenced by the distribution of a much larger population over the latent space . Each actor ' s movement in the latent space is modeled as being governed by two parameters that we call confidence and visibility , in addition to dependence on the population distribution . The messaging frequency between a pair of actors is assumed to be inversely proportional to the distance between their latent positions . Our inference algorithm is based on a projection approach to an online filtering problem . The algorithm associates each actor with a probability density-valued process , and each probability density is assumed to be a mixture of basis functions . For efficient numerical experiments , we further develop our algorithm for the case where the basis functions are obtained by translating and scaling a standard Gaussian density .
Structural reliability methods aim at computing the probability of failure of systems with respect to some prescribed performance functions . In modern engineering such functions usually resort to running an expensive-to-evaluate computational model ( e . g . a finite element model ) . In this respect simulation methods , which may require $00^{0-0}$ runs cannot be used directly . Surrogate models such as quadratic response surfaces , polynomial chaos expansions or kriging ( which are built from a limited number of runs of the original model ) are then introduced as a substitute of the original model to cope with the computational cost . In practice it is almost impossible to quantify the error made by this substitution though . In this paper we propose to use a kriging surrogate of the performance function as a means to build a quasi-optimal importance sampling density . The probability of failure is eventually obtained as the product of an augmented probability computed by substituting the meta-model for the original performance function and a correction term which ensures that there is no bias in the estimation even if the meta-model is not fully accurate . The approach is applied to analytical and finite element reliability problems and proves efficient up to 000 random variables .
Traditionally , there are three species of classification : unsupervised , supervised , and semi-supervised . Supervised and semi-supervised classification differ by whether or not weight is given to unlabelled observations in the classification procedure . In unsupervised classification , or clustering , all observations are unlabeled and hence full weight is given to unlabelled observations . When some observations are unlabelled , it can be very difficult to \textit{a~priori} choose the optimal level of supervision , and the consequences of a sub-optimal choice can be non-trivial . A flexible fractionally-supervised approach to classification is introduced , where any level of supervision --- ranging from unsupervised to supervised --- can be attained . Our approach uses a weighted likelihood , wherein weights control the relative role that labelled and unlabelled data have in building a classifier . A comparison between our approach and the traditional species is presented using simulated and real data . Gaussian mixture models are used as a vehicle to illustrate our fractionally-supervised classification approach ; however , it is broadly applicable and variations on the postulated model can be easily made .
This work examines a semi-blind single-channel source separation problem . Our specific aim is to separate one source whose local structure is approximately known , from another a priori unspecified background source , given only a single linear combination of the two sources . We propose a separation technique based on local sparse approximations along the lines of recent efforts in sparse representations and dictionary learning . A key feature of our procedure is the online learning of dictionaries ( using only the data itself ) to sparsely model the background source , which facilitates its separation from the partially-known source . Our approach is applicable to source separation problems in various application domains ; here , we demonstrate the performance of our proposed approach via simulation on a stylized audio source separation task .
Max-product Belief Propagation ( BP ) is a popular message-passing algorithm for computing a Maximum-A-Posteriori ( MAP ) assignment over a distribution represented by a Graphical Model ( GM ) . It has been shown that BP can solve a number of combinatorial optimization problems including minimum weight matching , shortest path , network flow and vertex cover under the following common assumption : the respective Linear Programming ( LP ) relaxation is tight , i . e . , no integrality gap is present . However , when LP shows an integrality gap , no model has been known which can be solved systematically via sequential applications of BP . In this paper , we develop the first such algorithm , coined Blossom-BP , for solving the minimum weight matching problem over arbitrary graphs . Each step of the sequential algorithm requires applying BP over a modified graph constructed by contractions and expansions of blossoms , i . e . , odd sets of vertices . Our scheme guarantees termination in O ( n^0 ) of BP runs , where n is the number of vertices in the original graph . In essence , the Blossom-BP offers a distributed version of the celebrated Edmonds ' Blossom algorithm by jumping at once over many sub-steps with a single BP . Moreover , our result provides an interpretation of the Edmonds ' algorithm as a sequence of LPs .
This work considers the problem of learning the structure of multivariate linear tree models , which include a variety of directed tree graphical models with continuous , discrete , and mixed latent variables such as linear-Gaussian models , hidden Markov models , Gaussian mixture models , and Markov evolutionary trees . The setting is one where we only have samples from certain observed variables in the tree , and our goal is to estimate the tree structure ( i . e . , the graph of how the underlying hidden variables are connected to each other and to the observed variables ) . We propose the Spectral Recursive Grouping algorithm , an efficient and simple bottom-up procedure for recovering the tree structure from independent samples of the observed variables . Our finite sample size bounds for exact recovery of the tree structure reveal certain natural dependencies on underlying statistical and structural properties of the underlying joint distribution . Furthermore , our sample complexity guarantees have no explicit dependence on the dimensionality of the observed variables , making the algorithm applicable to many high-dimensional settings . At the heart of our algorithm is a spectral quartet test for determining the relative topology of a quartet of variables from second-order statistics .
The problem of population recovery refers to estimating a distribution based on incomplete or corrupted samples . Consider a random poll of sample size $n$ conducted on a population of individuals , where each pollee is asked to answer $d$ binary questions . We consider one of the two polling impediments : ( a ) in lossy population recovery , a pollee may skip each question with probability $\epsilon$ , ( b ) in noisy population recovery , a pollee may lie on each question with probability $\epsilon$ . Given $n$ lossy or noisy samples , the goal is to estimate the probabilities of all $0^d$ binary vectors simultaneously within accuracy $\delta$ with high probability . This paper settles the sample complexity of population recovery . For lossy model , the optimal sample complexity is $\tilde\Theta ( \delta^{-0\max\{\frac{\epsilon}{0-\epsilon} , 0\}} ) $ , improving the state of the art by Moitra and Saks in several ways : a lower bound is established , the upper bound is improved and the result depends at most on the logarithm of the dimension . Surprisingly , the sample complexity undergoes a phase transition from parametric to nonparametric rate when $\epsilon$ exceeds $0/0$ . For noisy population recovery , the sharp sample complexity turns out to be more sensitive to dimension and scales as $\exp ( \Theta ( d^{0/0} \log^{0/0} ( 0/\delta ) ) ) $ except for the trivial cases of $\epsilon=0 , 0/0$ or $0$ . For both models , our estimators simply compute the empirical mean of a certain function , which is found by pre-solving a linear program ( LP ) . Curiously , the dual LP can be understood as Le Cam ' s method for lower-bounding the minimax risk , thus establishing the statistical optimality of the proposed estimators . The value of the LP is determined by complex-analytic methods .
We propose a computationally efficient random walk on a convex body which rapidly mixes and closely tracks a time-varying log-concave distribution . We develop general theoretical guarantees on the required number of steps ; this number can be calculated on the fly according to the distance from and the shape of the next distribution . We then illustrate the technique on several examples . Within the context of exponential families , the proposed method produces samples from a posterior distribution which is updated as data arrive in a streaming fashion . The sampling technique can be used to track time-varying truncated distributions , as well as to obtain samples from a changing mixture model , fitted in a streaming fashion to data . In the setting of linear optimization , the proposed method has oracle complexity with best known dependence on the dimension for certain geometries . In the context of online learning and repeated games , the algorithm is an efficient method for implementing no-regret mixture forecasting strategies . Remarkably , in some of these examples , only one step of the random walk is needed to track the next distribution .
In magnetoencephalography ( MEG ) the conventional approach to source reconstruction is to solve the underdetermined inverse problem independently over time and space . Here we present how the conventional approach can be extended by regularizing the solution in space and time by a Gaussian process ( Gaussian random field ) model . Assuming a separable covariance function in space and time , the computational complexity of the proposed model becomes ( without any further assumptions or restrictions ) $\mathcal{O} ( t^0 + n^0 + m^0n ) $ , where $t$ is the number of time steps , $m$ is the number of sources , and $n$ is the number of sensors . We apply the method to both simulated and empirical data , and demonstrate the efficiency and generality of our Bayesian source reconstruction approach which subsumes various classical approaches in the literature .
A typical goal of supervised dimension reduction is to find a low-dimensional subspace of the input space such that the projected input variables preserve maximal information about the output variables . The dependence maximization approach solves the supervised dimension reduction problem through maximizing a statistical dependence between projected input variables and output variables . A well-known statistical dependence measure is mutual information ( MI ) which is based on the Kullback-Leibler ( KL ) divergence . However , it is known that the KL divergence is sensitive to outliers . On the other hand , quadratic MI ( QMI ) is a variant of MI based on the $L_0$ distance which is more robust against outliers than the KL divergence , and a computationally efficient method to estimate QMI from data , called least-squares QMI ( LSQMI ) , has been proposed recently . For these reasons , developing a supervised dimension reduction method based on LSQMI seems promising . However , not QMI itself , but the derivative of QMI is needed for subspace search in supervised dimension reduction , and the derivative of an accurate QMI estimator is not necessarily a good estimator of the derivative of QMI . In this paper , we propose to directly estimate the derivative of QMI without estimating QMI itself . We show that the direct estimation of the derivative of QMI is more accurate than the derivative of the estimated QMI . Finally , we develop a supervised dimension reduction algorithm which efficiently uses the proposed derivative estimator , and demonstrate through experiments that the proposed method is more robust against outliers than existing methods .
This work considers an estimation task in compressive sensing , where the goal is to estimate an unknown signal from compressive measurements that are corrupted by additive pre-measurement noise ( interference , or clutter ) as well as post-measurement noise , in the specific setting where some ( perhaps limited ) prior knowledge on the signal , interference , and noise is available . The specific aim here is to devise a strategy for incorporating this prior information into the design of an appropriate compressive measurement strategy . Here , the prior information is interpreted as statistics of a prior distribution on the relevant quantities , and an approach based on Bayesian Experimental Design is proposed . Experimental results on synthetic data demonstrate that the proposed approach outperforms traditional random compressive measurement designs , which are agnostic to the prior information , as well as several other knowledge-enhanced sensing matrix designs based on more heuristic notions .
The distance metric plays an important role in nearest neighbor ( NN ) classification . Usually the Euclidean distance metric is assumed or a Mahalanobis distance metric is optimized to improve the NN performance . In this paper , we study the problem of embedding arbitrary metric spaces into a Euclidean space with the goal to improve the accuracy of the NN classifier . We propose a solution by appealing to the framework of regularization in a reproducing kernel Hilbert space and prove a representer-like theorem for NN classification . The embedding function is then determined by solving a semidefinite program which has an interesting connection to the soft-margin linear binary support vector machine classifier . Although the main focus of this paper is to present a general , theoretical framework for metric embedding in a NN setting , we demonstrate the performance of the proposed method on some benchmark datasets and show that it performs better than the Mahalanobis metric learning algorithm in terms of leave-one-out and generalization errors .
Work in the classification literature has shown that in computing a classification function , one need not know the class membership of all observations in the training set ; the unlabeled observations still provide information on the marginal distribution of the feature set , and can thus contribute to increased classification accuracy for future observations . The present paper will show that this scheme can also be used for the estimation of class prior probabilities , which would be very useful in applications in which it is difficult or expensive to determine class membership . Both parametric and nonparametric estimators are developed . Asymptotic distributions of the estimators are derived , and it is proven that the use of the unlabeled observations does reduce asymptotic variance . This methodology is also extended to the estimation of subclass probabilities .
Machine learning techniques have become increasingly popular in the field of resting state fMRI ( functional magnetic resonance imaging ) network based classification . However , the application of convolutional networks has been proposed only very recently and has remained largely unexplored . In this paper we describe a convolutional neural network architecture for functional connectome classification called connectome-convolutional neural network ( CCNN ) . Our results on simulated datasets and a publicly available dataset for amnestic mild cognitive impairment classification demonstrate that our CCNN model can efficiently distinguish between subject groups . We also show that the connectome-convolutional network is capable to combine information from diverse functional connectivity metrics and that models using a combination of different connectivity descriptors are able to outperform classifiers using only one metric . From this flexibility follows that our proposed CCNN model can be easily adapted to a wide range of connectome based classification or regression tasks , by varying which connectivity descriptor combinations are used to train the network .
It is oftentimes impossible to understand how machine learning models reach a decision . While recent research has proposed various technical approaches to provide some clues as to how a learning model makes individual decisions , they cannot provide users with ability to inspect a learning model as a complete entity . In this work , we propose a new technical approach that augments a Bayesian regression mixture model with multiple elastic nets . Using the enhanced mixture model , we extract explanations for a target model through global approximation . To demonstrate the utility of our approach , we evaluate it on different learning models covering the tasks of text mining and image recognition . Our results indicate that the proposed approach not only outperforms the state-of-the-art technique in explaining individual decisions but also provides users with an ability to discover the vulnerabilities of a learning model .
In a previous work we have detailed the requirements to obtain a maximal performance benefit by implementing fully connected deep neural networks ( DNN ) in form of arrays of resistive devices for deep learning . This concept of Resistive Processing Unit ( RPU ) devices we extend here towards convolutional neural networks ( CNNs ) . We show how to map the convolutional layers to RPU arrays such that the parallelism of the hardware can be fully utilized in all three cycles of the backpropagation algorithm . We find that the noise and bound limitations imposed due to analog nature of the computations performed on the arrays effect the training accuracy of the CNNs . Noise and bound management techniques are presented that mitigate these problems without introducing any additional complexity in the analog circuits and can be addressed by the digital circuits . In addition , we discuss digitally programmable update management and device variability reduction techniques that can be used selectively for some of the layers in a CNN . We show that combination of all those techniques enables a successful application of the RPU concept for training CNNs . The techniques discussed here are more general and can be applied beyond CNN architectures and therefore enables applicability of RPU approach for large class of neural network architectures .
We consider the two problems of predicting links in a dynamic graph sequence and predicting functions defined at each node of the graph . In many applications , the solution of one problem is useful for solving the other . Indeed , if these functions reflect node features , then they are related through the graph structure . In this paper , we formulate a hybrid approach that simultaneously learns the structure of the graph and predicts the values of the node-related functions . Our approach is based on the optimization of a joint regularization objective . We empirically test the benefits of the proposed method with both synthetic and real data . The results indicate that joint regularization improves prediction performance over the graph evolution and the node features .
In this paper we propose and investigate a novel nonlinear unit , called $L_p$ unit , for deep neural networks . The proposed $L_p$ unit receives signals from several projections of a subset of units in the layer below and computes a normalized $L_p$ norm . We notice two interesting interpretations of the $L_p$ unit . First , the proposed unit can be understood as a generalization of a number of conventional pooling operators such as average , root-mean-square and max pooling widely used in , for instance , convolutional neural networks ( CNN ) , HMAX models and neocognitrons . Furthermore , the $L_p$ unit is , to a certain degree , similar to the recently proposed maxout unit ( Goodfellow et al . , 0000 ) which achieved the state-of-the-art object recognition results on a number of benchmark datasets . Secondly , we provide a geometrical interpretation of the activation function based on which we argue that the $L_p$ unit is more efficient at representing complex , nonlinear separating boundaries . Each $L_p$ unit defines a superelliptic boundary , with its exact shape defined by the order $p$ . We claim that this makes it possible to model arbitrarily shaped , curved boundaries more efficiently by combining a few $L_p$ units of different orders . This insight justifies the need for learning different orders for each unit in the model . We empirically evaluate the proposed $L_p$ units on a number of datasets and show that multilayer perceptrons ( MLP ) consisting of the $L_p$ units achieve the state-of-the-art results on a number of benchmark datasets . Furthermore , we evaluate the proposed $L_p$ unit on the recently proposed deep recurrent neural networks ( RNN ) .
In Bayesian statistics , many problems can be expressed as the evaluation of the expectation of a quantity of interest with respect to the posterior distribution . Standard Monte Carlo method is often not applicable because the encountered posterior distributions cannot be sampled directly . In this case , the most popular strategies are the importance sampling method , Markov chain Monte Carlo , and annealing . In this paper , we introduce a new scheme for Bayesian inference , called Asymptotically Independent Markov Sampling ( AIMS ) , which is based on the above methods . We derive important ergodic properties of AIMS . In particular , it is shown that , under certain conditions , the AIMS algorithm produces a uniformly ergodic Markov chain . The choice of the free parameters of the algorithm is discussed and recommendations are provided for this choice , both theoretically and heuristically based . The efficiency of AIMS is demonstrated with three numerical examples , which include both multi-modal and higher-dimensional target posterior distributions .
Swarm systems constitute a challenging problem for reinforcement learning ( RL ) as the algorithm needs to learn decentralized control policies that can cope with limited local sensing and communication abilities of the agents . Although there have been recent advances of deep RL algorithms applied to multi-agent systems , learning communication protocols while simultaneously learning the behavior of the agents is still beyond the reach of deep RL algorithms . However , while it is often difficult to directly define the behavior of the agents , simple communication protocols can be defined more easily using prior knowledge about the given task . In this paper , we propose a number of simple communication protocols that can be exploited by deep reinforcement learning to find decentralized control policies in a multi-robot swarm environment . The protocols are based on histograms that encode the local neighborhood relations of the agents and can also transmit task-specific information , such as the shortest distance and direction to a desired target . In our framework , we use an adaptation of Trust Region Policy Optimization to learn complex collaborative tasks , such as formation building , building a communication link , and pushing an intruder . We evaluate our findings in a simulated 0D-physics environment , and compare the implications of different communication protocols .
We point out an issue with Theorem 0 appearing in " Group-based active query selection for rapid diagnosis in time-critical situations " . Theorem 0 bounds the expected number of queries for a greedy algorithm to identify the class of an item within a constant factor of optimal . The Theorem is based on correctness of a result on minimization of adaptive submodular functions . We present an example that shows that a critical step in Theorem A . 00 of " Adaptive Submodularity : Theory and Applications in Active Learning and Stochastic Optimization " is incorrect .
We consider the problem of learning regression functions from pairwise data when there exists prior knowledge that the relation to be learned is symmetric or anti-symmetric . Such prior knowledge is commonly enforced by symmetrizing or anti-symmetrizing pairwise kernel functions . Through spectral analysis , we show that these transformations reduce the kernel ' s effective dimension . Further , we provide an analysis of the approximation properties of the resulting kernels , and bound the regularization bias of the kernels in terms of the corresponding bias of the original kernel .
We propose an inference method to estimate sparse interactions and biases according to Boltzmann machine learning . The basis of this method is $L_0$ regularization , which is often used in compressed sensing , a technique for reconstructing sparse input signals from undersampled outputs . $L_0$ regularization impedes the simple application of the gradient method , which optimizes the cost function that leads to accurate estimations , owing to the cost function ' s lack of smoothness . In this study , we utilize the majorizer minimization method , which is a well-known technique implemented in optimization problems , to avoid the non-smoothness of the cost function . By using the majorizer minimization method , we elucidate essentially relevant biases and interactions from given data with seemingly strongly-correlated components .
Graphical models for structured domains are powerful tools , but the computational complexities of combinatorial prediction spaces can force restrictions on models , or require approximate inference in order to be tractable . Instead of working in a combinatorial space , we use hinge-loss Markov random fields ( HL-MRFs ) , an expressive class of graphical models with log-concave density functions over continuous variables , which can represent confidences in discrete predictions . This paper demonstrates that HL-MRFs are general tools for fast and accurate structured prediction . We introduce the first inference algorithm that is both scalable and applicable to the full class of HL-MRFs , and show how to train HL-MRFs with several learning algorithms . Our experiments show that HL-MRFs match or surpass the predictive performance of state-of-the-art methods , including discrete models , in four application domains .
Markov random fields ( MRFs ) are difficult to evaluate as generative models because computing the test log-probabilities requires the intractable partition function . Annealed importance sampling ( AIS ) is widely used to estimate MRF partition functions , and often yields quite accurate results . However , AIS is prone to overestimate the log-likelihood with little indication that anything is wrong . We present the Reverse AIS Estimator ( RAISE ) , a stochastic lower bound on the log-likelihood of an approximation to the original MRF model . RAISE requires only the same MCMC transition operators as standard AIS . Experimental results indicate that RAISE agrees closely with AIS log-probability estimates for RBMs , DBMs , and DBNs , but typically errs on the side of underestimating , rather than overestimating , the log-likelihood .
We study unsupervised generative modeling in terms of the optimal transport ( OT ) problem between true ( but unknown ) data distribution $P_X$ and the latent variable model distribution $P_G$ . We show that the OT problem can be equivalently written in terms of probabilistic encoders , which are constrained to match the posterior and prior distributions over the latent space . When relaxed , this constrained optimization problem leads to a penalized optimal transport ( POT ) objective , which can be efficiently minimized using stochastic gradient descent by sampling from $P_X$ and $P_G$ . We show that POT for the 0-Wasserstein distance coincides with the objective heuristically employed in adversarial auto-encoders ( AAE ) ( Makhzani et al . , 0000 ) , which provides the first theoretical justification for AAEs known to the authors . We also compare POT to other popular techniques like variational auto-encoders ( VAE ) ( Kingma and Welling , 0000 ) . Our theoretical results include ( a ) a better understanding of the commonly observed blurriness of images generated by VAEs , and ( b ) establishing duality between Wasserstein GAN ( Arjovsky and Bottou , 0000 ) and POT for the 0-Wasserstein distance .
In this paper we propose a strategy for semi-supervised image classification that leverages unsupervised representation learning and co-training . The strategy , that is called CURL from Co-trained Unsupervised Representation Learning , iteratively builds two classifiers on two different views of the data . The two views correspond to different representations learned from both labeled and unlabeled data and differ in the fusion scheme used to combine the image features . To assess the performance of our proposal , we conducted several experiments on widely used data sets for scene and object recognition . We considered three scenarios ( inductive , transductive and self-taught learning ) that differ in the strategy followed to exploit the unlabeled data . As image features we considered a combination of GIST , PHOG , and LBP as well as features extracted from a Convolutional Neural Network . Moreover , two embodiments of CURL are investigated : one using Ensemble Projection as unsupervised representation learning coupled with Logistic Regression , and one based on LapSVM . The results show that CURL clearly outperforms other supervised and semi-supervised learning methods in the state of the art .
Statistical relational models provide compact encodings of probabilistic dependencies in relational domains , but result in highly intractable graphical models . The goal of lifted inference is to carry out probabilistic inference without needing to reason about each individual separately , by instead treating exchangeable , undistinguished objects as a whole . In this paper , we study the domain recursion inference rule , which , despite its central role in early theoretical results on domain-lifted inference , has later been believed redundant . We show that this rule is more powerful than expected , and in fact significantly extends the range of models for which lifted inference runs in time polynomial in the number of individuals in the domain . This includes an open problem called S0 , the symmetric transitivity model , and a first-order logic encoding of the birthday paradox . We further identify new classes S0FO0 and S0RU of domain-liftable theories , which respectively subsume FO0 and recursively unary theories , the largest classes of domain-liftable theories known so far , and show that using domain recursion can achieve exponential speedup even in theories that cannot fully be lifted with the existing set of inference rules .
Reconstruction of a function from noisy data is often formulated as a regularized optimization problem over an infinite-dimensional reproducing kernel Hilbert space ( RKHS ) . The solution describes the observed data and has a small RKHS norm . When the data fit is measured using a quadratic loss , this estimator has a known statistical interpretation . Given the noisy measurements , the RKHS estimate represents the posterior mean ( minimum variance estimate ) of a Gaussian random field with covariance proportional to the kernel associated with the RKHS . In this paper , we provide a statistical interpretation when more general losses are used , such as absolute value , Vapnik or Huber . Specifically , for any finite set of sampling locations ( including where the data were collected ) , the MAP estimate for the signal samples is given by the RKHS estimate evaluated at these locations .
The problem of human activity recognition is central for understanding and predicting the human behavior , in particular in a prospective of assistive services to humans , such as health monitoring , well being , security , etc . There is therefore a growing need to build accurate models which can take into account the variability of the human activities over time ( dynamic models ) rather than static ones which can have some limitations in such a dynamic context . In this paper , the problem of activity recognition is analyzed through the segmentation of the multidimensional time series of the acceleration data measured in the 0-d space using body-worn accelerometers . The proposed model for automatic temporal segmentation is a specific statistical latent process model which assumes that the observed acceleration sequence is governed by sequence of hidden ( unobserved ) activities . More specifically , the proposed approach is based on a specific multiple regression model incorporating a hidden discrete logistic process which governs the switching from one activity to another over time . The model is learned in an unsupervised context by maximizing the observed-data log-likelihood via a dedicated expectation-maximization ( EM ) algorithm . We applied it on a real-world automatic human activity recognition problem and its performance was assessed by performing comparisons with alternative approaches , including well-known supervised static classifiers and the standard hidden Markov model ( HMM ) . The obtained results are very encouraging and show that the proposed approach is quite competitive even it works in an entirely unsupervised way and does not requires a feature extraction preprocessing step .
In this paper we describe our attempt at producing a state-of-the-art Twitter sentiment classifier using Convolutional Neural Networks ( CNNs ) and Long Short Term Memory ( LSTMs ) networks . Our system leverages a large amount of unlabeled data to pre-train word embeddings . We then use a subset of the unlabeled data to fine tune the embeddings using distant supervision . The final CNNs and LSTMs are trained on the SemEval-0000 Twitter dataset where the embeddings are fined tuned again . To boost performances we ensemble several CNNs and LSTMs together . Our approach achieved first rank on all of the five English subtasks amongst 00 teams .
In an era when big data are becoming the norm , there is less concern with the quantity but more with the quality and completeness of the data . In many disciplines , data are collected from heterogeneous sources , resulting in multi-view or multi-modal datasets . The missing data problem has been challenging to address in multi-view data analysis . Especially , when certain samples miss an entire view of data , it creates the missing view problem . Classic multiple imputations or matrix completion methods are hardly effective here when no information can be based on in the specific view to impute data for such samples . The commonly-used simple method of removing samples with a missing view can dramatically reduce sample size , thus diminishing the statistical power of a subsequent analysis . In this paper , we propose a novel approach for view imputation via generative adversarial networks ( GANs ) , which we name by VIGAN . This approach first treats each view as a separate domain and identifies domain-to-domain mappings via a GAN using randomly-sampled data from each view , and then employs a multi-modal denoising autoencoder ( DAE ) to reconstruct the missing view from the GAN outputs based on paired data across the views . Then , by optimizing the GAN and DAE jointly , our model enables the knowledge integration for domain mappings and view correspondences to effectively recover the missing view . Empirical results on benchmark datasets validate the VIGAN approach by comparing against the state of the art . The evaluation of VIGAN in a genetic study of substance use disorders further proves the effectiveness and usability of this approach in life science .
We consider the problem of inference in a causal generative model where the set of available observations differs between data instances . We show how combining samples drawn from the graphical model with an appropriate masking function makes it possible to train a single neural network to approximate all the corresponding conditional marginal distributions and thus amortize the cost of inference . We further demonstrate that the efficiency of importance sampling may be improved by basing proposals on the output of the neural network . We also outline how the same network can be used to generate samples from an approximate joint posterior via a chain decomposition of the graph .
We consider the problem of recovering a complete ( i . e . , square and invertible ) matrix $\mathbf A_0$ , from $\mathbf Y \in \mathbb{R}^{n \times p}$ with $\mathbf Y = \mathbf A_0 \mathbf X_0$ , provided $\mathbf X_0$ is sufficiently sparse . This recovery problem is central to theoretical understanding of dictionary learning , which seeks a sparse representation for a collection of input signals and finds numerous applications in modern signal processing and machine learning . We give the first efficient algorithm that provably recovers $\mathbf A_0$ when $\mathbf X_0$ has $O ( n ) $ nonzeros per column , under suitable probability model for $\mathbf X_0$ . In contrast , prior results based on efficient algorithms either only guarantee recovery when $\mathbf X_0$ has $O ( \sqrt{n} ) $ zeros per column , or require multiple rounds of SDP relaxation to work when $\mathbf X_0$ has $O ( n^{0-\delta} ) $ nonzeros per column ( for any constant $\delta \in ( 0 , 0 ) $ ) . } Our algorithmic pipeline centers around solving a certain nonconvex optimization problem with a spherical constraint . In this paper , we provide a geometric characterization of the objective landscape . In particular , we show that the problem is highly structured : with high probability , ( 0 ) there are no " spurious " local minimizers ; and ( 0 ) around all saddle points the objective has a negative directional curvature . This distinctive structure makes the problem amenable to efficient optimization algorithms . In a companion paper ( arXiv : 0000 . 00000 ) , we design a second-order trust-region algorithm over the sphere that provably converges to a local minimizer from arbitrary initializations , despite the presence of saddle points .
The interaction between transitivity and sparsity , two common features in empirical networks , implies that there are local regions of large sparse networks that are dense . We call this the blessing of transitivity and it has consequences for both modeling and inference . Extant research suggests that statistical inference for the Stochastic Blockmodel is more difficult when the edges are sparse . However , this conclusion is confounded by the fact that the asymptotic limit in all of the previous studies is not merely sparse , but also non-transitive . To retain transitivity , the blocks cannot grow faster than the expected degree . Thus , in sparse models , the blocks must remain asymptotically small . \n Previous algorithmic research demonstrates that small " local " clusters are more amenable to computation , visualization , and interpretation when compared to " global " graph partitions . This paper provides the first statistical results that demonstrate how these small transitive clusters are also more amenable to statistical estimation . Theorem 0 shows that a " local " clustering algorithm can , with high probability , detect a transitive stochastic block of a fixed size ( e . g . 00 nodes ) embedded in a large graph . The only constraint on the ambient graph is that it is large and sparse--it could be generated at random or by an adversary--suggesting a theoretical explanation for the robust empirical performance of local clustering algorithms .
In latent Gaussian trees the pairwise correlation signs between the variables are intrinsically unrecoverable . Such information is vital since it completely determines the direction in which two variables are associated . In this work , we resort to information theoretical approaches to achieve two fundamental goals : First , we quantify the amount of information loss due to unrecoverable sign information . Second , we show the importance of such information in determining the maximum achievable rate region , in which the observed output vector can be synthesized , given its probability density function . In particular , we model the graphical model as a communication channel and propose a new layered encoding framework to synthesize observed data using upper layer Gaussian inputs and independent Bernoulli correlation sign inputs from each layer . We find the achievable rate region for the rate tuples of multi-layer latent Gaussian messages to synthesize the desired observables .
Large scale , streaming datasets are ubiquitous in modern machine learning . Streaming algorithms must be scalable , amenable to incremental training and robust to the presence of non-stationarity . In this work consider the problem of learning $\ell_0$ regularized linear models in the context of streaming data . In particular , the focus of this work revolves around how to select the regularization parameter when data arrives sequentially and the underlying distribution is non-stationary ( implying the choice of optimal regularization parameter is itself time-varying ) . We propose a framework through which to infer an adaptive regularization parameter . Our approach employs an $\ell_0$ penalty constraint where the corresponding sparsity parameter is iteratively updated via stochastic gradient descent . This serves to reformulate the choice of regularization parameter in a principled framework for online learning . The proposed method is derived for linear regression and subsequently extended to generalized linear models . We validate our approach using simulated and real datasets and present an application to a neuroimaging dataset .
We consider the least-square linear regression problem with regularization by the l0-norm , a problem usually referred to as the Lasso . In this paper , we present a detailed asymptotic analysis of model consistency of the Lasso . For various decays of the regularization parameter , we compute asymptotic equivalents of the probability of correct model selection ( i . e . , variable selection ) . For a specific rate decay , we show that the Lasso selects all the variables that should enter the model with probability tending to one exponentially fast , while it selects all other variables with strictly positive probability . We show that this property implies that if we run the Lasso for several bootstrapped replications of a given sample , then intersecting the supports of the Lasso bootstrap estimates leads to consistent model selection . This novel variable selection algorithm , referred to as the Bolasso , is compared favorably to other linear regression methods on synthetic data and datasets from the UCI machine learning repository .
This article studies the achievable guarantees on the error rates of certain learning algorithms , with particular focus on refining logarithmic factors . Many of the results are based on a general technique for obtaining bounds on the error rates of sample-consistent classifiers with monotonic error regions , in the realizable case . We prove bounds of this type expressed in terms of either the VC dimension or the sample compression size . This general technique also enables us to derive several new bounds on the error rates of general sample-consistent learning algorithms , as well as refined bounds on the label complexity of the CAL active learning algorithm . Additionally , we establish a simple necessary and sufficient condition for the existence of a distribution-free bound on the error rates of all sample-consistent learning rules , converging at a rate inversely proportional to the sample size . We also study learning in the presence of classification noise , deriving a new excess error rate guarantee for general VC classes under Tsybakov ' s noise condition , and establishing a simple and general necessary and sufficient condition for the minimax excess risk under bounded noise to converge at a rate inversely proportional to the sample size .
We empirically investigate the best trade-off between sparse and uniformly-weighted multiple kernel learning ( MKL ) using the elastic-net regularization on real and simulated datasets . We find that the best trade-off parameter depends not only on the sparsity of the true kernel-weight spectrum but also on the linear dependence among kernels and the number of samples .
Nonnegative matrix factorization ( NMF ) factorizes a non-negative matrix into product of two non-negative matrices , namely a signal matrix and a mixing matrix . NMF suffers from the scale and ordering ambiguities . Often , the source signals can be monotonous in nature . For example , in source separation problem , the source signals can be monotonously increasing or decreasing while the mixing matrix can have nonnegative entries . NMF methods may not be effective for such cases as it suffers from the ordering ambiguity . This paper proposes an approach to incorporate notion of monotonicity in NMF , labeled as monotonous NMF . An algorithm based on alternating least-squares is proposed for recovering monotonous signals from a data matrix . Further , the assumption on mixing matrix is relaxed to extend monotonous NMF for data matrix with real numbers as entries . The approach is illustrated using synthetic noisy data . The results obtained by monotonous NMF are compared with standard NMF algorithms in the literature , and it is shown that monotonous NMF estimates source signals well in comparison to standard NMF algorithms when the underlying sources signals are monotonous .
In reinforcement learning , agents learn by performing actions and observing their outcomes . Sometimes , it is desirable for a human operator to \textit{interrupt} an agent in order to prevent dangerous situations from happening . Yet , as part of their learning process , agents may link these interruptions , that impact their reward , to specific states and deliberately avoid them . The situation is particularly challenging in a multi-agent context because agents might not only learn from their own past interruptions , but also from those of other agents . Orseau and Armstrong defined \emph{safe interruptibility} for one learner , but their work does not naturally extend to multi-agent systems . This paper introduces \textit{dynamic safe interruptibility} , an alternative definition more suited to decentralized learning problems , and studies this notion in two learning frameworks : \textit{joint action learners} and \textit{independent learners} . We give realistic sufficient conditions on the learning algorithm to enable dynamic safe interruptibility in the case of joint action learners , yet show that these conditions are not sufficient for independent learners . We show however that if agents can detect interruptions , it is possible to prune the observations to ensure dynamic safe interruptibility even for independent learners .
Many machine learning tasks can be formulated in terms of predicting structured outputs . In frameworks such as the structured support vector machine ( SVM-Struct ) and the structured perceptron , discriminative functions are learned by iteratively applying efficient maximum a posteriori ( MAP ) decoding . However , maximum likelihood estimation ( MLE ) of probabilistic models over these same structured spaces requires computing partition functions , which is generally intractable . This paper presents a method for learning discrete exponential family models using the Bethe approximation to the MLE . Remarkably , this problem also reduces to iterative ( MAP ) decoding . This connection emerges by combining the Bethe approximation with a Frank-Wolfe ( FW ) algorithm on a convex dual objective which circumvents the intractable partition function . The result is a new single loop algorithm MLE-Struct , which is substantially more efficient than previous double-loop methods for approximate maximum likelihood estimation . Our algorithm outperforms existing methods in experiments involving image segmentation , matching problems from vision , and a new dataset of university roommate assignments .
It is shown that bootstrap approximations of an estimator which is based on a continuous operator from the set of Borel probability measures defined on a compact metric space into a complete separable metric space is stable in the sense of qualitative robustness . Support vector machines based on shifted loss functions are treated as special cases .
Many machine learning algorithms are vulnerable to almost imperceptible perturbations of their inputs . So far it was unclear how much risk adversarial perturbations carry for the safety of real-world machine learning applications because most methods used to generate such perturbations rely either on detailed model information ( gradient-based attacks ) or on confidence scores such as class probabilities ( score-based attacks ) , neither of which are available in most real-world scenarios . In many such cases one currently needs to retreat to transfer-based attacks which rely on cumbersome substitute models , need access to the training data and can be defended against . Here we emphasise the importance of attacks which solely rely on the final model decision . Such decision-based attacks are ( 0 ) applicable to real-world black-box models such as autonomous cars , ( 0 ) need less knowledge and are easier to apply than transfer-based attacks and ( 0 ) are more robust to simple defences than gradient- or score-based attacks . Previous attacks in this category were limited to simple models or simple datasets . Here we introduce the Boundary Attack , a decision-based attack that starts from a large adversarial perturbation and then seeks to reduce the perturbation while staying adversarial . The attack is conceptually simple , requires close to no hyperparameter tuning , does not rely on substitute models and is competitive with the best gradient-based attacks in standard computer vision tasks like ImageNet . We apply the attack on two black-box algorithms from Clarifai . com . The Boundary Attack in particular and the class of decision-based attacks in general open new avenues to study the robustness of machine learning models and raise new questions regarding the safety of deployed machine learning systems . An implementation of the attack is available as part of Foolbox at https : //github . com/bethgelab/foolbox .
Many modern data analysis problems involve inferences from streaming data . However , streaming data is not easily amenable to the standard probabilistic modeling approaches , which assume that we condition on finite data . We develop population variational Bayes , a new approach for using Bayesian modeling to analyze streams of data . It approximates a new type of distribution , the population posterior , which combines the notion of a population distribution of the data with Bayesian inference in a probabilistic model . We study our method with latent Dirichlet allocation and Dirichlet process mixtures on several large-scale data sets .
We consider the partial observability model for multi-armed bandits , introduced by Mannor and Shamir . Our main result is a characterization of regret in the directed observability model in terms of the dominating and independence numbers of the observability graph . We also show that in the undirected case , the learner can achieve optimal regret without even accessing the observability graph before selecting an action . Both results are shown using variants of the Exp0 algorithm operating on the observability graph in a time-efficient manner .
This paper considers the matrix completion problem . We show that it is not necessary to assume joint incoherence , which is a standard but unintuitive and restrictive condition that is imposed by previous studies . This leads to a sample complexity bound that is order-wise optimal with respect to the incoherence parameter ( as well as to the rank $r$ and the matrix dimension $n$ up to a log factor ) . As a consequence , we improve the sample complexity of recovering a semidefinite matrix from $O ( nr^{0}\log^{0}n ) $ to $O ( nr\log^{0}n ) $ , and the highest allowable rank from $\Theta ( \sqrt{n}/\log n ) $ to $\Theta ( n/\log^{0}n ) $ . The key step in proof is to obtain new bounds on the $\ell_{\infty , 0}$-norm , defined as the maximum of the row and column norms of a matrix . To illustrate the applicability of our techniques , we discuss extensions to SVD projection , structured matrix completion and semi-supervised clustering , for which we provide order-wise improvements over existing results . Finally , we turn to the closely-related problem of low-rank-plus-sparse matrix decomposition . We show that the joint incoherence condition is unavoidable here for polynomial-time algorithms conditioned on the Planted Clique conjecture . This means it is intractable in general to separate a rank-$\omega ( \sqrt{n} ) $ positive semidefinite matrix and a sparse matrix . Interestingly , our results show that the standard and joint incoherence conditions are associated respectively with the information ( statistical ) and computational aspects of the matrix decomposition problem .
We propose generative neural network methods to generate DNA sequences and tune them to have desired properties . We present three approaches : creating synthetic DNA sequences using a generative adversarial network ; a DNA-based variant of the activation maximization ( " deep dream " ) design method ; and a joint procedure which combines these two approaches together . We show that these tools capture important structures of the data and , when applied to designing probes for protein binding microarrays , allow us to generate new sequences whose properties are estimated to be superior to those found in the training data . We believe that these results open the door for applying deep generative models to advance genomics research .
Tackling large approximate dynamic programming or reinforcement learning problems requires methods that can exploit regularities , or intrinsic structure , of the problem in hand . Most current methods are geared towards exploiting the regularities of either the value function or the policy . We introduce a general classification-based approximate policy iteration ( CAPI ) framework , which encompasses a large class of algorithms that can exploit regularities of both the value function and the policy space , depending on what is advantageous . This framework has two main components : a generic value function estimator and a classifier that learns a policy based on the estimated value function . We establish theoretical guarantees for the sample complexity of CAPI-style algorithms , which allow the policy evaluation step to be performed by a wide variety of algorithms ( including temporal-difference-style methods ) , and can handle nonparametric representations of policies . Our bounds on the estimation error of the performance loss are tighter than existing results . We also illustrate this approach empirically on several problems , including a large HIV control task .
The rising popularity of intelligent mobile devices and the daunting computational cost of deep learning-based models call for efficient and accurate on-device inference schemes . We propose a quantization scheme that allows inference to be carried out using integer-only arithmetic , which can be implemented more efficiently than floating point inference on commonly available integer-only hardware . We also co-design a training procedure to preserve end-to-end model accuracy post quantization . As a result , the proposed quantization scheme improves the tradeoff between accuracy and on-device latency . The improvements are significant even on MobileNets , a model family known for run-time efficiency , and are demonstrated in ImageNet classification and COCO detection on popular CPUs .
The variational autoencoder ( VAE ) is a popular probabilistic generative model . However , one shortcoming of VAEs is that the latent variables cannot be discrete , which makes it difficult to generate data from different modes of a distribution . Here , we propose an extension of the VAE framework that incorporates a classifier to infer the discrete class of the modeled data . To model sequential data , we can combine our Classifying VAE with a recurrent neural network such as an LSTM . We apply this model to algorithmic music generation , where our model learns to generate musical sequences in different keys . Most previous work in this area avoids modeling key by transposing data into only one or two keys , as opposed to the 00+ different keys in the original music . We show that our Classifying VAE and Classifying VAE+LSTM models outperform the corresponding non-classifying models in generating musical samples that stay in key . This benefit is especially apparent when trained on untransposed music data in the original keys .
Given a similarity graph between items , correlation clustering ( CC ) groups similar items together and dissimilar ones apart . One of the most popular CC algorithms is KwikCluster : an algorithm that serially clusters neighborhoods of vertices , and obtains a 0-approximation ratio . Unfortunately , KwikCluster in practice requires a large number of clustering rounds , a potential bottleneck for large graphs . We present C0 and ClusterWild ! , two algorithms for parallel correlation clustering that run in a polylogarithmic number of rounds and achieve nearly linear speedups , provably . C0 uses concurrency control to enforce serializability of a parallel clustering process , and guarantees a 0-approximation ratio . ClusterWild ! is a coordination free algorithm that abandons consistency for the benefit of better scaling ; this leads to a provably small loss in the 0-approximation ratio . We provide extensive experimental results for both algorithms , where we outperform the state of the art , both in terms of clustering accuracy and running time . We show that our algorithms can cluster billion-edge graphs in under 0 seconds on 00 cores , while achieving a 00x speedup .
Recently , there has been significant progress in understanding reinforcement learning in discounted infinite-horizon Markov decision processes ( MDPs ) by deriving tight sample complexity bounds . However , in many real-world applications , an interactive learning agent operates for a fixed or bounded period of time , for example tutoring students for exams or handling customer service requests . Such scenarios can often be better treated as episodic fixed-horizon MDPs , for which only looser bounds on the sample complexity exist . A natural notion of sample complexity in this setting is the number of episodes required to guarantee a certain performance with high probability ( PAC guarantee ) . In this paper , we derive an upper PAC bound $\tilde O ( \frac{|\mathcal S|^0 |\mathcal A| H^0}{\epsilon^0} \ln\frac 0 \delta ) $ and a lower PAC bound $\tilde \Omega ( \frac{|\mathcal S| |\mathcal A| H^0}{\epsilon^0} \ln \frac 0 {\delta + c} ) $ that match up to log-terms and an additional linear dependency on the number of states $|\mathcal S|$ . The lower bound is the first of its kind for this setting . Our upper bound leverages Bernstein ' s inequality to improve on previous bounds for episodic finite-horizon MDPs which have a time-horizon dependency of at least $H^0$ .
The fundamental aim of clustering algorithms is to partition data points . We consider tasks where the discovered partition is allowed to vary with some covariate such as space or time . One approach would be to use fragmentation-coagulation processes , but these , being Markov processes , are restricted to linear or tree structured covariate spaces . We define a partition-valued process on an arbitrary covariate space using Gaussian processes . We use the process to construct a multitask clustering model which partitions datapoints in a similar way across multiple data sources , and a time series model of network data which allows cluster assignments to vary over time . We describe sampling algorithms for inference and apply our method to defining cancer subtypes based on different types of cellular characteristics , finding regulatory modules from gene expression data from multiple human populations , and discovering time varying community structure in a social network .
Big data applications , such as medical imaging and genetics , typically generate datasets that consist of few observations n on many more variables p , a scenario that we denote as p>>n . Traditional data processing methods are often insufficient for extracting information out of big data . This calls for the development of new algorithms that can deal with the size , complexity , and the special structure of such datasets . In this paper , we consider the problem of classifying p>>n data and propose a classification method based on linear discriminant analysis ( LDA ) . Traditional LDA depends on the covariance estimate of the data , but when p>>n the sample covariance estimate is singular . The proposed method estimates the covariance by using a sparse version of noisy principal component analysis ( nPCA ) . The use of sparsity in this setting aims at automatically selecting variables that are relevant for classification . In experiments , the new method is compared to state-of-the art methods for big data problems using both simulated datasets and imaging genetics datasets .
In this paper , we propose the nonlinearity generation method to speed up and stabilize the training of deep convolutional neural networks . The proposed method modifies a family of activation functions as nonlinearity generators ( NGs ) . NGs make the activation functions linear symmetric for their inputs to lower model capacity , and automatically introduce nonlinearity to enhance the capacity of the model during training . The proposed method can be considered an unusual form of regularization : the model parameters are obtained by training a relatively low-capacity model , that is relatively easy to optimize at the beginning , with only a few iterations , and these parameters are reused for the initialization of a higher-capacity model . We derive the upper and lower bounds of variance of the weight variation , and show that the initial symmetric structure of NGs helps stabilize training . We evaluate the proposed method on different frameworks of convolutional neural networks over two object recognition benchmark tasks ( CIFAR-00 and CIFAR-000 ) . Experimental results showed that the proposed method allows us to ( 0 ) speed up the convergence of training , ( 0 ) allow for less careful weight initialization , ( 0 ) improve or at least maintain the performance of the model at negligible extra computational cost , and ( 0 ) easily train a very deep model .
A rapid pattern-recognition approach to characterize driver ' s curve-negotiating behavior is proposed . To shorten the recognition time and improve the recognition of driving styles , a k-means clustering-based support vector machine ( kMC-SVM ) method is developed and used for classifying drivers into two types : aggressive and moderate . First , vehicle speed and throttle opening are treated as the feature parameters to reflect the driving styles . Second , to discriminate driver curve-negotiating behaviors and reduce the number of support vectors , the k-means clustering method is used to extract and gather the two types of driving data and shorten the recognition time . Then , based on the clustering results , a support vector machine approach is utilized to generate the hyperplane for judging and predicting to which types the human driver are subject . Lastly , to verify the validity of the kMC-SVM method , a cross-validation experiment is designed and conducted . The research results show that the $ k $MC-SVM is an effective method to classify driving styles with a short time , compared with SVM method .
We propose a privacy-enhanced matrix factorization recommender that exploits the fact that users can often be grouped together by interest . This allows a form of " hiding in the crowd " privacy . We introduce a novel matrix factorization approach suited to making recommendations in a shared group ( or nym ) setting and the BLC algorithm for carrying out this matrix factorization in a privacy-enhanced manner . We demonstrate that the increased privacy does not come at the cost of reduced recommendation accuracy .
While the channel capacity reflects a theoretical upper bound on the achievable information transmission rate in the limit of infinitely many bits , it does not characterise the information transfer of a given encoding routine with finitely many bits . In this note , we characterise the quality of a code ( i . e . a given encoding routine ) by an upper bound on the expected minimum error probability that can be achieved when using this code . We show that for equientropic channels this upper bound is minimal for codes with maximal marginal entropy . As an instructive example we show for the additive white Gaussian noise ( AWGN ) channel that random coding---also a capacity achieving code---indeed maximises the marginal entropy in the limit of infinite messages .
We show an efficient algorithm for the following problem : Given uniformly random points from an arbitrary n-dimensional simplex , estimate the simplex . The size of the sample and the number of arithmetic operations of our algorithm are polynomial in n . This answers a question of Frieze , Jerrum and Kannan [FJK] . Our result can also be interpreted as efficiently learning the intersection of n+0 half-spaces in R^n in the model where the intersection is bounded and we are given polynomially many uniform samples from it . Our proof uses the local search technique from Independent Component Analysis ( ICA ) , also used by [FJK] . Unlike these previous algorithms , which were based on analyzing the fourth moment , ours is based on the third moment . We also show a direct connection between the problem of learning a simplex and ICA : a simple randomized reduction to ICA from the problem of learning a simplex . The connection is based on a known representation of the uniform measure on a simplex . Similar representations lead to a reduction from the problem of learning an affine transformation of an n-dimensional l_p ball to ICA .
A distinctive property of human and animal intelligence is the ability to form abstractions by neglecting irrelevant information which allows to separate structure from noise . From an information theoretic point of view abstractions are desirable because they allow for very efficient information processing . In artificial systems abstractions are often implemented through computationally costly formations of groups or clusters . In this work we establish the relation between the free-energy framework for decision making and rate-distortion theory and demonstrate how the application of rate-distortion for decision-making leads to the emergence of abstractions . We argue that abstractions are induced due to a limit in information processing capacity .
Regularized training of an autoencoder typically results in hidden unit biases that take on large negative values . We show that negative biases are a natural result of using a hidden layer whose responsibility is to both represent the input data and act as a selection mechanism that ensures sparsity of the representation . We then show that negative biases impede the learning of data distributions whose intrinsic dimensionality is high . We also propose a new activation function that decouples the two roles of the hidden layer and that allows us to learn representations on data with very high intrinsic dimensionality , where standard autoencoders typically fail . Since the decoupled activation function acts like an implicit regularizer , the model can be trained by minimizing the reconstruction error of training data , without requiring any additional regularization .
Although deep Convolutional Neural Network ( CNN ) has shown better performance in various computer vision tasks , its application is restricted by a significant increase in storage and computation . Among CNN simplification techniques , parameter pruning is a promising approach which aims at reducing the number of weights of various layers without intensively reducing the original accuracy . In this paper , we propose a novel progressive parameter pruning method , named Structured Probabilistic Pruning ( SPP ) , which effectively prunes weights of convolutional layers in a probabilistic manner . Specifically , unlike existing deterministic pruning approaches , where unimportant weights are permanently eliminated , SPP introduces a pruning probability for each weight , and pruning is guided by sampling from the pruning probabilities . A mechanism is designed to increase and decrease pruning probabilities based on importance criteria for the training process . Experiments show that , with 0x speedup , SPP can accelerate AlexNet with only 0 . 0% loss of top-0 accuracy and VGG-00 with 0 . 0% loss of top-0 accuracy in ImageNet classification . Moreover , SPP can be directly applied to accelerate multi-branch CNN networks , such as ResNet , without specific adaptations . Our 0x speedup ResNet-00 only suffers 0 . 0% loss of top-0 accuracy on ImageNet . We further prove the effectiveness of our method on transfer learning task on Flower-000 dataset with AlexNet .
Functional Magnetic Resonance Imaging ( fMRI ) relies on multi-step data processing pipelines to accurately determine brain activity ; among them , the crucial step of spatial smoothing . These pipelines are commonly suboptimal , given the local optimisation strategy they use , treating each step in isolation . With the advent of new tools for deep learning , recent work has proposed to turn these pipelines into end-to-end learning networks . This change of paradigm offers new avenues to improvement as it allows for a global optimisation . The current work aims at benefitting from this paradigm shift by defining a smoothing step as a layer in these networks able to adaptively modulate the degree of smoothing required by each brain volume to better accomplish a given data analysis task . The viability is evaluated on real fMRI data where subjects did alternate between left and right finger tapping tasks .
We summarize the potential impact that the European Union ' s new General Data Protection Regulation will have on the routine use of machine learning algorithms . Slated to take effect as law across the EU in 0000 , it will restrict automated individual decision-making ( that is , algorithms that make decisions based on user-level predictors ) which " significantly affect " users . The law will also effectively create a " right to explanation , " whereby a user can ask for an explanation of an algorithmic decision that was made about them . We argue that while this law will pose large challenges for industry , it highlights opportunities for computer scientists to take the lead in designing algorithms and evaluation frameworks which avoid discrimination and enable explanation .
Classifiers deployed in the real world operate in a dynamic environment , where the data distribution can change over time . These changes , referred to as concept drift , can cause the predictive performance of the classifier to drop over time , thereby making it obsolete . To be of any real use , these classifiers need to detect drifts and be able to adapt to them , over time . Detecting drifts has traditionally been approached as a supervised task , with labeled data constantly being used for validating the learned model . Although effective in detecting drifts , these techniques are impractical , as labeling is a difficult , costly and time consuming activity . On the other hand , unsupervised change detection techniques are unreliable , as they produce a large number of false alarms . The inefficacy of the unsupervised techniques stems from the exclusion of the characteristics of the learned classifier , from the detection process . In this paper , we propose the Margin Density Drift Detection ( MD0 ) algorithm , which tracks the number of samples in the uncertainty region of a classifier , as a metric to detect drift . The MD0 algorithm is a distribution independent , application independent , model independent , unsupervised and incremental algorithm for reliably detecting drifts from data streams . Experimental evaluation on 0 drift induced datasets and 0 additional datasets from the cybersecurity domain demonstrates that the MD0 approach can reliably detect drifts , with significantly fewer false alarms compared to unsupervised feature based drift detectors . The reduced false alarms enables the signaling of drifts only when they are most likely to affect classification performance . As such , the MD0 approach leads to a detection scheme which is credible , label efficient and general in its applicability .
This paper illustrates the similarities between the problems of customer churn and employee turnover . An example of employee turnover prediction model leveraging classical machine learning techniques is developed . Model outputs are then discussed to design \& test employee retention policies . This type of retention discussion is , to our knowledge , innovative and constitutes the main value of this paper .
An augmented Lagrangian ( AL ) can convert a constrained optimization problem into a sequence of simpler ( e . g . , unconstrained ) problems , which are then usually solved with local solvers . Recently , surrogate-based Bayesian optimization ( BO ) sub-solvers have been successfully deployed in the AL framework for a more global search in the presence of inequality constraints ; however , a drawback was that expected improvement ( EI ) evaluations relied on Monte Carlo . Here we introduce an alternative slack variable AL , and show that in this formulation the EI may be evaluated with library routines . The slack variables furthermore facilitate equality as well as inequality constraints , and mixtures thereof . We show how our new slack " ALBO " compares favorably to the original . Its superiority over conventional alternatives is reinforced on several mixed constraint examples .
Bandit methods for black-box optimisation , such as Bayesian optimisation , are used in a variety of applications including hyper-parameter tuning and experiment design . Recently , \emph{multi-fidelity} methods have garnered considerable attention since function evaluations have become increasingly expensive in such applications . Multi-fidelity methods use cheap approximations to the function of interest to speed up the overall optimisation process . However , most multi-fidelity methods assume only a finite number of approximations . In many practical applications however , a continuous spectrum of approximations might be available . For instance , when tuning an expensive neural network , one might choose to approximate the cross validation performance using less data $N$ and/or few training iterations $T$ . Here , the approximations are best viewed as arising out of a continuous two dimensional space $ ( N , T ) $ . In this work , we develop a Bayesian optimisation method , BOCA , for this setting . We characterise its theoretical properties and show that it achieves better regret than than strategies which ignore the approximations . BOCA outperforms several other baselines in synthetic and real experiments .
When analyzing the genome , researchers have discovered that proteins bind to DNA based on certain patterns of the DNA sequence known as " motifs " . However , it is difficult to manually construct motifs due to their complexity . Recently , externally learned memory models have proven to be effective methods for reasoning over inputs and supporting sets . In this work , we present memory matching networks ( MMN ) for classifying DNA sequences as protein binding sites . Our model learns a memory bank of encoded motifs , which are dynamic memory modules , and then matches a new test sequence to each of the motifs to classify the sequence as a binding or nonbinding site .
Calculation of the log-normalizer is a major computational obstacle in applications of log-linear models with large output spaces . The problem of fast normalizer computation has therefore attracted significant attention in the theoretical and applied machine learning literature . In this paper , we analyze a recently proposed technique known as " self-normalization " , which introduces a regularization term in training to penalize log normalizers for deviating from zero . This makes it possible to use unnormalized model scores as approximate probabilities . Empirical evidence suggests that self-normalization is extremely effective , but a theoretical understanding of why it should work , and how generally it can be applied , is largely lacking . We prove generalization bounds on the estimated variance of normalizers and upper bounds on the loss in accuracy due to self-normalization , describe classes of input distributions that self-normalize easily , and construct explicit examples of high-variance input distributions . Our theoretical results make predictions about the difficulty of fitting self-normalized models to several classes of distributions , and we conclude with empirical validation of these predictions .
This article addresses the problem of classification method based on both labeled and unlabeled data , where we assume that a density function for labeled data is different from that for unlabeled data . We propose a semi-supervised logistic regression model for classification problem along with the technique of covariate shift adaptation . Unknown parameters involved in proposed models are estimated by regularization with EM algorithm . A crucial issue in the modeling process is the choices of tuning parameters in our semi-supervised logistic models . In order to select the parameters , a model selection criterion is derived from an information-theoretic approach . Some numerical studies show that our modeling procedure performs well in various cases .
Mechanistic models of single-neuron dynamics have been extensively studied in computational neuroscience . However , identifying which models can quantitatively reproduce empirically measured data has been challenging . We propose to overcome this limitation by using likelihood-free inference approaches ( also known as Approximate Bayesian Computation , ABC ) to perform full Bayesian inference on single-neuron models . Our approach builds on recent advances in ABC by learning a neural network which maps features of the observed data to the posterior distribution over parameters . We learn a Bayesian mixture-density network approximating the posterior over multiple rounds of adaptively chosen simulations . Furthermore , we propose an efficient approach for handling missing features and parameter settings for which the simulator fails , as well as a strategy for automatically learning relevant features using recurrent neural networks . On synthetic data , our approach efficiently estimates posterior distributions and recovers ground-truth parameters . On in-vitro recordings of membrane voltages , we recover multivariate posteriors over biophysical parameters , which yield model-predicted voltage traces that accurately match empirical data . Our approach will enable neuroscientists to perform Bayesian inference on complex neuron models without having to design model-specific algorithms , closing the gap between mechanistic and statistical approaches to single-neuron modelling .
The diversification ( generating slightly varying separating discriminators ) of Support Vector Machines ( SVMs ) for boosting has proven to be a challenge due to the strong learning nature of SVMs . Based on the insight that perturbing the SVM kernel may help in diversifying SVMs , we propose two kernel perturbation based boosting schemes where the kernel is modified in each round so as to increase the resolution of the kernel-induced Reimannian metric in the vicinity of the datapoints misclassified in the previous round . We propose a method for identifying the disjuncts in a dataset , dispelling the dependence on rule-based learning methods for identifying the disjuncts . We also present a new performance measure called Geometric Small Disjunct Index ( GSDI ) to quantify the performance on small disjuncts for balanced as well as class imbalanced datasets . Experimental comparison with a variety of state-of-the-art algorithms is carried out using the best classifiers of each type selected by a new approach inspired by multi-criteria decision making . The proposed method is found to outperform the contending state-of-the-art methods on different datasets ( ranging from mildly imbalanced to highly imbalanced and characterized by varying number of disjuncts ) in terms of three different performance indices ( including the proposed GSDI ) .
A fundamental challenge in developing high-impact machine learning technologies is balancing the need to model rich , structured domains with the ability to scale to big data . Many important problem areas are both richly structured and large scale , from social and biological networks , to knowledge graphs and the Web , to images , video , and natural language . In this paper , we introduce two new formalisms for modeling structured data , and show that they can both capture rich structure and scale to big data . The first , hinge-loss Markov random fields ( HL-MRFs ) , is a new kind of probabilistic graphical model that generalizes different approaches to convex inference . We unite three approaches from the randomized algorithms , probabilistic graphical models , and fuzzy logic communities , showing that all three lead to the same inference objective . We then define HL-MRFs by generalizing this unified objective . The second new formalism , probabilistic soft logic ( PSL ) , is a probabilistic programming language that makes HL-MRFs easy to define using a syntax based on first-order logic . We introduce an algorithm for inferring most-probable variable assignments ( MAP inference ) that is much more scalable than general-purpose convex optimization methods , because it uses message passing to take advantage of sparse dependency structures . We then show how to learn the parameters of HL-MRFs . The learned HL-MRFs are as accurate as analogous discrete models , but much more scalable . Together , these algorithms enable HL-MRFs and PSL to model rich , structured data at scales not previously possible .
We are increasingly surrounded by artificially intelligent technology that takes decisions and executes actions on our behalf . This creates a pressing need for general means to communicate with , instruct and guide artificial agents , with human language the most compelling means for such communication . To achieve this in a scalable fashion , agents must be able to relate language to the world and to actions ; that is , their understanding of language must be grounded and embodied . However , learning grounded language is a notoriously challenging problem in artificial intelligence research . Here we present an agent that learns to interpret language in a simulated 0D environment where it is rewarded for the successful execution of written instructions . Trained via a combination of reinforcement and unsupervised learning , and beginning with minimal prior knowledge , the agent learns to relate linguistic symbols to emergent perceptual representations of its physical surroundings and to pertinent sequences of actions . The agent ' s comprehension of language extends beyond its prior experience , enabling it to apply familiar language to unfamiliar situations and to interpret entirely novel instructions . Moreover , the speed with which this agent learns new words increases as its semantic knowledge grows . This facility for generalising and bootstrapping semantic knowledge indicates the potential of the present approach for reconciling ambiguous natural language with the complexity of the physical world .
Hybrid methods that utilize both content and rating information are commonly used in many recommender systems . However , most of them use either handcrafted features or the bag-of-words representation as a surrogate for the content information but they are neither effective nor natural enough . To address this problem , we develop a collaborative recurrent autoencoder ( CRAE ) which is a denoising recurrent autoencoder ( DRAE ) that models the generation of content sequences in the collaborative filtering ( CF ) setting . The model generalizes recent advances in recurrent deep learning from i . i . d . input to non-i . i . d . ( CF-based ) input and provides a new denoising scheme along with a novel learnable pooling scheme for the recurrent autoencoder . To do this , we first develop a hierarchical Bayesian model for the DRAE and then generalize it to the CF setting . The synergy between denoising and CF enables CRAE to make accurate recommendations while learning to fill in the blanks in sequences . Experiments on real-world datasets from different domains ( CiteULike and Netflix ) show that , by jointly modeling the order-aware generation of sequences for the content information and performing CF for the ratings , CRAE is able to significantly outperform the state of the art on both the recommendation task based on ratings and the sequence generation task based on content information .
We propose a penalized likelihood method that simultaneously fits the multinomial logistic regression model and combines subsets of the response categories . The penalty is non differentiable when pairs of columns in the optimization variable are equal . This encourages pairwise equality of these columns in the estimator , which corresponds to response category combination . We use an alternating direction method of multipliers algorithm to compute the estimator and we discuss the algorithm ' s convergence . Prediction and model selection are also addressed .
We propose a test of independence of two multivariate random vectors , given a sample from the underlying population . Our approach , which we call MINT , is based on the estimation of mutual information , whose decomposition into joint and marginal entropies facilitates the use of recently-developed efficient entropy estimators derived from nearest neighbour distances . The proposed critical values , which may be obtained from simulation ( in the case where one marginal is known ) or resampling , guarantee that the test has nominal size , and we provide local power analyses , uniformly over classes of densities whose mutual information satisfies a lower bound . Our ideas may be extended to provide a new goodness-of-fit tests of normal linear models based on assessing the independence of our vector of covariates and an appropriately-defined notion of an error vector . The theory is supported by numerical studies on both simulated and real data .
In this paper , we present Neural Phrase-based Machine Translation ( NPMT ) . Our method explicitly models the phrase structures in output sequences using Sleep-WAke Networks ( SWAN ) , a recently proposed segmentation-based sequence modeling method . To mitigate the monotonic alignment requirement of SWAN , we introduce a new layer to perform ( soft ) local reordering of input sequences . Different from existing neural machine translation ( NMT ) approaches , NPMT does not use attention-based decoding mechanisms . Instead , it directly outputs phrases in a sequential order . Our experiments show that NPMT achieves superior performances on IWSLT 0000 German-English/English-German and IWSLT 0000 English-Vietnamese machine translation tasks compared with strong NMT baselines . We also observe that our method produces meaningful phrases in output languages .
Reconstruction based subspace clustering methods compute a self reconstruction matrix over the samples and use it for spectral clustering to obtain the final clustering result . Their success largely relies on the assumption that the underlying subspaces are independent , which , however , does not always hold in the applications with increasing number of subspaces . In this paper , we propose a novel reconstruction based subspace clustering model without making the subspace independence assumption . In our model , certain properties of the reconstruction matrix are explicitly characterized using the latent cluster indicators , and the affinity matrix used for spectral clustering can be directly built from the posterior of the latent cluster indicators instead of the reconstruction matrix . Experimental results on both synthetic and real-world datasets show that the proposed model can outperform the state-of-the-art methods .
We consider support recovery in the quadratic logistic regression setting - where the target depends on both p linear terms $x_i$ and up to $p^0$ quadratic terms $x_i x_j$ . Quadratic terms enable prediction/modeling of higher-order effects between features and the target , but when incorporated naively may involve solving a very large regression problem . We consider the sparse case , where at most $s$ terms ( linear or quadratic ) are non-zero , and provide a new faster algorithm . It involves ( a ) identifying the weak support ( i . e . all relevant variables ) and ( b ) standard logistic regression optimization only on these chosen variables . The first step relies on a novel insight about correlation tests in the presence of non-linearity , and takes $O ( pn ) $ time for $n$ samples - giving potentially huge computational gains over the naive approach . Motivated by insights from the boolean case , we propose a non-linear correlation test for non-binary finite support case that involves hashing a variable and then correlating with the output variable . We also provide experimental results to demonstrate the effectiveness of our methods .
Deep neural networks have been developed drawing inspiration from the brain visual pathway , implementing an end-to-end approach : from image data to video object classes . However building an fMRI decoder with the typical structure of Convolutional Neural Network ( CNN ) , i . e . learning multiple level of representations , seems impractical due to lack of brain data . As a possible solution , this work presents the first hybrid fMRI and deep features decoding approach : collected fMRI and deep learnt representations of video object classes are linked together by means of Kernel Canonical Correlation Analysis . In decoding , this allows exploiting the discriminatory power of CNN by relating the fMRI representation to the last layer of CNN ( fc0 ) . We show the effectiveness of embedding fMRI data onto a subspace related to deep features in distinguishing semantic visual categories based solely on brain imaging data .
This paper considers a multiple regression model and compares , under full model hypothesis , analytically as well as by simulation , the performance characteristics of some popular penalty estimators such as ridge regression , LASSO , adaptive LASSO , SCAD , and elastic net versus Least Squares Estimator , restricted estimator , preliminary test estimator , and Stein-type estimators when the dimension of the parameter space is smaller than the sample space dimension . We find that RR uniformly dominates LSE , RE , PTE , SE and PRSE while LASSO , aLASSO , SCAD , and EN uniformly dominates LSE only . Further , it is observed that neither penalty estimators nor Stein-type estimator dominate one another .
Kernel approximation via nonlinear random feature maps is widely used in speeding up kernel machines . There are two main challenges for the conventional kernel approximation methods . First , before performing kernel approximation , a good kernel has to be chosen . Picking a good kernel is a very challenging problem in itself . Second , high-dimensional maps are often required in order to achieve good performance . This leads to high computational cost in both generating the nonlinear maps , and in the subsequent learning and prediction process . In this work , we propose to optimize the nonlinear maps directly with respect to the classification objective in a data-dependent fashion . The proposed approach achieves kernel approximation and kernel learning in a joint framework . This leads to much more compact maps without hurting the performance . As a by-product , the same framework can also be used to achieve more compact kernel maps to approximate a known kernel . We also introduce Circulant Nonlinear Maps , which uses a circulant-structured projection matrix to speed up the nonlinear maps for high-dimensional data .
We attempt to set a mathematical foundation of immunology and amino acid chains . To measure the similarities of these chains , a kernel on strings is defined using only the sequence of the chains and a good amino acid substitution matrix ( e . g . BLOSUM00 ) . The kernel is used in learning machines to predict binding affinities of peptides to human leukocyte antigens DR ( HLA-DR ) molecules . On both fixed allele ( Nielsen and Lund 0000 ) and pan-allele ( Nielsen et . al . 0000 ) benchmark databases , our algorithm achieves the state-of-the-art performance . The kernel is also used to define a distance on an HLA-DR allele set based on which a clustering analysis precisely recovers the serotype classifications assigned by WHO ( Nielsen and Lund 0000 , and Marsh et . al . 0000 ) . These results suggest that our kernel relates well the chain structure of both peptides and HLA-DR molecules to their biological functions , and that it offers a simple , powerful and promising methodology to immunology and amino acid chain studies .
Magnetic resonance image ( MRI ) reconstruction is a severely ill-posed linear inverse task demanding time and resource intensive computations that can substantially trade off {\it accuracy} for {\it speed} in real-time imaging . In addition , state-of-the-art compressed sensing ( CS ) analytics are not cognizant of the image {\it diagnostic quality} . To cope with these challenges we put forth a novel CS framework that permeates benefits from generative adversarial networks ( GAN ) to train a ( low-dimensional ) manifold of diagnostic-quality MR images from historical patients . Leveraging a mixture of least-squares ( LS ) GANs and pixel-wise $\ell_0$ cost , a deep residual network with skip connections is trained as the generator that learns to remove the {\it aliasing} artifacts by projecting onto the manifold . LSGAN learns the texture details , while $\ell_0$ controls the high-frequency noise . A multilayer convolutional neural network is then jointly trained based on diagnostic quality images to discriminate the projection quality . The test phase performs feed-forward propagation over the generator network that demands a very low computational overhead . Extensive evaluations are performed on a large contrast-enhanced MR dataset of pediatric patients . In particular , images rated based on expert radiologists corroborate that GANCS retrieves high contrast images with detailed texture relative to conventional CS , and pixel-wise schemes . In addition , it offers reconstruction under a few milliseconds , two orders of magnitude faster than state-of-the-art CS-MRI schemes .
We study a stochastic and distributed algorithm for nonconvex problems whose objective consists of a sum of $N$ nonconvex $L_i/N$-smooth functions , plus a nonsmooth regularizer . The proposed NonconvEx primal-dual SpliTTing ( NESTT ) algorithm splits the problem into $N$ subproblems , and utilizes an augmented Lagrangian based primal-dual scheme to solve it in a distributed and stochastic manner . With a special non-uniform sampling , a version of NESTT achieves $\epsilon$-stationary solution using $\mathcal{O} ( ( \sum_{i=0}^N\sqrt{L_i/N} ) ^0/\epsilon ) $ gradient evaluations , which can be up to $\mathcal{O} ( N ) $ times better than the ( proximal ) gradient descent methods . It also achieves Q-linear convergence rate for nonconvex $\ell_0$ penalized quadratic problems with polyhedral constraints . Further , we reveal a fundamental connection between primal-dual based methods and a few primal only methods such as IAG/SAG/SAGA .
In iterative supervised learning algorithms it is common to reach a point in the search where no further induction seems to be possible with the available data . If the search is continued beyond this point , the risk of overfitting increases significantly . Following the recent developments in inductive semantic stochastic methods , this paper studies the feasibility of using information gathered from the semantic neighborhood to decide when to stop the search . Two semantic stopping criteria are proposed and experimentally assessed in Geometric Semantic Genetic Programming ( GSGP ) and in the Semantic Learning Machine ( SLM ) algorithm ( the equivalent algorithm for neural networks ) . The experiments are performed on real-world high-dimensional regression datasets . The results show that the proposed semantic stopping criteria are able to detect stopping points that result in a competitive generalization for both GSGP and SLM . This approach also yields computationally efficient algorithms as it allows the evolution of neural networks in less than 0 seconds on average , and of GP trees in at most 00 seconds . The usage of the proposed semantic stopping criteria in conjunction with the computation of optimal mutation/learning steps also results in small trees and neural networks .
Hypergraph partitioning lies at the heart of a number of problems in machine learning and network sciences . Many algorithms for hypergraph partitioning have been proposed that extend standard approaches for graph partitioning to the case of hypergraphs . However , theoretical aspects of such methods have seldom received attention in the literature as compared to the extensive studies on the guarantees of graph partitioning . For instance , consistency results of spectral graph partitioning under the stochastic block model are well known . In this paper , we present a planted partition model for sparse random non-uniform hypergraphs that generalizes the stochastic block model . We derive an error bound for a spectral hypergraph partitioning algorithm under this model using matrix concentration inequalities . To the best of our knowledge , this is the first consistency result related to partitioning non-uniform hypergraphs .
When applying the support vector machine ( SVM ) to high-dimensional classification problems , we often impose a sparse structure in the SVM to eliminate the influences of the irrelevant predictors . The lasso and other variable selection techniques have been successfully used in the SVM to perform automatic variable selection . In some problems , there is a natural hierarchical structure among the variables . Thus , in order to have an interpretable SVM classifier , it is important to respect the heredity principle when enforcing the sparsity in the SVM . Many variable selection methods , however , do not respect the heredity principle . In this paper we enforce both sparsity and the heredity principle in the SVM by using the so-called structured variable selection ( SVS ) framework originally proposed in Yuan , Joseph and Zou ( 0000 ) . We minimize the empirical hinge loss under a set of linear inequality constraints and a lasso-type penalty . The solution always obeys the desired heredity principle and enjoys sparsity . The new SVM classifier can be efficiently fitted , because the optimization problem is a linear program . Another contribution of this work is to present a nonparametric extension of the SVS framework , and we propose nonparametric heredity SVMs . Simulated and real data are used to illustrate the merits of the proposed method .
Inference and Estimation in Missing Information ( MI ) scenarios are important topics in Statistical Learning Theory and Machine Learning ( ML ) . In ML literature , attempts have been made to enhance prediction through precise feature selection methods . In sparse linear models , LASSO is well-known in extracting the desired support of the signal and resisting against noisy systems . When sparse models are also suffering from MI , the sparse recovery and inference of the missing models are taken into account simultaneously . In this paper , we will introduce an approach which enjoys sparse regression and covariance matrix estimation to improve matrix completion accuracy , and as a result enhancing feature selection preciseness which leads to reduction in prediction Mean Squared Error ( MSE ) . We will compare the effect of employing covariance matrix in enhancing estimation accuracy to the case it is not used in feature selection . Simulations show the improvement in the performance as compared to the case where the covariance matrix estimation is not used .
This paper presents the first theoretical results showing that stable identification of overcomplete $\mu$-coherent dictionaries $\Phi \in \mathbb{R}^{d\times K}$ is locally possible from training signals with sparsity levels $S$ up to the order $O ( \mu^{-0} ) $ and signal to noise ratios up to $O ( \sqrt{d} ) $ . In particular the dictionary is recoverable as the local maximum of a new maximisation criterion that generalises the K-means criterion . For this maximisation criterion results for asymptotic exact recovery for sparsity levels up to $O ( \mu^{-0} ) $ and stable recovery for sparsity levels up to $O ( \mu^{-0} ) $ as well as signal to noise ratios up to $O ( \sqrt{d} ) $ are provided . These asymptotic results translate to finite sample size recovery results with high probability as long as the sample size $N$ scales as $O ( K^0dS \tilde \varepsilon^{-0} ) $ , where the recovery precision $\tilde \varepsilon$ can go down to the asymptotically achievable precision . Further , to actually find the local maxima of the new criterion , a very simple Iterative Thresholding and K ( signed ) Means algorithm ( ITKM ) , which has complexity $O ( dKN ) $ in each iteration , is presented and its local efficiency is demonstrated in several experiments .
We present a novel approach for supervised domain adaptation that is based upon the probabilistic framework of Gaussian processes ( GPs ) . Specifically , we introduce domain-specific GPs as local experts for facial expression classification from face images . The adaptation of the classifier is facilitated in probabilistic fashion by conditioning the target expert on multiple source experts . Furthermore , in contrast to existing adaptation approaches , we also learn a target expert from available target data solely . Then , a single and confident classifier is obtained by combining the predictions from multiple experts based on their confidence . Learning of the model is efficient and requires no retraining/reweighting of the source classifiers . We evaluate the proposed approach on two publicly available datasets for multi-class ( MultiPIE ) and multi-label ( DISFA ) facial expression classification . To this end , we perform adaptation of two contextual factors : ' where ' ( view ) and ' who ' ( subject ) . We show in our experiments that the proposed approach consistently outperforms both source and target classifiers , while using as few as 00 target examples . It also outperforms the state-of-the-art approaches for supervised domain adaptation .
Joint state and parameter estimation is a core problem for dynamic Bayesian networks . Although modern probabilistic inference toolkits make it relatively easy to specify large and practically relevant probabilistic models , the silver bullet---an efficient and general online inference algorithm for such problems---remains elusive , forcing users to write special-purpose code for each application . We propose a novel blackbox algorithm -- a hybrid of particle filtering for state variables and assumed density filtering for parameter variables . It has following advantages : ( a ) it is efficient due to its online nature , and ( b ) it is applicable to both discrete and continuous parameter spaces . On a variety of toy and real models , our system is able to generate more accurate results within a fixed computation budget . This preliminary evidence indicates that the proposed approach is likely to be of practical use .
Clustering analysis by nonnegative low-rank approximations has achieved remarkable progress in the past decade . However , most approximation approaches in this direction are still restricted to matrix factorization . We propose a new low-rank learning method to improve the clustering performance , which is beyond matrix factorization . The approximation is based on a two-step bipartite random walk through virtual cluster nodes , where the approximation is formed by only cluster assigning probabilities . Minimizing the approximation error measured by Kullback-Leibler divergence is equivalent to maximizing the likelihood of a discriminative model , which endows our method with a solid probabilistic interpretation . The optimization is implemented by a relaxed Majorization-Minimization algorithm that is advantageous in finding good local minima . Furthermore , we point out that the regularized algorithm with Dirichlet prior only serves as initialization . Experimental results show that the new method has strong performance in clustering purity for various datasets , especially for large-scale manifold data .
Mini-batch optimization has proven to be a powerful paradigm for large-scale learning . However , the state of the art parallel mini-batch algorithms assume synchronous operation or cyclic update orders . When worker nodes are heterogeneous ( due to different computational capabilities or different communication delays ) , synchronous and cyclic operations are inefficient since they will leave workers idle waiting for the slower nodes to complete their computations . In this paper , we propose an asynchronous mini-batch algorithm for regularized stochastic optimization problems with smooth loss functions that eliminates idle waiting and allows workers to run at their maximal update rates . We show that by suitably choosing the step-size values , the algorithm achieves a rate of the order $O ( 0/\sqrt{T} ) $ for general convex regularization functions , and the rate $O ( 0/T ) $ for strongly convex regularization functions , where $T$ is the number of iterations . In both cases , the impact of asynchrony on the convergence rate of our algorithm is asymptotically negligible , and a near-linear speedup in the number of workers can be expected . Theoretical results are confirmed in real implementations on a distributed computing infrastructure .
In many real-world problems , we are dealing with collections of high-dimensional data , such as images , videos , text and web documents , DNA microarray data , and more . Often , high-dimensional data lie close to low-dimensional structures corresponding to several classes or categories the data belongs to . In this paper , we propose and study an algorithm , called Sparse Subspace Clustering ( SSC ) , to cluster data points that lie in a union of low-dimensional subspaces . The key idea is that , among infinitely many possible representations of a data point in terms of other points , a sparse representation corresponds to selecting a few points from the same subspace . This motivates solving a sparse optimization program whose solution is used in a spectral clustering framework to infer the clustering of data into subspaces . Since solving the sparse optimization program is in general NP-hard , we consider a convex relaxation and show that , under appropriate conditions on the arrangement of subspaces and the distribution of data , the proposed minimization program succeeds in recovering the desired sparse representations . The proposed algorithm can be solved efficiently and can handle data points near the intersections of subspaces . Another key advantage of the proposed algorithm with respect to the state of the art is that it can deal with data nuisances , such as noise , sparse outlying entries , and missing entries , directly by incorporating the model of the data into the sparse optimization program . We demonstrate the effectiveness of the proposed algorithm through experiments on synthetic data as well as the two real-world problems of motion segmentation and face clustering .
In many signal processing applications , the aim is to reconstruct a signal that has a simple representation with respect to a certain basis or frame . Fundamental elements of the basis known as " atoms " allow us to define " atomic norms " that can be used to formulate convex regularizations for the reconstruction problem . Efficient algorithms are available to solve these formulations in certain special cases , but an approach that works well for general atomic norms , both in terms of speed and reconstruction accuracy , remains to be found . This paper describes an optimization algorithm called CoGEnT that produces solutions with succinct atomic representations for reconstruction problems , generally formulated with atomic-norm constraints . CoGEnT combines a greedy selection scheme based on the conditional gradient approach with a backward ( or " truncation " ) step that exploits the quadratic nature of the objective to reduce the basis size . We establish convergence properties and validate the algorithm via extensive numerical experiments on a suite of signal processing applications . Our algorithm and analysis also allow for inexact forward steps and for occasional enhancements of the current representation to be performed . CoGEnT can outperform the basic conditional gradient method , and indeed many methods that are tailored to specific applications , when the enhancement and truncation steps are defined appropriately . We also introduce several novel applications that are enabled by the atomic-norm framework , including tensor completion , moment problems in signal processing , and graph deconvolution .
We propose a framework to perform streaming covariance selection . Our approach employs regularization constraints where a time-varying sparsity parameter is iteratively estimated via stochastic gradient descent . This allows for the regularization parameter to be efficiently learnt in an online manner . The proposed framework is developed for linear regression models and extended to graphical models via neighbourhood selection . Under mild assumptions , we are able to obtain convergence results in a non-stochastic setting . The capabilities of such an approach are demonstrated using both synthetic data as well as neuroimaging data .
We consider high-dimensional quadratic classifiers in non-sparse settings . The target of classification rules is not Bayes error rates in the context . The classifier based on the Mahalanobis distance does not always give a preferable performance even if the populations are normal distributions having known covariance matrices . The quadratic classifiers proposed in this paper draw information about heterogeneity effectively through both the differences of expanding mean vectors and covariance matrices . We show that they hold a consistency property in which misclassification rates tend to zero as the dimension goes to infinity under non-sparse settings . We verify that they are asymptotically distributed as a normal distribution under certain conditions . We also propose a quadratic classifier after feature selection by using both the differences of mean vectors and covariance matrices . Finally , we discuss performances of the classifiers in actual data analyses . The proposed classifiers achieve highly accurate classification with very low computational costs .
We introduce the localized Lasso , which is suited for learning models that are both interpretable and have a high predictive power in problems with high dimensionality $d$ and small sample size $n$ . More specifically , we consider a function defined by local sparse models , one at each data point . We introduce sample-wise network regularization to borrow strength across the models , and sample-wise exclusive group sparsity ( a . k . a . , $\ell_{0 , 0}$ norm ) to introduce diversity into the choice of feature sets in the local models . The local models are interpretable in terms of similarity of their sparsity patterns . The cost function is convex , and thus has a globally optimal solution . Moreover , we propose a simple yet efficient iterative least-squares based optimization procedure for the localized Lasso , which does not need a tuning parameter , and is guaranteed to converge to a globally optimal solution . The solution is empirically shown to outperform alternatives for both simulated and genomic personalized medicine data .
A method for quickly determining deployment schedules that meet a given fuel cycle demand is presented here . This algorithm is fast enough to perform in situ within low-fidelity fuel cycle simulators . It uses Gaussian process regression models to predict the production curve as a function of time and the number of deployed facilities . Each of these predictions is measured against the demand curve using the dynamic time warping distance . The minimum distance deployment schedule is evaluated in a full fuel cycle simulation , whose generated production curve then informs the model on the next optimization iteration . The method converges within five to ten iterations to a distance that is less than one percent of the total deployable production . A representative once-through fuel cycle is used to demonstrate the methodology for reactor deployment .
We propose a novel statistical model for sparse networks with overlapping community structure . The model is based on representing the graph as an exchangeable point process , and naturally generalizes existing probabilistic models with overlapping block-structure to the sparse regime . Our construction builds on vectors of completely random measures , and has interpretable parameters , each node being assigned a vector representing its level of affiliation to some latent communities . We develop methods for simulating this class of random graphs , as well as to perform posterior inference . We show that the proposed approach can recover interpretable structure from two real-world networks and can handle graphs with thousands of nodes and tens of thousands of edges .
Directed acyclic graphs ( DAGs ) are commonly used to represent causal relationships among random variables in graphical models . Applications of these models arise in the study of physical , as well as biological systems , where directed edges between nodes represent the influence of components of the system on each other . The general problem of estimating DAGs from observed data is computationally NP-hard , Moreover two directed graphs may be observationally equivalent . When the nodes exhibit a natural ordering , the problem of estimating directed graphs reduces to the problem of estimating the structure of the network . In this paper , we propose a penalized likelihood approach that directly estimates the adjacency matrix of DAGs . Both lasso and adaptive lasso penalties are considered and an efficient algorithm is proposed for estimation of high dimensional DAGs . We study variable selection consistency of the two penalties when the number of variables grows to infinity with the sample size . We show that although lasso can only consistently estimate the true network under stringent assumptions , adaptive lasso achieves this task under mild regularity conditions . The performance of the proposed methods is compared to alternative methods in simulated , as well as real , data examples .
Gathering the most information by picking the least amount of data is a common task in experimental design or when exploring an unknown environment in reinforcement learning and robotics . A widely used measure for quantifying the information contained in some distribution of interest is its entropy . Greedily minimizing the expected entropy is therefore a standard method for choosing samples in order to gain strong beliefs about the underlying random variables . We show that this approach is prone to temporally getting stuck in local optima corresponding to wrongly biased beliefs . We suggest instead maximizing the expected cross entropy between old and new belief , which aims at challenging refutable beliefs and thereby avoids these local optima . We show that both criteria are closely related and that their difference can be traced back to the asymmetry of the Kullback-Leibler divergence . In illustrative examples as well as simulated and real-world experiments we demonstrate the advantage of cross entropy over simple entropy for practical applications .
We present a general framework for accelerating a large class of widely used Markov chain Monte Carlo ( MCMC ) algorithms . Our approach exploits fast , iterative approximations to the target density to speculatively evaluate many potential future steps of the chain in parallel . The approach can accelerate computation of the target distribution of a Bayesian inference problem , without compromising exactness , by exploiting subsets of data . It takes advantage of whatever parallel resources are available , but produces results exactly equivalent to standard serial execution . In the initial burn-in phase of chain evaluation , it achieves speedup over serial evaluation that is close to linear in the number of available cores .
Databases are widespread , yet extracting relevant data can be difficult . Without substantial domain knowledge , multivariate search queries often return sparse or uninformative results . This paper introduces an approach for searching structured data based on probabilistic programming and nonparametric Bayes . Users specify queries in a probabilistic language that combines standard SQL database search operators with an information theoretic ranking function called predictive relevance . Predictive relevance can be calculated by a fast sparse matrix algorithm based on posterior samples from CrossCat , a nonparametric Bayesian model for high-dimensional , heterogeneously-typed data tables . The result is a flexible search technique that applies to a broad class of information retrieval problems , which we integrate into BayesDB , a probabilistic programming platform for probabilistic data analysis . This paper demonstrates applications to databases of US colleges , global macroeconomic indicators of public health , and classic cars . We found that human evaluators often prefer the results from probabilistic search to results from a standard baseline .
One way to avoid overfitting in machine learning is to use model parameters distributed according to a Bayesian posterior given the data , rather than the maximum likelihood estimator . Stochastic gradient Langevin dynamics ( SGLD ) is one algorithm to approximate such Bayesian posteriors for large models and datasets . SGLD is a standard stochastic gradient descent to which is added a controlled amount of noise , specifically scaled so that the parameter converges in law to the posterior distribution [WT00 , TTV00] . The posterior predictive distribution can be approximated by an ensemble of samples from the trajectory . Choice of the variance of the noise is known to impact the practical behavior of SGLD : for instance , noise should be smaller for sensitive parameter directions . Theoretically , it has been suggested to use the inverse Fisher information matrix of the model as the variance of the noise , since it is also the variance of the Bayesian posterior [PT00 , AKW00 , GC00] . But the Fisher matrix is costly to compute for large- dimensional models . Here we use the easily computed Fisher matrix approximations for deep neural networks from [MO00 , Oll00] . The resulting natural Langevin dynamics combines the advantages of Amari ' s natural gradient descent and Fisher-preconditioned Langevin dynamics for large neural networks . Small-scale experiments on MNIST show that Fisher matrix preconditioning brings SGLD close to dropout as a regularizing technique .
High-dimensional data pose challenges in statistical learning and modeling . Sometimes the predictors can be naturally grouped where pursuing the between-group sparsity is desired . Collinearity may occur in real-world high-dimensional applications where the popular $l_0$ technique suffers from both selection inconsistency and prediction inaccuracy . Moreover , the problems of interest often go beyond Gaussian models . To meet these challenges , nonconvex penalized generalized linear models with grouped predictors are investigated and a simple-to-implement algorithm is proposed for computation . A rigorous theoretical result guarantees its convergence and provides tight preliminary scaling . This framework allows for grouped predictors and nonconvex penalties , including the discrete $l_0$ and the `$l_0+l_0$ ' type penalties . Penalty design and parameter tuning for nonconvex penalties are examined . Applications of super-resolution spectrum estimation in signal processing and cancer classification with joint gene selection in bioinformatics show the performance improvement by nonconvex penalized estimation .
We create a new online reduction of multiclass classification to binary classification for which training and prediction time scale logarithmically with the number of classes . Compared to previous approaches , we obtain substantially better statistical performance for two reasons : First , we prove a tighter and more complete boosting theorem , and second we translate the results more directly into an algorithm . We show that several simple techniques give rise to an algorithm that can compete with one-against-all in both space and predictive power while offering exponential improvements in speed when the number of classes is large .
We propose an efficient Context-Aware clustering of Bandits ( CAB ) algorithm , which can capture collaborative effects . CAB can be easily deployed in a real-world recommendation system , where multi-armed bandits have been shown to perform well in particular with respect to the cold-start problem . CAB utilizes a context-aware clustering augmented by exploration-exploitation strategies . CAB dynamically clusters the users based on the content universe under consideration . We give a theoretical analysis in the standard stochastic multi-armed bandits setting . We show the efficiency of our approach on production and real-world datasets , demonstrate the scalability , and , more importantly , the significant increased prediction performance against several state-of-the-art methods .
We consider active maximum a posteriori ( MAP ) inference problem for Hidden Markov Models ( HMM ) , where , given an initial MAP estimate of the hidden sequence , we select to label certain states in the sequence to improve the estimation accuracy of the remaining states . We develop an analytical approach to this problem for the case of binary symmetric HMMs , and obtain a closed form solution that relates the expected error reduction to model parameters under the specified active inference scheme . We then use this solution to determine most optimal active inference scheme in terms of error reduction , and examine the relation of those schemes to heuristic principles of uncertainty reduction and solution unicity .
Drug-drug interaction ( DDI ) is a major cause of morbidity and mortality and a subject of intense scientific interest . Biomedical literature mining can aid DDI research by extracting evidence for large numbers of potential interactions from published literature and clinical databases . Though DDI is investigated in domains ranging in scale from intracellular biochemistry to human populations , literature mining has not been used to extract specific types of experimental evidence , which are reported differently for distinct experimental goals . We focus on pharmacokinetic evidence for DDI , essential for identifying causal mechanisms of putative interactions and as input for further pharmacological and pharmaco-epidemiology investigations . We used manually curated corpora of PubMed abstracts and annotated sentences to evaluate the efficacy of literature mining on two tasks : first , identifying PubMed abstracts containing pharmacokinetic evidence of DDIs ; second , extracting sentences containing such evidence from abstracts . We implemented a text mining pipeline and evaluated it using several linear classifiers and a variety of feature transforms . The most important textual features in the abstract and sentence classification tasks were analyzed . We also investigated the performance benefits of using features derived from PubMed metadata fields , various publicly available named entity recognizers , and pharmacokinetic dictionaries . Several classifiers performed very well in distinguishing relevant and irrelevant abstracts ( reaching F0~=0 . 00 , MCC~=0 . 00 , iAUC~=0 . 00 ) and sentences ( F0~=0 . 00 , MCC~=0 . 00 , iAUC~=0 . 00 ) . We found that word bigram features were important for achieving optimal classifier performance and that features derived from Medical Subject Headings ( MeSH ) terms significantly improved abstract classification . . . .
Robust high-dimensional data processing has witnessed an exciting development in recent years , as theoretical results have shown that it is possible using convex programming to optimize data fit to a low-rank component plus a sparse outlier component . This problem is also known as Robust PCA , and it has found application in many areas of computer vision . In image and video processing and face recognition , the opportunity to process massive image databases is emerging as people upload photo and video data online in unprecedented volumes . However , data quality and consistency is not controlled in any way , and the massiveness of the data poses a serious computational challenge . In this paper we present t-GRASTA , or " Transformed GRASTA ( Grassmannian Robust Adaptive Subspace Tracking Algorithm ) " . t-GRASTA iteratively performs incremental gradient descent constrained to the Grassmann manifold of subspaces in order to simultaneously estimate a decomposition of a collection of images into a low-rank subspace , a sparse part of occlusions and foreground objects , and a transformation such as rotation or translation of the image . We show that t-GRASTA is 0 $\times$ faster than state-of-the-art algorithms , has half the memory requirement , and can achieve alignment for face images as well as jittered camera surveillance images .
In this paper , we propose a novel application of Generative Adversarial Networks ( GAN ) to the synthesis of cells imaged by fluorescence microscopy . Compared to natural images , cells tend to have a simpler and more geometric global structure that facilitates image generation . However , the correlation between the spatial pattern of different fluorescent proteins reflects important biological functions , and synthesized images have to capture these relationships to be relevant for biological applications . We adapt GANs to the task at hand and propose new models with casual dependencies between image channels that can generate multi-channel images , which would be impossible to obtain experimentally . We evaluate our approach using two independent techniques and compare it against sensible baselines . Finally , we demonstrate that by interpolating across the latent space we can mimic the known changes in protein localization that occur through time during the cell cycle , allowing us to predict temporal evolution from static images .
Most classification methods provide either a prediction of class membership or an assessment of class membership probability . In the case of two-group classification the predicted probability can be described as " risk " of belonging to a " special " class . When the required output is a set of ordinal-risk groups , a discretization of the continuous risk prediction is achieved by two common methods : by constructing a set of models that describe the conditional risk function at specific points ( quantile regression ) or by dividing the output of an " optimal " classification model into adjacent intervals that correspond to the desired risk groups . By defining a new error measure for the distribution of risk onto intervals we are able to identify lower bounds on the accuracy of these methods , showing sub-optimality both in their distribution of risk and in the efficiency of their resulting partition into intervals . By adding a new form of constraint to the existing maximum likelihood optimization framework and by introducing a penalty function to avoid degenerate solutions , we show how existing methods can be augmented to solve the ordinal risk-group classification problem . We implement our method for logistic regression ( LR ) and show a numeric example .
In intractable , undirected graphical models , an intuitive way of creating structured mean field approximations is to select an acyclic tractable subgraph . We show that the hardness of computing the objective function and gradient of the mean field objective qualitatively depends on a simple graph property . If the tractable subgraph has this property- we call such subgraphs v-acyclic-a very fast block coordinate ascent algorithm is possible . If not , optimization is harder , but we show a new algorithm based on the construction of an auxiliary exponential family that can be used to make inference possible in this case as well . We discuss the advantages and disadvantages of each regime and compare the algorithms empirically .
The problem of finding overlapping communities in networks has gained much attention recently . Optimization-based approaches use non-negative matrix factorization ( NMF ) or variants , but the global optimum cannot be provably attained in general . Model-based approaches , such as the popular mixed-membership stochastic blockmodel or MMSB ( Airoldi et al . , 0000 ) , use parameters for each node to specify the overlapping communities , but standard inference techniques cannot guarantee consistency . We link the two approaches , by ( a ) establishing sufficient conditions for the symmetric NMF optimization to have a unique solution under MMSB , and ( b ) proposing a computationally efficient algorithm called GeoNMF that is provably optimal and hence consistent for a broad parameter regime . We demonstrate its accuracy on both simulated and real-world datasets .
There have been several spectral bounds for the percolation transition in networks , using spectrum of matrices associated with the network such as the adjacency matrix and the non-backtracking matrix . However they are far from being tight when the network is sparse and displays clustering or transitivity , which is represented by existence of short loops e . g . triangles . In this work , for the bond percolation , we first propose a message passing algorithm for calculating size of percolating clusters considering effects of triangles , then relate the percolation transition to the leading eigenvalue of a matrix that we name the triangle-non-backtracking matrix , by analyzing stability of the message passing equations . We establish that our method gives a tighter lower-bound to the bond percolation transition than previous spectral bounds , and it becomes exact for an infinite network with no loops longer than 0 . We evaluate numerically our methods on synthetic and real-world networks , and discuss further generalizations of our approach to include higher-order sub-structures .
Variational inference ( VI ) is widely used as an efficient alternative to Markov chain Monte Carlo . It posits a family of approximating distributions $q$ and finds the closest member to the exact posterior $p$ . Closeness is usually measured via a divergence $D ( q || p ) $ from $q$ to $p$ . While successful , this approach also has problems . Notably , it typically leads to underestimation of the posterior variance . In this paper we propose CHIVI , a black-box variational inference algorithm that minimizes $D_{\chi} ( p || q ) $ , the $\chi$-divergence from $p$ to $q$ . CHIVI minimizes an upper bound of the model evidence , which we term the $\chi$ upper bound ( CUBO ) . Minimizing the CUBO leads to improved posterior uncertainty , and it can also be used with the classical VI lower bound ( ELBO ) to provide a sandwich estimate of the model evidence . We study CHIVI on three models : probit regression , Gaussian process classification , and a Cox process model of basketball plays . When compared to expectation propagation and classical VI , CHIVI produces better error rates and more accurate estimates of posterior variance .
Graph connection Laplacian ( GCL ) is a modern data analysis technique that is starting to be applied for the analysis of high dimensional and massive datasets . Motivated by this technique , we study matrices that are akin to the ones appearing in the null case of GCL , i . e the case where there is no structure in the dataset under investigation . Developing this understanding is important in making sense of the output of the algorithms based on GCL . We hence develop a theory explaining the behavior of the spectral distribution of a large class of random matrices , in particular random matrices with random block entries of fixed size . Part of the theory covers the case where there is significant dependence between the blocks . Numerical work shows that the agreement between our theoretical predictions and numerical simulations is generally very good .
We present a solution to scale spectral algorithms for learning sequence functions . We are interested in the case where these functions are sparse ( that is , for most sequences they return 0 ) . Spectral algorithms reduce the learning problem to the task of computing an SVD decomposition over a special type of matrix called the Hankel matrix . This matrix is designed to capture the relevant statistics of the training sequences . What is crucial is that to capture long range dependencies we must consider very large Hankel matrices . Thus the computation of the SVD becomes a critical bottleneck . Our solution finds a subset of rows and columns of the Hankel that realizes a compact and informative Hankel submatrix . The novelty lies in the way that this subset is selected : we exploit a maximal bipartite matching combinatorial algorithm to look for a sub-block with full structural rank , and show how computation of this sub-block can be further improved by exploiting the specific structure of Hankel matrices .
This paper aims to develop a new and robust approach to feature representation . Motivated by the success of Auto-Encoders , we first theoretical summarize the general properties of all algorithms that are based on traditional Auto-Encoders : 0 ) The reconstruction error of the input or corrupted input can not be lower than a lower bound , which can be viewed as a guiding principle for reconstructing the input or corrupted input . 0 ) The reconstruction of a hidden representation achieving its ideal situation is the necessary condition for the reconstruction of the input to reach the ideal state . 0 ) Minimizing the Frobenius norm of the Jacobian matrix has a deficiency and may result in a much worse local optimum value . 0 ) Minimizing the reconstruction error of the hidden representation is more robust than minimizing the Frobenius norm of the Jacobian matrix . Based on the above analysis , we propose a new model termed Double Denoising Auto-Encoders ( DDAEs ) , which uses corruption and reconstruction on both the input and the hidden representation . We demonstrate that the proposed model is highly flexible and extensible . We also show that for handling inessential features , our model is more robust than Denoising Auto-Encoders ( DAEs ) . Comparative experiments illustrate that our model is significantly better for representation learning than the state-of-the-art models .
Non-Gaussian component analysis ( NGCA ) is aimed at identifying a linear subspace such that the projected data follows a non-Gaussian distribution . In this paper , we propose a novel NGCA algorithm based on log-density gradient estimation . Unlike existing methods , the proposed NGCA algorithm identifies the linear subspace by using the eigenvalue decomposition without any iterative procedures , and thus is computationally reasonable . Furthermore , through theoretical analysis , we prove that the identified subspace converges to the true subspace at the optimal parametric rate . Finally , the practical performance of the proposed algorithm is demonstrated on both artificial and benchmark datasets .
We consider the problem of high-dimensional Ising ( graphical ) model selection . We propose a simple algorithm for structure estimation based on the thresholding of the empirical conditional variation distances . We introduce a novel criterion for tractable graph families , where this method is efficient , based on the presence of sparse local separators between node pairs in the underlying graph . For such graphs , the proposed algorithm has a sample complexity of $n=\Omega ( J_{\min}^{-0}\log p ) $ , where $p$ is the number of variables , and $J_{\min}$ is the minimum ( absolute ) edge potential in the model . We also establish nonasymptotic necessary and sufficient conditions for structure estimation .
Given an overcomplete dictionary $A$ and a signal $b$ that is a linear combination of a few linearly independent columns of $A$ , classical sparse recovery theory deals with the problem of recovering the unique sparse representation $x$ such that $b = A x$ . It is known that under certain conditions on $A$ , $x$ can be recovered by the Basis Pursuit ( BP ) and the Orthogonal Matching Pursuit ( OMP ) algorithms . In this work , we consider the more general case where $b$ lies in a low-dimensional subspace spanned by some columns of $A$ , which are possibly linearly dependent . In this case , the sparsest solution $x$ is generally not unique , and we study the problem that the representation $x$ identifies the subspace , i . e . the nonzero entries of $x$ correspond to dictionary atoms that are in the subspace . Such a representation $x$ is called subspace-sparse . We present sufficient conditions for guaranteeing subspace-sparse recovery , which have clear geometric interpretations and explain properties of subspace-sparse recovery . We also show that the sufficient conditions can be satisfied under a randomized model . Our results are applicable to the traditional sparse recovery problem and we get conditions for sparse recovery that are less restrictive than the canonical mutual coherent condition . We also use the results to analyze the sparse representation based classification ( SRC ) method , for which we get conditions to show its correctness .
In the last few years , we have seen the transformative impact of deep learning in many applications , particularly in speech recognition and computer vision . Inspired by Google ' s Inception-ResNet deep convolutional neural network ( CNN ) for image classification , we have developed " Chemception " , a deep CNN for the prediction of chemical properties , using just the images of 0D drawings of molecules . We develop Chemception without providing any additional explicit chemistry knowledge , such as basic concepts like periodicity , or advanced features like molecular descriptors and fingerprints . We then show how Chemception can serve as a general-purpose neural network architecture for predicting toxicity , activity , and solvation properties when trained on a modest database of 000 to 00 , 000 compounds . When compared to multi-layer perceptron ( MLP ) deep neural networks trained with ECFP fingerprints , Chemception slightly outperforms in activity and solvation prediction and slightly underperforms in toxicity prediction . Having matched the performance of expert-developed QSAR/QSPR deep learning models , our work demonstrates the plausibility of using deep neural networks to assist in computational chemistry research , where the feature engineering process is performed primarily by a deep learning algorithm .
Researchers have used from 00 days to several years of daily returns as source data for clustering financial time series based on their correlations . This paper sets up a statistical framework to study the validity of such practices . We first show that clustering correlated random variables from their observed values is statistically consistent . Then , we also give a first empirical answer to the much debated question : How long should the time series be ? If too short , the clusters found can be spurious ; if too long , dynamics can be smoothed out .
Independent component analysis ( ICA ) is a powerful method for blind source separation based on the assumption that sources are statistically independent . Though ICA has proven useful and has been employed in many applications , complete statistical independence can be too restrictive an assumption in practice . Additionally , important prior information about the data , such as sparsity , is usually available . Sparsity is a natural property of the data , a form of diversity , which , if incorporated into the ICA model , can relax the independence assumption , resulting in an improvement in the overall separation performance . In this work , we propose a new variant of ICA by entropy bound minimization ( ICA-EBM ) -a flexible , yet parameter-free algorithm-through the direct exploitation of sparsity . Using this new SparseICA-EBM algorithm , we study the synergy of independence and sparsity through simulations on synthetic as well as functional magnetic resonance imaging ( fMRI ) -like data .
Tree ensemble models such as random forests and boosted trees are among the most widely used and practically successful predictive models in applied machine learning and business analytics . Although such models have been used to make predictions based on exogenous , uncontrollable independent variables , they are increasingly being used to make predictions where the independent variables are controllable and are also decision variables . In this paper , we study the problem of tree ensemble optimization : given a tree ensemble that predicts some dependent variable using controllable independent variables , how should we set these variables so as to maximize the predicted value ? We formulate the problem as a mixed-integer optimization problem . We theoretically examine the strength of our formulation , provide a hierarchy of approximate formulations with bounds on approximation quality and exploit the structure of the problem to develop two large-scale solution methods , one based on Benders decomposition and one based on iteratively generating tree split constraints . We test our methodology on real data sets , including two case studies in drug design and customized pricing , and show that our methodology can efficiently solve large-scale instances to near or full optimality , and outperforms solutions obtained by heuristic approaches . In our drug design case , we show how our approach can identify compounds that efficiently trade-off predicted performance and novelty with respect to existing , known compounds . In our customized pricing case , we show how our approach can efficiently determine optimal store-level prices under a random forest model that delivers excellent predictive accuracy .
As traditional neural network consumes a significant amount of computing resources during back propagation , \citet{Sun0000mePropSB} propose a simple yet effective technique to alleviate this problem . In this technique , only a small subset of the full gradients are computed to update the model parameters . In this paper we extend this technique into the Convolutional Neural Network ( CNN ) to reduce calculation in back propagation , and the surprising results verify its validity in CNN : only 0\% of the gradients are passed back but the model still achieves the same effect as the traditional CNN , or even better . We also show that the top-$k$ selection of gradients leads to a sparse calculation in back propagation , which may bring significant computational benefits for high computational complexity of convolution operation in CNN .
The goal of the paper is to design sequential strategies which lead to efficient optimization of an unknown function under the only assumption that it has a finite Lipschitz constant . We first identify sufficient conditions for the consistency of generic sequential algorithms and formulate the expected minimax rate for their performance . We introduce and analyze a first algorithm called LIPO which assumes the Lipschitz constant to be known . Consistency , minimax rates for LIPO are proved , as well as fast rates under an additional H\ " older like condition . An adaptive version of LIPO is also introduced for the more realistic setup where the Lipschitz constant is unknown and has to be estimated along with the optimization . Similar theoretical guarantees are shown to hold for the adaptive LIPO algorithm and a numerical assessment is provided at the end of the paper to illustrate the potential of this strategy with respect to state-of-the-art methods over typical benchmark problems for global optimization .
Building models , or maps , of robot environments is a highly active research area ; however , most existing techniques construct unstructured maps and assume static environments . In this paper , we present an algorithm for learning object models of non-stationary objects found in office-type environments . Our algorithm exploits the fact that many objects found in office environments look alike ( e . g . , chairs , recycling bins ) . It does so through a two-level hierarchical representation , which links individual objects with generic shape templates of object classes . We derive an approximate EM algorithm for learning shape parameters at both levels of the hierarchy , using local occupancy grid maps for representing shape . Additionally , we develop a Bayesian model selection algorithm that enables the robot to estimate the total number of objects and object templates in the environment . Experimental results using a real robot equipped with a laser range finder indicate that our approach performs well at learning object-based maps of simple office environments . The approach outperforms a previously developed non-hierarchical algorithm that models objects but lacks class templates .
The performance of stochastic gradient descent ( SGD ) depends critically on how learning rates are tuned and decreased over time . We propose a method to automatically adjust multiple learning rates so as to minimize the expected error at any one time . The method relies on local gradient variations across samples . In our approach , learning rates can increase as well as decrease , making it suitable for non-stationary problems . Using a number of convex and non-convex learning tasks , we show that the resulting algorithm matches the performance of SGD or other adaptive approaches with their best settings obtained through systematic search , and effectively removes the need for learning rate tuning .
Multipath is among the major sources of errors in precise positioning using GPS and continues to be extensively studied . Two Fast Fourier Transform ( FFT ) -based detectors are presented in this paper as GPS multipath detection techniques . The detectors are formulated as binary hypothesis tests under the assumption that the multipath exists for a sufficient time frame that allows its detection based on the quadrature arm of the coherent Early-minus-Late discriminator ( Q EmL ) for a scalar tracking loop ( STL ) or on the quadrature ( Q EmL ) and/or in-phase arm ( I EmL ) for a vector tracking loop ( VTL ) , using an observation window of N samples . Performance analysis of the suggested detectors is done on multipath signal data acquired from the multipath environment simulator developed by the German Aerospace Centre ( DLR ) as well as on multipath data from real GPS signals . Application of the detection tests to correlator outputs of scalar and vector tracking loops shows that they may be used to exclude multipath contaminated satellites from the navigation solution . These detection techniques can be extended to other Global Navigation Satellite Systems ( GNSS ) such as GLONASS , Galileo and Beidou .
Recent work has demonstrated that neural networks are vulnerable to adversarial examples , i . e . , inputs that are almost indistinguishable from natural data and yet classified incorrectly by the network . In fact , some of the latest findings suggest that the existence of adversarial attacks may be an inherent weakness of deep learning models . To address this problem , we study the adversarial robustness of neural networks through the lens of robust optimization . This approach provides us with a broad and unifying view on much of the prior work on this topic . Its principled nature also enables us to identify methods for both training and attacking neural networks that are reliable and , in a certain sense , universal . In particular , they specify a concrete security guarantee that would protect against any adversary . These methods let us train networks with significantly improved resistance to a wide range of adversarial attacks . They also suggest the notion of security against a first-order adversary as a natural and broad security guarantee . We believe that robustness against such well-defined classes of adversaries is an important stepping stone towards fully resistant deep learning models .
Binary hashing is a well-known approach for fast approximate nearest-neighbor search in information retrieval . Much work has focused on affinity-based objective functions involving the hash functions or binary codes . These objective functions encode neighborhood information between data points and are often inspired by manifold learning algorithms . They ensure that the hash functions differ from each other through constraints or penalty terms that encourage codes to be orthogonal or dissimilar across bits , but this couples the binary variables and complicates the already difficult optimization . We propose a much simpler approach : we train each hash function ( or bit ) independently from each other , but introduce diversity among them using techniques from classifier ensembles . Surprisingly , we find that not only is this faster and trivially parallelizable , but it also improves over the more complex , coupled objective function , and achieves state-of-the-art precision and recall in experiments with image retrieval .
Mixture models with Gamma and or inverse-Gamma distributed mixture components are useful for medical image tissue segmentation or as post-hoc models for regression coefficients obtained from linear regression within a Generalised Linear Modeling framework ( GLM ) , used in this case to separate stochastic ( Gaussian ) noise from some kind of positive or negative " activation " ( modeled as Gamma or inverse-Gamma distributed ) . To date , the most common choice in this context it is Gaussian/Gamma mixture models learned through a maximum likelihood ( ML ) approach ; we recently extended such algorithm for mixture models with inverse-Gamma components . Here , we introduce a fully analytical Variational Bayes ( VB ) learning framework for both Gamma and/or inverse-Gamma components . We use synthetic and resting state fMRI data to compare the performance of the ML and VB algorithms in terms of area under the curve and computational cost . We observed that the ML Gaussian/Gamma model is very expensive specially when considering high resolution images ; furthermore , these solutions are highly variable and they occasionally can overestimate the activations severely . The Bayesian Gauss-Gamma is in general the fastest algorithm but provides too dense solutions . The maximum likelihood Gaussian/inverse-Gamma is also very fast but provides in general very sparse solutions . The variational Gaussian/inverse-Gamma mixture model is the most robust and its cost is acceptable even for high resolution images . Further , the presented methodology represents an essential building block that can be directly used in more complex inference tasks , specially designed to analyse MRI-fMRI data ; such models include for example analytical variational mixture models with adaptive spatial regularization or better source models for new spatial blind source separation approaches .
A key requirement for the current generation of artificial decision-makers is that they should adapt well to changes in unexpected situations . This paper addresses the situation in which an AI for aerial dog fighting , with tunable parameters that govern its behavior , must optimize behavior with respect to an objective function that is evaluated and learned through simulations . Bayesian optimization with a Gaussian Process surrogate is used as the method for investigating the objective function . One key benefit is that during optimization , the Gaussian Process learns a global estimate of the true objective function , with predicted outcomes and a statistical measure of confidence in areas that haven ' t been investigated yet . Having a model of the objective function is important for being able to understand possible outcomes in the decision space ; for example this is crucial for training and providing feedback to human pilots . However , standard Bayesian optimization does not perform consistently or provide an accurate Gaussian Process surrogate function for highly volatile objective functions . We treat these problems by introducing a novel sampling technique called Hybrid Repeat/Multi-point Sampling . This technique gives the AI ability to learn optimum behaviors in a highly uncertain environment . More importantly , it not only improves the reliability of the optimization , but also creates a better model of the entire objective surface . With this improved model the agent is equipped to more accurately/efficiently predict performance in unexplored scenarios .
Low-dimensional embedding , manifold learning , clustering , classification , and anomaly detection are among the most important problems in machine learning . The existing methods usually consider the case when each instance has a fixed , finite-dimensional feature representation . Here we consider a different setting . We assume that each instance corresponds to a continuous probability distribution . These distributions are unknown , but we are given some i . i . d . samples from each distribution . Our goal is to estimate the distances between these distributions and use these distances to perform low-dimensional embedding , clustering/classification , or anomaly detection for the distributions . We present estimation algorithms , describe how to apply them for machine learning tasks on distributions , and show empirical results on synthetic data , real word images , and astronomical data sets .
We present a novel method for variable selection in regression models when covariates are measured with error . The iterative algorithm we propose , MEBoost , follows a path defined by estimating equations that correct for covariate measurement error . Via simulation , we evaluated our method and compare its performance to the recently-proposed Convex Conditioned Lasso ( CoCoLasso ) and to the " naive " Lasso which does not correct for measurement error . Increasing the degree of measurement error increased prediction error and decreased the probability of accurate covariate selection , but this loss of accuracy was least pronounced when using MEBoost . We illustrate the use of MEBoost in practice by analyzing data from the Box Lunch Study , a clinical trial in nutrition where several variables are based on self-report and hence measured with error .
Dropout is one of the key techniques to prevent the learning from overfitting . It is explained that dropout works as a kind of modified L0 regularization . Here , we shed light on the dropout from Bayesian standpoint . Bayesian interpretation enables us to optimize the dropout rate , which is beneficial for learning of weight parameters and prediction after learning . The experiment result also encourages the optimization of the dropout .
This paper deals with chain graphs under the classic Lauritzen-Wermuth-Frydenberg interpretation . We prove that the regular Gaussian distributions that factorize with respect to a chain graph $G$ with $d$ parameters have positive Lebesgue measure with respect to $\mathbb{R}^d$ , whereas those that factorize with respect to $G$ but are not faithful to it have zero Lebesgue measure with respect to $\mathbb{R}^d$ . This means that , in the measure-theoretic sense described , almost all the regular Gaussian distributions that factorize with respect to $G$ are faithful to it .
The problem of on-line off-policy evaluation ( OPE ) has been actively studied in the last decade due to its importance both as a stand-alone problem and as a module in a policy improvement scheme . However , most Temporal Difference ( TD ) based solutions ignore the discrepancy between the stationary distribution of the behavior and target policies and its effect on the convergence limit when function approximation is applied . In this paper we propose the Consistent Off-Policy Temporal Difference ( COP-TD ( $\lambda$ , $\beta$ ) ) algorithm that addresses this issue and reduces this bias at some computational expense . We show that COP-TD ( $\lambda$ , $\beta$ ) can be designed to converge to the same value that would have been obtained by using on-policy TD ( $\lambda$ ) with the target policy . Subsequently , the proposed scheme leads to a related and promising heuristic we call log-COP-TD ( $\lambda$ , $\beta$ ) . Both algorithms have favorable empirical results to the current state of the art on-line OPE algorithms . Finally , our formulation sheds some new light on the recently proposed Emphatic TD learning .
Nonnegative matrix factorization ( NMF ) has been shown to be identifiable under the separability assumption , under which all the columns ( or rows ) of the input data matrix belong to the convex cone generated by only a few of these columns ( or rows ) [0] . In real applications , however , such separability assumption is hard to satisfy . Following [0] and [0] , in this paper , we look at the Linear Programming ( LP ) based reformulation to locate the extreme rays of the convex cone but in a noisy setting . Furthermore , in order to deal with the large scale data , we employ First-Order Methods ( FOM ) to mitigate the computational complexity of LP , which primarily results from a large number of constraints . We show the performance of the algorithm on real and synthetic data sets .
We propose a new algorithm called Parle for parallel training of deep networks that converges 0-0x faster than a data-parallel implementation of SGD , while achieving significantly improved error rates that are nearly state-of-the-art on several benchmarks including CIFAR-00 and CIFAR-000 , without introducing any additional hyper-parameters . We exploit the phenomenon of flat minima that has been shown to lead to improved generalization error for deep networks . Parle requires very infrequent communication with the parameter server and instead performs more computation on each client , which makes it well-suited to both single-machine , multi-GPU settings and distributed implementations .
This paper takes a step towards temporal reasoning in a dynamically changing video , not in the pixel space that constitutes its frames , but in a latent space that describes the non-linear dynamics of the objects in its world . We introduce the Kalman variational auto-encoder , a framework for unsupervised learning of sequential data that disentangles two latent representations : an object ' s representation , coming from a recognition model , and a latent state describing its dynamics . As a result , the evolution of the world can be imagined and missing data imputed , both without the need to generate high dimensional frames at each time step . The model is trained end-to-end on videos of a variety of simulated physical systems , and outperforms competing methods in generative and missing data imputation tasks .
The K-Mean and EM algorithms are popular in clustering and mixture modeling , due to their simplicity and ease of implementation . However , they have several significant limitations . Both coverage to a local optimum of their respective objective functions ( ignoring the uncertainty in the model space ) , require the apriori specification of the number of classes/clsuters , and are inconsistent . In this work we overcome these limitations by using the Minimum Message Length ( MML ) principle and a variation to the K-Means/EM observation assignment and parameter calculation scheme . We maintain the simplicity of these approaches while constructing a Bayesian mixture modeling tool that samples/searches the model space using a Markov Chain Monte Carlo ( MCMC ) sampler known as a Gibbs sampler . Gibbs sampling allows us to visit each model according to its posterior probability . Therefore , if the model space is multi-modal we will visit all models and not get stuck in local optima . We call our approach multiple chains at equilibrium ( MCE ) MML sampling .
We introduce and describe the results of a novel shared task on bandit learning for machine translation . The task was organized jointly by Amazon and Heidelberg University for the first time at the Second Conference on Machine Translation ( WMT 0000 ) . The goal of the task is to encourage research on learning machine translation from weak user feedback instead of human references or post-edits . On each of a sequence of rounds , a machine translation system is required to propose a translation for an input , and receives a real-valued estimate of the quality of the proposed translation for learning . This paper describes the shared task ' s learning and evaluation setup , using services hosted on Amazon Web Services ( AWS ) , the data and evaluation metrics , and the results of various machine translation architectures and learning protocols .
In dictionary learning , also known as sparse coding , the algorithm is given samples of the form $y = Ax$ where $x\in \mathbb{R}^m$ is an unknown random sparse vector and $A$ is an unknown dictionary matrix in $\mathbb{R}^{n\times m}$ ( usually $m > n$ , which is the overcomplete case ) . The goal is to learn $A$ and $x$ . This problem has been studied in neuroscience , machine learning , visions , and image processing . In practice it is solved by heuristic algorithms and provable algorithms seemed hard to find . Recently , provable algorithms were found that work if the unknown feature vector $x$ is $\sqrt{n}$-sparse or even sparser . Spielman et al . \cite{DBLP : journals/jmlr/SpielmanWW00} did this for dictionaries where $m=n$ ; Arora et al . \cite{AGM} gave an algorithm for overcomplete ( $m >n$ ) and incoherent matrices $A$ ; and Agarwal et al . \cite{DBLP : journals/corr/AgarwalAN00} handled a similar case but with weaker guarantees . This raised the problem of designing provable algorithms that allow sparsity $\gg \sqrt{n}$ in the hidden vector $x$ . The current paper designs algorithms that allow sparsity up to $n/poly ( \log n ) $ . It works for a class of matrices where features are individually recoverable , a new notion identified in this paper that may motivate further work . The algorithm runs in quasipolynomial time because they use limited enumeration .
We consider the problem of dictionary learning under the assumption that the observed signals can be represented as sparse linear combinations of the columns of a single large dictionary matrix . In particular , we analyze the minimax risk of the dictionary learning problem which governs the mean squared error ( MSE ) performance of any learning scheme , regardless of its computational complexity . By following an established information-theoretic method based on Fanos inequality , we derive a lower bound on the minimax risk for a given dictionary learning problem . This lower bound yields a characterization of the sample-complexity , i . e . , a lower bound on the required number of observations such that consistent dictionary learning schemes exist . Our bounds may be compared with the performance of a given learning scheme , allowing to characterize how far the method is from optimal performance .
In this work we develop a theory of hierarchical clustering for graphs . Our modeling assumption is that graphs are sampled from a graphon , which is a powerful and general model for generating graphs and analyzing large networks . Graphons are a far richer class of graph models than stochastic blockmodels , the primary setting for recent progress in the statistical theory of graph clustering . We define what it means for an algorithm to produce the " correct " clustering , give sufficient conditions in which a method is statistically consistent , and provide an explicit algorithm satisfying these properties .
Under-determined systems of linear equations with sparse solutions have been the subject of an extensive research in last several years above all due to results of \cite{CRT , CanRomTao00 , DonohoPol} . In this paper we will consider \emph{noisy} under-determined linear systems . In a breakthrough \cite{CanRomTao00} it was established that in \emph{noisy} systems for any linear level of under-determinedness there is a linear sparsity that can be \emph{approximately} recovered through an SOCP ( second order cone programming ) optimization algorithm so that the approximate solution vector is ( in an $\ell_0$-norm sense ) guaranteed to be no further from the sparse unknown vector than a constant times the noise . In our recent work \cite{StojnicGenSocp00} we established an alternative framework that can be used for statistical performance analysis of the SOCP algorithms . To demonstrate how the framework works we then showed in \cite{StojnicGenSocp00} how one can use it to precisely characterize the \emph{generic} ( worst-case ) performance of the SOCP . In this paper we present a different set of results that can be obtained through the framework of \cite{StojnicGenSocp00} . The results will relate to \emph{problem dependent} performance analysis of SOCP ' s . We will consider specific types of unknown sparse vectors and characterize the SOCP performance when used for recovery of such vectors . We will also show that our theoretical predictions are in a solid agreement with the results one can get through numerical simulations .
Optimization of very expensive black-box functions requires utilization of maximum information gathered by the process of optimization . Model Guided Sampling Optimization ( MGSO ) forms a more robust alternative to Jones ' Gaussian-process-based EGO algorithm . Instead of EGO ' s maximizing expected improvement , the MGSO uses sampling the probability of improvement which is shown to be helpful against trapping in local minima . Further , the MGSO can reach close-to-optimum solutions faster than standard optimization algorithms on low dimensional or smooth problems .
This work facilitates ensuring fairness of machine learning in the real world by decoupling fairness considerations in compound decisions . In particular , this work studies how fairness propagates through a compound decision-making processes , which we call a pipeline . Prior work in algorithmic fairness only focuses on fairness with respect to one decision . However , many decision-making processes require more than one decision . For instance , hiring is at least a two stage model : deciding who to interview from the applicant pool and then deciding who to hire from the interview pool . Perhaps surprisingly , we show that the composition of fair components may not guarantee a fair pipeline under a $ ( 0+\varepsilon ) $-equal opportunity definition of fair . However , we identify circumstances that do provide that guarantee . We also propose numerous directions for future work on more general compound machine learning decisions .
In this paper we analyze the asymptotic properties of l0 penalized maximum likelihood estimation of signals with piece-wise constant mean values and/or variances . The focus is on segmentation of a non-stationary time series with respect to changes in these model parameters . This change point detection and estimation problem is also referred to as total variation denoising or l0 -mean filtering and has many important applications in most fields of science and engineering . We establish the ( approximate ) sparse consistency properties , including rate of convergence , of the so-called fused lasso signal approximator ( FLSA ) . We show that this only holds if the sign of the corresponding consecutive changes are all different , and that this estimator is otherwise incapable of correctly detecting the underlying sparsity pattern . The key idea is to notice that the optimality conditions for this problem can be analyzed using techniques related to brownian bridge theory .
Sequential or online dimensional reduction is of interests due to the explosion of streaming data based applications and the requirement of adaptive statistical modeling , in many emerging fields , such as the modeling of energy end-use profile . Principal Component Analysis ( PCA ) , is the classical way of dimensional reduction . However , traditional Singular Value Decomposition ( SVD ) based PCA fails to model data which largely deviates from Gaussian distribution . The Bregman Divergence was recently introduced to achieve a generalized PCA framework . If the random variable under dimensional reduction follows Bernoulli distribution , which occurs in many emerging fields , the generalized PCA is called Logistic PCA ( LPCA ) . In this paper , we extend the batch LPCA to a sequential version ( i . e . SLPCA ) , based on the sequential convex optimization theory . The convergence property of this algorithm is discussed compared to the batch version of LPCA ( i . e . BLPCA ) , as well as its performance in reducing the dimension for multivariate binary-state systems . Its application in building energy end-use profile modeling is also investigated .
Voltage control plays an important role in the operation of electricity distribution networks , especially with high penetration of distributed energy resources . These resources introduces significant and fast varying uncertainties . In this paper , we focus on reactive power compensation to control voltage in the presence of uncertainties . We adopt a probabilistic approach that accounts for arbitrary correlations between renewable resources at each of the buses and we use the linearized DistFlow equations to model the distribution network . We then show that this optimization problem is convex for a wide variety of probabilistic distributions . Compared to conventional per-bus chance constraints , our formulation is more robust to uncertainty and more computationally tractable . We illustrate the results using standard IEEE distribution test feeders .
We study the problem of collaborative filtering where ranking information is available . Focusing on the core of the collaborative ranking process , the user and their community , we propose new models for representation of the underlying permutations and prediction of ranks . The first approach is based on the assumption that the user makes successive choice of items in a stage-wise manner . In particular , we extend the Plackett-Luce model in two ways - introducing parameter factoring to account for user-specific contribution , and modelling the latent community in a generative setting . The second approach relies on log-linear parameterisation , which relaxes the discrete-choice assumption , but makes learning and inference much more involved . We propose MCMC-based learning and inference methods and derive linear-time prediction algorithms .
We propose a new reinforcement learning algorithm for partially observable Markov decision processes ( POMDP ) based on spectral decomposition methods . While spectral methods have been previously employed for consistent learning of ( passive ) latent variable models such as hidden Markov models , POMDPs are more challenging since the learner interacts with the environment and possibly changes the future observations in the process . We devise a learning algorithm running through episodes , in each episode we employ spectral techniques to learn the POMDP parameters from a trajectory generated by a fixed policy . At the end of the episode , an optimization oracle returns the optimal memoryless planning policy which maximizes the expected reward based on the estimated POMDP model . We prove an order-optimal regret bound with respect to the optimal memoryless policy and efficient scaling with respect to the dimensionality of observation and action spaces .
In high-dimensional classification settings , we wish to seek a balance between high power and ensuring control over a desired loss function . In many settings , the points most likely to be misclassified are those who lie near the decision boundary of the given classification method . Often , these uninformative points should not be classified as they are noisy and do not exhibit strong signals . In this paper , we introduce the Thresholding Method to parameterize the problem of determining which points exhibit strong signals and should be classified . We demonstrate the empirical performance of this novel calibration method in providing loss function control at a desired level , as well as explore how the method assuages the effect of overfitting . We explore the benefits of error control through the Thresholding Method in difficult , high-dimensional , simulated settings . Finally , we show the flexibility of the Thresholding Method through applying the method in a variety of real data settings .
Multiple kernel learning ( MKL ) , structured sparsity , and multi-task learning have recently received considerable attention . In this paper , we show how different MKL algorithms can be understood as applications of either regularization on the kernel weights or block-norm-based regularization , which is more common in structured sparsity and multi-task learning . We show that these two regularization strategies can be systematically mapped to each other through a concave conjugate operation . When the kernel-weight-based regularizer is separable into components , we can naturally consider a generative probabilistic model behind MKL . Based on this model , we propose learning algorithms for the kernel weights through the maximization of marginal likelihood . We show through numerical experiments that $\ell_0$-norm MKL and Elastic-net MKL achieve comparable accuracy to uniform kernel combination . Although uniform kernel combination might be preferable from its simplicity , $\ell_0$-norm MKL and Elastic-net MKL can learn the usefulness of the information sources represented as kernels . In particular , Elastic-net MKL achieves sparsity in the kernel weights .
As a lossy compression framework , compressed sensing has drawn much attention in wireless telemonitoring of biosignals due to its ability to reduce energy consumption and make possible the design of low-power devices . However , the non-sparseness of biosignals presents a major challenge to compressed sensing . This study proposes and evaluates a spatio-temporal sparse Bayesian learning algorithm , which has the desired ability to recover such non-sparse biosignals . It exploits both temporal correlation in each individual biosignal and inter-channel correlation among biosignals from different channels . The proposed algorithm was used for compressed sensing of multichannel electroencephalographic ( EEG ) signals for estimating vehicle drivers ' drowsiness . Results showed that the drowsiness estimation was almost unaffected even if raw EEG signals ( containing various artifacts ) were compressed by 00% .
Learning to Optimize is a recently proposed framework for learning optimization algorithms using reinforcement learning . In this paper , we explore learning an optimization algorithm for training shallow neural nets . Such high-dimensional stochastic optimization problems present interesting challenges for existing reinforcement learning algorithms . We develop an extension that is suited to learning optimization algorithms in this setting and demonstrate that the learned optimization algorithm consistently outperforms other known optimization algorithms even on unseen tasks and is robust to changes in stochasticity of gradients and the neural net architecture . More specifically , we show that an optimization algorithm trained with the proposed method on the problem of training a neural net on MNIST generalizes to the problems of training neural nets on the Toronto Faces Dataset , CIFAR-00 and CIFAR-000 .
Measurement error in the observed values of the variables can greatly change the output of various causal discovery methods . This problem has received much attention in multiple fields , but it is not clear to what extent the causal model for the measurement-error-free variables can be identified in the presence of measurement error with unknown variance . In this paper , we study precise sufficient identifiability conditions for the measurement-error-free causal model and show what information of the causal model can be recovered from observed data . In particular , we present two different sets of identifiability conditions , based on the second-order statistics and higher-order statistics of the data , respectively . The former was inspired by the relationship between the generating model of the measurement-error-contaminated data and the factor analysis model , and the latter makes use of the identifiability result of the over-complete independent component analysis problem .
We describe two techniques that significantly improve the running time of several standard machine-learning algorithms when data is sparse . The first technique is an algorithm that effeciently extracts one-way and two-way counts--either real or expected-- from discrete data . Extracting such counts is a fundamental step in learning algorithms for constructing a variety of models including decision trees , decision graphs , Bayesian networks , and naive-Bayes clustering models . The second technique is an algorithm that efficiently performs the E-step of the EM algorithm ( i . e . inference ) when applied to a naive-Bayes clustering model . Using real-world data sets , we demonstrate a dramatic decrease in running time for algorithms that incorporate these techniques .
In an online contract selection problem there is a seller which offers a set of contracts to sequentially arriving buyers whose types are drawn from an unknown distribution . If there exists a profitable contract for the buyer in the offered set , i . e . , a contract with payoff higher than the payoff of not accepting any contracts , the buyer chooses the contract that maximizes its payoff . In this paper we consider the online contract selection problem to maximize the sellers profit . Assuming that a structural property called ordered preferences holds for the buyer ' s payoff function , we propose online learning algorithms that have sub-linear regret with respect to the best set of contracts given the distribution over the buyer ' s type . This problem has many applications including spectrum contracts , wireless service provider data plans and recommendation systems .
In query learning , the goal is to identify an unknown object while minimizing the number of " yes or no " questions ( queries ) posed about that object . We consider three extensions of this fundamental problem that are motivated by practical considerations in real-world , time-critical identification tasks such as emergency response . First , we consider the problem where the objects are partitioned into groups , and the goal is to identify only the group to which the object belongs . Second , we address the situation where the queries are partitioned into groups , and an algorithm may suggest a group of queries to a human user , who then selects the actual query . Third , we consider the problem of query learning in the presence of persistent query noise , and relate it to group identification . To address these problems we show that a standard algorithm for query learning , known as the splitting algorithm or generalized binary search , may be viewed as a generalization of Shannon-Fano coding . We then extend this result to the group-based settings , leading to new algorithms . The performance of our algorithms is demonstrated on simulated data and on a database used by first responders for toxic chemical identification .
We introduce a methodology for efficient monitoring of processes running on hosts in a corporate network . The methodology is based on collecting streams of system calls produced by all or selected processes on the hosts , and sending them over the network to a monitoring server , where machine learning algorithms are used to identify changes in process behavior due to malicious activity , hardware failures , or software errors . The methodology uses a sequence of system call count vectors as the data format which can handle large and varying volumes of data . Unlike previous approaches , the methodology introduced in this paper is suitable for distributed collection and processing of data in large corporate networks . We evaluate the methodology both in a laboratory setting on a real-life setup and provide statistics characterizing performance and accuracy of the methodology .
We give a novel formal theoretical framework for unsupervised learning with two distinctive characteristics . First , it does not assume any generative model and based on a worst-case performance metric . Second , it is comparative , namely performance is measured with respect to a given hypothesis class . This allows to avoid known computational hardness results and improper algorithms based on convex relaxations . We show how several families of unsupervised learning models , which were previously only analyzed under probabilistic assumptions and are otherwise provably intractable , can be efficiently learned in our framework by convex optimization .
We study parameter estimation in Nonlinear Factor Analysis ( NFA ) where the generative model is parameterized by a deep neural network . Recent work has focused on learning such models using inference ( or recognition ) networks ; we identify a crucial problem when modeling large , sparse , high-dimensional datasets -- underfitting . We study the extent of underfitting , highlighting that its severity increases with the sparsity of the data . We propose methods to tackle it via iterative optimization inspired by stochastic variational inference \citep{hoffman0000stochastic} and improvements in the sparse data representation used for inference . The proposed techniques drastically improve the ability of these powerful models to fit sparse data , achieving state-of-the-art results on a benchmark text-count dataset and excellent results on the task of top-N recommendation .
The recent literature on deep learning offers new tools to learn a rich probability distribution over high dimensional data such as images or sounds . In this work we investigate the possibility of learning the prior distribution over neural network parameters using such tools . Our resulting variational Bayes algorithm generalizes well to new tasks , even when very few training examples are provided . Furthermore , this learned prior allows the model to extrapolate correctly far from a given task ' s training data on a meta-dataset of periodic signals .
The stochastic block model is a powerful tool for inferring community structure from network topology . However , it predicts a Poisson degree distribution within each community , while most real-world networks have a heavy-tailed degree distribution . The degree-corrected block model can accommodate arbitrary degree distributions within communities . But since it takes the vertex degrees as parameters rather than generating them , it cannot use them to help it classify the vertices , and its natural generalization to directed graphs cannot even use the orientations of the edges . In this paper , we present variants of the block model with the best of both worlds : they can use vertex degrees and edge orientations in the classification process , while tolerating heavy-tailed degree distributions within communities . We show that for some networks , including synthetic networks and networks of word adjacencies in English text , these new block models achieve a higher accuracy than either standard or degree-corrected block models .
Bayesian inference is a popular method to build learning algorithms but it is hampered by the fact that its key object , the posterior probability distribution , is often uncomputable . Expectation Propagation ( EP ) ( Minka ( 0000 ) ) is a popular algorithm that solves this issue by computing a parametric approximation ( e . g : Gaussian ) to the density of the posterior . However , while it is known empirically to quickly compute fine approximations , EP is extremely poorly understood which prevents it from being adopted by a larger fraction of the community . The object of the present article is to shed intuitive light on EP , by relating it to other better understood methods . More precisely , we link it to using gradient descent to compute the Laplace approximation of a target probability distribution . We show that EP is exactly equivalent to performing gradient descent on a smoothed energy landscape : i . e : the original energy landscape convoluted with some smoothing kernel . This also relates EP to algorithms that compute the Gaussian approximation which minimizes the reverse KL divergence to the target distribution , a link that has been conjectured before but has not been proved rigorously yet . These results can help practitioners to get a better feel for how EP works , as well as lead to other new results on this important method .
We consider on-line density estimation with a parameterized density from the exponential family . The on-line algorithm receives one example at a time and maintains a parameter that is essentially an average of the past examples . After receiving an example the algorithm incurs a loss which is the negative log-likelihood of the example w . r . t . the past parameter of the algorithm . An off-line algorithm can choose the best parameter based on all the examples . We prove bounds on the additional total loss of the on-line algorithm over the total loss of the off-line algorithm . These relative loss bounds hold for an arbitrary sequence of examples . The goal is to design algorithms with the best possible relative loss bounds . We use a certain divergence to derive and analyze the algorithms . This divergence is a relative entropy between two exponential distributions .
We present a new anytime algorithm that achieves near-optimal regret for any instance of finite stochastic partial monitoring . In particular , the new algorithm achieves the minimax regret , within logarithmic factors , for both " easy " and " hard " problems . For easy problems , it additionally achieves logarithmic individual regret . Most importantly , the algorithm is adaptive in the sense that if the opponent strategy is in an " easy region " of the strategy space then the regret grows as if the problem was easy . As an implication , we show that under some reasonable additional assumptions , the algorithm enjoys an O ( \sqrt{T} ) regret in Dynamic Pricing , proven to be hard by Bartok et al . ( 0000 ) .
Despite the success of the popular kernelized support vector machines , they have two major limitations : they are restricted to Positive Semi-Definite ( PSD ) kernels , and their training complexity scales at least quadratically with the size of the data . Many natural measures of similarity between pairs of samples are not PSD e . g . invariant kernels , and those that are implicitly or explicitly defined by latent variable models . In this paper , we investigate scalable approaches for using indefinite similarity measures in large margin frameworks . In particular we show that a normalization of similarity to a subset of the data points constitutes a representation suitable for linear classifiers . The result is a classifier which is competitive to kernelized SVM in terms of accuracy , despite having better training and test time complexities . Experimental results demonstrate that on CIFAR-00 dataset , the model equipped with similarity measures invariant to rigid and non-rigid deformations , can be made more than 0 times sparser while being more accurate than kernelized SVM using RBF kernels .
This paper introduces self-paced task selection to multitask learning , where instances from more closely related tasks are selected in a progression of easier-to-harder tasks , to emulate an effective human education strategy , but applied to multitask machine learning . We develop the mathematical foundation for the approach based on iterative selection of the most appropriate task , learning the task parameters , and updating the shared knowledge , optimizing a new bi-convex loss function . This proposed method applies quite generally , including to multitask feature learning , multitask learning with alternating structure optimization , etc . Results show that in each of the above formulations self-paced ( easier-to-harder ) task selection outperforms the baseline version of these methods in all the experiments .
Traditional voxel-level multiple testing procedures in neuroimaging , mostly $p$-value based , often ignore the spatial correlations among neighboring voxels and thus suffer from substantial loss of power . We extend the local-significance-index based procedure originally developed for the hidden Markov chain models , which aims to minimize the false nondiscovery rate subject to a constraint on the false discovery rate , to three-dimensional neuroimaging data using a hidden Markov random field model . A generalized expectation-maximization algorithm for maximizing the penalized likelihood is proposed for estimating the model parameters . Extensive simulations show that the proposed approach is more powerful than conventional false discovery rate procedures . We apply the method to the comparison between mild cognitive impairment , a disease status with increased risk of developing Alzheimer ' s or another dementia , and normal controls in the FDG-PET imaging study of the Alzheimer ' s Disease Neuroimaging Initiative .
Classifying streaming data requires the development of methods which are computationally efficient and able to cope with changes in the underlying distribution of the stream , a phenomenon known in the literature as concept drift . We propose a new method for detecting concept drift which uses an Exponentially Weighted Moving Average ( EWMA ) chart to monitor the misclassification rate of an streaming classifier . Our approach is modular and can hence be run in parallel with any underlying classifier to provide an additional layer of concept drift detection . Moreover our method is computationally efficient with overhead O ( 0 ) and works in a fully online manner with no need to store data points in memory . Unlike many existing approaches to concept drift detection , our method allows the rate of false positive detections to be controlled and kept constant over time .
We study a two-level multiview learning with more than two views under the PAC-Bayesian framework . This approach , sometimes referred as late fusion , consists in learning sequentially multiple view-specific classifiers at the first level , and then combining these view-specific classifiers at the second level . Our main theoretical result is a generalization bound on the risk of the majority vote which exhibits a term of diversity in the predictions of the view-specific classifiers . From this result it comes out that controlling the trade-off between diversity and accuracy is a key element for multiview learning , which complements other results in multiview learning . Finally , we experiment our principle on multiview datasets extracted from the Reuters RCV0/RCV0 collection .
We develop a Bayesian " sum-of-trees " model where each tree is constrained by a regularization prior to be a weak learner , and fitting and inference are accomplished via an iterative Bayesian backfitting MCMC algorithm that generates samples from a posterior . Effectively , BART is a nonparametric Bayesian regression approach which uses dimensionally adaptive random basis elements . Motivated by ensemble methods in general , and boosting algorithms in particular , BART is defined by a statistical model : a prior and a likelihood . This approach enables full posterior inference including point and interval estimates of the unknown regression function as well as the marginal effects of potential predictors . By keeping track of predictor inclusion frequencies , BART can also be used for model-free variable selection . BART ' s many features are illustrated with a bake-off against competing methods on 00 different data sets , with a simulation experiment and on a drug discovery classification problem .
In this paper , we consider the block-sparse signals recovery problem in the context of multiple measurement vectors ( MMV ) with common row sparsity patterns . We develop a new method for recovery of common row sparsity MMV signals , where a pattern-coupled hierarchical Gaussian prior model is introduced to characterize both the block-sparsity of the coefficients and the statistical dependency between neighboring coefficients of the common row sparsity MMV signals . Unlike many other methods , the proposed method is able to automatically capture the block sparse structure of the unknown signal . Our method is developed using an expectation-maximization ( EM ) framework . Simulation results show that our proposed method offers competitive performance in recovering block-sparse common row sparsity pattern MMV signals .
We propose a method for learning cyclic causal models from a combination of observational and interventional equilibrium data . Novel aspects of the proposed method are its ability to work with continuous data ( without assuming linearity ) and to deal with feedback loops . Within the context of biochemical reactions , we also propose a novel way of modeling interventions that modify the activity of compounds instead of their abundance . For computational reasons , we approximate the nonlinear causal mechanisms by ( coupled ) local linearizations , one for each experimental condition . We apply the method to reconstruct a cellular signaling network from the flow cytometry data measured by Sachs et al . ( 0000 ) . We show that our method finds evidence in the data for feedback loops and that it gives a more accurate quantitative description of the data at comparable model complexity .
Integrative analysis of disparate data blocks measured on a common set of experimental subjects is a major challenge in modern data analysis . This data structure naturally motivates the simultaneous exploration of the joint and individual variation within each data block resulting in new insights . For instance , there is a strong desire to integrate the multiple genomic data sets in The Cancer Genome Atlas to characterize the common and also the unique aspects of cancer genetics and cell biology for each source . In this paper we introduce Angle-Based Joint and Individual Variation Explained capturing both joint and individual variation within each data block . This is a major improvement over earlier approaches to this challenge in terms of a new conceptual understanding , much better adaption to data heterogeneity and a fast linear algebra computation . Important mathematical contributions are the use of score subspaces as the principal descriptors of variation structure and the use of perturbation theory as the guide for variation segmentation . This leads to an exploratory data analysis method which is insensitive to the heterogeneity among data blocks and does not require separate normalization . An application to cancer data reveals different behaviors of each type of signal in characterizing tumor subtypes . An application to a mortality data set reveals interesting historical lessons . Software and data are available at GitHub https : //github . com/MeileiJiang/AJIVE_Project .
The superior performance of ensemble methods with infinite models are well known . Most of these methods are based on optimization problems in infinite-dimensional spaces with some regularization , for instance , boosting methods and convex neural networks use $L^0$-regularization with the non-negative constraint . However , due to the difficulty of handling $L^0$-regularization , these problems require early stopping or a rough approximation to solve it inexactly . In this paper , we propose a new ensemble learning method that performs in a space of probability measures , that is , our method can handle the $L^0$-constraint and the non-negative constraint in a rigorous way . Such an optimization is realized by proposing a general purpose stochastic optimization method for learning probability measures via parameterization using transport maps on base models . As a result of running the method , a transport map to output an infinite ensemble is obtained , which forms a residual-type network . From the perspective of functional gradient methods , we give a convergence rate as fast as that of a stochastic optimization method for finite dimensional nonconvex problems . Moreover , we show an interior optimality property of a local optimality condition used in our analysis .
Sequence-to-sequence models with soft attention have been successfully applied to a wide variety of problems , but their decoding process incurs a quadratic time and space cost and is inapplicable to real-time sequence transduction . To address these issues , we propose Monotonic Chunkwise Attention ( MoChA ) , which adaptively splits the input sequence into small chunks over which soft attention is computed . We show that models utilizing MoChA can be trained efficiently with standard backpropagation while allowing online and linear-time decoding at test time . When applied to online speech recognition , we obtain state-of-the-art results and match the performance of a model using an offline soft attention mechanism . In document summarization experiments where we do not expect monotonic alignments , we show significantly improved performance compared to a baseline monotonic attention-based model .
The scalable calculation of matrix determinants has been a bottleneck to the widespread application of many machine learning methods such as determinantal point processes , Gaussian processes , generalised Markov random fields , graph models and many others . In this work , we estimate log determinants under the framework of maximum entropy , given information in the form of moment constraints from stochastic trace estimation . The estimates demonstrate a significant improvement on state-of-the-art alternative methods , as shown on a wide variety of UFL sparse matrices . By taking the example of a general Markov random field , we also demonstrate how this approach can significantly accelerate inference in large-scale learning methods involving the log determinant .
We present a simple and fast geometric method for modeling data by a union of affine subspaces . The method begins by forming a collection of local best-fit affine subspaces , i . e . , subspaces approximating the data in local neighborhoods . The correct sizes of the local neighborhoods are determined automatically by the Jones ' $\beta_0$ numbers ( we prove under certain geometric conditions that our method finds the optimal local neighborhoods ) . The collection of subspaces is further processed by a greedy selection procedure or a spectral method to generate the final model . We discuss applications to tracking-based motion segmentation and clustering of faces under different illuminating conditions . We give extensive experimental evidence demonstrating the state of the art accuracy and speed of the suggested algorithms on these problems and also on synthetic hybrid linear data as well as the MNIST handwritten digits data ; and we demonstrate how to use our algorithms for fast determination of the number of affine subspaces .
This paper presents regression models obtained from a process of blind prediction of peptide binding affinity from provided descriptors for several distinct datasets as part of the 0000 Comparative Evaluation of Prediction Algorithms ( COEPRA ) contest . This paper finds that kernel partial least squares , a nonlinear partial least squares ( PLS ) algorithm , outperforms PLS , and that the incorporation of transferable atom equivalent features improves predictive capability .
Modeling dynamical systems is important in many disciplines , e . g . , control , robotics , or neurotechnology . Commonly the state of these systems is not directly observed , but only available through noisy and potentially high-dimensional observations . In these cases , system identification , i . e . , finding the measurement mapping and the transition mapping ( system dynamics ) in latent space can be challenging . For linear system dynamics and measurement mappings efficient solutions for system identification are available . However , in practical applications , the linearity assumptions does not hold , requiring non-linear system identification techniques . If additionally the observations are high-dimensional ( e . g . , images ) , non-linear system identification is inherently hard . To address the problem of non-linear system identification from high-dimensional observations , we combine recent advances in deep learning and system identification . In particular , we jointly learn a low-dimensional embedding of the observation by means of deep auto-encoders and a predictive transition model in this low-dimensional space . We demonstrate that our model enables learning good predictive models of dynamical systems from pixel information only .
In a physical neural system , where storage and processing are intimately intertwined , the rules for adjusting the synaptic weights can only depend on variables that are available locally , such as the activity of the pre- and post-synaptic neurons , resulting in local learning rules . A systematic framework for studying the space of local learning rules is obtained by first specifying the nature of the local variables , and then the functional form that ties them together into each learning rule . Such a framework enables also the systematic discovery of new learning rules and exploration of relationships between learning rules and group symmetries . We study polynomial local learning rules stratified by their degree and analyze their behavior and capabilities in both linear and non-linear units and networks . Stacking local learning rules in deep feedforward networks leads to deep local learning . While deep local learning can learn interesting representations , it cannot learn complex input-output functions , even when targets are available for the top layer . Learning complex input-output functions requires local deep learning where target information is communicated to the deep layers through a backward learning channel . The nature of the communicated information about the targets and the structure of the learning channel partition the space of learning algorithms . We estimate the learning channel capacity associated with several algorithms and show that backpropagation outperforms them by simultaneously maximizing the information rate and minimizing the computational cost , even in recurrent networks . The theory clarifies the concept of Hebbian learning , establishes the power and limitations of local learning rules , introduces the learning channel which enables a formal analysis of the optimality of backpropagation , and explains the sparsity of the space of learning rules discovered so far .
We consider the problem of minimizing the sum of an average function of a large number of smooth convex components and a general , possibly non-differentiable , convex function . Although many methods have been proposed to solve this problem with the assumption that the sum is strongly convex , few methods support the non-strongly convex cases . Adding a small quadratic regularization is a common trick used to tackle non-strongly convex problems ; however , it may worsen the quality of solutions or weaken the performance of the algorithms . Avoiding this trick , we propose a new accelerated stochastic mirror descent method for solving the problem without the strongly convex assumption . Our method extends the deterministic accelerated proximal gradient methods of Paul Tseng and can be applied even when proximal points are computed inexactly . Our direct algorithms can be proven to achieve the optimal convergence rate $O ( \frac{0}{k^0} ) $ under a suitable choice of the errors in calculating the proximal points . We also propose a scheme for solving the problem when the component functions are non-smooth and finally apply the new algorithms to a class of composite convex concave optimization problems .
Given a training set with binary classification , the Support Vector Machine identifies the hyperplane maximizing the margin between the two classes of training data . This general formulation is useful in that it can be applied without regard to variance differences between the classes . Ignoring these differences is not optimal , however , as the general SVM will give the class with lower variance an unjustifiably wide berth . This increases the chance of misclassification of the other class and results in an overall loss of predictive performance . An alternate construction is proposed in which the margins of the separating hyperplane are different for each class , each proportional to the standard deviation of its class along the direction perpendicular to the hyperplane . The construction agrees with the SVM in the case of equal class variances . This paper will then examine the impact to the dual representation of the modified constraint equations .
A method for dimension reduction with clustering , classification , or discriminant analysis is introduced . This mixture model-based approach is based on fitting generalized hyperbolic mixtures on a reduced subspace within the paradigm of model-based clustering , classification , or discriminant analysis . A reduced subspace of the data is derived by considering the extent to which group means and group covariances vary . The members of the subspace arise through linear combinations of the original data , and are ordered by importance via the associated eigenvalues . The observations can be projected onto the subspace , resulting in a set of variables that captures most of the clustering information available . The use of generalized hyperbolic mixtures gives a robust framework capable of dealing with skewed clusters . Although dimension reduction is increasingly in demand across many application areas , the authors are most familiar with biological applications and so two of the five real data examples are within that sphere . Simulated data are also used for illustration . The approach introduced herein can be considered the most general such approach available , and so we compare results to three special and limiting cases . Comparisons with several well established techniques illustrate its promising performance .
A convolution neural network ( CNN ) based classification method for broadband DOA estimation is proposed , where the phase component of the short-time Fourier transform coefficients of the received microphone signals are directly fed into the CNN and the features required for DOA estimation are learnt during training . Since only the phase component of the input is used , the CNN can be trained with synthesized noise signals , thereby making the preparation of the training data set easier compared to using speech signals . Through experimental evaluation , the ability of the proposed noise trained CNN framework to generalize to speech sources is demonstrated . In addition , the robustness of the system to noise , small perturbations in microphone positions , as well as its ability to adapt to different acoustic conditions is investigated using experiments with simulated and real data .
Crowdsourcing systems , in which numerous tasks are electronically distributed to numerous " information piece-workers " , have emerged as an effective paradigm for human-powered solving of large scale problems in domains such as image classification , data entry , optical character recognition , recommendation , and proofreading . Because these low-paid workers can be unreliable , nearly all such systems must devise schemes to increase confidence in their answers , typically by assigning each task multiple times and combining the answers in an appropriate manner , e . g . majority voting . In this paper , we consider a general model of such crowdsourcing tasks and pose the problem of minimizing the total price ( i . e . , number of task assignments ) that must be paid to achieve a target overall reliability . We give a new algorithm for deciding which tasks to assign to which workers and for inferring correct answers from the workers ' answers . We show that our algorithm , inspired by belief propagation and low-rank matrix approximation , significantly outperforms majority voting and , in fact , is optimal through comparison to an oracle that knows the reliability of every worker . Further , we compare our approach with a more general class of algorithms which can dynamically assign tasks . By adaptively deciding which questions to ask to the next arriving worker , one might hope to reduce uncertainty more efficiently . We show that , perhaps surprisingly , the minimum price necessary to achieve a target reliability scales in the same manner under both adaptive and non-adaptive scenarios . Hence , our non-adaptive approach is order-optimal under both scenarios . This strongly relies on the fact that workers are fleeting and can not be exploited . Therefore , architecturally , our results suggest that building a reliable worker-reputation system is essential to fully harnessing the potential of adaptive designs .
We formulate and analyze a graphical model selection method for inferring the conditional independence graph of a high-dimensional non-stationary Gaussian random process ( time series ) from a finite-length observation . The observed process samples are assumed uncorrelated over time but having different covariance matrices . We characterize the sample complexity of graphical model selection for such processes by analyzing a particular selection method , which is based on sparse neighborhood regression . Our results indicate , similar to the case of i . i . d . samples , accurate GMS is possible even in the high- dimensional regime if the underlying conditional independence graph is sufficiently sparse .
Training neural networks involves solving large-scale non-convex optimization problems . This task has long been believed to be extremely difficult , with fear of local minima and other obstacles motivating a variety of schemes to improve optimization , such as unsupervised pretraining . However , modern neural networks are able to achieve negligible training error on complex tasks , using only direct training with stochastic gradient descent . We introduce a simple analysis technique to look for evidence that such networks are overcoming local optima . We find that , in fact , on a straight path from initialization to solution , a variety of state of the art neural networks never encounter any significant obstacles .
Stochastic gradient descent is a simple approach to find the local minima of a cost function whose evaluations are corrupted by noise . In this paper , we develop a procedure extending stochastic gradient descent algorithms to the case where the function is defined on a Riemannian manifold . We prove that , as in the Euclidian case , the gradient descent algorithm converges to a critical point of the cost function . The algorithm has numerous potential applications , and is illustrated here by four examples . In particular a novel gossip algorithm on the set of covariance matrices is derived and tested numerically .
We define and study the statistical models in exponential family form whose sufficient statistics are the degree distributions and the bi-degree distributions of undirected labelled simple graphs . Graphs that are constrained by the joint degree distributions are called $dK$-graphs in the computer science literature and this paper attempts to provide the first statistically grounded analysis of this type of models . In addition to formalizing these models , we provide some preliminary results for the parameter estimation and the asymptotic behaviour of the model for degree distribution , and discuss the parameter estimation for the model for bi-degree distribution .
The Hierarchical Mixture of Experts ( HME ) is a well-known tree-based model for regression and classification , based on soft probabilistic splits . In its original formulation it was trained by maximum likelihood , and is therefore prone to over-fitting . Furthermore the maximum likelihood framework offers no natural metric for optimizing the complexity and structure of the tree . Previous attempts to provide a Bayesian treatment of the HME model have relied either on ad-hoc local Gaussian approximations or have dealt with related models representing the joint distribution of both input and output variables . In this paper we describe a fully Bayesian treatment of the HME model based on variational inference . By combining local and global variational methods we obtain a rigourous lower bound on the marginal probability of the data under the model . This bound is optimized during the training phase , and its resulting value can be used for model order selection . We present results using this approach for a data set describing robot arm kinematics .
The behaviour of many real-world phenomena can be modelled by nonlinear dynamical systems whereby a latent system state is observed through a filter . We are interested in interacting subsystems of this form , which we model by a set of coupled maps as a synchronous update graph dynamical systems . Specifically , we study the structure learning problem for spatially distributed dynamical systems coupled via a directed acyclic graph . Unlike established structure learning procedures that find locally maximum posterior probabilities of a network structure containing latent variables , our work exploits the properties of dynamical systems to compute globally optimal approximations of these distributions . We arrive at this result by the use of time delay embedding theorems . Taking an information-theoretic perspective , we show that the log-likelihood has an intuitive interpretation in terms of information transfer .
As machine learning systems become ubiquitous , there has been a surge of interest in interpretable machine learning : systems that provide explanation for their outputs . These explanations are often used to qualitatively assess other criteria such as safety or non-discrimination . However , despite the interest in interpretability , there is very little consensus on what interpretable machine learning is and how it should be measured . In this position paper , we first define interpretability and describe when interpretability is needed ( and when it is not ) . Next , we suggest a taxonomy for rigorous evaluation and expose open questions towards a more rigorous science of interpretable machine learning .
We consider a wide range of regularized stochastic minimization problems with two regularization terms , one of which is composed with a linear function . This optimization model abstracts a number of important applications in artificial intelligence and machine learning , such as fused Lasso , fused logistic regression , and a class of graph-guided regularized minimization . The computational challenges of this model are in two folds . On one hand , the closed-form solution of the proximal mapping associated with the composed regularization term or the expected objective function is not available . On the other hand , the calculation of the full gradient of the expectation in the objective is very expensive when the number of input data samples is considerably large . To address these issues , we propose a stochastic variant of extra-gradient type methods , namely \textsf{Stochastic Primal-Dual Proximal ExtraGradient descent ( SPDPEG ) } , and analyze its convergence property for both convex and strongly convex objectives . For general convex objectives , the uniformly average iterates generated by \textsf{SPDPEG} converge in expectation with $O ( 0/\sqrt{t} ) $ rate . While for strongly convex objectives , the uniformly and non-uniformly average iterates generated by \textsf{SPDPEG} converge with $O ( \log ( t ) /t ) $ and $O ( 0/t ) $ rates , respectively . The order of the rate of the proposed algorithm is known to match the best convergence rate for first-order stochastic algorithms . Experiments on fused logistic regression and graph-guided regularized logistic regression problems show that the proposed algorithm performs very efficiently and consistently outperforms other competing algorithms .
Statistical inference can be computationally prohibitive in ultrahigh-dimensional linear models . Correlation-based variable screening , in which one leverages marginal correlations for removal of irrelevant variables from the model prior to statistical inference , can be used to overcome this challenge . Prior works on correlation-based variable screening either impose strong statistical priors on the linear model or assume specific post-screening inference methods . This paper first extends the analysis of correlation-based variable screening to arbitrary linear models and post-screening inference techniques . In particular , ( $i$ ) it shows that a condition---termed the screening condition---is sufficient for successful correlation-based screening of linear models , and ( $ii$ ) it provides insights into the dependence of marginal correlation-based screening on different problem parameters . Numerical experiments confirm that these insights are not mere artifacts of analysis ; rather , they are reflective of the challenges associated with marginal correlation-based variable screening . Second , the paper explicitly derives the screening condition for two families of linear models , namely , sub-Gaussian linear models and arbitrary ( random or deterministic ) linear models . In the process , it establishes that---under appropriate conditions---it is possible to reduce the dimension of an ultrahigh-dimensional , arbitrary linear model to almost the sample size even when the number of active variables scales almost linearly with the sample size .
Simultaneously recorded electroencephalography ( EEG ) and functional magnetic resonance imaging ( fMRI ) can be used to non-invasively measure the spatiotemporal dynamics of the human brain . One challenge is dealing with the artifacts that each modality introduces into the other when the two are recorded concurrently , for example the ballistocardiogram ( BCG ) . We conducted a preliminary comparison of three different MR compatible EEG recording systems and assessed their performance in terms of single-trial classification of the EEG when simultaneously collecting fMRI . We found tradeoffs across all three systems , for example varied ease of setup and improved classification accuracy with reference electrodes ( REF ) but not for pulse artifact subtraction ( PAS ) or reference layer adaptive filtering ( RLAF ) .
We introduce a new paradigm that is important for community detection in the realm of network analysis . Networks contain a set of strong , dominant communities , which interfere with the detection of weak , natural community structure . When most of the members of the weak communities also belong to stronger communities , they are extremely hard to be uncovered . We call the weak communities the hidden community structure . We present a novel approach called HICODE ( HIdden COmmunity DEtection ) that identifies the hidden community structure as well as the dominant community structure . By weakening the strength of the dominant structure , one can uncover the hidden structure beneath . Likewise , by reducing the strength of the hidden structure , one can more accurately identify the dominant structure . In this way , HICODE tackles both tasks simultaneously . Extensive experiments on real-world networks demonstrate that HICODE outperforms several state-of-the-art community detection methods in uncovering both the dominant and the hidden structure . In the Facebook university social networks , we find multiple non-redundant sets of communities that are strongly associated with residential hall , year of registration or career position of the faculties or students , while the state-of-the-art algorithms mainly locate the dominant ground truth category . In the Due to the difficulty of labeling all ground truth communities in real-world datasets , HICODE provides a promising approach to pinpoint the existing latent communities and uncover communities for which there is no ground truth . Finding this unknown structure is an extremely important community detection problem .
When humans learn a new concept , they might ignore examples that they cannot make sense of at first , and only later focus on such examples , when they are more useful for learning . We propose incorporating this idea of tunable sensitivity for hard examples in neural network learning , using a new generalization of the cross-entropy gradient step , which can be used in place of the gradient in any gradient-based training method . The generalized gradient is parameterized by a value that controls the sensitivity of the training process to harder training examples . We tested our method on several benchmark datasets . We propose , and corroborate in our experiments , that the optimal level of sensitivity to hard example is positively correlated with the depth of the network . Moreover , the test prediction error obtained by our method is generally lower than that of the vanilla cross-entropy gradient learner . We therefore conclude that tunable sensitivity can be helpful for neural network learning .
Online social networking sites are experimenting with the following crowd-powered procedure to reduce the spread of fake news and misinformation : whenever a user is exposed to a story through her feed , she can flag the story as misinformation and , if the story receives enough flags , it is sent to a trusted third party for fact checking . If this party identifies the story as misinformation , it is marked as disputed . However , given the uncertain number of exposures , the high cost of fact checking , and the trade-off between flags and exposures , the above mentioned procedure requires careful reasoning and smart algorithms which , to the best of our knowledge , do not exist to date . In this paper , we first introduce a flexible representation of the above procedure using the framework of marked temporal point processes . Then , we develop a scalable online algorithm , Curb , to select which stories to send for fact checking and when to do so to efficiently reduce the spread of misinformation with provable guarantees . In doing so , we need to solve a novel stochastic optimal control problem for stochastic differential equations with jumps , which is of independent interest . Experiments on two real-world datasets gathered from Twitter and Weibo show that our algorithm may be able to effectively reduce the spread of fake news and misinformation .
We propose a new high dimensional semiparametric principal component analysis ( PCA ) method , named Copula Component Analysis ( COCA ) . The semiparametric model assumes that , after unspecified marginally monotone transformations , the distributions are multivariate Gaussian . COCA improves upon PCA and sparse PCA in three aspects : ( i ) It is robust to modeling assumptions ; ( ii ) It is robust to outliers and data contamination ; ( iii ) It is scale-invariant and yields more interpretable results . We prove that the COCA estimators obtain fast estimation rates and are feature selection consistent when the dimension is nearly exponentially large relative to the sample size . Careful experiments confirm that COCA outperforms sparse PCA on both synthetic and real-world datasets .
In this note , we present a version of the Thompson sampling algorithm for the problem of online linear generalization with full information ( i . e . , the experts setting ) , studied by Kalai and Vempala , 0000 . The algorithm uses a Gaussian prior and time-varying Gaussian likelihoods , and we show that it essentially reduces to Kalai and Vempala ' s Follow-the-Perturbed-Leader strategy , with exponentially distributed noise replaced by Gaussian noise . This implies sqrt ( T ) regret bounds for Thompson sampling ( with time-varying likelihood ) for online learning with full information .
Multi-instance data , in which each object ( bag ) contains a collection of instances , are widespread in machine learning , computer vision , bioinformatics , signal processing , and social sciences . We present a maximum entropy ( ME ) framework for learning from multi-instance data . In this approach each bag is represented as a distribution using the principle of ME . We introduce the concept of confidence-constrained ME ( CME ) to simultaneously learn the structure of distribution space and infer each distribution . The shared structure underlying each density is used to learn from instances inside each bag . The proposed CME is free of tuning parameters . We devise a fast optimization algorithm capable of handling large scale multi-instance data . In the experimental section , we evaluate the performance of the proposed approach in terms of exact rank recovery in the space of distributions and compare it with the regularized ME approach . Moreover , we compare the performance of CME with Multi-Instance Learning ( MIL ) state-of-the-art algorithms and show a comparable performance in terms of accuracy with reduced computational complexity .
Consider a movie recommendation system where apart from the ratings information , side information such as user ' s age or movie ' s genre is also available . Unlike standard matrix completion , in this setting one should be able to predict inductively on new users/movies . In this paper , we study the problem of inductive matrix completion in the exact recovery setting . That is , we assume that the ratings matrix is generated by applying feature vectors to a low-rank matrix and the goal is to recover back the underlying matrix . Furthermore , we generalize the problem to that of low-rank matrix estimation using rank-0 measurements . We study this generic problem and provide conditions that the set of measurements should satisfy so that the alternating minimization method ( which otherwise is a non-convex method with no convergence guarantees ) is able to recover back the {\em exact} underlying low-rank matrix . In addition to inductive matrix completion , we show that two other low-rank estimation problems can be studied in our framework : a ) general low-rank matrix sensing using rank-0 measurements , and b ) multi-label regression with missing labels . For both the problems , we provide novel and interesting bounds on the number of measurements required by alternating minimization to provably converges to the {\em exact} low-rank matrix . In particular , our analysis for the general low rank matrix sensing problem significantly improves the required storage and computational cost than that required by the RIP-based matrix sensing methods \cite{RechtFP0000} . Finally , we provide empirical validation of our approach and demonstrate that alternating minimization is able to recover the true matrix for the above mentioned problems using a small number of measurements .
The completion of tensors , or high-order arrays , attracts significant attention in recent research . Current literature on tensor completion primarily focuses on recovery from a set of uniformly randomly measured entries , and the required number of measurements to achieve recovery is not guaranteed to be optimal . In addition , the implementation of some previous methods are NP-hard . In this article , we propose a framework for low-rank tensor completion via a novel tensor measurement scheme we name Cross . The proposed procedure is efficient and easy to implement . In particular , we show that a third order tensor of Tucker rank-$ ( r_0 , r_0 , r_0 ) $ in $p_0$-by-$p_0$-by-$p_0$ dimensional space can be recovered from as few as $r_0r_0r_0 + r_0 ( p_0-r_0 ) + r_0 ( p_0-r_0 ) + r_0 ( p_0-r_0 ) $ noiseless measurements , which matches the sample complexity lower-bound . In the case of noisy measurements , we also develop a theoretical upper bound and the matching minimax lower bound for recovery error over certain classes of low-rank tensors for the proposed procedure . The results can be further extended to fourth or higher-order tensors . Simulation studies show that the method performs well under a variety of settings . Finally , the procedure is illustrated through a real dataset in neuroimaging .
Suppose the data consist of a set $S$ of points $x_j$ , $0\leq j \leq J$ , distributed in a bounded domain $D\subset R^N$ , where $N$ is a large number . An algorithm is given for finding the sets $L_k$ of dimension $k\ll N$ , $k=0 , 0 , . . . K$ , in a neighborhood of which maximal amount of points $x_j\in S$ lie . The algorithm is different from PCA ( principal component analysis )
Exponential family extensions of principal component analysis ( EPCA ) have received a considerable amount of attention in recent years , demonstrating the growing need for basic modeling tools that do not assume the squared loss or Gaussian distribution . We extend the EPCA model toolbox by presenting the first exponential family multi-view learning methods of the partial least squares and canonical correlation analysis , based on a unified representation of EPCA as matrix factorization of the natural parameters of exponential family . The models are based on a new family of priors that are generally usable for all such factorizations . We also introduce new inference strategies , and demonstrate how the methods outperform earlier ones when the Gaussianity assumption does not hold .
A major open problem on the road to artificial intelligence is the development of incrementally learning systems that learn about more and more concepts over time from a stream of data . In this work , we introduce a new training strategy , iCaRL , that allows learning in such a class-incremental way : only the training data for a small number of classes has to be present at the same time and new classes can be added progressively . iCaRL learns strong classifiers and a data representation simultaneously . This distinguishes it from earlier works that were fundamentally limited to fixed data representations and therefore incompatible with deep learning architectures . We show by experiments on CIFAR-000 and ImageNet ILSVRC 0000 data that iCaRL can learn many classes incrementally over a long period of time where other strategies quickly fail .
This paper is concerned with the problems of interaction screening and nonlinear classification in a high-dimensional setting . We propose a two-step procedure , IIS-SQDA , where in the first step an innovated interaction screening ( IIS ) approach based on transforming the original $p$-dimensional feature vector is proposed , and in the second step a sparse quadratic discriminant analysis ( SQDA ) is proposed for further selecting important interactions and main effects and simultaneously conducting classification . Our IIS approach screens important interactions by examining only $p$ features instead of all two-way interactions of order $O ( p^0 ) $ . Our theory shows that the proposed method enjoys sure screening property in interaction selection in the high-dimensional setting of $p$ growing exponentially with the sample size . In the selection and classification step , we establish a sparse inequality on the estimated coefficient vector for QDA and prove that the classification error of our procedure can be upper-bounded by the oracle classification error plus some smaller order term . Extensive simulation studies and real data analysis show that our proposal compares favorably with existing methods in interaction selection and high-dimensional classification .
This brief note highlights some basic concepts required toward understanding the evolution of machine learning and deep learning models . The note starts with an overview of artificial intelligence and its relationship to biological neuron that ultimately led to the evolution of todays intelligent models .
tick is a statistical learning library for Python~0 , with a particular emphasis on time-dependent models , such as point processes , and tools for generalized linear models and survival analysis . The core of the library is an optimization module providing model computational classes , solvers and proximal operators for regularization . tick relies on a C++ implementation and state-of-the-art optimization algorithms to provide very fast computations in a single node multi-core setting . Source code and documentation can be downloaded from https : //github . com/X-DataInitiative/tick
MM ( majorization--minimization ) algorithms are an increasingly popular tool for solving optimization problems in machine learning and statistical estimation . This article introduces the MM algorithm framework in general and via three popular example applications : Gaussian mixture regressions , multinomial logistic regressions , and support vector machines . Specific algorithms for the three examples are derived and numerical demonstrations are presented . Theoretical and practical aspects of MM algorithm design are discussed .
Inspired by recent successes of deep learning in computer vision , we propose a novel framework for encoding time series as different types of images , namely , Gramian Angular Summation/Difference Fields ( GASF/GADF ) and Markov Transition Fields ( MTF ) . This enables the use of techniques from computer vision for time series classification and imputation . We used Tiled Convolutional Neural Networks ( tiled CNNs ) on 00 standard datasets to learn high-level features from the individual and compound GASF-GADF-MTF images . Our approaches achieve highly competitive results when compared to nine of the current best time series classification approaches . Inspired by the bijection property of GASF on 0/0 rescaled data , we train Denoised Auto-encoders ( DA ) on the GASF images of four standard and one synthesized compound dataset . The imputation MSE on test data is reduced by 00 . 00%-00 . 00% when compared to using the raw data . An analysis of the features and weights learned via tiled CNNs and DAs explains why the approaches work .
Latent variable models are used to estimate variables of interest quantities which are observable only up to some measurement error . In many studies , such variables are known but not precisely quantifiable ( such as " job satisfaction " in social sciences and marketing , " analytical ability " in educational testing , or " inflation " in economics ) . This leads to the development of measurement instruments to record noisy indirect evidence for such unobserved variables such as surveys , tests and price indexes . In such problems , there are postulated latent variables and a given measurement model . At the same time , other unantecipated latent variables can add further unmeasured confounding to the observed variables . The problem is how to deal with unantecipated latents variables . In this paper , we provide a method loosely inspired by canonical correlation that makes use of background information concerning the " known " latent variables . Given a partially specified structure , it provides a structure learning approach to detect " unknown unknowns , " the confounding effect of potentially infinitely many other latent variables . This is done without explicitly modeling such extra latent factors . Because of the special structure of the problem , we are able to exploit a new variation of composite likelihood fitting to efficiently learn this structure . Validation is provided with experiments in synthetic data and the analysis of a large survey done with a sample of over 000 , 000 staff members of the National Health Service of the United Kingdom .
Achieving efficient and scalable exploration in complex domains poses a major challenge in reinforcement learning . While Bayesian and PAC-MDP approaches to the exploration problem offer strong formal guarantees , they are often impractical in higher dimensions due to their reliance on enumerating the state-action space . Hence , exploration in complex domains is often performed with simple epsilon-greedy methods . In this paper , we consider the challenging Atari games domain , which requires processing raw pixel inputs and delayed rewards . We evaluate several more sophisticated exploration strategies , including Thompson sampling and Boltzman exploration , and propose a new exploration method based on assigning exploration bonuses from a concurrently learned model of the system dynamics . By parameterizing our learned model with a neural network , we are able to develop a scalable and efficient approach to exploration bonuses that can be applied to tasks with complex , high-dimensional state spaces . In the Atari domain , our method provides the most consistent improvement across a range of games that pose a major challenge for prior methods . In addition to raw game-scores , we also develop an AUC-000 metric for the Atari Learning domain to evaluate the impact of exploration on this benchmark .
Most prior work on active learning of classifiers has focused on sequentially selecting one unlabeled example at a time to be labeled in order to reduce the overall labeling effort . In many scenarios , however , it is desirable to label an entire batch of examples at once , for example , when labels can be acquired in parallel . This motivates us to study batch active learning , which iteratively selects batches of $k>0$ examples to be labeled . We propose a novel batch active learning method that leverages the availability of high-quality and efficient sequential active-learning policies by attempting to approximate their behavior when applied for $k$ steps . Specifically , our algorithm first uses Monte-Carlo simulation to estimate the distribution of unlabeled examples selected by a sequential policy over $k$ step executions . The algorithm then attempts to select a set of $k$ examples that best matches this distribution , leading to a combinatorial optimization problem that we term " bounded coordinated matching " . While we show this problem is NP-hard in general , we give an efficient greedy solution , which inherits approximation bounds from supermodular minimization theory . Our experimental results on eight benchmark datasets show that the proposed approach is highly effective
Grasping is a complex process involving knowledge of the object , the surroundings , and of oneself . While humans are able to integrate and process all of the sensory information required for performing this task , equipping machines with this capability is an extremely challenging endeavor . In this paper , we investigate how deep learning techniques can allow us to translate high-level concepts such as motor imagery to the problem of robotic grasp synthesis . We explore a paradigm based on generative models for learning integrated object-action representations , and demonstrate its capacity for capturing and generating multimodal , multi-finger grasp configurations on a simulated grasping dataset .
Tensor methods have emerged as a powerful paradigm for consistent learning of many latent variable models such as topic models , independent component analysis and dictionary learning . Model parameters are estimated via CP decomposition of the observed higher order input moments . However , in many domains , additional invariances such as shift invariances exist , enforced via models such as convolutional dictionary learning . In this paper , we develop novel tensor decomposition algorithms for parameter estimation of convolutional models . Our algorithm is based on the popular alternating least squares method , but with efficient projections onto the space of stacked circulant matrices . Our method is embarrassingly parallel and consists of simple operations such as fast Fourier transforms and matrix multiplications . Our algorithm converges to the dictionary much faster and more accurately compared to the alternating minimization over filters and activation maps .
Kernel fusion is a popular and effective approach for combining multiple features that characterize different aspects of data . Traditional approaches for Multiple Kernel Learning ( MKL ) attempt to learn the parameters for combining the kernels through sophisticated optimization procedures . In this paper , we propose an alternative approach that creates dense embeddings for data using the kernel similarities and adopts a deep neural network architecture for fusing the embeddings . In order to improve the effectiveness of this network , we introduce the kernel dropout regularization strategy coupled with the use of an expanded set of composition kernels . Experiment results on a real-world activity recognition dataset show that the proposed architecture is effective in fusing kernels and achieves state-of-the-art performance .
We consider a Degree-Corrected Planted-Partition model : a random graph on $n$ nodes with two asymptotically equal-sized clusters . The model parameters are two constants $a , b > 0$ and an i . i . d . sequence of weights $ ( \phi_u ) _{u=0}^n$ , with finite second moment $\Phi^{ ( 0 ) }$ . Vertices $u$ and $v$ are joined by an edge with probability $\frac{\phi_u \phi_v}{n}a$ when they are in the same class and with probability $\frac{\phi_u \phi_v}{n}b$ otherwise . We prove that it is information-theoretically impossible to estimate the spins in a way positively correlated with the true community structure when $ ( a-b ) ^0 \Phi^{ ( 0 ) } \leq 0 ( a+b ) $ . A by-product of our proof is a precise coupling-result for local-neighbourhoods in Degree-Corrected Planted-Partition models , which could be of independent interest .
Traditional recommendation systems rely on past usage data in order to generate new recommendations . Those approaches fail to generate sensible recommendations for new users and items into the system due to missing information about their past interactions . In this paper , we propose a solution for successfully addressing item-cold start problem which uses model-based approach and recent advances in deep learning . In particular , we use latent factor model for recommendation , and predict the latent factors from item ' s descriptions using convolutional neural network when they cannot be obtained from usage data . Latent factors obtained by applying matrix factorization to the available usage data are used as ground truth to train the convolutional neural network . To create latent factor representations for the new items , the convolutional neural network uses their textual description . The results from the experiments reveal that the proposed approach significantly outperforms several baseline estimators .
We provide a classification of graphical models according to their representation as subfamilies of exponential families . Undirected graphical models with no hidden variables are linear exponential families ( LEFs ) , directed acyclic graphical models and chain graphs with no hidden variables , including Bayesian networks with several families of local distributions , are curved exponential families ( CEFs ) and graphical models with hidden variables are stratified exponential families ( SEFs ) . An SEF is a finite union of CEFs satisfying a frontier condition . In addition , we illustrate how one can automatically generate independence and non-independence constraints on the distributions over the observable variables implied by a Bayesian network with hidden variables . The relevance of these results for model selection is examined .
We introduce the hierarchical compositional network ( HCN ) , a directed generative model able to discover and disentangle , without supervision , the building blocks of a set of binary images . The building blocks are binary features defined hierarchically as a composition of some of the features in the layer immediately below , arranged in a particular manner . At a high level , HCN is similar to a sigmoid belief network with pooling . Inference and learning in HCN are very challenging and existing variational approximations do not work satisfactorily . A main contribution of this work is to show that both can be addressed using max-product message passing ( MPMP ) with a particular schedule ( no EM required ) . Also , using MPMP as an inference engine for HCN makes new tasks simple : adding supervision information , classifying images , or performing inpainting all correspond to clamping some variables of the model to their known values and running MPMP on the rest . When used for classification , fast inference with HCN has exactly the same functional form as a convolutional neural network ( CNN ) with linear activations and binary weights . However , HCN ' s features are qualitatively very different .
In this paper , a new method is proposed for sparse PCA based on the recursive divide-and-conquer methodology . The main idea is to separate the original sparse PCA problem into a series of much simpler sub-problems , each having a closed-form solution . By recursively solving these sub-problems in an analytical way , an efficient algorithm is constructed to solve the sparse PCA problem . The algorithm only involves simple computations and is thus easy to implement . The proposed method can also be very easily extended to other sparse PCA problems with certain constraints , such as the nonnegative sparse PCA problem . Furthermore , we have shown that the proposed algorithm converges to a stationary point of the problem , and its computational complexity is approximately linear in both data size and dimensionality . The effectiveness of the proposed method is substantiated by extensive experiments implemented on a series of synthetic and real data in both reconstruction-error-minimization and data-variance-maximization viewpoints .
We propose maximum likelihood estimation for learning Gaussian graphical models with a Gaussian ( ell_0^0 ) prior on the parameters . This is in contrast to the commonly used Laplace ( ell_0 ) prior for encouraging sparseness . We show that our optimization problem leads to a Riccati matrix equation , which has a closed form solution . We propose an efficient algorithm that performs a singular value decomposition of the training data . Our algorithm is O ( NT^0 ) -time and O ( NT ) -space for N variables and T samples . Our method is tailored to high-dimensional problems ( N gg T ) , in which sparseness promoting methods become intractable . Furthermore , instead of obtaining a single solution for a specific regularization parameter , our algorithm finds the whole solution path . We show that the method has logarithmic sample complexity under the spiked covariance model . We also propose sparsification of the dense solution with provable performance guarantees . We provide techniques for using our learnt models , such as removing unimportant variables , computing likelihoods and conditional distributions . Finally , we show promising results in several gene expressions datasets .
A significantly faster algorithm is presented for the original kNN mode seeking procedure . It has the advantages over the well-known mean shift algorithm that it is feasible in high-dimensional vector spaces and results in uniquely , well defined modes . Moreover , without any additional computational effort it may yield a multi-scale hierarchy of clusterings . The time complexity is just O ( n^0 . 0 ) . resulting computing times range from seconds for 00^0 objects to minutes for 00^0 objects and to less than an hour for 00^0 objects . The space complexity is just O ( n ) . The procedure is well suited for finding large sets of small clusters and is thereby a candidate to analyze thousands of clusters in millions of objects . The kNN mode seeking procedure can be used for active learning by assigning the clusters to the class of the modal objects of the clusters . Its feasibility is shown by some examples with up to 0 . 0 million handwritten digits . The obtained classification results based on the clusterings are compared with those obtained by the nearest neighbor rule and the support vector classifier based on the same labeled objects for training . It can be concluded that using the clustering structure for classification can be significantly better than using the trained classifiers . A drawback of using the clustering for classification , however , is that no classifier is obtained that may be used for out-of-sample objects .
Given i . i . d . observations of a random vector $X \in \mathbb{R}^p$ , we study the problem of estimating both its covariance matrix $\Sigma^*$ , and its inverse covariance or concentration matrix {$\Theta^* = ( \Sigma^* ) ^{-0}$ . } We estimate $\Theta^*$ by minimizing an $\ell_0$-penalized log-determinant Bregman divergence ; in the multivariate Gaussian case , this approach corresponds to $\ell_0$-penalized maximum likelihood , and the structure of $\Theta^*$ is specified by the graph of an associated Gaussian Markov random field . We analyze the performance of this estimator under high-dimensional scaling , in which the number of nodes in the graph $p$ , the number of edges $s$ and the maximum node degree $d$ , are allowed to grow as a function of the sample size $n$ . In addition to the parameters $ ( p , s , d ) $ , our analysis identifies other key quantities covariance matrix $\Sigma^*$ ; and ( b ) the $\ell_\infty$ operator norm of the sub-matrix $\Gamma^*_{S S}$ , where $S$ indexes the graph edges , and $\Gamma^* = ( \Theta^* ) ^{-0} \otimes ( \Theta^* ) ^{-0}$ ; and ( c ) a mutual incoherence or irrepresentability measure on the matrix $\Gamma^*$ and ( d ) the rate of decay $0/f ( n , \delta ) $ on the probabilities $ \{|\hat{\Sigma}^n_{ij}- \Sigma^*_{ij}| > \delta \}$ , where $\hat{\Sigma}^n$ is the sample covariance based on $n$ samples . Our first result establishes consistency of our estimate $\hat{\Theta}$ in the elementwise maximum-norm . This in turn allows us to derive convergence rates in Frobenius and spectral norms , with improvements upon existing results for graphs with maximum node degrees $d = o ( \sqrt{s} ) $ . In our second result , we show that with probability converging to one , the estimate $\hat{\Theta}$ correctly specifies the zero pattern of the concentration matrix $\Theta^*$ .
Efron et al . ( 0000 ) proposed empirical Bayes formulation of the frequentist Benjamini and Hochbergs False Discovery Rate method ( Benjamini and Hochberg , 0000 ) . This article attempts to unify the `two cultures ' using concepts of comparison density and distribution function . We have also shown how almost all of the existing local fdr methods can be viewed as proposing various model specification for comparison density - unifies the vast literature of false discovery methods under one concept and notation .
Sequential Monte Carlo ( SMC ) methods comprise one of the most successful approaches to approximate Bayesian filtering . However , SMC without good proposal distributions struggle in high dimensions . We propose nested sequential Monte Carlo ( NSMC ) , a methodology that generalises the SMC framework by requiring only approximate , properly weighted , samples from the SMC proposal distribution , while still resulting in a correct SMC algorithm . This way we can exactly approximate the locally optimal proposal , and extend the class of models for which we can perform efficient inference using SMC . We show improved accuracy over other state-of-the-art methods on several spatio-temporal state space models .
Restricted Boltzmann machine ( RBM ) is one of the fundamental building blocks of deep learning . RBM finds wide applications in dimensional reduction , feature extraction , and recommender systems via modeling the probability distributions of a variety of input data including natural images , speech signals , and customer ratings , etc . We build a bridge between RBM and tensor network states ( TNS ) widely used in quantum many-body physics research . We devise efficient algorithms to translate an RBM into the commonly used TNS . Conversely , we give sufficient and necessary conditions to determine whether a TNS can be transformed into an RBM of given architectures . Revealing these general and constructive connections can cross-fertilize both deep learning and quantum-many body physics . Notably , by exploiting the entanglement entropy bound of TNS , we can rigorously quantify the expressive power of RBM on complex datasets . Insights into TNS and its entanglement capacity can guide the design of more powerful deep learning architectures . On the other hand , RBM can represent quantum many-body states with fewer parameters compared to TNS , which may allow more efficient classical simulations .
We draw a formal connection between using synthetic training data to optimize neural network parameters and approximate , Bayesian , model-based reasoning . In particular , training a neural network using synthetic data can be viewed as learning a proposal distribution generator for approximate inference in the synthetic-data generative model . We demonstrate this connection in a recognition task where we develop a novel Captcha-breaking architecture and train it using synthetic data , demonstrating both state-of-the-art performance and a way of computing task-specific posterior uncertainty . Using a neural network trained this way , we also demonstrate successful breaking of real-world Captchas currently used by Facebook and Wikipedia . Reasoning from these empirical results and drawing connections with Bayesian modeling , we discuss the robustness of synthetic data results and suggest important considerations for ensuring good neural network generalization when training with synthetic data .
We present Fashion-MNIST , a new dataset comprising of 00x00 grayscale images of 00 , 000 fashion products from 00 categories , with 0 , 000 images per category . The training set has 00 , 000 images and the test set has 00 , 000 images . Fashion-MNIST is intended to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms , as it shares the same image size , data format and the structure of training and testing splits . The dataset is freely available at https : //github . com/zalandoresearch/fashion-mnist
The process of collecting and organizing sets of observations represents a common theme throughout the history of science . However , despite the ubiquity of scientists measuring , recording , and analyzing the dynamics of different processes , an extensive organization of scientific time-series data and analysis methods has never been performed . Addressing this , annotated collections of over 00 000 real-world and model-generated time series and over 0000 time-series analysis algorithms are analyzed in this work . We introduce reduced representations of both time series , in terms of their properties measured by diverse scientific methods , and of time-series analysis methods , in terms of their behaviour on empirical time series , and use them to organize these interdisciplinary resources . This new approach to comparing across diverse scientific data and methods allows us to organize time-series datasets automatically according to their properties , retrieve alternatives to particular analysis methods developed in other scientific disciplines , and automate the selection of useful methods for time-series classification and regression tasks . The broad scientific utility of these tools is demonstrated on datasets of electroencephalograms , self-affine time series , heart beat intervals , speech signals , and others , in each case contributing novel analysis techniques to the existing literature . Highly comparative techniques that compare across an interdisciplinary literature can thus be used to guide more focused research in time-series analysis for applications across the scientific disciplines .
Effectively modelling hidden structures in a network is very practical but theoretically challenging . Existing relational models only involve very limited information , namely the binary directional link data , embedded in a network to learn hidden networking structures . There is other rich and meaningful information ( e . g . , various attributes of entities and more granular information than binary elements such as " like " or " dislike " ) missed , which play a critical role in forming and understanding relations in a network . In this work , we propose an informative relational model ( InfRM ) framework to adequately involve rich information and its granularity in a network , including metadata information about each entity and various forms of link data . Firstly , an effective metadata information incorporation method is employed on the prior information from relational models MMSB and LFRM . This is to encourage the entities with similar metadata information to have similar hidden structures . Secondly , we propose various solutions to cater for alternative forms of link data . Substantial efforts have been made towards modelling appropriateness and efficiency , for example , using conjugate priors . We evaluate our framework and its inference algorithms in different datasets , which shows the generality and effectiveness of our models in capturing implicit structures in networks .
The community detection problem for graphs asks one to partition the n vertices V of a graph G into k communities , or clusters , such that there are many intracluster edges and few intercluster edges . Of course this is equivalent to finding a permutation matrix P such that , if A denotes the adjacency matrix of G , then PAP^T is approximately block diagonal . As there are k^n possible partitions of n vertices into k subsets , directly determining the optimal clustering is clearly infeasible . Instead one seeks to solve a more tractable approximation to the clustering problem . In this paper we reformulate the community detection problem via sparse solution of a linear system associated with the Laplacian of a graph G and then develop a two-stage approach based on a thresholding technique and a compressive sensing algorithm to find a sparse solution which corresponds to the community containing a vertex of interest in G . Crucially , our approach results in an algorithm which is able to find a single cluster of size n_0 in O ( nlog ( n ) n_0 ) operations and all k clusters in fewer than O ( n^0ln ( n ) ) operations . This is a marked improvement over the classic spectral clustering algorithm , which is unable to find a single cluster at a time and takes approximately O ( n^0 ) operations to find all k clusters . Moreover , we are able to provide robust guarantees of success for the case where G is drawn at random from the Stochastic Block Model , a popular model for graphs with clusters . Extensive numerical results are also provided , showing the efficacy of our algorithm on both synthetic and real-world data sets .
Epsilon-machines are minimal , unifilar presentations of stationary stochastic processes . They were originally defined in the history machine sense , as hidden Markov models whose states are the equivalence classes of infinite pasts with the same probability distribution over futures . In analyzing synchronization , though , an alternative generator definition was given : unifilar , edge-emitting hidden Markov models with probabilistically distinct states . The key difference is that history epsilon-machines are defined by a process , whereas generator epsilon-machines define a process . We show here that these two definitions are equivalent in the finite-state case .
This paper considers the recovery of a rank $r$ positive semidefinite matrix $X X^T\in\mathbb{R}^{n\times n}$ from $m$ scalar measurements of the form $y_i : = a_i^T X X^T a_i$ ( i . e . , quadratic measurements of $X$ ) . Such problems arise in a variety of applications , including covariance sketching of high-dimensional data streams , quadratic regression , quantum state tomography , among others . A natural approach to this problem is to minimize the loss function $f ( U ) = \sum_i ( y_i - a_i^TUU^Ta_i ) ^0$ which has an entire manifold of solutions given by $\{XO\}_{O\in\mathcal{O}_r}$ where $\mathcal{O}_r$ is the orthogonal group of $r\times r$ orthogonal matrices ; this is {\it non-convex} in the $n\times r$ matrix $U$ , but methods like gradient descent are simple and easy to implement ( as compared to semidefinite relaxation approaches ) . In this paper we show that once we have $m \geq C nr \log^0 ( n ) $ samples from isotropic gaussian $a_i$ , with high probability {\em ( a ) } this function admits a dimension-independent region of {\em local strong convexity} on lines perpendicular to the solution manifold , and {\em ( b ) } with an additional polynomial factor of $r$ samples , a simple spectral initialization will land within the region of convexity with high probability . Together , this implies that gradient descent with initialization ( but no re-sampling ) will converge linearly to the correct $X$ , up to an orthogonal transformation . We believe that this general technique ( local convexity reachable by spectral initialization ) should prove applicable to a broader class of nonconvex optimization problems .
Constrained optimization of high-dimensional numerical problems plays an important role in many scientific and industrial applications . Function evaluations in many industrial applications are severely limited and no analytical information about objective function and constraint functions is available . For such expensive black-box optimization tasks , the constraint optimization algorithm COBRA was proposed , making use of RBF surrogate modeling for both the objective and the constraint functions . COBRA has shown remarkable success in solving reliably complex benchmark problems in less than 000 function evaluations . Unfortunately , COBRA requires careful adjustment of parameters in order to do so . In this work we present a new self-adjusting algorithm SACOBRA , which is based on COBRA and capable to achieve high-quality results with very few function evaluations and no parameter tuning . It is shown with the help of performance profiles on a set of benchmark problems ( G-problems , MOPTA00 ) that SACOBRA consistently outperforms any COBRA algorithm with fixed parameter setting . We analyze the importance of the several new elements in SACOBRA and find that each element of SACOBRA plays a role to boost up the overall optimization performance . We discuss the reasons behind and get in this way a better understanding of high-quality RBF surrogate modeling .
We present a novel approach for estimating conditional probability tables , based on a joint , rather than independent , estimate of the conditional distributions belonging to the same table . We derive exact analytical expressions for the estimators and we analyse their properties both analytically and via simulation . We then apply this method to the estimation of parameters in a Bayesian network . Given the structure of the network , the proposed approach better estimates the joint distribution and significantly improves the classification performance with respect to traditional approaches .
Current approaches for Knowledge Distillation ( KD ) either directly use training data or sample from the training data distribution . In this paper , we demonstrate effectiveness of ' mismatched ' unlabeled stimulus to perform KD for image classification networks . For illustration , we consider scenarios where this is a complete absence of training data , or mismatched stimulus has to be used for augmenting a small amount of training data . We demonstrate that stimulus complexity is a key factor for distillation ' s good performance . Our examples include use of various datasets for stimulating MNIST and CIFAR teachers .
The learning of domain-invariant representations in the context of domain adaptation with neural networks is considered . We propose a new regularization method that minimizes the discrepancy between domain-specific latent feature representations directly in the hidden activation space . Although some standard distribution matching approaches exist that can be interpreted as the matching of weighted sums of moments , e . g . Maximum Mean Discrepancy ( MMD ) , an explicit order-wise matching of higher order moments has not been considered before . We propose to match the higher order central moments of probability distributions by means of order-wise moment differences . Our model does not require computationally expensive distance and kernel matrix computations . We utilize the equivalent representation of probability distributions by moment sequences to define a new distance function , called Central Moment Discrepancy ( CMD ) . We prove that CMD is a metric on the set of probability distributions on a compact interval . We further prove that convergence of probability distributions on compact intervals w . r . t . the new metric implies convergence in distribution of the respective random variables . We test our approach on two different benchmark data sets for object recognition ( Office ) and sentiment analysis of product reviews ( Amazon reviews ) . CMD achieves a new state-of-the-art performance on most domain adaptation tasks of Office and outperforms networks trained with MMD , Variational Fair Autoencoders and Domain Adversarial Neural Networks on Amazon reviews . In addition , a post-hoc parameter sensitivity analysis shows that the new approach is stable w . r . t . parameter changes in a certain interval . The source code of the experiments is publicly available .
A field known as Compressive Sensing ( CS ) has recently emerged to help address the growing challenges of capturing and processing high-dimensional signals and data sets . CS exploits the surprising fact that the information contained in a sparse signal can be preserved in a small number of compressive ( or random ) linear measurements of that signal . Strong theoretical guarantees have been established on the accuracy to which sparse or near-sparse signals can be recovered from noisy compressive measurements . In this paper , we address similar questions in the context of a different modeling framework . Instead of sparse models , we focus on the broad class of manifold models , which can arise in both parametric and non-parametric signal families . Building upon recent results concerning the stable embeddings of manifolds within the measurement space , we establish both deterministic and probabilistic instance-optimal bounds in $\ell_0$ for manifold-based signal recovery and parameter estimation from noisy compressive measurements . In line with analogous results for sparsity-based CS , we conclude that much stronger bounds are possible in the probabilistic setting . Our work supports the growing empirical evidence that manifold-based models can be used with high accuracy in compressive signal processing .
Reinforcement learning for embodied agents is a challenging problem . The accumulated reward to be optimized is often a very rugged function , and gradient methods are impaired by many local optimizers . We demonstrate , in an experimental setting , that incorporating an intrinsic reward can smoothen the optimization landscape while preserving the global optimizers of interest . We show that policy gradient optimization for locomotion in a complex morphology is significantly improved when supplementing the extrinsic reward by an intrinsic reward defined in terms of the mutual information of time consecutive sensor readings .
Many of the recent approaches to polyphonic piano note onset transcription require training a machine learning model on a large piano database . However , such approaches are limited by dataset availability ; additional training data is difficult to produce , and proposed systems often perform poorly on novel recording conditions . We propose a method to quickly synthesize arbitrary quantities of training data , avoiding the need for curating large datasets . Various aspects of piano note dynamics - including nonlinearity of note signatures with velocity , different articulations , temporal clustering of onsets , and nonlinear note partial interference - are modeled to match the characteristics of real pianos . Our method also avoids the disentanglement problem , a recently noted issue affecting machine-learning based approaches . We train a feed-forward neural network with two hidden layers on our generated training data and achieve both good transcription performance on the large MAPS piano dataset and excellent generalization qualities .
Trans-dimensional random field language models ( TRF LMs ) where sentences are modeled as a collection of random fields , have shown close performance with LSTM LMs in speech recognition and are computationally more efficient in inference . However , the training efficiency of neural TRF LMs is not satisfactory , which limits the scalability of TRF LMs on large training corpus . In this paper , several techniques on both model formulation and parameter estimation are proposed to improve the training efficiency and the performance of neural TRF LMs . First , TRFs are reformulated in the form of exponential tilting of a reference distribution . Second , noise-contrastive estimation ( NCE ) is introduced to jointly estimate the model parameters and normalization constants . Third , we extend the neural TRF LMs by marrying the deep convolutional neural network ( CNN ) and the bidirectional LSTM into the potential function to extract the deep hierarchical features and bidirectionally sequential features . Utilizing all the above techniques enables the successful and efficient training of neural TRF LMs on a 00x larger training set with only 0/0 training time and further reduces the WER with relative reduction of 0 . 0% on top of a strong LSTM LM baseline .
Community detection is a fundamental task in social network analysis . In this paper , first we develop an endorsement filtered user connectivity network by utilizing Heider ' s structural balance theory and certain Twitter triad patterns . Next , we develop three Nonnegative Matrix Factorization frameworks to investigate the contributions of different types of user connectivity and content information in community detection . We show that user content and endorsement filtered connectivity information are complementary to each other in clustering politically motivated users into pure political communities . Word usage is the strongest indicator of users ' political orientation among all content categories . Incorporating user-word matrix and word similarity regularizer provides the missing link in connectivity only methods which suffer from detection of artificially large number of clusters for Twitter networks .
Piecewise constant denoising can be solved either by deterministic optimization approaches , based on the Potts model , or by stochastic Bayesian procedures . The former lead to low computational time but require the selection of a regularization parameter , whose value significantly impacts the achieved solution , and whose automated selection remains an involved and challenging problem . Conversely , fully Bayesian formalisms encapsulate the regularization parameter selection into hierarchical models , at the price of high computational costs . This contribution proposes an operational strategy that combines hierarchical Bayesian and Potts model formulations , with the double aim of automatically tuning the regularization parameter and of maintaining computational effciency . The proposed procedure relies on formally connecting a Bayesian framework to a l0-Potts functional . Behaviors and performance for the proposed piecewise constant denoising and regularization parameter tuning techniques are studied qualitatively and assessed quantitatively , and shown to compare favorably against those of a fully Bayesian hierarchical procedure , both in accuracy and in computational load .
In most real-world settings such as recommender systems , finance , and healthcare , collecting useful information is costly and requires an active choice on the part of the decision maker . The decision-maker needs to learn simultaneously what observations to make and what actions to take . This paper incorporates the information acquisition decision into an online learning framework . We propose two different algorithms for this dual learning problem : Sim-OOS and Seq-OOS where observations are made simultaneously and sequentially , respectively . We prove that both algorithms achieve a regret that is sublinear in time . The developed framework and algorithms can be used in many applications including medical informatics , recommender systems and actionable intelligence in transportation , finance , cyber-security etc . , in which collecting information prior to making decisions is costly . We validate our algorithms in a breast cancer example setting in which we show substantial performance gains for our proposed algorithms .
We introduce a novel approach for parallelizing MCMC inference in models with spatially determined conditional independence relationships , for which existing techniques exploiting graphical model structure are not applicable . Our approach is motivated by a model of seismic events and signals , where events detected in distant regions are approximately independent given those in intermediate regions . We perform parallel inference by coloring a factor graph defined over regions of latent space , rather than individual model variables . Evaluating on a model of seismic event detection , we achieve significant speedups over serial MCMC with no degradation in inference quality .
We consider sequential decision making problems for binary classification scenario in which the learner takes an active role in repeatedly selecting samples from the action pool and receives the binary label of the selected alternatives . Our problem is motivated by applications where observations are time consuming and/or expensive , resulting in small samples . The goal is to identify the best alternative with the highest response . We use Bayesian logistic regression to predict the response of each alternative . By formulating the problem as a Markov decision process , we develop a knowledge-gradient type policy to guide the experiment by maximizing the expected value of information of labeling each alternative and provide a finite-time analysis on the estimated error . Experiments on benchmark UCI datasets demonstrate the effectiveness of the proposed method .
We prove statistical rates of convergence for kernel-based least squares regression from i . i . d . data using a conjugate gradient algorithm , where regularization against overfitting is obtained by early stopping . This method is related to Kernel Partial Least Squares , a regression method that combines supervised dimensionality reduction with least squares projection . Following the setting introduced in earlier related literature , we study so-called " fast convergence rates " depending on the regularity of the target regression function ( measured by a source condition in terms of the kernel integral operator ) and on the effective dimensionality of the data mapped into the kernel space . We obtain upper bounds , essentially matching known minimax lower bounds , for the $\mathcal{L}^0$ ( prediction ) norm as well as for the stronger Hilbert norm , if the true regression function belongs to the reproducing kernel Hilbert space . If the latter assumption is not fulfilled , we obtain similar convergence rates for appropriate norms , provided additional unlabeled data are available .
The goal of ordinal embedding is to represent items as points in a low-dimensional Euclidean space given a set of constraints in the form of distance comparisons like " item $i$ is closer to item $j$ than item $k$ " . Ordinal constraints like this often come from human judgments . To account for errors and variation in judgments , we consider the noisy situation in which the given constraints are independently corrupted by reversing the correct constraint with some probability . This paper makes several new contributions to this problem . First , we derive prediction error bounds for ordinal embedding with noise by exploiting the fact that the rank of a distance matrix of points in $\mathbb{R}^d$ is at most $d+0$ . These bounds characterize how well a learned embedding predicts new comparative judgments . Second , we investigate the special case of a known noise model and study the Maximum Likelihood estimator . Third , knowledge of the noise model enables us to relate prediction errors to embedding accuracy . This relationship is highly non-trivial since we show that the linear map corresponding to distance comparisons is non-invertible , but there exists a nonlinear map that is invertible . Fourth , two new algorithms for ordinal embedding are proposed and evaluated in experiments .
In machine learning and data mining , linear models have been widely used to model the response as parametric linear functions of the predictors . To relax such stringent assumptions made by parametric linear models , additive models consider the response to be a summation of unknown transformations applied on the predictors ; in particular , additive isotonic models ( AIMs ) assume the unknown transformations to be monotone . In this paper , we introduce sparse linear isotonic models ( SLIMs ) for highdimensional problems by hybridizing ideas in parametric sparse linear models and AIMs , which enjoy a few appealing advantages over both . In the high-dimensional setting , a two-step algorithm is proposed for estimating the sparse parameters as well as the monotone functions over predictors . Under mild statistical assumptions , we show that the algorithm can accurately estimate the parameters . Promising preliminary experiments are presented to support the theoretical results .
Network anomaly detection is still a vibrant research area . As the fast growth of network bandwidth and the tremendous traffic on the network , there arises an extremely challengeable question : How to efficiently and accurately detect the anomaly on multiple traffic ? In multi-task learning , the traffic consisting of flows at different time periods is considered as a task . Multiple tasks at different time periods performed simultaneously to detect anomalies . In this paper , we apply the multi-task feature selection in network anomaly detection area which provides a powerful method to gather information from multiple traffic and detect anomalies on it simultaneously . In particular , the multi-task feature selection includes the well-known l0-norm based feature selection as a special case given only one task . Moreover , we show that the multi-task feature selection is more accurate by utilizing more information simultaneously than the l0-norm based method . At the evaluation stage , we preprocess the raw data trace from trans-Pacific backbone link between Japan and the United States , label with anomaly communities , and generate a 000-feature dataset . We show empirically that the multi-task feature selection outperforms independent l0-norm based feature selection on real traffic dataset .
This paper presents a case study of a recommender system that can be used to save energy in smart homes without lowering the comfort of the inhabitants . We present an algorithm that uses consumer behavior data only and uses machine learning to suggest actions for inhabitants to reduce the energy consumption of their homes . The system mines for frequent and periodic patterns in the event data provided by the Digitalstrom home automation system . These patterns are converted into association rules , prioritized and compared with the current behavior of the inhabitants . If the system detects an opportunities to save energy without decreasing the comfort level it sends a recommendation to the residents .
A trend in compressed sensing ( CS ) is to exploit structure for improved reconstruction performance . In the basic CS model , exploiting the clustering structure among nonzero elements in the solution vector has drawn much attention , and many algorithms have been proposed . However , few algorithms explicitly consider correlation within a cluster . Meanwhile , in the multiple measurement vector ( MMV ) model correlation among multiple solution vectors is largely ignored . Although several recently developed algorithms consider the exploitation of the correlation , these algorithms need to know a priori the correlation structure , thus limiting their effectiveness in practical problems . Recently , we developed a sparse Bayesian learning ( SBL ) algorithm , namely T-SBL , and its variants , which adaptively learn the correlation structure and exploit such correlation information to significantly improve reconstruction performance . Here we establish their connections to other popular algorithms , such as the group Lasso , iterative reweighted $\ell_0$ and $\ell_0$ algorithms , and algorithms for time-varying sparsity . We also provide strategies to improve these existing algorithms .
Covariance graphical lasso applies a lasso penalty on the elements of the covariance matrix . This method is useful because it not only produces sparse estimation of covariance matrix but also discovers marginal independence structures by generating zeros in the covariance matrix . We propose and explore two new algorithms for solving the covariance graphical lasso problem . Our new algorithms are based on coordinate descent and ECM . We show that these two algorithms are more attractive than the only existing competing algorithm of Bien and Tibshirani ( 0000 ) in terms of simplicity , speed and stability . We also discuss convergence properties of our algorithms .
Quantum time evolution exhibits rich physics , attributable to the interplay between the density and phase of a wave function . However , unlike classical heat diffusion , the wave nature of quantum mechanics has not yet been extensively explored in modern data analysis . We propose that the Laplace transform of quantum transport ( QT ) can be used to construct a powerful ensemble of maps from a given complex network to a circle $S^0$ , such that closely-related nodes on the network are grouped into sharply concentrated clusters on $S^0$ . The resulting QT clustering ( QTC ) algorithm is shown to outperform the state-of-the-art spectral clustering method on synthetic and real data sets containing complex geometric patterns . The observed phenomenon of QTC can be interpreted as a collective behavior of the microscopic nodes that evolve as macroscopic cluster orbitals in an effective tight-binding model recapitulating the network .
Tuning hyperparameters of learning algorithms is hard because gradients are usually unavailable . We compute exact gradients of cross-validation performance with respect to all hyperparameters by chaining derivatives backwards through the entire training procedure . These gradients allow us to optimize thousands of hyperparameters , including step-size and momentum schedules , weight initialization distributions , richly parameterized regularization schemes , and neural network architectures . We compute hyperparameter gradients by exactly reversing the dynamics of stochastic gradient descent with momentum .
A good clustering can help a data analyst to explore and understand a data set , but what constitutes a good clustering may depend on domain-specific and application-specific criteria . These criteria can be difficult to formalize , even when it is easy for an analyst to know a good clustering when they see one . We present a new approach to interactive clustering for data exploration called TINDER , based on a particularly simple feedback mechanism , in which an analyst can reject a given clustering and request a new one , which is chosen to be different from the previous clustering while fitting the data well . We formalize this interaction in a Bayesian framework as a method for prior elicitation , in which each different clustering is produced by a prior distribution that is modified to discourage previously rejected clusterings . We show that TINDER successfully produces a diverse set of clusterings , each of equivalent quality , that are much more diverse than would be obtained by randomized restarts .
Black box variational inference ( BBVI ) with reparameterization gradients triggered the exploration of divergence measures other than the Kullback-Leibler ( KL ) divergence , such as alpha divergences . In this paper , we view BBVI with generalized divergences as a form of estimating the marginal likelihood via biased importance sampling . The choice of divergence determines a bias-variance trade-off between the tightness of a bound on the marginal likelihood ( low bias ) and the variance of its gradient estimators . Drawing on variational perturbation theory of statistical physics , we use these insights to construct a family of new variational bounds . Enumerated by an odd integer order $K$ , this family captures the standard KL bound for $K=0$ , and converges to the exact marginal likelihood as $K\to\infty$ . Compared to alpha-divergences , our reparameterization gradients have a lower variance . We show in experiments on Gaussian Processes and Variational Autoencoders that the new bounds are more mass covering , and that the resulting posterior covariances are closer to the true posterior and lead to higher likelihoods on held-out data .
Digital pathology is not only one of the most promising fields of diagnostic medicine , but at the same time a hot topic for fundamental research . Digital pathology is not just the transfer of histopathological slides into digital representations . The combination of different data sources ( images , patient records , and *omics data ) together with current advances in artificial intelligence/machine learning enable to make novel information accessible and quantifiable to a human expert , which is not yet available and not exploited in current medical settings . The grand goal is to reach a level of usable intelligence to understand the data in the context of an application task , thereby making machine decisions transparent , interpretable and explainable . The foundation of such an " augmented pathologist " needs an integrated approach : While machine learning algorithms require many thousands of training examples , a human expert is often confronted with only a few data points . Interestingly , humans can learn from such few examples and are able to instantly interpret complex patterns . Consequently , the grand goal is to combine the possibilities of artificial intelligence with human intelligence and to find a well-suited balance between them to enable what neither of them could do on their own . This can raise the quality of education , diagnosis , prognosis and prediction of cancer and other diseases . In this paper we describe some ( incomplete ) research issues which we believe should be addressed in an integrated and concerted effort for paving the way towards the augmented pathologist .
Bayesian optimization has recently emerged as a popular and efficient tool for global optimization and hyperparameter tuning . Currently , the established Bayesian optimization practice requires a user-defined bounding box which is assumed to contain the optimizer . However , when little is known about the probed objective function , it can be difficult to prescribe such bounds . In this work we modify the standard Bayesian optimization framework in a principled way to allow automatic resizing of the search space . We introduce two alternative methods and compare them on two common synthetic benchmarking test functions as well as the tasks of tuning the stochastic gradient descent optimizer of a multi-layered perceptron and a convolutional neural network on MNIST .
We provide comments on the article " High-dimensional simultaneous inference with the bootstrap " by Ruben Dezeure , Peter Buhlmann and Cun-Hui Zhang .
The problem of Poisson denoising appears in various imaging applications , such as low-light photography , medical imaging and microscopy . In cases of high SNR , several transformations exist so as to convert the Poisson noise into an additive i . i . d . Gaussian noise , for which many effective algorithms are available . However , in a low SNR regime , these transformations are significantly less accurate , and a strategy that relies directly on the true noise statistics is required . A recent work by Salmon et al . took this route , proposing a patch-based exponential image representation model based on GMM ( Gaussian mixture model ) , leading to state-of-the-art results . In this paper , we propose to harness sparse-representation modeling to the image patches , adopting the same exponential idea . Our scheme uses a greedy pursuit with boot-strapping based stopping condition and dictionary learning within the denoising process . The reconstruction performance of the proposed scheme is competitive with leading methods in high SNR , and achieving state-of-the-art results in cases of low SNR .
We connect a broad class of generative models through their shared reliance on sequential decision making . Motivated by this view , we develop extensions to an existing model , and then explore the idea further in the context of data imputation -- perhaps the simplest setting in which to investigate the relation between unconditional and conditional generative modelling . We formulate data imputation as an MDP and develop models capable of representing effective policies for it . We construct the models using neural networks and train them using a form of guided policy search . Our models generate predictions through an iterative process of feedback and refinement . We show that this approach can learn effective policies for imputation problems of varying difficulty and across multiple datasets .
In this paper , we explore different ways to extend a recurrent neural network ( RNN ) to a \textit{deep} RNN . We start by arguing that the concept of depth in an RNN is not as clear as it is in feedforward neural networks . By carefully analyzing and understanding the architecture of an RNN , however , we find three points of an RNN which may be made deeper ; ( 0 ) input-to-hidden function , ( 0 ) hidden-to-hidden transition and ( 0 ) hidden-to-output function . Based on this observation , we propose two novel architectures of a deep RNN which are orthogonal to an earlier attempt of stacking multiple recurrent layers to build a deep RNN ( Schmidhuber , 0000 ; El Hihi and Bengio , 0000 ) . We provide an alternative interpretation of these deep RNNs using a novel framework based on neural operators . The proposed deep RNNs are empirically evaluated on the tasks of polyphonic music prediction and language modeling . The experimental result supports our claim that the proposed deep RNNs benefit from the depth and outperform the conventional , shallow RNNs .
This paper studies a new Bayesian algorithm for the joint reconstruction and classification of reflectance confocal microscopy ( RCM ) images , with application to the identification of human skin lentigo . The proposed Bayesian approach takes advantage of the distribution of the multiplicative speckle noise affecting the true reflectivity of these images and of appropriate priors for the unknown model parameters . A Markov chain Monte Carlo ( MCMC ) algorithm is proposed to jointly estimate the model parameters and the image of true reflectivity while classifying images according to the distribution of their reflectivity . Precisely , a Metropolis-whitin-Gibbs sampler is investigated to sample the posterior distribution of the Bayesian model associated with RCM images and to build estimators of its parameters , including labels indicating the class of each RCM image . The resulting algorithm is applied to synthetic data and to real images from a clinical study containing healthy and lentigo patients .
This work is about recognizing human activities occurring in videos at distinct semantic levels , including individual actions , interactions , and group activities . The recognition is realized using a two-level hierarchy of Long Short-Term Memory ( LSTM ) networks , forming a feed-forward deep architecture , which can be trained end-to-end . In comparison with existing architectures of LSTMs , we make two key contributions giving the name to our approach as Confidence-Energy Recurrent Network -- CERN . First , instead of using the common softmax layer for prediction , we specify a novel energy layer ( EL ) for estimating the energy of our predictions . Second , rather than finding the common minimum-energy class assignment , which may be numerically unstable under uncertainty , we specify that the EL additionally computes the p-values of the solutions , and in this way estimates the most confident energy minimum . The evaluation on the Collective Activity and Volleyball datasets demonstrates : ( i ) advantages of our two contributions relative to the common softmax and energy-minimization formulations and ( ii ) a superior performance relative to the state-of-the-art approaches .
Consider the problem of sampling sequentially from a finite number of $N \geq 0$ populations , specified by random variables $X^i_k$ , $ i = 0 , \ldots , N , $ and $k = 0 , 0 , \ldots$ ; where $X^i_k$ denotes the outcome from population $i$ the $k^{th}$ time it is sampled . It is assumed that for each fixed $i$ , $\{ X^i_k \}_{k \geq 0}$ is a sequence of i . i . d . normal random variables , with unknown mean $\mu_i$ and unknown variance $\sigma_i^0$ . The objective is to have a policy $\pi$ for deciding from which of the $N$ populations to sample form at any time $n=0 , 0 , \ldots$ so as to maximize the expected sum of outcomes of $n$ samples or equivalently to minimize the regret due to lack on information of the parameters $\mu_i$ and $\sigma_i^0$ . In this paper , we present a simple inflated sample mean ( ISM ) index policy that is asymptotically optimal in the sense of Theorem 0 below . This resolves a standing open problem from Burnetas and Katehakis ( 0000 ) . Additionally , finite horizon regret bounds are given .
Despite having various attractive qualities such as high prediction accuracy and the ability to quantify uncertainty and avoid over-fitting , Bayesian Matrix Factorization has not been widely adopted because of the prohibitive cost of inference . In this paper , we propose a scalable distributed Bayesian matrix factorization algorithm using stochastic gradient MCMC . Our algorithm , based on Distributed Stochastic Gradient Langevin Dynamics , can not only match the prediction accuracy of standard MCMC methods like Gibbs sampling , but at the same time is as fast and simple as stochastic gradient descent . In our experiments , we show that our algorithm can achieve the same level of prediction accuracy as Gibbs sampling an order of magnitude faster . We also show that our method reduces the prediction error as fast as distributed stochastic gradient descent , achieving a 0 . 0% improvement in RMSE for the Netflix dataset and an 0 . 0% for the Yahoo music dataset .
We study active learning where the labeler can not only return incorrect labels but also abstain from labeling . We consider different noise and abstention conditions of the labeler . We propose an algorithm which utilizes abstention responses , and analyze its statistical consistency and query complexity under fairly natural assumptions on the noise and abstention rate of the labeler . This algorithm is adaptive in a sense that it can automatically request less queries with a more informed or less noisy labeler . We couple our algorithm with lower bounds to show that under some technical conditions , it achieves nearly optimal query complexity .
One approach for constructing copula functions is by multiplication . Given that products of cumulative distribution functions ( CDFs ) are also CDFs , an adjustment to this multiplication will result in a copula model , as discussed by Liebscher ( J Mult Analysis , 0000 ) . Parameterizing models via products of CDFs has some advantages , both from the copula perspective ( e . g . , it is well-defined for any dimensionality ) and from general multivariate analysis ( e . g . , it provides models where small dimensional marginal distributions can be easily read-off from the parameters ) . Independently , Huang and Frey ( J Mach Learn Res , 0000 ) showed the connection between certain sparse graphical models and products of CDFs , as well as message-passing ( dynamic programming ) schemes for computing the likelihood function of such models . Such schemes allows models to be estimated with likelihood-based methods . We discuss and demonstrate MCMC approaches for estimating such models in a Bayesian context , their application in copula modeling , and how message-passing can be strongly simplified . Importantly , our view of message-passing opens up possibilities to scaling up such methods , given that even dynamic programming is not a scalable solution for calculating likelihood functions in many models .
Recently dictionary screening has been proposed as an effective way to improve the computational efficiency of solving the lasso problem , which is one of the most commonly used method for learning sparse representations . To address today ' s ever increasing large dataset , effective screening relies on a tight region bound on the solution to the dual lasso . Typical region bounds are in the form of an intersection of a sphere and multiple half spaces . One way to tighten the region bound is using more half spaces , which however , adds to the overhead of solving the high dimensional optimization problem in lasso screening . This paper reveals the interesting property that the optimization problem only depends on the projection of features onto the subspace spanned by the normals of the half spaces . This property converts an optimization problem in high dimension to much lower dimension , and thus sheds light on reducing the computation overhead of lasso screening based on tighter region bounds .
Representing 0D shape deformations by linear models in high-dimensional space has many applications in computer vision and medical imaging , such as shape-based interpolation or segmentation . Commonly , using Principal Components Analysis a low-dimensional ( affine ) subspace of the high-dimensional shape space is determined . However , the resulting factors ( the most dominant eigenvectors of the covariance matrix ) have global support , i . e . changing the coefficient of a single factor deforms the entire shape . In this paper , a method to obtain deformation factors with local support is presented . The benefits of such models include better flexibility and interpretability as well as the possibility of interactively deforming shapes locally . For that , based on a well-grounded theoretical motivation , we formulate a matrix factorisation problem employing sparsity and graph-based regularisation terms . We demonstrate that for brain shapes our method outperforms the state of the art in local support models with respect to generalisation ability and sparse shape reconstruction , whereas for human body shapes our method gives more realistic deformations .
We present an efficient algorithm for simultaneously training sparse generalized linear models across many related problems , which may arise from bootstrapping , cross-validation and nonparametric permutation testing . Our approach leverages the redundancies across problems to obtain significant computational improvements relative to solving the problems sequentially by a conventional algorithm . We demonstrate our fast simultaneous training of generalized linear models ( FaSTGLZ ) algorithm on a number of real-world datasets , and we run otherwise computationally intensive bootstrapping and permutation test analyses that are typically necessary for obtaining statistically rigorous classification results and meaningful interpretation . Code is freely available at http : //liinc . bme . columbia . edu/fastglz .
In this paper , we consider the problem of estimating multiple graphical models simultaneously using the fused lasso penalty , which encourages adjacent graphs to share similar structures . A motivating example is the analysis of brain networks of Alzheimer ' s disease using neuroimaging data . Specifically , we may wish to estimate a brain network for the normal controls ( NC ) , a brain network for the patients with mild cognitive impairment ( MCI ) , and a brain network for Alzheimer ' s patients ( AD ) . We expect the two brain networks for NC and MCI to share common structures but not to be identical to each other ; similarly for the two brain networks for MCI and AD . The proposed formulation can be solved using a second-order method . Our key technical contribution is to establish the necessary and sufficient condition for the graphs to be decomposable . Based on this key property , a simple screening rule is presented , which decomposes the large graphs into small subgraphs and allows an efficient estimation of multiple independent ( small ) subgraphs , dramatically reducing the computational cost . We perform experiments on both synthetic and real data ; our results demonstrate the effectiveness and efficiency of the proposed approach .
We develop and analyze stochastic optimization algorithms for problems in which the expected loss is strongly convex , and the optimum is ( approximately ) sparse . Previous approaches are able to exploit only one of these two structures , yielding an $\order ( \pdim/T ) $ convergence rate for strongly convex objectives in $\pdim$ dimensions , and an $\order ( \sqrt{ ( \spindex \log \pdim ) /T} ) $ convergence rate when the optimum is $\spindex$-sparse . Our algorithm is based on successively solving a series of $\ell_0$-regularized optimization problems using Nesterov ' s dual averaging algorithm . We establish that the error of our solution after $T$ iterations is at most $\order ( ( \spindex \log\pdim ) /T ) $ , with natural extensions to approximate sparsity . Our results apply to locally Lipschitz losses including the logistic , exponential , hinge and least-squares losses . By recourse to statistical minimax results , we show that our convergence rates are optimal up to multiplicative constant factors . The effectiveness of our approach is also confirmed in numerical simulations , in which we compare to several baselines on a least-squares regression problem .
One of the major issues in stochastic gradient descent ( SGD ) methods is how to choose an appropriate step size while running the algorithm . Since the traditional line search technique does not apply for stochastic optimization algorithms , the common practice in SGD is either to use a diminishing step size , or to tune a fixed step size by hand , which can be time consuming in practice . In this paper , we propose to use the Barzilai-Borwein ( BB ) method to automatically compute step sizes for SGD and its variant : stochastic variance reduced gradient ( SVRG ) method , which leads to two algorithms : SGD-BB and SVRG-BB . We prove that SVRG-BB converges linearly for strongly convex objective functions . As a by-product , we prove the linear convergence result of SVRG with Option I proposed in [00] , whose convergence result is missing in the literature . Numerical experiments on standard data sets show that the performance of SGD-BB and SVRG-BB is comparable to and sometimes even better than SGD and SVRG with best-tuned step sizes , and is superior to some advanced SGD variants .
In this document we are going to derive the equations needed to implement a Variational Bayes i-vector extractor . This can be used to extract longer i-vectors reducing the risk of overfittig or to adapt an i-vector extractor from a database to another with scarce development data . This work is based on Patrick Kenny ' s joint factor analysis and Christopher Bishop ' s variational principal components .
Deep learning algorithms have been shown to perform extremely well on many classical machine learning problems . However , recent studies have shown that deep learning , like other machine learning techniques , is vulnerable to adversarial samples : inputs crafted to force a deep neural network ( DNN ) to provide adversary-selected outputs . Such attacks can seriously undermine the security of the system supported by the DNN , sometimes with devastating consequences . For example , autonomous vehicles can be crashed , illicit or illegal content can bypass content filters , or biometric authentication systems can be manipulated to allow improper access . In this work , we introduce a defensive mechanism called defensive distillation to reduce the effectiveness of adversarial samples on DNNs . We analytically investigate the generalizability and robustness properties granted by the use of defensive distillation when training DNNs . We also empirically study the effectiveness of our defense mechanisms on two DNNs placed in adversarial settings . The study shows that defensive distillation can reduce effectiveness of sample creation from 00% to less than 0 . 0% on a studied DNN . Such dramatic gains can be explained by the fact that distillation leads gradients used in adversarial sample creation to be reduced by a factor of 00^00 . We also find that distillation increases the average minimum number of features that need to be modified to create adversarial samples by about 000% on one of the DNNs we tested .
PAQ0 is an open source lossless data compression algorithm that currently achieves the best compression rates on many benchmarks . This report presents a detailed description of PAQ0 from a statistical machine learning perspective . It shows that it is possible to understand some of the modules of PAQ0 and use this understanding to improve the method . However , intuitive statistical explanations of the behavior of other modules remain elusive . We hope the description in this report will be a starting point for discussions that will increase our understanding , lead to improvements to PAQ0 , and facilitate a transfer of knowledge from PAQ0 to other machine learning methods , such a recurrent neural networks and stochastic memoizers . Finally , the report presents a broad range of new applications of PAQ to machine learning tasks including language modeling and adaptive text prediction , adaptive game playing , classification , and compression using features from the field of deep learning .
We propose a semidefinite programming ( SDP ) algorithm for community detection in the stochastic block model , a popular model for networks with latent community structure . We prove that our algorithm achieves exact recovery of the latent communities , up to the information-theoretic limits determined by Abbe and Sandon ( 0000 ) . Our result extends prior SDP approaches by allowing for many communities of different sizes . By virtue of a semidefinite approach , our algorithms succeed against a semirandom variant of the stochastic block model , guaranteeing a form of robustness and generalization . We further explore how semirandom models can lend insight into both the strengths and limitations of SDPs in this setting .
Within the natural language processing ( NLP ) community , active learning has been widely investigated and applied in order to alleviate the annotation bottleneck faced by developers of new NLP systems and technologies . This paper presents the first theoretical analysis of stopping active learning based on stabilizing predictions ( SP ) . The analysis has revealed three elements that are central to the success of the SP method : ( 0 ) bounds on Cohen ' s Kappa agreement between successively trained models impose bounds on differences in F-measure performance of the models ; ( 0 ) since the stop set does not have to be labeled , it can be made large in practice , helping to guarantee that the results transfer to previously unseen streams of examples at test/application time ; and ( 0 ) good ( low variance ) sample estimates of Kappa between successive models can be obtained . Proofs of relationships between the level of Kappa agreement and the difference in performance between consecutive models are presented . Specifically , if the Kappa agreement between two models exceeds a threshold T ( where $T>0$ ) , then the difference in F-measure performance between those models is bounded above by $\frac{0 ( 0-T ) }{T}$ in all cases . If precision of the positive conjunction of the models is assumed to be $p$ , then the bound can be tightened to $\frac{0 ( 0-T ) }{ ( p+0 ) T}$ .
As datasets grow richer , an important challenge is to leverage the full features in the data to maximize the number of useful discoveries while controlling for false positives . We address this problem in the context of multiple hypotheses testing , where for each hypothesis , we observe a p-value along with a set of features specific to that hypothesis . For example , in genetic association studies , each hypothesis tests the correlation between a variant and the trait . We have a rich set of features for each variant ( e . g . its location , conservation , epigenetics etc . ) which could inform how likely the variant is to have a true association . However popular testing approaches , such as Benjamini-Hochberg ' s procedure ( BH ) and independent hypothesis weighting ( IHW ) , either ignore these features or assume that the features are categorical or uni-variate . We propose a new algorithm , NeuralFDR , which automatically learns a discovery threshold as a function of all the hypothesis features . We parametrize the discovery threshold as a neural network , which enables flexible handling of multi-dimensional discrete and continuous features as well as efficient end-to-end optimization . We prove that NeuralFDR has strong false discovery rate ( FDR ) guarantees , and show that it makes substantially more discoveries in synthetic and real datasets . Moreover , we demonstrate that the learned discovery threshold is directly interpretable .
In this paper , we study the nonnegative matrix factorization problem under the separability assumption ( that is , there exists a cone spanned by a small subset of the columns of the input nonnegative data matrix containing all columns ) , which is equivalent to the hyperspectral unmixing problem under the linear mixing model and the pure-pixel assumption . We present a family of fast recursive algorithms , and prove they are robust under any small perturbations of the input data matrix . This family generalizes several existing hyperspectral unmixing algorithms and hence provides for the first time a theoretical justification of their better practical performance .
We study the computational capacity of a model neuron , the Tempotron , which classifies sequences of spikes by linear-threshold operations . We use statistical mechanics and extreme value theory to derive the capacity of the system in random classification tasks . In contrast to its static analog , the Perceptron , the Tempotron ' s solutions space consists of a large number of small clusters of weight vectors . The capacity of the system per synapse is finite in the large size limit and weakly diverges with the stimulus duration relative to the membrane and synaptic time constants .
This paper focuses on the problem of estimating historical traffic volumes between sparsely-located traffic sensors , which transportation agencies need to accurately compute statewide performance measures . To this end , the paper examines applications of vehicle probe data , automatic traffic recorder counts , and neural network models to estimate hourly volumes in the Maryland highway network , and proposes a novel approach that combines neural networks with an existing profiling method . On average , the proposed approach yields 00% more accurate estimates than volume profiles , which are currently used by transportation agencies across the US to compute statewide performance measures . The paper also quantifies the value of using vehicle probe data in estimating hourly traffic volumes , which provides important managerial insights to transportation agencies interested in acquiring this type of data . For example , results show that volumes can be estimated with a mean absolute percent error of about 00% at locations where average number of observed probes is between 00 and 00 vehicles/hr , which provides a useful guideline for assessing the value of probe vehicle data from different vendors .
In this paper , we initiate a systematic investigation of differentially private algorithms for convex empirical risk minimization . Various instantiations of this problem have been studied before . We provide new algorithms and matching lower bounds for private ERM assuming only that each data point ' s contribution to the loss function is Lipschitz bounded and that the domain of optimization is bounded . We provide a separate set of algorithms and matching lower bounds for the setting in which the loss functions are known to also be strongly convex . Our algorithms run in polynomial time , and in some cases even match the optimal non-private running time ( as measured by oracle complexity ) . We give separate algorithms ( and lower bounds ) for $ ( \epsilon , 0 ) $- and $ ( \epsilon , \delta ) $-differential privacy ; perhaps surprisingly , the techniques used for designing optimal algorithms in the two cases are completely different . Our lower bounds apply even to very simple , smooth function families , such as linear and quadratic functions . This implies that algorithms from previous work can be used to obtain optimal error rates , under the additional assumption that the contributions of each data point to the loss function is smooth . We show that simple approaches to smoothing arbitrary loss functions ( in order to apply previous techniques ) do not yield optimal error rates . In particular , optimal algorithms were not previously known for problems such as training support vector machines and the high-dimensional median .
We propose an efficient ADMM method with guarantees for high-dimensional problems . We provide explicit bounds for the sparse optimization problem and the noisy matrix decomposition problem . For sparse optimization , we establish that the modified ADMM method has an optimal convergence rate of $\mathcal{O} ( s\log d/T ) $ , where $s$ is the sparsity level , $d$ is the data dimension and $T$ is the number of steps . This matches with the minimax lower bounds for sparse estimation . For matrix decomposition into sparse and low rank components , we provide the first guarantees for any online method , and prove a convergence rate of $\tilde{\mathcal{O}} ( ( s+r ) \beta^0 ( p ) /T ) + \mathcal{O} ( 0/p ) $ for a $p\times p$ matrix , where $s$ is the sparsity level , $r$ is the rank and $\Theta ( \sqrt{p} ) \leq \beta ( p ) \leq \Theta ( p ) $ . Our guarantees match the minimax lower bound with respect to $s , r$ and $T$ . In addition , we match the minimax lower bound with respect to the matrix dimension $p$ , i . e . $\beta ( p ) =\Theta ( \sqrt{p} ) $ , for many important statistical models including the independent noise model , the linear Bayesian network and the latent Gaussian graphical model under some conditions . Our ADMM method is based on epoch-based annealing and consists of inexpensive steps which involve projections on to simple norm balls . Experiments show that for both sparse optimization and matrix decomposition problems , our algorithm outperforms the state-of-the-art methods . In particular , we reach higher accuracy with same time complexity .
This paper considers the problem of clustering a collection of unlabeled data points assumed to lie near a union of lower-dimensional planes . As is common in computer vision or unsupervised learning applications , we do not know in advance how many subspaces there are nor do we have any information about their dimensions . We develop a novel geometric analysis of an algorithm named sparse subspace clustering ( SSC ) [In IEEE Conference on Computer Vision and Pattern Recognition , 0000 . CVPR 0000 ( 0000 ) 0000-0000 . IEEE] , which significantly broadens the range of problems where it is provably effective . For instance , we show that SSC can recover multiple subspaces , each of dimension comparable to the ambient dimension . We also prove that SSC can correctly cluster data points even when the subspaces of interest intersect . Further , we develop an extension of SSC that succeeds when the data set is corrupted with possibly overwhelmingly many outliers . Underlying our analysis are clear geometric insights , which may bear on other sparse recovery problems . A numerical study complements our theoretical analysis and demonstrates the effectiveness of these methods .
This paper introduces a general Bayesian non- parametric latent feature model suitable to per- form automatic exploratory analysis of heterogeneous datasets , where the attributes describing each object can be either discrete , continuous or mixed variables . The proposed model presents several important properties . First , it accounts for heterogeneous data while can be inferred in linear time with respect to the number of objects and attributes . Second , its Bayesian nonparametric nature allows us to automatically infer the model complexity from the data , i . e . , the number of features necessary to capture the latent structure in the data . Third , the latent features in the model are binary-valued variables , easing the interpretability of the obtained latent features in data exploration tasks .
Success in the quest for artificial intelligence has the potential to bring unprecedented benefits to humanity , and it is therefore worthwhile to investigate how to maximize these benefits while avoiding potential pitfalls . This article gives numerous examples ( which should by no means be construed as an exhaustive list ) of such worthwhile research aimed at ensuring that AI remains robust and beneficial .
Class imbalance is a challenging issue in practical classification problems for deep learning models as well as traditional models . Traditionally successful countermeasures such as synthetic over-sampling have had limited success with complex , structured data handled by deep learning models . In this paper , we propose Deep Over-sampling ( DOS ) , a framework for extending the synthetic over-sampling method to exploit the deep feature space acquired by a convolutional neural network ( CNN ) . Its key feature is an explicit , supervised representation learning , for which the training data presents each raw input sample with a synthetic embedding target in the deep feature space , which is sampled from the linear subspace of in-class neighbors . We implement an iterative process of training the CNN and updating the targets , which induces smaller in-class variance among the embeddings , to increase the discriminative power of the deep representation . We present an empirical study using public benchmarks , which shows that the DOS framework not only counteracts class imbalance better than the existing method , but also improves the performance of the CNN in the standard , balanced settings .
Most accurate predictions are typically obtained by learning machines with complex feature spaces ( as e . g . induced by kernels ) . Unfortunately , such decision rules are hardly accessible to humans and cannot easily be used to gain insights about the application domain . Therefore , one often resorts to linear models in combination with variable selection , thereby sacrificing some predictive power for presumptive interpretability . Here , we introduce the Feature Importance Ranking Measure ( FIRM ) , which by retrospective analysis of arbitrary learning machines allows to achieve both excellent predictive performance and superior interpretation . In contrast to standard raw feature weighting , FIRM takes the underlying correlation structure of the features into account . Thereby , it is able to discover the most relevant features , even if their appearance in the training data is entirely prevented by noise . The desirable properties of FIRM are investigated analytically and illustrated in simulations .
Recent research on multiple kernel learning has lead to a number of approaches for combining kernels in regularized risk minimization . The proposed approaches include different formulations of objectives and varying regularization strategies . In this paper we present a unifying general optimization criterion for multiple kernel learning and show how existing formulations are subsumed as special cases . We also derive the criterion ' s dual representation , which is suitable for general smooth optimization algorithms . Finally , we evaluate multiple kernel learning in this framework analytically using a Rademacher complexity bound on the generalization error and empirically in a set of experiments .
We consider the inverse Ising problem , i . e . the inference of network couplings from observed spin trajectories for a model with continuous time Glauber dynamics . By introducing two sets of auxiliary latent random variables we render the likelihood into a form , which allows for simple iterative inference algorithms with analytical updates . The variables are : ( 0 ) Poisson variables to linearise an exponential term which is typical for point process likelihoods and ( 0 ) P\ ' olya-Gamma variables , which make the likelihood quadratic in the coupling parameters . Using the augmented likelihood , we derive an expectation-maximization ( EM ) algorithm to obtain the maximum likelihood estimate of network parameters . Using a third set of latent variables we extend the EM algorithm to sparse couplings via L0 regularization . Finally , we develop an efficient approximate Bayesian inference algorithm using a variational approach . We demonstrate the performance of our algorithms on data simulated from an Ising model . For data which are simulated from a more biologically plausible network with spiking neurons , we show that the Ising model captures well the low order statistics of the data and how the Ising couplings are related to the underlying synaptic structure of the simulated network .
This paper studies least-square regression penalized with partly smooth convex regularizers . This class of functions is very large and versatile allowing to promote solutions conforming to some notion of low-complexity . Indeed , they force solutions of variational problems to belong to a low-dimensional manifold ( the so-called model ) which is stable under small perturbations of the function . This property is crucial to make the underlying low-complexity model robust to small noise . We show that a generalized " irrepresentable condition " implies stable model selection under small noise perturbations in the observations and the design matrix , when the regularization parameter is tuned proportionally to the noise level . This condition is shown to be almost a necessary condition . We then show that this condition implies model consistency of the regularized estimator . That is , with a probability tending to one as the number of measurements increases , the regularized estimator belongs to the correct low-dimensional model manifold . This work unifies and generalizes several previous ones , where model consistency is known to hold for sparse , group sparse , total variation and low-rank regularizations .
Probabilistic programming allows specification of probabilistic models in a declarative manner . Recently , several new software systems and languages for probabilistic programming have been developed on the basis of newly developed and improved methods for approximate inference in probabilistic models . In this contribution a probabilistic model for an idealized dark matter localization problem is described . We first derive the probabilistic model for the inference of dark matter locations and masses , and then show how this model can be implemented using BUGS and Infer . NET , two software systems for probabilistic programming . Finally , the different capabilities of both systems are discussed . The presented dark matter model includes mainly non-conjugate factors , thus , it is difficult to implement this model with Infer . NET .
This paper studies graphical model selection , i . e . , the problem of estimating a graph of statistical relationships among a collection of random variables . Conventional graphical model selection algorithms are passive , i . e . , they require all the measurements to have been collected before processing begins . We propose an active learning algorithm that uses junction tree representations to adapt future measurements based on the information gathered from prior measurements . We prove that , under certain conditions , our active learning algorithm requires fewer scalar measurements than any passive algorithm to reliably estimate a graph . A range of numerical results validate our theory and demonstrates the benefits of active learning .
We analyze the performance of spectral clustering for community extraction in stochastic block models . We show that , under mild conditions , spectral clustering applied to the adjacency matrix of the network can consistently recover hidden communities even when the order of the maximum expected degree is as small as $\log n$ , with $n$ the number of nodes . This result applies to some popular polynomial time spectral clustering algorithms and is further extended to degree corrected stochastic block models using a spherical $k$-median spectral clustering method . A key component of our analysis is a combinatorial bound on the spectrum of binary random matrices , which is sharper than the conventional matrix Bernstein inequality and may be of independent interest .
SVRG and its variants are among the state of art optimization algorithms for large scale machine learning problems . It is well known that SVRG converges linearly when the objective function is strongly convex . However this setup can be restrictive , and does not include several important formulations such as Lasso , group Lasso , logistic regression , and some non-convex models including corrected Lasso and SCAD . In this paper , we prove that , for a class of statistical M-estimators covering examples mentioned above , SVRG solves the formulation with {\em a linear convergence rate} without strong convexity or even convexity . Our analysis makes use of {\em restricted strong convexity} , under which we show that SVRG converges linearly to the fundamental statistical precision of the model , i . e . , the difference between true unknown parameter $\theta^*$ and the optimal solution $\hat{\theta}$ of the model .
This paper studies the problem of inferring a global preference based on the partial rankings provided by many users over different subsets of items according to the Plackett-Luce model . A question of particular interest is how to optimally assign items to users for ranking and how many item assignments are needed to achieve a target estimation error . For a given assignment of items to users , we first derive an oracle lower bound of the estimation error that holds even for the more general Thurstone models . Then we show that the Cram\ ' er-Rao lower bound and our upper bounds inversely depend on the spectral gap of the Laplacian of an appropriately defined comparison graph . When the system is allowed to choose the item assignment , we propose a random assignment scheme . Our oracle lower bound and upper bounds imply that it is minimax-optimal up to a logarithmic factor among all assignment schemes and the lower bound can be achieved by the maximum likelihood estimator as well as popular rank-breaking schemes that decompose partial rankings into pairwise comparisons . The numerical experiments corroborate our theoretical findings .
This paper presents GRASTA ( Grassmannian Robust Adaptive Subspace Tracking Algorithm ) , an efficient and robust online algorithm for tracking subspaces from highly incomplete information . The algorithm uses a robust $l^0$-norm cost function in order to estimate and track non-stationary subspaces when the streaming data vectors are corrupted with outliers . We apply GRASTA to the problems of robust matrix completion and real-time separation of background from foreground in video . In this second application , we show that GRASTA performs high-quality separation of moving objects from background at exceptional speeds : In one popular benchmark video example , GRASTA achieves a rate of 00 frames per second , even when run in MATLAB on a personal laptop .
Expectation propagation ( EP ) is a deterministic approximation algorithm that is often used to perform approximate Bayesian parameter learning . EP approximates the full intractable posterior distribution through a set of local approximations that are iteratively refined for each datapoint . EP can offer analytic and computational advantages over other approximations , such as Variational Inference ( VI ) , and is the method of choice for a number of models . The local nature of EP appears to make it an ideal candidate for performing Bayesian learning on large models in large-scale dataset settings . However , EP has a crucial limitation in this context : the number of approximating factors needs to increase with the number of data-points , N , which often entails a prohibitively large memory overhead . This paper presents an extension to EP , called stochastic expectation propagation ( SEP ) , that maintains a global posterior approximation ( like VI ) but updates it in a local way ( like EP ) . Experiments on a number of canonical learning problems using synthetic and real-world datasets indicate that SEP performs almost as well as full EP , but reduces the memory consumption by a factor of $N$ . SEP is therefore ideally suited to performing approximate Bayesian learning in the large model , large dataset setting .
Recovering low-rank and sparse matrices from incomplete or corrupted observations is an important problem in machine learning , statistics , bioinformatics , computer vision , as well as signal and image processing . In theory , this problem can be solved by the natural convex joint/mixed relaxations ( i . e . , l_{0}-norm and trace norm ) under certain conditions . However , all current provable algorithms suffer from superlinear per-iteration cost , which severely limits their applicability to large-scale problems . In this paper , we propose a scalable , provable structured low-rank matrix factorization method to recover low-rank and sparse matrices from missing and grossly corrupted data , i . e . , robust matrix completion ( RMC ) problems , or incomplete and grossly corrupted measurements , i . e . , compressive principal component pursuit ( CPCP ) problems . Specifically , we first present two small-scale matrix trace norm regularized bilinear structured factorization models for RMC and CPCP problems , in which repetitively calculating SVD of a large-scale matrix is replaced by updating two much smaller factor matrices . Then , we apply the alternating direction method of multipliers ( ADMM ) to efficiently solve the RMC problems . Finally , we provide the convergence analysis of our algorithm , and extend it to address general CPCP problems . Experimental results verified both the efficiency and effectiveness of our method compared with the state-of-the-art methods .
In this paper , we investigate how to learn to control a group of cooperative agents with limited sensing capabilities such as robot swarms . The agents have only very basic sensor capabilities , yet in a group they can accomplish sophisticated tasks , such as distributed assembly or search and rescue tasks . Learning a policy for a group of agents is difficult due to distributed partial observability of the state . Here , we follow a guided approach where a critic has central access to the global state during learning , which simplifies the policy evaluation problem from a reinforcement learning point of view . For example , we can get the positions of all robots of the swarm using a camera image of a scene . This camera image is only available to the critic and not to the control policies of the robots . We follow an actor-critic approach , where the actors base their decisions only on locally sensed information . In contrast , the critic is learned based on the true global state . Our algorithm uses deep reinforcement learning to approximate both the Q-function and the policy . The performance of the algorithm is evaluated on two tasks with simple simulated 0D agents : 0 ) finding and maintaining a certain distance to each others and 0 ) locating a target .
In a variety of application domains the content to be recommended to users is associated with text . This includes research papers , movies with associated plot summaries , news articles , blog posts , etc . Recommendation approaches based on latent factor models can be extended naturally to leverage text by employing an explicit mapping from text to factors . This enables recommendations for new , unseen content , and may generalize better , since the factors for all items are produced by a compactly-parametrized model . Previous work has used topic models or averages of word embeddings for this mapping . In this paper we present a method leveraging deep recurrent neural networks to encode the text sequence into a latent vector , specifically gated recurrent units ( GRUs ) trained end-to-end on the collaborative filtering task . For the task of scientific paper recommendation , this yields models with significantly higher accuracy . In cold-start scenarios , we beat the previous state-of-the-art , all of which ignore word order . Performance is further improved by multi-task learning , where the text encoder network is trained for a combination of content recommendation and item metadata prediction . This regularizes the collaborative filtering model , ameliorating the problem of sparsity of the observed rating matrix .
The SLOPE estimates regression coefficients by minimizing a regularized residual sum of squares using a sorted-$\ell_0$-norm penalty . The SLOPE combines testing and estimation in regression problems . It exhibits suitable variable selection and prediction properties , as well as minimax optimality . This paper introduces the Bayesian SLOPE procedure for linear regression . The classical SLOPE estimate is the posterior mode in the normal regression problem with an appropriate prior on the coefficients . The Bayesian SLOPE considers the full Bayesian model and has the advantage of offering credible sets and standard error estimates for the parameters . Moreover , the hierarchical Bayesian framework allows for full Bayesian and empirical Bayes treatment of the penalty coefficients ; whereas it is not clear how to choose these coefficients when using the SLOPE on a general design matrix . A direct characterization of the posterior is provided which suggests a Gibbs sampler that does not involve latent variables . An efficient hybrid Gibbs sampler for the Bayesian SLOPE is introduced . Point estimation using the posterior mean is highlighted , which automatically facilitates the Bayesian prediction of future observations . These are demonstrated on real and synthetic data .
This manuscript provides optimization guarantees , generalization bounds , and statistical consistency results for AdaBoost variants which replace the exponential loss with the logistic and similar losses ( specifically , twice differentiable convex losses which are Lipschitz and tend to zero on one side ) . The heart of the analysis is to show that , in lieu of explicit regularization and constraints , the structure of the problem is fairly rigidly controlled by the source distribution itself . The first control of this type is in the separable case , where a distribution-dependent relaxed weak learning rate induces speedy convergence with high probability over any sample . Otherwise , in the nonseparable case , the convex surrogate risk itself exhibits distribution-dependent levels of curvature , and consequently the algorithm ' s output has small norm with high probability .
We propose a method for recovering the structure of a sparse undirected graphical model when very few samples are available . The method decides about the presence or absence of bonds between pairs of variable by considering one pair at a time and using a closed form formula , analytically derived by calculating the posterior probability for every possible model explaining a two body system using Jeffreys prior . The approach does not rely on the optimisation of any cost functions and consequently is much faster than existing algorithms . Despite this time and computational advantage , numerical results show that for several sparse topologies the algorithm is comparable to the best existing algorithms , and is more accurate in the presence of hidden variables . We apply this approach to the analysis of US stock market data and to neural data , in order to show its efficiency in recovering robust statistical dependencies in real data with non stationary correlations in time and space .
Video sequences contain rich dynamic patterns , such as dynamic texture patterns that exhibit stationarity in the temporal domain , and action patterns that are non-stationary in either spatial or temporal domain . We show that a spatial-temporal generative ConvNet can be used to model and synthesize dynamic patterns . The model defines a probability distribution on the video sequence , and the log probability is defined by a spatial-temporal ConvNet that consists of multiple layers of spatial-temporal filters to capture spatial-temporal patterns of different scales . The model can be learned from the training video sequences by an " analysis by synthesis " learning algorithm that iterates the following two steps . Step 0 synthesizes video sequences from the currently learned model . Step 0 then updates the model parameters based on the difference between the synthesized video sequences and the observed training sequences . We show that the learning algorithm can synthesize realistic dynamic patterns .
Efficiently representing real world data in a succinct and parsimonious manner is of central importance in many fields . We present a generalized greedy pursuit framework , allowing us to efficiently solve structured matrix factorization problems , where the factors are allowed to be from arbitrary sets of structured vectors . Such structure may include sparsity , non-negativeness , order , or a combination thereof . The algorithm approximates a given matrix by a linear combination of few rank-0 matrices , each factorized into an outer product of two vector atoms of the desired structure . For the non-convex subproblems of obtaining good rank-0 structured matrix atoms , we employ and analyze a general atomic power method . In addition to the above applications , we prove linear convergence for generalized pursuit variants in Hilbert spaces - for the task of approximation over the linear span of arbitrary dictionaries - which generalizes OMP and is useful beyond matrix problems . Our experiments on real datasets confirm both the efficiency and also the broad applicability of our framework in practice .
Percolation on complex networks has been used to study computer viruses , epidemics , and other casual processes . Here , we present conditions for the existence of a network specific , observation dependent , phase transition in the updated posterior of node states resulting from actively monitoring the network . Since traditional percolation thresholds are derived using observation independent Markov chains , the threshold of the posterior should more accurately model the true phase transition of a network , as the updated posterior more accurately tracks the process . These conditions should provide insight into modeling the dynamic response of the updated posterior to active intervention and control policies while monitoring large complex networks .
Approximating non-linear kernels using feature maps has gained a lot of interest in recent years due to applications in reducing training and testing times of SVM classifiers and other kernel based learning algorithms . We extend this line of work and present low distortion embeddings for dot product kernels into linear Euclidean spaces . We base our results on a classical result in harmonic analysis characterizing all dot product kernels and use it to define randomized feature maps into explicit low dimensional Euclidean spaces in which the native dot product provides an approximation to the dot product kernel with high confidence .
Sampling is an important tool for estimating large , complex sums and integrals over high dimensional spaces . For instance , important sampling has been used as an alternative to exact methods for inference in belief networks . Ideally , we want to have a sampling distribution that provides optimal-variance estimators . In this paper , we present methods that improve the sampling distribution by systematically adapting it as we obtain information from the samples . We present a stochastic-gradient-descent method for sequentially updating the sampling distribution based on the direct minization of the variance . We also present other stochastic-gradient-descent methods based on the minimizationof typical notions of distance between the current sampling distribution and approximations of the target , optimal distribution . We finally validate and compare the different methods empirically by applying them to the problem of action evaluation in influence diagrams .
Automated discovery of early visual concepts from raw image data is a major open challenge in AI research . Addressing this problem , we propose an unsupervised approach for learning disentangled representations of the underlying factors of variation . We draw inspiration from neuroscience , and show how this can be achieved in an unsupervised generative model by applying the same learning pressures as have been suggested to act in the ventral visual stream in the brain . By enforcing redundancy reduction , encouraging statistical independence , and exposure to data with transform continuities analogous to those to which human infants are exposed , we obtain a variational autoencoder ( VAE ) framework capable of learning disentangled factors . Our approach makes few assumptions and works well across a wide variety of datasets . Furthermore , our solution has useful emergent properties , such as zero-shot inference and an intuitive understanding of " objectness " .
Many machine learning frameworks , such as resource-allocating networks , kernel-based methods , Gaussian processes , and radial-basis-function networks , require a sparsification scheme in order to address the online learning paradigm . For this purpose , several online sparsification criteria have been proposed to restrict the model definition on a subset of samples . The most known criterion is the ( linear ) approximation criterion , which discards any sample that can be well represented by the already contributing samples , an operation with excessive computational complexity . Several computationally efficient sparsification criteria have been introduced in the literature , such as the distance , the coherence and the Babel criteria . In this paper , we provide a framework that connects these sparsification criteria to the issue of approximating samples , by deriving theoretical bounds on the approximation errors . Moreover , we investigate the error of approximating any feature , by proposing upper-bounds on the approximation error for each of the aforementioned sparsification criteria . Two classes of features are described in detail , the empirical mean and the principal axes in the kernel principal component analysis .
In many real-world networks , nodes have class labels , attributes , or variables that affect the network ' s topology . If the topology of the network is known but the labels of the nodes are hidden , we would like to select a small subset of nodes such that , if we knew their labels , we could accurately predict the labels of all the other nodes . We develop an active learning algorithm for this problem which uses information-theoretic techniques to choose which nodes to explore . We test our algorithm on networks from three different domains : a social network , a network of English words that appear adjacently in a novel , and a marine food web . Our algorithm makes no initial assumptions about how the groups connect , and performs well even when faced with quite general types of network structure . In particular , we do not assume that nodes of the same class are more likely to be connected to each other---only that they connect to the rest of the network in similar ways .
We introduce a guide to help deep learning practitioners understand and manipulate convolutional neural network architectures . The guide clarifies the relationship between various properties ( input shape , kernel shape , zero padding , strides and output shape ) of convolutional , pooling and transposed convolutional layers , as well as the relationship between convolutional and transposed convolutional layers . Relationships are derived for various cases , and are illustrated in order to make them intuitive .
Representations in the auditory cortex might be based on mechanisms similar to the visual ventral stream ; modules for building invariance to transformations and multiple layers for compositionality and selectivity . In this paper we propose the use of such computational modules for extracting invariant and discriminative audio representations . Building on a theory of invariance in hierarchical architectures , we propose a novel , mid-level representation for acoustical signals , using the empirical distributions of projections on a set of templates and their transformations . Under the assumption that , by construction , this dictionary of templates is composed from similar classes , and samples the orbit of variance-inducing signal transformations ( such as shift and scale ) , the resulting signature is theoretically guaranteed to be unique , invariant to transformations and stable to deformations . Modules of projection and pooling can then constitute layers of deep networks , for learning composite representations . We present the main theoretical and computational aspects of a framework for unsupervised learning of invariant audio representations , empirically evaluated on music genre classification .
Motivated by applications in recommender systems , web search , social choice and crowdsourcing , we consider the problem of identifying the set of top $K$ items from noisy pairwise comparisons . In our setting , we are non-actively given $r$ pairwise comparisons between each pair of $n$ items , where each comparison has noise constrained by a very general noise model called the strong stochastic transitivity ( SST ) model . We analyze the competitive ratio of algorithms for the top-$K$ problem . In particular , we present a linear time algorithm for the top-$K$ problem which has a competitive ratio of $\tilde{O} ( \sqrt{n} ) $ ; i . e . to solve any instance of top-$K$ , our algorithm needs at most $\tilde{O} ( \sqrt{n} ) $ times as many samples needed as the best possible algorithm for that instance ( in contrast , all previous known algorithms for the top-$K$ problem have competitive ratios of $\tilde{\Omega} ( n ) $ or worse ) . We further show that this is tight : any algorithm for the top-$K$ problem has competitive ratio at least $\tilde{\Omega} ( \sqrt{n} ) $ .
The multiple fundamental frequency detection problem and the source separation problem from a single-channel signal containing multiple oscillatory components and a nonstationary noise are both challenging tasks . To extract the fetal electrocardiogram ( ECG ) from a single-lead maternal abdominal ECG , we face both challenges . In this paper , we propose a novel method to extract the fetal ECG signal from the single channel maternal abdominal ECG signal , without any additional measurement . The algorithm is composed of three main ingredients . First , the maternal and fetal heart rates are estimated by the de-shape short time Fourier transform , which is a recently proposed nonlinear time-frequency analysis technique ; second , the beat tracking technique is applied to accurately obtain the maternal and fetal R peaks ; third , the maternal and fetal ECG waveforms are established by the nonlocal median . The algorithm is evaluated on a simulated fetal ECG signal database ( {\em fecgsyn} database ) , and tested on two real databases with the annotation provided by experts ( {\em adfecgdb} database and {\em CinC0000} database ) . In general , the algorithm could be applied to solve other detection and source separation problems , and reconstruct the time-varying wave-shape function of each oscillatory component .
In X-ray binary star systems consisting of a compact object that accretes material from an orbiting secondary star , there is no straightforward means to decide if the compact object is a black hole or a neutron star . To assist this classification , we develop a Bayesian statistical model that makes use of the fact that X-ray binary systems appear to cluster based on their compact object type when viewed from a 0-dimensional coordinate system derived from X-ray spectral data . The first coordinate of this data is the ratio of counts in mid to low energy band ( color 0 ) , the second coordinate is the ratio of counts in high to low energy band ( color 0 ) , and the third coordinate is the sum of counts in all three bands . We use this model to estimate the probabilities that an X-ray binary system contains a black hole , non-pulsing neutron star , or pulsing neutron star . In particular , we utilize a latent variable model in which the latent variables follow a Gaussian process prior distribution , and hence we are able to induce the spatial correlation we believe exists between systems of the same type . The utility of this approach is evidenced by the accurate prediction of system types using Rossi X-ray Timing Explorer All Sky Monitor data , but it is not flawless . In particular , non-pulsing neutron systems containing " bursters " that are close to the boundary demarcating systems containing black holes tend to be classified as black hole systems . As a byproduct of our analyses , we provide the astronomer with public R code that can be used to predict the compact object type of X-ray binaries given training data .
Our goal is to identify beneficial interventions from observational data . We consider interventions that are narrowly focused ( impacting few covariates ) and may be tailored to each individual or globally enacted over a population . For applications where harmful intervention is drastically worse than proposing no change , we propose a conservative definition of the optimal intervention . Assuming the underlying relationship remains invariant under intervention , we develop efficient algorithms to identify the optimal intervention policy from limited data and provide theoretical guarantees for our approach in a Gaussian Process setting . Although our methods assume covariates can be precisely adjusted , they remain capable of improving outcomes in misspecified settings where interventions incur unintentional downstream effects . Empirically , our approach identifies good interventions in two practical applications : gene perturbation and writing improvement .
We have measured the dissimilarities among several printed characters of a single page in the Gutenberg 00-line bible and we prove statistically the existence of several different matrices from which the metal types where constructed . This is in contrast with the prevailing theory , which states that only one matrix per character was used in the printing process of Gutenberg ' s greatest work . The main mathematical tool for this purpose is cluster analysis , combined with a statistical test for outliers . We carry out the research with two letters , i and a . In the first case , an exact clustering method is employed ; in the second , with more specimens to be classified , we resort to an approximate agglomerative clustering method . The results show that the letters form clusters according to their shape , with significant shape differences among clusters , and allow to conclude , with a very small probability of error , that indeed the metal types used to print them were cast from several different matrices . Mathematics Subject Classification : 00H00
Disagreement-based approaches generate multiple classifiers and exploit the disagreement among them with unlabeled data to improve learning performance . Co-training is a representative paradigm of them , which trains two classifiers separately on two sufficient and redundant views ; while for the applications where there is only one view , several successful variants of co-training with two different classifiers on single-view data instead of two views have been proposed . For these disagreement-based approaches , there are several important issues which still are unsolved , in this article we present theoretical analyses to address these issues , which provides a theoretical foundation of co-training and disagreement-based approaches .
Cognitive neuroscience is enjoying rapid increase in extensive public brain-imaging datasets . It opens the door to large-scale statistical models . Finding a unified perspective for all available data calls for scalable and automated solutions to an old challenge : how to aggregate heterogeneous information on brain function into a universal cognitive system that relates mental operations/cognitive processes/psychological tasks to brain networks ? We cast this challenge in a machine-learning approach to predict conditions from statistical brain maps across different studies . For this , we leverage multi-task learning and multi-scale dimension reduction to learn low-dimensional representations of brain images that carry cognitive information and can be robustly associated with psychological stimuli . Our multi-dataset classification model achieves the best prediction performance on several large reference datasets , compared to models without cognitive-aware low-dimension representations , it brings a substantial performance boost to the analysis of small datasets , and can be introspected to identify universal template cognitive concepts .
We study the problem of distributed multi-task learning with shared representation , where each machine aims to learn a separate , but related , task in an unknown shared low-dimensional subspaces , i . e . when the predictor matrix has low rank . We consider a setting where each task is handled by a different machine , with samples for the task available locally on the machine , and study communication-efficient methods for exploiting the shared structure .
Online Passive-Aggressive ( PA ) learning is a class of online margin-based algorithms suitable for a wide range of real-time prediction tasks , including classification and regression . PA algorithms are formulated in terms of deterministic point-estimation problems governed by a set of user-defined hyperparameters : the approach fails to capture model/prediction uncertainty and makes their performance highly sensitive to hyperparameter configurations . In this paper , we introduce a novel PA learning framework for regression that overcomes the above limitations . We contribute a Bayesian state-space interpretation of PA regression , along with a novel online variational inference scheme , that not only produces probabilistic predictions , but also offers the benefit of automatic hyperparameter tuning . Experiments with various real-world data sets show that our approach performs significantly better than a more standard , linear Gaussian state-space model .
Non-convex sparsity-inducing penalties have recently received considerable attentions in sparse learning . Recent theoretical investigations have demonstrated their superiority over the convex counterparts in several sparse learning settings . However , solving the non-convex optimization problems associated with non-convex penalties remains a big challenge . A commonly used approach is the Multi-Stage ( MS ) convex relaxation ( or DC programming ) , which relaxes the original non-convex problem to a sequence of convex problems . This approach is usually not very practical for large-scale problems because its computational cost is a multiple of solving a single convex problem . In this paper , we propose a General Iterative Shrinkage and Thresholding ( GIST ) algorithm to solve the nonconvex optimization problem for a large class of non-convex penalties . The GIST algorithm iteratively solves a proximal operator problem , which in turn has a closed-form solution for many commonly used penalties . At each outer iteration of the algorithm , we use a line search initialized by the Barzilai-Borwein ( BB ) rule that allows finding an appropriate step size quickly . The paper also presents a detailed convergence analysis of the GIST algorithm . The efficiency of the proposed algorithm is demonstrated by extensive experiments on large-scale data sets .
State space models provide an interpretable framework for complex time series by combining an intuitive dynamical system model with a probabilistic observation model . We developed a flexible online learning framework for latent nonlinear state dynamics and filtered latent states . Our method utilizes the stochastic gradient variational Bayes method to jointly optimize the parameters of the nonlinear dynamics , observation model , and the recognition model . Unlike previous approaches , our framework can incorporate non-trivial observation noise models and infer in real-time . We test our method on point process observations driven by continuous attractor dynamics , demonstrating its ability to recover the phase portrait , filtered trajectory , and produce long-term predictions for neuroscience applications .
Estimating a constrained relation is a fundamental problem in machine learning . Special cases are classification ( the problem of estimating a map from a set of to-be-classified elements to a set of labels ) , clustering ( the problem of estimating an equivalence relation on a set ) and ranking ( the problem of estimating a linear order on a set ) . We contribute a family of probability measures on the set of all relations between two finite , non-empty sets , which offers a joint abstraction of multi-label classification , correlation clustering and ranking by linear ordering . Estimating ( learning ) a maximally probable measure , given ( a training set of ) related and unrelated pairs , is a convex optimization problem . Estimating ( inferring ) a maximally probable relation , given a measure , is a 00-linear program . It is solved in linear time for maps . It is NP-hard for equivalence relations and linear orders . Practical solutions for all three cases are shown in experiments with real data . Finally , estimating a maximally probable measure and relation jointly is posed as a mixed-integer nonlinear program . This formulation suggests a mathematical programming approach to semi-supervised learning .
We develop a framework that allows the use of the multi-level Monte Carlo ( MLMC ) methodology ( Giles 0000 ) to calculate expectations with respect to the invariant measures of ergodic SDEs . In that context , we study the ( over-damped ) Langevin equations with strongly convex potential . We show that , when appropriate contracting couplings for the numerical integrators are available , one can obtain a time-uniform estimates of the MLMC variance in stark contrast to the majority of the results in the MLMC literature . As a consequence , one can approximate expectations with respect to the invariant measure in an unbiased way without the need of a Metropolis- Hastings step . In addition , a root mean square error of $\mathcal{O} ( \epsilon ) $ is achieved with $\mathcal{O} ( \epsilon^{-0} ) $ complexity on par with Markov Chain Monte Carlo ( MCMC ) methods , which however can be computationally intensive when applied to large data sets . Finally , we present a multilevel version of the recently introduced Stochastic Gradient Langevin ( SGLD ) method ( Welling and Teh , 0000 ) built for large datasets applications . We show that this is the first stochastic gradient MCMC method with complexity $\mathcal{O} ( \epsilon^{-0}|\log {\epsilon}|^{0} ) $ , which is asymptotically an order $\epsilon$ lower than the $ \mathcal{O} ( \epsilon^{-0} ) $ complexity of all stochastic gradient MCMC methods that are currently available . Numerical experiments confirm our theoretical findings .
We provide fast algorithms for overconstrained $\ell_p$ regression and related problems : for an $n\times d$ input matrix $A$ and vector $b\in\mathbb{R}^n$ , in $O ( nd\log n ) $ time we reduce the problem $\min_{x\in\mathbb{R}^d} \|Ax-b\|_p$ to the same problem with input matrix $\tilde A$ of dimension $s \times d$ and corresponding $\tilde b$ of dimension $s\times 0$ . Here , $\tilde A$ and $\tilde b$ are a coreset for the problem , consisting of sampled and rescaled rows of $A$ and $b$ ; and $s$ is independent of $n$ and polynomial in $d$ . Our results improve on the best previous algorithms when $n\gg d$ , for all $p\in[0 , \infty ) $ except $p=0$ . We also provide a suite of improved results for finding well-conditioned bases via ellipsoidal rounding , illustrating tradeoffs between running time and conditioning quality , including a one-pass conditioning algorithm for general $\ell_p$ problems . We also provide an empirical evaluation of implementations of our algorithms for $p=0$ , comparing them with related algorithms . Our empirical results show that , in the asymptotic regime , the theory is a very good guide to the practical performance of these algorithms . Our algorithms use our faster constructions of well-conditioned bases for $\ell_p$ spaces and , for $p=0$ , a fast subspace embedding of independent interest that we call the Fast Cauchy Transform : a distribution over matrices $\Pi : \mathbb{R}^n\mapsto \mathbb{R}^{O ( d\log d ) }$ , found obliviously to $A$ , that approximately preserves the $\ell_0$ norms : that is , with large probability , simultaneously for all $x$ , $\|Ax\|_0 \approx \|\Pi Ax\|_0$ , with distortion $O ( d^{0+\eta} ) $ , for an arbitrarily small constant $\eta>0$ ; and , moreover , $\Pi A$ can be computed in $O ( nd\log d ) $ time . The techniques underlying our Fast Cauchy Transform include fast Johnson-Lindenstrauss transforms , low-coherence matrices , and rescaling by Cauchy random variables .
VAEs ( Variational AutoEncoders ) have proved to be powerful in the context of density modeling and have been used in a variety of contexts for creative purposes . In many settings , the data we model possesses continuous attributes that we would like to take into account at generation time . We propose in this paper GLSR-VAE , a Geodesic Latent Space Regularization for the Variational AutoEncoder architecture and its generalizations which allows a fine control on the embedding of the data into the latent space . When augmenting the VAE loss with this regularization , changes in the learned latent space reflects changes of the attributes of the data . This deeper understanding of the VAE latent space structure offers the possibility to modulate the attributes of the generated data in a continuous way . We demonstrate its efficiency on a monophonic music generation task where we manage to generate variations of discrete sequences in an intended and playful way .
Crowdsourcing has been proven to be an effective and efficient tool to annotate large datasets . User annotations are often noisy , so methods to combine the annotations to produce reliable estimates of the ground truth are necessary . We claim that considering the existence of clusters of users in this combination step can improve the performance . This is especially important in early stages of crowdsourcing implementations , where the number of annotations is low . At this stage there is not enough information to accurately estimate the bias introduced by each annotator separately , so we have to resort to models that consider the statistical links among them . In addition , finding these clusters is interesting in itself as knowing the behavior of the pool of annotators allows implementing efficient active learning strategies . Based on this , we propose in this paper two new fully unsupervised models based on a Chinese Restaurant Process ( CRP ) prior and a hierarchical structure that allows inferring these groups jointly with the ground truth and the properties of the users . Efficient inference algorithms based on Gibbs sampling with auxiliary variables are proposed . Finally , we perform experiments , both on synthetic and real databases , to show the advantages of our models over state-of-the-art algorithms .
In this paper , we study the missing sample recovery problem using methods based on sparse approximation . In this regard , we investigate the algorithms used for solving the inverse problem associated with the restoration of missed samples of image signal . This problem is also known as inpainting in the context of image processing and for this purpose , we suggest an iterative sparse recovery algorithm based on constrained $l_0$-norm minimization with a new fidelity metric . The proposed metric called Convex SIMilarity ( CSIM ) index , is a simplified version of the Structural SIMilarity ( SSIM ) index , which is convex and error-sensitive . The optimization problem incorporating this criterion , is then solved via Alternating Direction Method of Multipliers ( ADMM ) . Simulation results show the efficiency of the proposed method for missing sample recovery of 0D patch vectors and inpainting of 0D image signals .
We present the multiplicative recurrent neural network as a general model for compositional meaning in language , and evaluate it on the task of fine-grained sentiment analysis . We establish a connection to the previously investigated matrix-space models for compositionality , and show they are special cases of the multiplicative recurrent net . Our experiments show that these models perform comparably or better than Elman-type additive recurrent neural networks and outperform matrix-space models on a standard fine-grained sentiment analysis corpus . Furthermore , they yield comparable results to structural deep models on the recently published Stanford Sentiment Treebank without the need for generating parse trees .
An associative memory is a framework of content-addressable memory that stores a collection of message vectors ( or a dataset ) over a neural network while enabling a neurally feasible mechanism to recover any message in the dataset from its noisy version . Designing an associative memory requires addressing two main tasks : 0 ) learning phase : given a dataset , learn a concise representation of the dataset in the form of a graphical model ( or a neural network ) , 0 ) recall phase : given a noisy version of a message vector from the dataset , output the correct message vector via a neurally feasible algorithm over the network learnt during the learning phase . This paper studies the problem of designing a class of neural associative memories which learns a network representation for a large dataset that ensures correction against a large number of adversarial errors during the recall phase . Specifically , the associative memories designed in this paper can store dataset containing $\exp ( n ) $ $n$-length message vectors over a network with $O ( n ) $ nodes and can tolerate $\Omega ( \frac{n}{{\rm polylog} n} ) $ adversarial errors . This paper carries out this memory design by mapping the learning phase and recall phase to the tasks of dictionary learning with a square dictionary and iterative error correction in an expander code , respectively .
In many fields observations are performed irregularly along time , due to either measurement limitations or lack of a constant immanent rate . While discrete-time Markov models ( as Dynamic Bayesian Networks ) introduce either inefficient computation or an information loss to reasoning about such processes , continuous-time Markov models assume either a discrete state space ( as Continuous-Time Bayesian Networks ) , or a flat continuous state space ( as stochastic differential equations ) . To address these problems , we present a new modeling class called Irregular-Time Bayesian Networks ( ITBNs ) , generalizing Dynamic Bayesian Networks , allowing substantially more compact representations , and increasing the expressivity of the temporal dynamics . In addition , a globally optimal solution is guaranteed when learning temporal systems , provided that they are fully observed at the same irregularly spaced time-points , and a semiparametric subclass of ITBNs is introduced to allow further adaptation to the irregular nature of the available data .
Text documents are structured on multiple levels of detail : individual words are related by syntax , but larger units of text are related by discourse structure . Existing language models generally fail to account for discourse structure , but it is crucial if we are to have language models that reward coherence and generate coherent texts . We present and empirically evaluate a set of multi-level recurrent neural network language models , called Document-Context Language Models ( DCLM ) , which incorporate contextual information both within and beyond the sentence . In comparison with word-level recurrent neural network language models , the DCLM models obtain slightly better predictive likelihoods , and considerably better assessments of document coherence .
As part of the 0000 public evaluation challenge on Detection and Classification of Acoustic Scenes and Events ( DCASE 0000 ) , the second task focused on evaluating sound event detection systems using synthetic mixtures of office sounds . This task , which follows the `Event Detection - Office Synthetic ' task of DCASE 0000 , studies the behaviour of tested algorithms when facing controlled levels of audio complexity with respect to background noise and polyphony/density , with the added benefit of a very accurate ground truth . This paper presents the task formulation , evaluation metrics , submitted systems , and provides a statistical analysis of the results achieved , with respect to various aspects of the evaluation dataset .
Given a collection of entities ( or nodes ) in a network and our intermittent observations of activities from each entity , an important problem is to learn the hidden edges depicting directional relationships among these entities . Here , we study causal relationships ( excitations ) that are realized by a multivariate Hawkes process . The multivariate Hawkes process ( MHP ) and its variations ( spatio-temporal point processes ) have been used to study contagion in earthquakes , crimes , neural spiking activities , the stock and foreign exchange markets , etc . In this paper , we consider the multivariate Hawkes process with gaps in observations ( MHPG ) . We propose a variational problem for detecting sparsely hidden relationships with a multivariate Hawkes process that takes into account the gaps from each entity . We bypass the problem of dealing with a large amount of missing events by introducing a small number of unknown boundary conditions . In the case where our observations are sparse ( e . g . from 00% to 00% ) , we show through numerical simulations that robust recovery with MHPG is still possible even if the lengths of the observed intervals are small but they are chosen accordingly . The numerical results also show that the knowledge of gaps and imposing the right boundary conditions are very crucial in discovering the underlying patterns and hidden relationships .
In this paper , we tackle the real-world problem of predicting Yelp star-review rating based on business features ( such as images , descriptions ) , user features ( average previous ratings ) , and , of particular interest , network properties ( which businesses has a user rated before ) . We compare multiple models on different sets of features -- from simple linear regression on network features only to deep learning models on network and item features . In recent years , breakthroughs in deep learning have led to increased accuracy in common supervised learning tasks , such as image classification , captioning , and language understanding . However , the idea of combining deep learning with network feature and structure appears to be novel . While the problem of predicting future interactions in a network has been studied at length , these approaches have often ignored either node-specific data or global structure . We demonstrate that taking a mixed approach combining both node-level features and network information can effectively be used to predict Yelp-review star ratings . We evaluate on the Yelp dataset by splitting our data along the time dimension ( as would naturally occur in the real-world ) and comparing our model against others which do no take advantage of the network structure and/or deep learning .
$KS$-algebra consists of expressions constructed with four kinds operations , the minimum , maximum , difference and additively homogeneous generalized means . Five families of $Z$-classifiers are investigated on binary classification tasks between English phonemes . It is shown that the classifiers are able to reflect well known formant characteristics of vowels , while having very small Kolmogoroff ' s complexity .
Dialogue assistants are rapidly becoming an indispensable daily aid . To avoid the significant effort needed to hand-craft the required dialogue flow , the Dialogue Management ( DM ) module can be cast as a continuous Markov Decision Process ( MDP ) and trained through Reinforcement Learning ( RL ) . Several RL models have been investigated over recent years . However , the lack of a common benchmarking framework makes it difficult to perform a fair comparison between different models and their capability to generalise to different environments . Therefore , this paper proposes a set of challenging simulated environments for dialogue model development and evaluation . To provide some baselines , we investigate a number of representative parametric algorithms , namely deep reinforcement learning algorithms - DQN , A0C and Natural Actor-Critic and compare them to a non-parametric model , GP-SARSA . Both the environments and policy models are implemented using the publicly available PyDial toolkit and released on-line , in order to establish a testbed framework for further experiments and to facilitate experimental reproducibility .
The false discovery rate ( FDR ) ---the expected fraction of spurious discoveries among all the discoveries---provides a popular statistical assessment of the reproducibility of scientific studies in various disciplines . In this work , we introduce a new method for controlling the FDR in meta-analysis of many decentralized linear models . Our method targets the scenario where many research groups---possibly the number of which is random---are independently testing a common set of hypotheses and then sending summary statistics to a coordinating center in an online manner . Built on the knockoffs framework introduced by Barber and Candes ( 0000 ) , our procedure starts by applying the knockoff filter to each linear model and then aggregates the summary statistics via one-shot communication in a novel way . This method gives exact FDR control non-asymptotically without any knowledge of the noise variances or making any assumption about sparsity of the signal . In certain settings , it has a communication complexity that is optimal up to a logarithmic factor .
We present Random Partition Kernels , a new class of kernels derived by demonstrating a natural connection between random partitions of objects and kernels between those objects . We show how the construction can be used to create kernels from methods that would not normally be viewed as random partitions , such as Random Forest . To demonstrate the potential of this method , we propose two new kernels , the Random Forest Kernel and the Fast Cluster Kernel , and show that these kernels consistently outperform standard kernels on problems involving real-world datasets . Finally , we show how the form of these kernels lend themselves to a natural approximation that is appropriate for certain big data problems , allowing $O ( N ) $ inference in methods such as Gaussian Processes , Support Vector Machines and Kernel PCA .
Probabilistic models often have parameters that can be translated , scaled , permuted , or otherwise transformed without changing the model . These symmetries can lead to strong correlation and multimodality in the posterior distribution over the model ' s parameters , which can pose challenges both for performing inference and interpreting the results . In this work , we address the automatic detection of common problematic model symmetries . To do so , we introduce local symmetries , which cover many common cases and are amenable to automatic detection . We show how to derive algorithms to detect several broad classes of local symmetries . Our algorithms are compatible with probabilistic programming constructs such as arrays , for loops , and if statements , and they scale to models with many variables .
In this paper , we present a method to determine the global horizontal irradiance ( GHI ) from the power measurements of one or more PV systems , located in the same neighborhood . The method is completely unsupervised and is based on a physical model of a PV plant . The precise assessment of solar irradiance is pivotal for the forecast of the electric power generated by photovoltaic ( PV ) plants . However , on-ground measurements are expensive and are generally not performed for small and medium-sized PV plants . Satellite-based services represent a valid alternative to on site measurements , but their space-time resolution is limited . Results from two case studies located in Switzerland are presented . The performance of the proposed method at assessing GHI is compared with that of free and commercial satellite services . Our results show that the presented method is generally better than satellite-based services , especially at high temporal resolutions .
We investigate the generalizability of deep learning based on the sensitivity to input perturbation . We hypothesize that the high sensitivity to the perturbation of data degrades the performance on it . To reduce the sensitivity to perturbation , we propose a simple and effective regularization method , referred to as spectral norm regularization , which penalizes the high spectral norm of weight matrices in neural networks . We provide supportive evidence for the abovementioned hypothesis by experimentally confirming that the models trained using spectral norm regularization exhibit better generalizability than other baseline methods .
We present a robust generalization of the synthetic control method for comparative case studies . Like the classical method , we present an algorithm to estimate the unobservable counterfactual of a treatment unit . A distinguishing feature of our algorithm is that of de-noising the data matrix via singular value thresholding , which renders our approach robust in multiple facets : it automatically identifies a good subset of donors , overcomes the challenges of missing data , and continues to work well in settings where covariate information may not be provided . To begin , we establish the condition under which the fundamental assumption in synthetic control-like approaches holds , i . e . when the linear relationship between the treatment unit and the donor pool prevails in both the pre- and post-intervention periods . We provide the first finite sample analysis for a broader class of models , the Latent Variable Model , in contrast to Factor Models previously considered in the literature . Further , we show that our de-noising procedure accurately imputes missing entries , producing a consistent estimator of the underlying signal matrix provided $p = \Omega ( T^{-0 + \zeta} ) $ for some $\zeta > 0$ ; here , $p$ is the fraction of observed data and $T$ is the time interval of interest . Under the same setting , we prove that the mean-squared-error ( MSE ) in our prediction estimation scales as $O ( \sigma^0/p + 0/\sqrt{T} ) $ , where $\sigma^0$ is the noise variance . Using a data aggregation method , we show that the MSE can be made as small as $O ( T^{-0/0+\gamma} ) $ for any $\gamma \in ( 0 , 0/0 ) $ , leading to a consistent estimator . We also introduce a Bayesian framework to quantify the model uncertainty through posterior probabilities . Our experiments , using both real-world and synthetic datasets , demonstrate that our robust generalization yields an improvement over the classical synthetic control method .
This paper examines from an experimental perspective random forests , the increasingly used statistical method for classification and regression problems introduced by Leo Breiman in 0000 . It first aims at confirming , known but sparse , advice for using random forests and at proposing some complementary remarks for both standard problems as well as high dimensional ones for which the number of variables hugely exceeds the sample size . But the main contribution of this paper is twofold : to provide some insights about the behavior of the variable importance index based on random forests and in addition , to propose to investigate two classical issues of variable selection . The first one is to find important variables for interpretation and the second one is more restrictive and try to design a good prediction model . The strategy involves a ranking of explanatory variables using the random forests score of importance and a stepwise ascending variable introduction strategy .
Understanding tie strength in social networks , and the factors that influence it , have received much attention in a myriad of disciplines for decades . Several models incorporating indicators of tie strength have been proposed and used to quantify relationships in social networks , and a standard set of structural network metrics have been applied to predominantly online social media sites to predict tie strength . Here , we introduce the concept of the " social bow tie " framework , a small subgraph of the network that consists of a collection of nodes and ties that surround a tie of interest , forming a topological structure that resembles a bow tie . We also define several intuitive and interpretable metrics that quantify properties of the bow tie . We use random forests and regression models to predict categorical and continuous measures of tie strength from different properties of the bow tie , including nodal attributes . We also investigate what aspects of the bow tie are most predictive of tie strength in two distinct social networks : a collection of 00 rural villages in India and a nationwide call network of European mobile phone users . Our results indicate several of the bow tie metrics are highly predictive of tie strength , and we find the more the social circles of two individuals overlap , the stronger their tie , consistent with previous findings . However , we also find that the more tightly-knit their non-overlapping social circles , the weaker the tie . This new finding complements our current understanding of what drives the strength of ties in social networks .
Ranking over sets arise when users choose between groups of items . For example , a group may be of those movies deemed $0$ stars to them , or a customized tour package . It turns out , to model this data type properly , we need to investigate the general combinatorics problem of partitioning a set and ordering the subsets . Here we construct a probabilistic log-linear model over a set of ordered subsets . Inference in this combinatorial space is highly challenging : The space size approaches $ ( N ! /0 ) 0 . 00000^{N+0}$ as $N$ approaches infinity . We propose a \texttt{split-and-merge} Metropolis-Hastings procedure that can explore the state-space efficiently . For discovering hidden aspects in the data , we enrich the model with latent binary variables so that the posteriors can be efficiently evaluated . Finally , we evaluate the proposed model on large-scale collaborative filtering tasks and demonstrate that it is competitive against state-of-the-art methods .
In this work we present the novel ASTRID method for investigating which attribute interactions classifiers exploit when making predictions . Attribute interactions in classification tasks mean that two or more attributes together provide stronger evidence for a particular class label . Knowledge of such interactions makes models more interpretable by revealing associations between attributes . This has applications , e . g . , in pharmacovigilance to identify interactions between drugs or in bioinformatics to investigate associations between single nucleotide polymorphisms . We also show how the found attribute partitioning is related to a factorisation of the data generating distribution and empirically demonstrate the utility of the proposed method .
Hessian-free ( HF ) optimization has been successfully used for training deep autoencoders and recurrent networks . HF uses the conjugate gradient algorithm to construct update directions through curvature-vector products that can be computed on the same order of time as gradients . In this paper we exploit this property and study stochastic HF with gradient and curvature mini-batches independent of the dataset size . We modify Martens ' HF for these settings and integrate dropout , a method for preventing co-adaptation of feature detectors , to guard against overfitting . Stochastic Hessian-free optimization gives an intermediary between SGD and HF that achieves competitive performance on both classification and deep autoencoder experiments .
This paper introduces the hypervolume maximization with a single solution as an alternative to the mean loss minimization . The relationship between the two problems is proved through bounds on the cost function when an optimal solution to one of the problems is evaluated on the other , with a hyperparameter to control the similarity between the two problems . This same hyperparameter allows higher weight to be placed on samples with higher loss when computing the hypervolume ' s gradient , whose normalized version can range from the mean loss to the max loss . An experiment on MNIST with a neural network is used to validate the theory developed , showing that the hypervolume maximization can behave similarly to the mean loss minimization and can also provide better performance , resulting on a 00% reduction of the classification error on the test set .
Recent literature on online learning has focused on developing adaptive algorithms that take advantage of a regularity of the sequence of observations , yet retain worst-case performance guarantees . A complementary direction is to develop prediction methods that perform well against complex benchmarks . In this paper , we address these two directions together . We present a fully adaptive method that competes with dynamic benchmarks in which regret guarantee scales with regularity of the sequence of cost functions and comparators . Notably , the regret bound adapts to the smaller complexity measure in the problem environment . Finally , we apply our results to drifting zero-sum , two-player games where both players achieve no regret guarantees against best sequences of actions in hindsight .
Designing effective and efficient classifier for pattern analysis is a key problem in machine learning and computer vision . Many the solutions to the problem require to perform logic operations such as `and ' , `or ' , and `not ' . Classification and regression tree ( CART ) include these operations explicitly . Other methods such as neural networks , SVM , and boosting learn/compute a weighted sum on features ( weak classifiers ) , which weakly perform the ' and ' and ' or ' operations . However , it is hard for these classifiers to deal with the ' xor ' pattern directly . In this paper , we propose layered logic classifiers for patterns of complicated distributions by combining the `and ' , `or ' , and `not ' operations . The proposed algorithm is very general and easy to implement . We test the classifiers on several typical datasets from the Irvine repository and two challenging vision applications , object segmentation and pedestrian detection . We observe significant improvements on all the datasets over the widely used decision stump based AdaBoost algorithm . The resulting classifiers have much less training complexity than decision tree based AdaBoost , and can be applied in a wide range of domains .
Manifold learning and dimensionality reduction techniques are ubiquitous in science and engineering , but can be computationally expensive procedures when applied to large data sets or when similarities are expensive to compute . To date , little work has been done to investigate the tradeoff between computational resources and the quality of learned representations . We present both theoretical and experimental explorations of this question . In particular , we consider Laplacian eigenmaps embeddings based on a kernel matrix , and explore how the embeddings behave when this kernel matrix is corrupted by occlusion and noise . Our main theoretical result shows that under modest noise and occlusion assumptions , we can ( with high probability ) recover a good approximation to the Laplacian eigenmaps embedding based on the uncorrupted kernel matrix . Our results also show how regularization can aid this approximation . Experimentally , we explore the effects of noise and occlusion on Laplacian eigenmaps embeddings of two real-world data sets , one from speech processing and one from neuroscience , as well as a synthetic data set .
A grand challenge in machine learning is the development of computational algorithms that match or outperform humans in perceptual inference tasks that are complicated by nuisance variation . For instance , visual object recognition involves the unknown object position , orientation , and scale in object recognition while speech recognition involves the unknown voice pronunciation , pitch , and speed . Recently , a new breed of deep learning algorithms have emerged for high-nuisance inference tasks that routinely yield pattern recognition systems with near- or super-human capabilities . But a fundamental question remains : Why do they work ? Intuitions abound , but a coherent framework for understanding , analyzing , and synthesizing deep learning architectures has remained elusive . We answer this question by developing a new probabilistic framework for deep learning based on the Deep Rendering Model : a generative probabilistic model that explicitly captures latent nuisance variation . By relaxing the generative model to a discriminative one , we can recover two of the current leading deep learning systems , deep convolutional neural networks and random decision forests , providing insights into their successes and shortcomings , as well as a principled route to their improvement .
This paper explores unsupervised learning of parsing models along two directions . First , which models are identifiable from infinite data ? We use a general technique for numerically checking identifiability based on the rank of a Jacobian matrix , and apply it to several standard constituency and dependency parsing models . Second , for identifiable models , how do we estimate the parameters efficiently ? EM suffers from local optima , while recent work using spectral methods cannot be directly applied since the topology of the parse tree varies across sentences . We develop a strategy , unmixing , which deals with this additional complexity for restricted classes of parsing models .
The recently proposed Minimal Complexity Machine ( MCM ) finds a hyperplane classifier by minimizing an exact bound on the Vapnik-Chervonenkis ( VC ) dimension . The VC dimension measures the capacity of a learning machine , and a smaller VC dimension leads to improved generalization . On many benchmark datasets , the MCM generalizes better than SVMs and uses far fewer support vectors than the number used by SVMs . In this paper , we describe a neural network based on a linear dynamical system , that converges to the MCM solution . The proposed MCM dynamical system is conducive to an analogue circuit implementation on a chip or simulation using Ordinary Differential Equation ( ODE ) solvers . Numerical experiments on benchmark datasets from the UCI repository show that the proposed approach is scalable and accurate , as we obtain improved accuracies and fewer number of support vectors ( upto 00 . 0% reduction ) with the MCM dynamical system .
Telecommunications operators ( telcos ) traditional sources of income , voice and SMS , are shrinking due to customers using over-the-top ( OTT ) applications such as WhatsApp or Viber . In this challenging environment it is critical for telcos to maintain or grow their market share , by providing users with as good an experience as possible on their network . But the task of extracting customer insights from the vast amounts of data collected by telcos is growing in complexity and scale everey day . How can we measure and predict the quality of a user ' s experience on a telco network in real-time ? That is the problem that we address in this paper . We present an approach to capture , in ( near ) real-time , the mobile customer experience in order to assess which conditions lead the user to place a call to a telco ' s customer care center . To this end , we follow a supervised learning approach for prediction and train our ' Restricted Random Forest ' model using , as a proxy for bad experience , the observed customer transactions in the telco data feed before the user places a call to a customer care center . We evaluate our approach using a rich dataset provided by a major African telecommunication ' s company and a novel big data architecture for both the training and scoring of predictive models . Our empirical study shows our solution to be effective at predicting user experience by inferring if a customer will place a call based on his current context . These promising results open new possibilities for improved customer service , which will help telcos to reduce churn rates and improve customer experience , both factors that directly impact their revenue growth .
Deformation estimation of elastic object assuming an internal organ is important for the computer navigation of surgery . The aim of this study is to estimate the deformation of an entire three-dimensional elastic object using displacement information of very few observation points . A learning approach with a neural network was introduced to estimate the entire deformation of an object . We applied our method to two elastic objects ; a rectangular parallelepiped model , and a human liver model reconstructed from computed tomography data . The average estimation error for the human liver model was 0 . 000 mm when the object was deformed up to 00 . 0 mm , from only around 0 % observations . These results indicate that the deformation of an entire elastic object can be estimated with an acceptable level of error from limited observations by applying a trained neural network to a new deformation .
Imaging genetic research has essentially focused on discovering unique and co-association effects , but typically ignoring to identify outliers or atypical objects in genetic as well as non-genetics variables . Identifying significant outliers is an essential and challenging issue for imaging genetics and multiple sources data analysis . Therefore , we need to examine for transcription errors of identified outliers . First , we address the influence function ( IF ) of kernel mean element , kernel covariance operator , kernel cross-covariance operator , kernel canonical correlation analysis ( kernel CCA ) and multiple kernel CCA . Second , we propose an IF of multiple kernel CCA , which can be applied for more than two datasets . Third , we propose a visualization method to detect influential observations of multiple sources of data based on the IF of kernel CCA and multiple kernel CCA . Finally , the proposed methods are capable of analyzing outliers of subjects usually found in biomedical applications , in which the number of dimension is large . To examine the outliers , we use the stem-and-leaf display . Experiments on both synthesized and imaging genetics data ( e . g . , SNP , fMRI , and DNA methylation ) demonstrate that the proposed visualization can be applied effectively .
This paper proposes a subspace decomposition method based on an over-complete dictionary in sparse representation , called " Sparse Signal Subspace Decomposition " ( or 0SD ) method . This method makes use of a novel criterion based on the occurrence frequency of atoms of the dictionary over the data set . This criterion , well adapted to subspace-decomposition over a dependent basis set , adequately re ects the intrinsic characteristic of regularity of the signal . The 0SD method combines variance , sparsity and component frequency criteria into an unified framework . It takes benefits from using an over-complete dictionary which preserves details and from subspace decomposition which rejects strong noise . The 0SD method is very simple with a linear retrieval operation . It does not require any prior knowledge on distributions or parameters . When applied to image denoising , it demonstrates high performances both at preserving fine details and suppressing strong noise .
This work studies the chord length distribution , in the case where both ends lie on a $N$-dimensional hypersphere ( $N \geq 0$ ) . Actually , after connecting this distribution to the recently estimated surface of a hyperspherical cap \cite{SLi00} , closed-form expressions of both the probability density function and the cumulative distribution function are straightforwardly extracted , which are followed by a discussion on its basic properties , among which its dependence from the hypersphere dimension . Additionally , the distribution of the dot product of unitary vectors is estimated , a problem that is related to the chord length .
Multiple hypothesis testing is a core problem in statistical inference and arises in almost every scientific field . Given a set of null hypotheses $\mathcal{H} ( n ) = ( H_0 , \dotsc , H_n ) $ , Benjamini and Hochberg introduced the false discovery rate ( FDR ) , which is the expected proportion of false positives among rejected null hypotheses , and proposed a testing procedure that controls FDR below a pre-assigned significance level . Nowadays FDR is the criterion of choice for large scale multiple hypothesis testing . In this paper we consider the problem of controlling FDR in an " online manner " . Concretely , we consider an ordered --possibly infinite-- sequence of null hypotheses $\mathcal{H} = ( H_0 , H_0 , H_0 , \dots ) $ where , at each step $i$ , the statistician must decide whether to reject hypothesis $H_i$ having access only to the previous decisions . This model was introduced by Foster and Stine . We study a class of " generalized alpha-investing " procedures and prove that any rule in this class controls online FDR , provided $p$-values corresponding to true nulls are independent from the other $p$-values . ( Earlier work only established mFDR control . ) Next , we obtain conditions under which generalized alpha-investing controls FDR in the presence of general $p$-values dependencies . Finally , we develop a modified set of procedures that also allow to control the false discovery exceedance ( the tail of the proportion of false discoveries ) . Numerical simulations and analytical results indicate that online procedures do not incur a large loss in statistical power with respect to offline approaches , such as Benjamini-Hochberg .
Applying machine learning in the health care domain has shown promising results in recent years . Interpretable outputs from learning algorithms are desirable for decision making by health care personnel . In this work , we explore the possibility of utilizing causal relationships to refine diagnostic prediction . We focus on the task of diagnostic prediction using discomfort drawings , and explore two ways to employ causal identification to improve the diagnostic results . Firstly , we use causal identification to infer the causal relationships among diagnostic labels which , by itself , provides interpretable results to aid the decision making and training of health care personnel . Secondly , we suggest a post-processing approach where the inferred causal relationships are used to refine the prediction accuracy of a multi-view probabilistic model . Experimental results show firstly that causal identification is capable of detecting the causal relationships among diagnostic labels correctly , and secondly that there is potential for improving pain diagnostics prediction accuracy using the causal relationships .
This paper presents a novel approach to speaker subspace modelling based on Gaussian-Binary Restricted Boltzmann Machines ( GRBM ) . The proposed model is based on the idea of shared factors as in the Probabilistic Linear Discriminant Analysis ( PLDA ) . GRBM hidden layer is divided into speaker and channel factors , herein the speaker factor is shared over all vectors of the speaker . Then Maximum Likelihood Parameter Estimation ( MLE ) for proposed model is introduced . Various new scoring techniques for speaker verification using GRBM are proposed . The results for NIST i-vector Challenge 0000 dataset are presented .
We study the problem of determining the optimal low dimensional projection for maximising the separability of a binary partition of an unlabelled dataset , as measured by spectral graph theory . This is achieved by finding projections which minimise the second eigenvalue of the graph Laplacian of the projected data , which corresponds to a non-convex , non-smooth optimisation problem . We show that the optimal univariate projection based on spectral connectivity converges to the vector normal to the maximum margin hyperplane through the data , as the scaling parameter is reduced to zero . This establishes a connection between connectivity as measured by spectral graph theory and maximal Euclidean separation . The computational cost associated with each eigen-problem is quadratic in the number of data . To mitigate this issue , we propose an approximation method using microclusters with provable approximation error bounds . Combining multiple binary partitions within a divisive hierarchical model allows us to construct clustering solutions admitting clusters with varying scales and lying within different subspaces . We evaluate the performance of the proposed method on a large collection of benchmark datasets and find that it compares favourably with existing methods for projection pursuit and dimension reduction for data clustering .
Estimation of the covariance matrix has attracted a lot of attention of the statistical research community over the years , partially due to important applications such as Principal Component Analysis . However , frequently used empirical covariance estimator ( and its modifications ) is very sensitive to outliers in the data . As P . J . Huber wrote in 0000 , " . . . This raises a question which could have been asked already by Gauss , but which was , as far as I know , only raised a few years ago ( notably by Tukey ) : what happens if the true distribution deviates slightly from the assumed normal one ? As is now well known , the sample mean then may have a catastrophically bad performance . . . " Motivated by this question , we develop a new estimator of the ( element-wise ) mean of a random matrix , which includes covariance estimation problem as a special case . Assuming that the entries of a matrix possess only finite second moment , this new estimator admits sub-Gaussian or sub-exponential concentration around the unknown mean in the operator norm . We will explain the key ideas behind our construction , as well as applications to covariance estimation and matrix completion problems .
We introduce a dimension reduction method for visualizing the clustering structure obtained from a finite mixture of Gaussian densities . Information on the dimension reduction subspace is obtained from the variation on group means and , depending on the estimated mixture model , on the variation on group covariances . The proposed method aims at reducing the dimensionality by identifying a set of linear combinations , ordered by importance as quantified by the associated eigenvalues , of the original features which capture most of the cluster structure contained in the data . Observations may then be projected onto such a reduced subspace , thus providing summary plots which help to visualize the clustering structure . These plots can be particularly appealing in the case of high-dimensional data and noisy structure . The new constructed variables capture most of the clustering information available in the data , and they can be further reduced to improve clustering performance . We illustrate the approach on both simulated and real data sets .
A large number of problems in optimization , machine learning , signal processing can be effectively addressed by suitable semidefinite programming ( SDP ) relaxations . Unfortunately , generic SDP solvers hardly scale beyond instances with a few hundreds variables ( in the underlying combinatorial problem ) . On the other hand , it has been observed empirically that an effective strategy amounts to introducing a ( non-convex ) rank constraint , and solving the resulting smooth optimization problem by ascent methods . This non-convex problem has --generically-- a large number of local maxima , and the reason for this success is therefore unclear . This paper provides rigorous support for this approach . For the problem of maximizing a linear functional over the elliptope , we prove that all local maxima are within a small gap from the SDP optimum . In several problems of interest , arbitrarily small relative error can be achieved by taking the rank constraint $k$ to be of order one , independently of the problem size .
We propose and analyze a new parallel coordinate descent method---`NSync---in which at each iteration a random subset of coordinates is updated , in parallel , allowing for the subsets to be chosen non-uniformly . We derive convergence rates under a strong convexity assumption , and comment on how to assign probabilities to the sets to optimize the bound . The complexity and practical performance of the method can outperform its uniform variant by an order of magnitude . Surprisingly , the strategy of updating a single randomly selected coordinate per iteration---with optimal probabilities---may require less iterations , both in theory and practice , than the strategy of updating all coordinates at every iteration .
We analyze the learning properties of the stochastic gradient method when multiple passes over the data and mini-batches are allowed . We study how regularization properties are controlled by the step-size , the number of passes and the mini-batch size . In particular , we consider the square loss and show that for a universal step-size choice , the number of passes acts as a regularization parameter , and optimal finite sample bounds can be achieved by early-stopping . Moreover , we show that larger step-sizes are allowed when considering mini-batches . Our analysis is based on a unifying approach , encompassing both batch and stochastic gradient methods as special cases . As a byproduct , we derive optimal convergence results for batch gradient methods ( even in the non-attainable cases ) .
State of the art machine learning algorithms are highly optimized to provide the optimal prediction possible , naturally resulting in complex models . While these models often outperform simpler more interpretable models by order of magnitudes , in terms of understanding the way the model functions , we are often facing a " black box " . In this paper we suggest a simple method to interpret the behavior of any predictive model , both for regression and classification . Given a particular model , the information required to interpret it can be obtained by studying the partial derivatives of the model with respect to the input . We exemplify this insight by interpreting convolutional and multi-layer neural networks in the field of natural language processing .
In this paper , we study optimization methods consisting of iteratively minimizing surrogates of an objective function . By proposing several algorithmic variants and simple convergence analyses , we make two main contributions . First , we provide a unified viewpoint for several first-order optimization techniques such as accelerated proximal gradient , block coordinate descent , or Frank-Wolfe algorithms . Second , we introduce a new incremental scheme that experimentally matches or outperforms state-of-the-art solvers for large-scale optimization problems typically arising in machine learning .
We propose a novel model for generating graphs similar to a given example graph . Unlike standard approaches that compute features of graphs in Euclidean space , our approach obtains features on a surface of a hypersphere . We then utilize a von Mises-Fisher distribution , an exponential family distribution on the surface of a hypersphere , to define a model over possible feature values . While our approach bears similarity to a popular exponential random graph model ( ERGM ) , unlike ERGMs , it does not suffer from degeneracy , a situation when a significant probability mass is placed on unrealistic graphs . We propose a parameter estimation approach for our model , and a procedure for drawing samples from the distribution . We evaluate the performance of our approach both on the small domain of all 0-node graphs as well as larger real-world social networks .
Very few K-nearest-neighbor ( KNN ) ensembles exist , despite the efficacy of this approach in regression , classification , and outlier detection . Those that do exist focus on bagging features , rather than varying k or bagging observations ; it is unknown whether varying k or bagging observations can improve prediction . Given recent studies from topological data analysis , varying k may function like multiscale topological methods , providing stability and better prediction , as well as increased ensemble diversity . This paper explores 0 KNN ensemble algorithms combining bagged features , bagged observations , and varied k to understand how each of these contribute to model fit . Specifically , these algorithms are tested on Tweedie regression problems through simulations and 0 real datasets ; results are compared to state-of-the-art machine learning models including extreme learning machines , random forest , boosted regression , and Morse-Smale regression . Results on simulations suggest gains from varying k above and beyond bagging features or samples , as well as the robustness of KNN ensembles to the curse of dimensionality . KNN regression ensembles perform favorably against state-of-the-art algorithms and dramatically improve performance over KNN regression . Further , real dataset results suggest varying k is a good strategy in general ( particularly for difficult Tweedie regression problems ) and that KNN regression ensembles often outperform state-of-the-art methods . These results for k-varying ensembles echo recent theoretical results in topological data analysis , where multidimensional filter functions and multiscale coverings provide stability and performance gains over single-dimensional filters and single-scale covering . This opens up the possibility of leveraging multiscale neighborhoods and multiple measures of local geometry in ensemble methods .
As a technology to read brain states from measurable brain activities , brain decoding are widely applied in industries and medical sciences . In spite of high demands in these applications for a universal decoder that can be applied to all individuals simultaneously , large variation in brain activities across individuals has limited the scope of many studies to the development of individual-specific decoders . In this study , we used deep neural network ( DNN ) , a nonlinear hierarchical model , to construct a subject-transfer decoder . Our decoder is the first successful DNN-based subject-transfer decoder . When applied to a large-scale functional magnetic resonance imaging ( fMRI ) database , our DNN-based decoder achieved higher decoding accuracy than other baseline methods , including support vector machine ( SVM ) . In order to analyze the knowledge acquired by this decoder , we applied principal sensitivity analysis ( PSA ) to the decoder and visualized the discriminative features that are common to all subjects in the dataset . Our PSA successfully visualized the subject-independent features contributing to the subject-transferability of the trained decoder .
Recent approaches based on artificial neural networks ( ANNs ) have shown promising results for short-text classification . However , many short texts occur in sequences ( e . g . , sentences in a document or utterances in a dialog ) , and most existing ANN-based systems do not leverage the preceding short texts when classifying a subsequent one . In this work , we present a model based on recurrent neural networks and convolutional neural networks that incorporates the preceding short texts . Our model achieves state-of-the-art results on three different datasets for dialog act prediction .
Associating genetic markers with a multidimensional phenotype is an important yet challenging problem . In this work , we establish the equivalence between two popular methods : kernel-machine regression ( KMR ) , and kernel distance covariance ( KDC ) . KMR is a semiparametric regression frameworks that models the covariate effects parametrically , while the genetic markers are considered non-parametrically . KDC represents a class of methods that includes distance covariance ( DC ) and Hilbert-Schmidt Independence Criterion ( HSIC ) , which are nonparametric tests of independence . We show the equivalence between the score test of KMR and the KDC statistic under certain conditions . This result leads to a novel generalization of the KDC test that incorporates the covariates . Our contributions are three-fold : ( 0 ) establishing the equivalence between KMR and KDC ; ( 0 ) showing that the principles of kernel machine regression can be applied to the interpretation of KDC ; ( 0 ) the development of a broader class of KDC statistics , that the members are the quantities of different kernels . We demonstrate the proposals using simulation studies . Data from the Alzheimer ' s Disease Neuroimaging Initiative ( ADNI ) is used to explore the association between the genetic variants on gene \emph{FLJ00000} and phenotypes represented in 0D structural brain MR images adjusting for age and gender . The results suggest that SNPs of \emph{FLJ00000} exhibit strong pairwise interaction effects that are correlated to the changes of brain region volumes .
In the Bayesian approach to structure learning of graphical models , the equivalent sample size ( ESS ) in the Dirichlet prior over the model parameters was recently shown to have an important effect on the maximum-a-posteriori estimate of the Bayesian network structure . In our first contribution , we theoretically analyze the case of large ESS-values , which complements previous work : among other results , we find that the presence of an edge in a Bayesian network is favoured over its absence even if both the Dirichlet prior and the data imply independence , as long as the conditional empirical distribution is notably different from uniform . In our second contribution , we focus on realistic ESS-values , and provide an analytical approximation to the " optimal " ESS-value in a predictive sense ( its accuracy is also validated experimentally ) : this approximation provides an understanding as to which properties of the data have the main effect determining the " optimal " ESS-value .
Topic models , and more specifically the class of Latent Dirichlet Allocation ( LDA ) , are widely used for probabilistic modeling of text . MCMC sampling from the posterior distribution is typically performed using a collapsed Gibbs sampler . We propose a parallel sparse partially collapsed Gibbs sampler and compare its speed and efficiency to state-of-the-art samplers for topic models on five well-known text corpora of differing sizes and properties . In particular , we propose and compare two different strategies for sampling the parameter block with latent topic indicators . The experiments show that the increase in statistical inefficiency from only partial collapsing is smaller than commonly assumed , and can be more than compensated by the speedup from parallelization and sparsity on larger corpora . We also prove that the partially collapsed samplers scale well with the size of the corpus . The proposed algorithm is fast , efficient , exact , and can be used in more modeling situations than the ordinary collapsed sampler .
We study the tracking problem , namely , estimating the hidden state of an object over time , from unreliable and noisy measurements . The standard framework for the tracking problem is the generative framework , which is the basis of solutions such as the Bayesian algorithm and its approximation , the particle filters . However , these solutions can be very sensitive to model mismatches . In this paper , motivated by online learning , we introduce a new framework for tracking . We provide an efficient tracking algorithm for this framework . We provide experimental results comparing our algorithm to the Bayesian algorithm on simulated data . Our experiments show that when there are slight model mismatches , our algorithm outperforms the Bayesian algorithm .
We present a stochastic setting for optimization problems with nonsmooth convex separable objective functions over linear equality constraints . To solve such problems , we propose a stochastic Alternating Direction Method of Multipliers ( ADMM ) algorithm . Our algorithm applies to a more general class of nonsmooth convex functions that does not necessarily have a closed-form solution by minimizing the augmented function directly . We also demonstrate the rates of convergence for our algorithm under various structural assumptions of the stochastic functions : $O ( 0/\sqrt{t} ) $ for convex functions and $O ( \log t/t ) $ for strongly convex functions . Compared to previous literature , we establish the convergence rate of ADMM algorithm , for the first time , in terms of both the objective value and the feasibility violation .
A new approach to maximum likelihood learning of discrete graphical models and RBM in particular is introduced . Our method , Perturb and Descend ( PD ) is inspired by two ideas ( I ) perturb and MAP method for sampling ( II ) learning by Contrastive Divergence minimization . In contrast to perturb and MAP , PD leverages training data to learn the models that do not allow efficient MAP estimation . During the learning , to produce a sample from the current model , we start from a training data and descend in the energy landscape of the " perturbed model " , for a fixed number of steps , or until a local optima is reached . For RBM , this involves linear calculations and thresholding which can be very fast . Furthermore we show that the amount of perturbation is closely related to the temperature parameter and it can regularize the model by producing robust features resulting in sparse hidden layer activation .
In many classification problems unlabelled data is abundant and a subset can be chosen for labelling . This defines the context of active learning ( AL ) , where methods systematically select that subset , to improve a classifier by retraining . Given a classification problem , and a classifier trained on a small number of labelled examples , consider the selection of a single further example . This example will be labelled by the oracle and then used to retrain the classifier . This example selection raises a central question : given a fully specified stochastic description of the classification problem , which example is the optimal selection ? If optimality is defined in terms of loss , this definition directly produces expected loss reduction ( ELR ) , a central quantity whose maximum yields the optimal example selection . This work presents a new theoretical approach to AL , example quality , which defines optimal AL behaviour in terms of ELR . Once optimal AL behaviour is defined mathematically , reasoning about this abstraction provides insights into AL . In a theoretical context the optimal selection is compared to existing AL methods , showing that heuristics can make sub-optimal selections . Algorithms are constructed to estimate example quality directly . A large-scale experimental study shows these algorithms to be competitive with standard AL methods .
This paper is concerned with estimation and stochastic control in physical systems which contain unknown input signals or forces . These unknown signals are modeled as Gaussian processes ( GP ) in the sense that GP models are used in machine learning . The resulting latent force models ( LFMs ) can be seen as hybrid models that contain a first-principles physical model part and a non-parametric GP model part . The aim of this paper is to collect and extend the statistical inference and learning methods for this kind of models , provide new theoretical results for the models , and to extend the methodology and theory to stochastic control of LFMs .
The combination of multiple classifiers using ensemble methods is increasingly important for making progress in a variety of difficult prediction problems . We present a comparative analysis of several ensemble methods through two case studies in genomics , namely the prediction of genetic interactions and protein functions , to demonstrate their efficacy on real-world datasets and draw useful conclusions about their behavior . These methods include simple aggregation , meta-learning , cluster-based meta-learning , and ensemble selection using heterogeneous classifiers trained on resampled data to improve the diversity of their predictions . We present a detailed analysis of these methods across 0 genomics datasets and find the best of these methods offer statistically significant improvements over the state of the art in their respective domains . In addition , we establish a novel connection between ensemble selection and meta-learning , demonstrating how both of these disparate methods establish a balance between ensemble diversity and performance .
In this paper we analyze approximate methods for undertaking a principal components analysis ( PCA ) on large data sets . PCA is a classical dimension reduction method that involves the projection of the data onto the subspace spanned by the leading eigenvectors of the covariance matrix . This projection can be used either for exploratory purposes or as an input for further analysis , e . g . regression . If the data have billions of entries or more , the computational and storage requirements for saving and manipulating the design matrix in fast memory is prohibitive . Recently , the Nystr\ " om and column-sampling methods have appeared in the numerical linear algebra community for the randomized approximation of the singular value decomposition of large matrices . However , their utility for statistical applications remains unclear . We compare these approximations theoretically by bounding the distance between the induced subspaces and the desired , but computationally infeasible , PCA subspace . Additionally we show empirically , through simulations and a real data example involving a corpus of emails , the trade-off of approximation accuracy and computational complexity .
In mixtures-of-experts ( ME ) model , where a number of submodels ( experts ) are combined , there have been two longstanding problems : ( i ) how many experts should be chosen , given the size of the training data ? ( ii ) given the total number of parameters , is it better to use a few very complex experts , or is it better to combine many simple experts ? In this paper , we try to provide some insights to these problems through a theoretic study on a ME structure where $m$ experts are mixed , with each expert being related to a polynomial regression model of order $k$ . We study the convergence rate of the maximum likelihood estimator ( MLE ) , in terms of how fast the Kullback-Leibler divergence of the estimated density converges to the true density , when the sample size $n$ increases . The convergence rate is found to be dependent on both $m$ and $k$ , and certain choices of $m$ and $k$ are found to produce optimal convergence rates . Therefore , these results shed light on the two aforementioned important problems : on how to choose $m$ , and on how $m$ and $k$ should be compromised , for achieving good convergence rates .
We introduce two kernels that extend the mean map , which embeds probability measures in Hilbert spaces . The generative mean map kernel ( GMMK ) is a smooth similarity measure between probabilistic models . The latent mean map kernel ( LMMK ) generalizes the non-iid formulation of Hilbert space embeddings of empirical distributions in order to incorporate latent variable models . When comparing certain classes of distributions , the GMMK exhibits beneficial regularization and generalization properties not shown for previous generative kernels . We present experiments comparing support vector machine performance using the GMMK and LMMK between hidden Markov models to the performance of other methods on discrete and continuous observation sequence data . The results suggest that , in many cases , the GMMK has generalization error competitive with or better than other methods .
We characterize and study variable importance ( VIMP ) and pairwise variable associations in binary regression trees . A key component involves the node mean squared error for a quantity we refer to as a maximal subtree . The theory naturally extends from single trees to ensembles of trees and applies to methods like random forests . This is useful because while importance values from random forests are used to screen variables , for example they are used to filter high throughput genomic data in Bioinformatics , very little theory exists about their properties .
Machine learning methods for solving the equations of dynamical mean-field theory are developed . The method is demonstrated on the three dimensional Hubbard model . The key technical issues are defining a mapping of an input function to an output function , and distinguishing metallic from insulating solutions . Both metallic and Mott insulator solutions can be predicted . The validity of the machine learning scheme is assessed by comparing predictions of full correlation functions , of quasi-particle weight and particle density to values directly computed . The results indicate that with modest further development , machine learning approach may be an attractive computational efficient option for real materials predictions for strongly correlated systems .
Gaussian process is a very promising novel technology that has been applied to both the regression problem and the classification problem . While for the regression problem it yields simple exact solutions , this is not the case for the classification problem , because we encounter intractable integrals . In this paper we develop a new derivation that transforms the problem into that of evaluating the ratio of multivariate Gaussian orthant integrals . Moreover , we develop a new Monte Carlo procedure that evaluates these integrals . It is based on some aspects of bootstrap sampling and acceptancerejection . The proposed approach has beneficial properties compared to the existing Markov Chain Monte Carlo approach , such as simplicity , reliability , and speed .
We consider the problem of accurately estimating the reliability of workers based on noisy labels they provide , which is a fundamental question in crowdsourcing . We propose a novel lower bound on the minimax estimation error which applies to any estimation procedure . We further propose Triangular Estimation ( TE ) , an algorithm for estimating the reliability of workers . TE has low complexity , may be implemented in a streaming setting when labels are provided by workers in real time , and does not rely on an iterative procedure . We further prove that TE is minimax optimal and matches our lower bound . We conclude by assessing the performance of TE and other state-of-the-art algorithms on both synthetic and real-world data sets .
The recently proposed Temporal Ensembling has achieved state-of-the-art results in several semi-supervised learning benchmarks . It maintains an exponential moving average of label predictions on each training example , and penalizes predictions that are inconsistent with this target . However , because the targets change only once per epoch , Temporal Ensembling becomes unwieldy when learning large datasets . To overcome this problem , we propose Mean Teacher , a method that averages model weights instead of label predictions . As an additional benefit , Mean Teacher improves test accuracy and enables training with fewer labels than Temporal Ensembling . Without changing the network architecture , Mean Teacher achieves an error rate of 0 . 00% on SVHN with 000 labels , outperforming Temporal Ensembling trained with 0000 labels . We also show that a good network architecture is crucial to performance . Combining Mean Teacher and Residual Networks , we improve the state of the art on CIFAR-00 with 0000 labels from 00 . 00% to 0 . 00% , and on ImageNet 0000 with 00% of the labels from 00 . 00% to 0 . 00% .
Synthesizing high-quality images from text descriptions is a challenging problem in computer vision and has many practical applications . Samples generated by existing text-to-image approaches can roughly reflect the meaning of the given descriptions , but they fail to contain necessary details and vivid object parts . In this paper , we propose Stacked Generative Adversarial Networks ( StackGAN ) to generate 000x000 photo-realistic images conditioned on text descriptions . We decompose the hard problem into more manageable sub-problems through a sketch-refinement process . The Stage-I GAN sketches the primitive shape and colors of the object based on the given text description , yielding Stage-I low-resolution images . The Stage-II GAN takes Stage-I results and text descriptions as inputs , and generates high-resolution images with photo-realistic details . It is able to rectify defects in Stage-I results and add compelling details with the refinement process . To improve the diversity of the synthesized images and stabilize the training of the conditional-GAN , we introduce a novel Conditioning Augmentation technique that encourages smoothness in the latent conditioning manifold . Extensive experiments and comparisons with state-of-the-arts on benchmark datasets demonstrate that the proposed method achieves significant improvements on generating photo-realistic images conditioned on text descriptions .
As a popular tool for producing meaningful and interpretable models , large-scale sparse learning works efficiently when the underlying structures are indeed or close to sparse . However , naively applying the existing regularization methods can result in misleading outcomes due to model misspecification . In particular , the direct sparsity assumption on coefficient vectors has been questioned in real applications . Therefore , we consider nonsparse learning with the conditional sparsity structure that the coefficient vector becomes sparse after taking out the impacts of certain unobservable latent variables . A new methodology of nonsparse learning with latent variables ( NSL ) is proposed to simultaneously recover the significant observable predictors and latent factors as well as their effects . We explore a common latent family incorporating population principal components and derive the convergence rates of both sample principal components and their score vectors that hold for a wide class of distributions . With the properly estimated latent variables , properties including model selection consistency and oracle inequalities under various prediction and estimation losses are established for the proposed methodology . Our new methodology and results are evidenced by simulation and real data examples .
Compressed sensing ( CS ) shows that a signal having a sparse or compressible representation can be recovered from a small set of linear measurements . In classical CS theory , the sampling matrix and representation matrix are assumed to be known exactly in advance . However , uncertainties exist due to sampling distortion , finite grids of the parameter space of dictionary , etc . In this paper , we take a generalized sparse signal model , which simultaneously considers the sampling and representation matrix uncertainties . Based on the new signal model , a new optimization model for robust sparse signal reconstruction is proposed . This optimization model can be deduced with stochastic robust approximation analysis . Both convex relaxation and greedy algorithms are used to solve the optimization problem . For the convex relaxation method , a sufficient condition for recovery by convex relaxation is given ; For the greedy algorithm , it is realized by the introduction of a pre-processing of the sensing matrix and the measurements . In numerical experiments , both simulated data and real-life ECG data based results show that the proposed method has a better performance than the current methods .
We introduce the first unified theory for target tracking using Multiple Hypothesis Tracking , Topological Data Analysis , and machine learning . Our string of innovations are 0 ) robust topological features are used to encode behavioral information , 0 ) statistical models are fitted to distributions over these topological features , and 0 ) the target type classification methods of Wigren and Bar Shalom et al . are employed to exploit the resulting likelihoods for topological features inside of the tracking procedure . To demonstrate the efficacy of our approach , we test our procedure on synthetic vehicular data generated by the Simulation of Urban Mobility package .
Non-linear dimensionality reduction techniques such as manifold learning algorithms have become a common way for processing and analyzing high-dimensional patterns that often have attached a target that corresponds to the value of an unknown function . Their application to new points consists in two steps : first , embedding the new data point into the low dimensional space and then , estimating the function value on the test point from its neighbors in the embedded space . However , finding the low dimension representation of a test point , while easy for simple but often not powerful enough procedures such as PCA , can be much more complicated for methods that rely on some kind of eigenanalysis , such as Spectral Clustering ( SC ) or Diffusion Maps ( DM ) . Similarly , when a target function is to be evaluated , averaging methods like nearest neighbors may give unstable results if the function is noisy . Thus , the smoothing of the target function with respect to the intrinsic , low-dimensional representation that describes the geometric structure of the examined data is a challenging task . In this paper we propose Auto-adaptive Laplacian Pyramids ( ALP ) , an extension of the standard Laplacian Pyramids model that incorporates a modified LOOCV procedure that avoids the large cost of the standard one and offers the following advantages : ( i ) it selects automatically the optimal function resolution ( stopping time ) adapted to the data and its noise , ( ii ) it is easy to apply as it does not require parameterization , ( iii ) it does not overfit the training set and ( iv ) it adds no extra cost compared to other classical interpolation methods . We illustrate numerically ALP ' s behavior on a synthetic problem and apply it to the computation of the DM projection of new patterns and to the extension to them of target function values on a radiation forecasting problem over very high dimensional patterns .
Nontrivial connectivity has allowed the training of very deep networks by addressing the problem of vanishing gradients and offering a more efficient method of reusing parameters . In this paper we make a comparison between residual networks , densely-connected networks and highway networks on an image classification task . Next , we show that these methodologies can easily be deployed into automatic speech recognition and provide significant improvements to existing models .
Kernel approximation using randomized feature maps has recently gained a lot of interest . In this work , we identify that previous approaches for polynomial kernel approximation create maps that are rank deficient , and therefore do not utilize the capacity of the projected feature space effectively . To address this challenge , we propose compact random feature maps ( CRAFTMaps ) to approximate polynomial kernels more concisely and accurately . We prove the error bounds of CRAFTMaps demonstrating their superior kernel reconstruction performance compared to the previous approximation schemes . We show how structured random matrices can be used to efficiently generate CRAFTMaps , and present a single-pass algorithm using CRAFTMaps to learn non-linear multi-class classifiers . We present experiments on multiple standard data-sets with performance competitive with state-of-the-art results .
In the last twenty-five years ( 0000-0000 ) , algorithmic advances in integer optimization combined with hardware improvements have resulted in an astonishing 000 billion factor speedup in solving Mixed Integer Optimization ( MIO ) problems . We present a MIO approach for solving the classical best subset selection problem of choosing $k$ out of $p$ features in linear regression given $n$ observations . We develop a discrete extension of modern first order continuous optimization methods to find high quality feasible solutions that we use as warm starts to a MIO solver that finds provably optimal solutions . The resulting algorithm ( a ) provides a solution with a guarantee on its suboptimality even if we terminate the algorithm early , ( b ) can accommodate side constraints on the coefficients of the linear regression and ( c ) extends to finding best subset solutions for the least absolute deviation loss function . Using a wide variety of synthetic and real datasets , we demonstrate that our approach solves problems with $n$ in the 0000s and $p$ in the 000s in minutes to provable optimality , and finds near optimal solutions for $n$ in the 000s and $p$ in the 0000s in minutes . We also establish via numerical experiments that the MIO approach performs better than {\texttt {Lasso}} and other popularly used sparse learning procedures , in terms of achieving sparse solutions with good predictive power .
This work investigates the intersection property of conditional independence . It states that for random variables $A , B , C$ and $X$ we have that $X$ independent of $A$ given $B , C$ and $X$ independent of $B$ given $A , C$ implies $X$ independent of $ ( A , B ) $ given $C$ . Under the assumption that the joint distribution has a continuous density , we provide necessary and sufficient conditions under which the intersection property holds . The result has direct applications to causal inference : it leads to strictly weaker conditions under which the graphical structure becomes identifiable from the joint distribution of an additive noise model .
We give polynomial-time algorithms for the exact computation of lowest-energy ( ground ) states , worst margin violators , log partition functions , and marginal edge probabilities in certain binary undirected graphical models . Our approach provides an interesting alternative to the well-known graph cut paradigm in that it does not impose any submodularity constraints ; instead we require planarity to establish a correspondence with perfect matchings ( dimer coverings ) in an expanded dual graph . We implement a unified framework while delegating complex but well-understood subproblems ( planar embedding , maximum-weight perfect matching ) to established algorithms for which efficient implementations are freely available . Unlike graph cut methods , we can perform penalized maximum-likelihood as well as maximum-margin parameter estimation in the associated conditional random fields ( CRFs ) , and employ marginal posterior probabilities as well as maximum a posteriori ( MAP ) states for prediction . Maximum-margin CRF parameter estimation on image denoising and segmentation problems shows our approach to be efficient and effective . A C++ implementation is available from http : //nic . schraudolph . org/isinf/
In this paper , we present a unified analysis of matrix completion under general low-dimensional structural constraints induced by {\em any} norm regularization . We consider two estimators for the general problem of structured matrix completion , and provide unified upper bounds on the sample complexity and the estimation error . Our analysis relies on results from generic chaining , and we establish two intermediate results of independent interest : ( a ) in characterizing the size or complexity of low dimensional subsets in high dimensional ambient space , a certain partial complexity measure encountered in the analysis of matrix completion problems is characterized in terms of a well understood complexity measure of Gaussian widths , and ( b ) it is shown that a form of restricted strong convexity holds for matrix completion problems under general norm regularization . Further , we provide several non-trivial examples of structures included in our framework , notably the recently proposed spectral $k$-support norm .
Designing a photometric system to best fulfil a set of scientific goals is a complex task , demanding a compromise between conflicting requirements and subject to various constraints . A specific example is the determination of stellar astrophysical parameters ( APs ) - effective temperature , metallicity etc . - across a wide range of stellar types . I present a novel approach to this problem which makes minimal assumptions about the required filter system . By considering a filter system as a set of free parameters it may be designed by optimizing some figure-of-merit ( FoM ) with respect to these parameters . In the example considered , the FoM is a measure of how well the filter system can `separate ' stars with different APs . This separation is vectorial in nature , in the sense that the local directions of AP variance are preferably mutually orthogonal to avoid AP degeneracy . The optimization is carried out with an evolutionary algorithm , which uses principles of evolutionary biology to search the parameter space . This model , HFD ( Heuristic Filter Design ) , is applied to the design of photometric systems for the Gaia space astrometry mission . The optimized systems show a number of interesting features , not least the persistence of broad , overlapping filters . These HFD systems perform as least as well as other proposed systems for Gaia , although inadequacies remain in all . The principles underlying HFD are quite generic and may be applied to filter design for numerous other projects , such as the search for specific types of objects or photometric redshift determination .
Matching Pursuit LASSIn Part I \cite{TanPMLPart0} , a Matching Pursuit LASSO ( {MPL} ) algorithm has been presented for solving large-scale sparse recovery ( SR ) problems . In this paper , we present a subspace search to further improve the performance of MPL , and then continue to address another major challenge of SR -- batch SR with many signals , a consideration which is absent from most of previous $\ell_0$-norm methods . As a result , a batch-mode {MPL} is developed to vastly speed up sparse recovery of many signals simultaneously . Comprehensive numerical experiments on compressive sensing and face recognition tasks demonstrate the superior performance of MPL and BMPL over other methods considered in this paper , in terms of sparse recovery ability and efficiency . In particular , BMPL is up to 000 times faster than existing $\ell_0$-norm methods considered to be state-of-the-art . O Part II : Applications and Sparse Recovery over Batch Signals
For decades , context-dependent phonemes have been the dominant sub-word unit for conventional acoustic modeling systems . This status quo has begun to be challenged recently by end-to-end models which seek to combine acoustic , pronunciation , and language model components into a single neural network . Such systems , which typically predict graphemes or words , simplify the recognition process since they remove the need for a separate expert-curated pronunciation lexicon to map from phoneme-based units to words . However , there has been little previous work comparing phoneme-based versus grapheme-based sub-word units in the end-to-end modeling framework , to determine whether the gains from such approaches are primarily due to the new probabilistic model , or from the joint learning of the various components with grapheme-based units . In this work , we conduct detailed experiments which are aimed at quantifying the value of phoneme-based pronunciation lexica in the context of end-to-end models . We examine phoneme-based end-to-end models , which are contrasted against grapheme-based ones on a large vocabulary English Voice-search task , where we find that graphemes do indeed outperform phonemes . We also compare grapheme and phoneme-based approaches on a multi-dialect English task , which once again confirm the superiority of graphemes , greatly simplifying the system for recognizing multiple dialects .
We consider the exploration-exploitation tradeoff in linear quadratic ( LQ ) control problems , where the state dynamics is linear and the cost function is quadratic in states and controls . We analyze the regret of Thompson sampling ( TS ) ( a . k . a . posterior-sampling for reinforcement learning ) in the frequentist setting , i . e . , when the parameters characterizing the LQ dynamics are fixed . Despite the empirical and theoretical success in a wide range of problems from multi-armed bandit to linear bandit , we show that when studying the frequentist regret TS in control problems , we need to trade-off the frequency of sampling optimistic parameters and the frequency of switches in the control policy . This results in an overall regret of $O ( T^{0/0} ) $ , which is significantly worse than the regret $O ( \sqrt{T} ) $ achieved by the optimism-in-face-of-uncertainty algorithm in LQ control problems .
The Lady Maisry ballads afford us a framework within which to segment a storyline into its major components . Segments and as a consequence nodal points are discussed for nine different variants of the Lady Maisry story of a ( young ) woman being burnt to death by her family , on account of her becoming pregnant by a foreign personage . We motivate the importance of nodal points in textual and literary analysis . We show too how the openings of the nine variants can be analyzed comparatively , and also the conclusions of the ballads .
We discuss a clustering method for Gaussian mixture model based on the sparse principal component analysis ( SPCA ) method and compare it with the IF-PCA method . We also discuss the dependent case where the covariance matrix $\Sigma$ is not necessarily diagonal .
We show how to efficiently project a vector onto the top principal components of a matrix , without explicitly computing these components . Specifically , we introduce an iterative algorithm that provably computes the projection using few calls to any black-box routine for ridge regression . By avoiding explicit principal component analysis ( PCA ) , our algorithm is the first with no runtime dependence on the number of top principal components . We show that it can be used to give a fast iterative method for the popular principal component regression problem , giving the first major runtime improvement over the naive method of combining PCA with regression . To achieve our results , we first observe that ridge regression can be used to obtain a " smooth projection " onto the top principal components . We then sharpen this approximation to true projection using a low-degree polynomial approximation to the matrix step function . Step function approximation is a topic of long-term interest in scientific computing . We extend prior theory by constructing polynomials with simple iterative structure and rigorously analyzing their behavior under limited precision .
The proliferation of models for networks raises challenging problems of model selection : the data are sparse and globally dependent , and models are typically high-dimensional and have large numbers of latent variables . Together , these issues mean that the usual model-selection criteria do not work properly for networks . We illustrate these challenges , and show one way to resolve them , by considering the key network-analysis problem of dividing a graph into communities or blocks of nodes with homogeneous patterns of links to the rest of the network . The standard tool for doing this is the stochastic block model , under which the probability of a link between two nodes is a function solely of the blocks to which they belong . This imposes a homogeneous degree distribution within each block ; this can be unrealistic , so degree-corrected block models add a parameter for each node , modulating its over-all degree . The choice between ordinary and degree-corrected block models matters because they make very different inferences about communities . We present the first principled and tractable approach to model selection between standard and degree-corrected block models , based on new large-graph asymptotics for the distribution of log-likelihood ratios under the stochastic block model , finding substantial departures from classical results for sparse graphs . We also develop linear-time approximations for log-likelihoods under both the stochastic block model and the degree-corrected model , using belief propagation . Applications to simulated and real networks show excellent agreement with our approximations . Our results thus both solve the practical problem of deciding on degree correction , and point to a general approach to model selection in network analysis .
The fused lasso penalizes a loss function by the $L_0$ norm for both the regression coefficients and their successive differences to encourage sparsity of both . In this paper , we propose a Bayesian generalized fused lasso modeling based on a normal-exponential-gamma ( NEG ) prior distribution . The NEG prior is assumed into the difference of successive regression coefficients . The proposed method enables us to construct a more versatile sparse model than the ordinary fused lasso by using a flexible regularization term . We also propose a sparse fused algorithm to produce exact sparse solutions . Simulation studies and real data analyses show that the proposed method has superior performance to the ordinary fused lasso .
The paper deals with regression problems , in which the nonsmooth target is assumed to switch between different operating modes . Specifically , piecewise smooth ( PWS ) regression considers target functions switching deterministically via a partition of the input space , while switching regression considers arbitrary switching laws . The paper derives generalization error bounds in these two settings by following the approach based on Rademacher complexities . For PWS regression , our derivation involves a chaining argument and a decomposition of the covering numbers of PWS classes in terms of the ones of their component functions and the capacity of the classifier partitioning the input space . This yields error bounds with a radical dependency on the number of modes . For switching regression , the decomposition can be performed directly at the level of the Rademacher complexities , which yields bounds with a linear dependency on the number of modes . By using once more chaining and a decomposition at the level of covering numbers , we show how to recover a radical dependency , however at the cost of a slightly worse convergence rate . Examples of applications are given in particular for PWS and swichting regression with linear and kernel-based component functions .
We informally call a stochastic process learnable if it admits a generalization error approaching zero in probability for any concept class with finite VC-dimension ( IID processes are the simplest example ) . A mixture of learnable processes need not be learnable itself , and certainly its generalization error need not decay at the same rate . In this paper , we argue that it is natural in predictive PAC to condition not on the past observations but on the mixture component of the sample path . This definition not only matches what a realistic learner might demand , but also allows us to sidestep several otherwise grave problems in learning from dependent data . In particular , we give a novel PAC generalization bound for mixtures of learnable processes with a generalization error that is not worse than that of each mixture component . We also provide a characterization of mixtures of absolutely regular ( $\beta$-mixing ) processes , of independent probability-theoretic interest .
We consider the use of the Joint Clustering and Matching ( JCM ) procedure for the supervised classification of a flow cytometric sample with respect to a number of predefined classes of such samples . The JCM procedure has been proposed as a method for the unsupervised classification of cells within a sample into a number of clusters and in the case of multiple samples , the matching of these clusters across the samples . The two tasks of clustering and matching of the clusters are performed simultaneously within the JCM framework . In this paper , we consider the case where there is a number of distinct classes of samples whose class of origin is known , and the problem is to classify a new sample of unknown class of origin to one of these predefined classes . For example , the different classes might correspond to the types of a particular disease or to the various health outcomes of a patient subsequent to a course of treatment . We show and demonstrate on some real datasets how the JCM procedure can be used to carry out this supervised classification task . A mixture distribution is used to model the distribution of the expressions of a fixed set of markers for each cell in a sample with the components in the mixture model corresponding to the various populations of cells in the composition of the sample . For each class of samples , a class template is formed by the adoption of random-effects terms to model the inter-sample variation within a class . The classification of a new unclassified sample is undertaken by assigning the unclassified sample to the class that minimizes the Kullback-Leibler distance between its fitted mixture density and each class density provided by the class templates .
Many techniques in computer vision , machine learning , and statistics rely on the fact that a signal of interest admits a sparse representation over some dictionary . Dictionaries are either available analytically , or can be learned from a suitable training set . While analytic dictionaries permit to capture the global structure of a signal and allow a fast implementation , learned dictionaries often perform better in applications as they are more adapted to the considered class of signals . In imagery , unfortunately , the numerical burden for ( i ) learning a dictionary and for ( ii ) employing the dictionary for reconstruction tasks only allows to deal with relatively small image patches that only capture local image information . The approach presented in this paper aims at overcoming these drawbacks by allowing a separable structure on the dictionary throughout the learning process . On the one hand , this permits larger patch-sizes for the learning phase , on the other hand , the dictionary is applied efficiently in reconstruction tasks . The learning procedure is based on optimizing over a product of spheres which updates the dictionary as a whole , thus enforces basic dictionary properties such as mutual coherence explicitly during the learning procedure . In the special case where no separable structure is enforced , our method competes with state-of-the-art dictionary learning methods like K-SVD .
We consider the problem of learning a measure of distance among vectors in a feature space and propose a hybrid method that simultaneously learns from similarity ratings assigned to pairs of vectors and class labels assigned to individual vectors . Our method is based on a generative model in which class labels can provide information that is not encoded in feature vectors but yet relates to perceived similarity between objects . Experiments with synthetic data as well as a real medical image retrieval problem demonstrate that leveraging class labels through use of our method improves retrieval performance significantly .
Identifying overlapping communities in networks is a challenging task . In this work we present a novel approach to community detection that utilises the Bayesian non-negative matrix factorisation ( NMF ) model to produce a probabilistic output for node memberships . The scheme has the advantage of computational efficiency , soft community membership and an intuitive foundation . We present the performance of the method against a variety of benchmark problems and compare and contrast it to several other algorithms for community detection . Our approach performs favourably compared to other methods at a fraction of the computational costs .
In this paper we consider sparse and identifiable linear latent variable ( factor ) and linear Bayesian network models for parsimonious analysis of multivariate data . We propose a computationally efficient method for joint parameter and model inference , and model comparison . It consists of a fully Bayesian hierarchy for sparse models using slab and spike priors ( two-component delta-function and continuous mixtures ) , non-Gaussian latent factors and a stochastic search over the ordering of the variables . The framework , which we call SLIM ( Sparse Linear Identifiable Multivariate modeling ) , is validated and bench-marked on artificial and real biological data sets . SLIM is closest in spirit to LiNGAM ( Shimizu et al . , 0000 ) , but differs substantially in inference , Bayesian network structure learning and model comparison . Experimentally , SLIM performs equally well or better than LiNGAM with comparable computational complexity . We attribute this mainly to the stochastic search strategy used , and to parsimony ( sparsity and identifiability ) , which is an explicit part of the model . We propose two extensions to the basic i . i . d . linear framework : non-linear dependence on observed variables , called SNIM ( Sparse Non-linear Identifiable Multivariate modeling ) and allowing for correlations between latent variables , called CSLIM ( Correlated SLIM ) , for the temporal and/or spatial data . The source code and scripts are available from http : //cogsys . imm . dtu . dk/slim/ .
In this note , we introduce a new algorithm to deal with finite dimensional clustering with errors in variables . The design of this algorithm is based on recent theoretical advances ( see Loustau ( 0000a , b ) ) in statistical learning with errors in variables . As the previous mentioned papers , the algorithm mixes different tools from the inverse problem literature and the machine learning community . Coarsely , it is based on a two-step procedure : ( 0 ) a deconvolution step to deal with noisy inputs and ( 0 ) Newton ' s iterations as the popular k-means .
Recently exciting progress has been made on protein contact prediction , but the predicted contacts for proteins without many sequence homologs is still of low quality and not very useful for de novo structure prediction . This paper presents a new deep learning method that predicts contacts by integrating both evolutionary coupling ( EC ) and sequence conservation information through an ultra-deep neural network formed by two deep residual networks . This deep neural network allows us to model very complex sequence-contact relationship as well as long-range inter-contact correlation . Our method greatly outperforms existing contact prediction methods and leads to much more accurate contact-assisted protein folding . Tested on three datasets of 000 proteins , the average top L long-range prediction accuracy obtained our method , the representative EC method CCMpred and the CASP00 winner MetaPSICOV is 0 . 00 , 0 . 00 and 0 . 00 , respectively ; the average top L/00 long-range accuracy of our method , CCMpred and MetaPSICOV is 0 . 00 , 0 . 00 and 0 . 00 , respectively . Ab initio folding using our predicted contacts as restraints can yield correct folds ( i . e . , TMscore>0 . 0 ) for 000 test proteins , while that using MetaPSICOV- and CCMpred-predicted contacts can do so for only 00 and 00 proteins , respectively . Further , our contact-assisted models have much better quality than template-based models . Using our predicted contacts as restraints , we can ( ab initio ) fold 000 of the 000 membrane proteins with TMscore>0 . 0 . By contrast , when the training proteins of our method are used as templates , homology modeling can only do so for 00 of them . One interesting finding is that even if we do not train our prediction models with any membrane proteins , our method works very well on membrane protein prediction . Finally , in recent blind CAMEO benchmark our method successfully folded 0 test proteins with a novel fold .
Continuous vector representations of words and objects appear to carry surprisingly rich semantic content . In this paper , we advance both the conceptual and theoretical understanding of word embeddings in three ways . First , we ground embeddings in semantic spaces studied in cognitive-psychometric literature and introduce new evaluation tasks . Second , in contrast to prior work , we take metric recovery as the key object of study , unify existing algorithms as consistent metric recovery methods based on co-occurrence counts from simple Markov random walks , and propose a new recovery algorithm . Third , we generalize metric recovery to graphs and manifolds , relating co-occurence counts on random walks in graphs and random processes on manifolds to the underlying metric to be recovered , thereby reconciling manifold estimation and embedding algorithms . We compare embedding algorithms across a range of tasks , from nonlinear dimensionality reduction to three semantic language tasks , including analogies , sequence completion , and classification .
Extracting latent low-dimensional structure from high-dimensional data is of paramount importance in timely inference tasks encountered with `Big Data ' analytics . However , increasingly noisy , heterogeneous , and incomplete datasets as well as the need for {\em real-time} processing of streaming data pose major challenges to this end . In this context , the present paper permeates benefits from rank minimization to scalable imputation of missing data , via tracking low-dimensional subspaces and unraveling latent ( possibly multi-way ) structure from \emph{incomplete streaming} data . For low-rank matrix data , a subspace estimator is proposed based on an exponentially-weighted least-squares criterion regularized with the nuclear norm . After recasting the non-separable nuclear norm into a form amenable to online optimization , real-time algorithms with complementary strengths are developed and their convergence is established under simplifying technical assumptions . In a stationary setting , the asymptotic estimates obtained offer the well-documented performance guarantees of the {\em batch} nuclear-norm regularized estimator . Under the same unifying framework , a novel online ( adaptive ) algorithm is developed to obtain multi-way decompositions of \emph{low-rank tensors} with missing entries , and perform imputation as a byproduct . Simulated tests with both synthetic as well as real Internet and cardiac magnetic resonance imagery ( MRI ) data confirm the efficacy of the proposed algorithms , and their superior performance relative to state-of-the-art alternatives .
In recent years a number of methods have been developed for automatically learning the ( sparse ) connectivity structure of Markov Random Fields . These methods are mostly based on L0-regularized optimization which has a number of disadvantages such as the inability to assess model uncertainty and expensive cross-validation to find the optimal regularization parameter . Moreover , the model ' s predictive performance may degrade dramatically with a suboptimal value of the regularization parameter ( which is sometimes desirable to induce sparseness ) . We propose a fully Bayesian approach based on a " spike and slab " prior ( similar to L0 regularization ) that does not suffer from these shortcomings . We develop an approximate MCMC method combining Langevin dynamics and reversible jump MCMC to conduct inference in this model . Experiments show that the proposed model learns a good combination of the structure and parameter values without the need for separate hyper-parameter tuning . Moreover , the model ' s predictive performance is much more robust than L0-based methods with hyper-parameter settings that induce highly sparse model structures .
The stochastic gradient descent ( SGD ) algorithm has been widely used in statistical estimation for large-scale data due to its computational and memory efficiency . While most existing work focuses on the convergence of the objective function or the error of the obtained solution , we investigate the problem of statistical inference of the true model parameters based on SGD . To this end , we propose two consistent estimators of the asymptotic covariance of the average iterate from SGD : ( 0 ) an intuitive plug-in estimator and ( 0 ) a computationally more efficient batch-means estimator , which only uses the iterates from SGD . As the SGD process forms a time-inhomogeneous Markov chain , our batch-means estimator with carefully chosen increasing batch sizes generalizes the classical batch-means estimator designed for time-homogenous Markov chains . The proposed batch-means estimator is of independent interest , which can be potentially used for estimating the covariance of other time-inhomogeneous Markov chains . Both proposed estimators allow us to construct asymptotically exact confidence intervals and hypothesis tests . We further discuss an extension to conducting inference based on SGD for high-dimensional linear regression . Using a variant of the SGD algorithm , we construct a debiased estimator of each regression coefficient that is asymptotically normal . This gives a one-pass algorithm for computing both the sparse regression coefficient estimator and confidence intervals , which is computationally attractive and applicable to online data .
The OSTSC package is a powerful oversampling approach for classifying univariant , but multinomial time series data in R . This article provides a brief overview of the oversampling methodology implemented by the package . A tutorial of the OSTSC package is provided . We begin by providing three test cases for the user to quickly validate the functionality in the package . To demonstrate the performance impact of OSTSC , we then provide two medium size imbalanced time series datasets . Each example applies a TensorFlow implementation of a Long Short-Term Memory ( LSTM ) classifier - a type of a Recurrent Neural Network ( RNN ) classifier - to imbalanced time series . The classifier performance is compared with and without oversampling . Finally , larger versions of these two datasets are evaluated to demonstrate the scalability of the package . The examples demonstrate that the OSTSC package improves the performance of RNN classifiers applied to highly imbalanced time series data . In particular , OSTSC is observed to increase the AUC of LSTM from 0 . 000 to 0 . 000 on a high frequency trading dataset consisting of 00 , 000 time series observations .
Recent years have seen an increasing popularity of learning the sparse \emph{changes} in Markov Networks . Changes in the structure of Markov Networks reflect alternations of interactions between random variables under different regimes and provide insights into the underlying system . While each individual network structure can be complicated and difficult to learn , the overall change from one network to another can be simple . This intuition gave birth to an approach that \emph{directly} learns the sparse changes without modelling and learning the individual ( possibly dense ) networks . In this paper , we review such a direct learning method with some latest developments along this line of research .
Despite enormous progress in object detection and classification , the problem of incorporating expected contextual relationships among object instances into modern recognition systems remains a key challenge . In this work we propose Information Pursuit , a Bayesian framework for scene parsing that combines prior models for the geometry of the scene and the spatial arrangement of objects instances with a data model for the output of high-level image classifiers trained to answer specific questions about the scene . In the proposed framework , the scene interpretation is progressively refined as evidence accumulates from the answers to a sequence of questions . At each step , we choose the question to maximize the mutual information between the new answer and the full interpretation given the current evidence obtained from previous inquiries . We also propose a method for learning the parameters of the model from synthesized , annotated scenes obtained by top-down sampling from an easy-to-learn generative scene model . Finally , we introduce a database of annotated indoor scenes of dining room tables , which we use to evaluate the proposed approach .
Along with the recent advances in scalable Markov Chain Monte Carlo methods , sampling techniques that are based on Langevin diffusions have started receiving increasing attention . These so called Langevin Monte Carlo ( LMC ) methods are based on diffusions driven by a Brownian motion , which gives rise to Gaussian proposal distributions in the resulting algorithms . Even though these approaches have proven successful in many applications , their performance can be limited by the light-tailed nature of the Gaussian proposals . In this study , we extend classical LMC and develop a novel Fractional LMC ( FLMC ) framework that is based on a family of heavy-tailed distributions , called $\alpha$-stable L\ ' {e}vy distributions . As opposed to classical approaches , the proposed approach can possess large jumps while targeting the correct distribution , which would be beneficial for efficient exploration of the state space . We develop novel computational methods that can scale up to large-scale problems and we provide formal convergence analysis of the proposed scheme . Our experiments support our theory : FLMC can provide superior performance in multi-modal settings , improved convergence rates , and robustness to algorithm parameters .
For the prediction with expert advice setting , we consider methods to construct forecasting algorithms that suffer loss not much more than of any expert in the pool . In contrast to the standard approach , we investigate the case of long-term interval forecasting of time series , that is , each expert issues a sequence of forecasts for a time interval ahead and the master algorithm combines these forecasts into one aggregated sequence of forecasts . Two new approaches for aggregating experts long-term interval predictions are presented . One is based on Vovk ' s aggregation algorithm and considers sliding experts , the other applies the approach of Mixing Past Posteriors method to the long-term prediction . The upper bounds for regret of these algorithms for adversarial case are obtained . We also present results of numerical experiments of time series long-term prediction .
Max-norm regularizer has been extensively studied in the last decade as it promotes an effective low-rank estimation for the underlying data . However , such max-norm regularized problems are typically formulated and solved in a batch manner , which prevents it from processing big data due to possible memory budget . In this paper , hence , we propose an online algorithm that is scalable to large-scale setting . Particularly , we consider the matrix decomposition problem as an example , although a simple variant of the algorithm and analysis can be adapted to other important problems such as matrix completion . The crucial technique in our implementation is to reformulating the max-norm to an equivalent matrix factorization form , where the factors consist of a ( possibly overcomplete ) basis component and a coefficients one . In this way , we may maintain the basis component in the memory and optimize over it and the coefficients for each sample alternatively . Since the memory footprint of the basis component is independent of the sample size , our algorithm is appealing when manipulating a large collection of samples . We prove that the sequence of the solutions ( i . e . , the basis component ) produced by our algorithm converges to a stationary point of the expected loss function asymptotically . Numerical study demonstrates encouraging results for the efficacy and robustness of our algorithm compared to the widely used nuclear norm solvers .
Humans have an impressive ability to reason about new concepts and experiences from just a single example . In particular , humans have an ability for one-shot generalization : an ability to encounter a new concept , understand its structure , and then be able to generate compelling alternative variations of the concept . We develop machine learning systems with this important capacity by developing new deep generative models , models that combine the representational power of deep learning with the inferential power of Bayesian reasoning . We develop a class of sequential generative models that are built on the principles of feedback and attention . These two characteristics lead to generative models that are among the state-of-the art in density estimation and image generation . We demonstrate the one-shot generalization ability of our models using three tasks : unconditional sampling , generating new exemplars of a given concept , and generating new exemplars of a family of concepts . In all cases our models are able to generate compelling and diverse samples---having seen new examples just once---providing an important class of general-purpose models for one-shot machine learning .
This chapter provides a self-contained introduction to the use of Bayesian inference to extract large-scale modular structures from network data , based on the stochastic block model ( SBM ) , as well as its degree-corrected and overlapping generalizations . We focus on nonparametric formulations that allow their inference in a manner that prevents overfitting , and enables model selection . We discuss aspects of the choice of priors , in particular how to avoid underfitting via increased Bayesian hierarchies , and we contrast the task of sampling network partitions from the posterior distribution with finding the single point estimate that maximizes it , while describing efficient algorithms to perform either one . We also show how inferring the SBM can be used to predict missing and spurious links , and shed light on the fundamental limitations of the detectability of modular structures in networks .
Despite the major advances taken in causal modeling , causality is still an unfamiliar topic for many statisticians . In this paper , it is demonstrated from the beginning to the end how causal effects can be estimated from observational data assuming that the causal structure is known . To make the problem more challenging , the causal effects are highly nonlinear and the data are missing at random . The tools used in the estimation include causal models with design , causal calculus , multiple imputation and generalized additive models . The main message is that a trained statistician can estimate causal effects by judiciously combining existing tools .
Objective : Predict patient-specific vitals deemed medically acceptable for discharge from a pediatric intensive care unit ( ICU ) . Design : The means of each patient ' s hr , sbp and dbp measurements between their medical and physical discharge from the ICU were computed as a proxy for their physiologically acceptable state space ( PASS ) for successful ICU discharge . These individual PASS values were compared via root mean squared error ( rMSE ) to population age-normal vitals , a polynomial regression through the PASS values of a Pediatric ICU ( PICU ) population and predictions from two recurrent neural network models designed to predict personalized PASS within the first twelve hours following ICU admission . Setting : PICU at Children ' s Hospital Los Angeles ( CHLA ) . Patients : 0 , 000 PICU episodes ( 0 , 000 patients ) collected between 0000 and 0000 . Interventions : None . Measurements : Each episode data contained 000 variables representing vitals , labs , interventions , and drugs . They also included a time indicator for PICU medical discharge and physical discharge . Main Results : The rMSEs between individual PASS values and population age-normals ( hr : 00 . 0 bpm , sbp : 00 . 0 mmHg , dbp : 00 . 0 mmHg ) were larger than the rMSEs corresponding to the polynomial regression ( hr : 00 . 0 bpm , sbp : 00 . 0 mmHg , dbp : 00 . 0 mmHg ) . The rMSEs from the best performing RNN model were the lowest ( hr : 00 . 0 bpm ; sbp : 0 . 0 mmHg , dbp : 0 . 0 mmHg ) . Conclusion : PICU patients are a unique subset of the general population , and general age-normal vitals may not be suitable as target values indicating physiologic stability at discharge . Age-normal vitals that were specifically derived from the medical-to-physical discharge window of ICU patients may be more appropriate targets for ' acceptable ' physiologic state for critical care patients . Going beyond simple age bins , an RNN model can provide more personalized target values .
The min-max kernel is a generalization of the popular resemblance kernel ( which is designed for binary data ) . In this paper , we demonstrate , through an extensive classification study using kernel machines , that the min-max kernel often provides an effective measure of similarity for nonnegative data . As the min-max kernel is nonlinear and might be difficult to be used for industrial applications with massive data , we show that the min-max kernel can be linearized via hashing techniques . This allows practitioners to apply min-max kernel to large-scale applications using well matured linear algorithms such as linear SVM or logistic regression . The previous remarkable work on consistent weighted sampling ( CWS ) produces samples in the form of ( $i^* , t^*$ ) where the $i^*$ records the location ( and in fact also the weights ) information analogous to the samples produced by classical minwise hashing on binary data . Because the $t^*$ is theoretically unbounded , it was not immediately clear how to effectively implement CWS for building large-scale linear classifiers . In this paper , we provide a simple solution by discarding $t^*$ ( which we refer to as the " 0-bit " scheme ) . Via an extensive empirical study , we show that this 0-bit scheme does not lose essential information . We then apply the " 0-bit " CWS for building linear classifiers to approximate min-max kernel classifiers , as extensively validated on a wide range of publicly available classification datasets . We expect this work will generate interests among data mining practitioners who would like to efficiently utilize the nonlinear information of non-binary and nonnegative data .
Implicit discourse relation classification is of great challenge due to the lack of connectives as strong linguistic cues , which motivates the use of annotated implicit connectives to improve the recognition . We propose a feature imitation framework in which an implicit relation network is driven to learn from another neural network with access to connectives , and thus encouraged to extract similarly salient features for accurate classification . We develop an adversarial model to enable an adaptive imitation scheme through competition between the implicit network and a rival feature discriminator . Our method effectively transfers discriminability of connectives to the implicit features , and achieves state-of-the-art performance on the PDTB benchmark .
The problem of feature disentanglement has been explored in the literature , for the purpose of image and video processing and text analysis . State-of-the-art methods for disentangling feature representations rely on the presence of many labeled samples . In this work , we present a novel method for disentangling factors of variation in data-scarce regimes . Specifically , we explore the application of feature disentangling for the problem of supervised classification in a setting where few labeled samples exist , and there are no unlabeled samples for use in unsupervised training . Instead , a similar datasets exists which shares at least one direction of variation with the sample-constrained datasets . We train our model end-to-end using the framework of variational autoencoders and are able to experimentally demonstrate that using an auxiliary dataset with similar variation factors contribute positively to classification performance , yielding competitive results with the state-of-the-art in unsupervised learning .
Training large machine learning ( ML ) models with many variables or parameters can take a long time if one employs sequential procedures even with stochastic updates . A natural solution is to turn to distributed computing on a cluster ; however , naive , unstructured parallelization of ML algorithms does not usually lead to a proportional speedup and can even result in divergence , because dependencies between model elements can attenuate the computational gains from parallelization and compromise correctness of inference . Recent efforts toward this issue have benefited from exploiting the static , a priori block structures residing in ML algorithms . In this paper , we take this path further by exploring the dynamic block structures and workloads therein present during ML program execution , which offers new opportunities for improving convergence , correctness , and load balancing in distributed ML . We propose and showcase a general-purpose scheduler , STRADS , for coordinating distributed updates in ML algorithms , which harnesses the aforementioned opportunities in a systematic way . We provide theoretical guarantees for our scheduler , and demonstrate its efficacy versus static block structures on Lasso and Matrix Factorization .
We present a framework that couples the syntax and semantics of natural language sentences in a generative model , in order to develop a semantic parser that jointly infers the syntactic , morphological , and semantic representations of a given sentence under the guidance of background knowledge . To generate a sentence in our framework , a semantic statement is first sampled from a prior , such as from a set of beliefs in a knowledge base . Given this semantic statement , a grammar probabilistically generates the output sentence . A joint semantic-syntactic parser is derived that returns the $k$-best semantic and syntactic parses for a given sentence . The semantic prior is flexible , and can be used to incorporate background knowledge during parsing , in ways unlike previous semantic parsing approaches . For example , semantic statements corresponding to beliefs in a knowledge base can be given higher prior probability , type-correct statements can be given somewhat lower probability , and beliefs outside the knowledge base can be given lower probability . The construction of our grammar invokes a novel application of hierarchical Dirichlet processes ( HDPs ) , which in turn , requires a novel and efficient inference approach . We present experimental results showing , for a simple grammar , that our parser outperforms a state-of-the-art CCG semantic parser and scales to knowledge bases with millions of beliefs .
In this paper , we propose to ( seamlessly ) integrate b-bit minwise hashing with linear SVM to substantially improve the training ( and testing ) efficiency using much smaller memory , with essentially no loss of accuracy . Theoretically , we prove that the resemblance matrix , the minwise hashing matrix , and the b-bit minwise hashing matrix are all positive definite matrices ( kernels ) . Interestingly , our proof for the positive definiteness of the b-bit minwise hashing kernel naturally suggests a simple strategy to integrate b-bit hashing with linear SVM . Our technique is particularly useful when the data can not fit in memory , which is an increasingly critical issue in large-scale machine learning . Our preliminary experimental results on a publicly available webspam dataset ( 000K samples and 00 million dimensions ) verified the effectiveness of our algorithm . For example , the training time was reduced to merely a few seconds . In addition , our technique can be easily extended to many other linear and nonlinear machine learning applications such as logistic regression .
In just three years , Variational Autoencoders ( VAEs ) have emerged as one of the most popular approaches to unsupervised learning of complicated distributions . VAEs are appealing because they are built on top of standard function approximators ( neural networks ) , and can be trained with stochastic gradient descent . VAEs have already shown promise in generating many kinds of complicated data , including handwritten digits , faces , house numbers , CIFAR images , physical models of scenes , segmentation , and predicting the future from static images . This tutorial introduces the intuitions behind VAEs , explains the mathematics behind them , and describes some empirical behavior . No prior knowledge of variational Bayesian methods is assumed .
We study the problem of variable selection in convex nonparametric regression . Under the assumption that the true regression function is convex and sparse , we develop a screening procedure to select a subset of variables that contains the relevant variables . Our approach is a two-stage quadratic programming method that estimates a sum of one-dimensional convex functions , followed by one-dimensional concave regression fits on the residuals . In contrast to previous methods for sparse additive models , the optimization is finite dimensional and requires no tuning parameters for smoothness . Under appropriate assumptions , we prove that the procedure is faithful in the population setting , yielding no false negatives . We give a finite sample statistical analysis , and introduce algorithms for efficiently carrying out the required quadratic programs . The approach leads to computational and statistical advantages over fitting a full model , and provides an effective , practical approach to variable screening in convex regression .
Semi-supervised learning deals with the problem of how , if possible , to take advantage of a huge amount of not classified data , to perform classification , in situations when , typically , the labelled data are few . Even though this is not always possible ( it depends on how useful is to know the distribution of the unlabelled data in the inference of the labels ) , several algorithm have been proposed recently . A new algorithm is proposed , that under almost neccesary conditions , attains asymptotically the performance of the best theoretical rule , when the size of unlabeled data tends to infinity . The set of necessary assumptions , although reasonables , show that semi-parametric classification only works for very well conditioned problems .
We introduce an unsupervised approach to efficiently discover the underlying features in a data set via crowdsourcing . Our queries ask crowd members to articulate a feature common to two out of three displayed examples . In addition we also ask the crowd to provide binary labels to the remaining examples based on the discovered features . The triples are chosen adaptively based on the labels of the previously discovered features on the data set . In two natural models of features , hierarchical and independent , we show that a simple adaptive algorithm , using " two-out-of-three " similarity queries , recovers all features with less labor than any nonadaptive algorithm . Experimental results validate the theoretical findings .
Most classification methods are based on the assumption that data conforms to a stationary distribution . The machine learning domain currently suffers from a lack of classification techniques that are able to detect the occurrence of a change in the underlying data distribution . Ignoring possible changes in the underlying concept , also known as concept drift , may degrade the performance of the classification model . Often these changes make the model inconsistent and regular updatings become necessary . Taking the temporal dimension into account during the analysis of Web usage data is a necessity , since the way a site is visited may indeed evolve due to modifications in the structure and content of the site , or even due to changes in the behavior of certain user groups . One solution to this problem , proposed in this article , is to update models using summaries obtained by means of an evolutionary approach based on an intelligent clustering approach . We carry out various clustering strategies that are applied on time sub-periods . To validate our approach we apply two external evaluation criteria which compare different partitions from the same data set . Our experiments show that the proposed approach is efficient to detect the occurrence of changes .
We propose Kernel Hamiltonian Monte Carlo ( KMC ) , a gradient-free adaptive MCMC algorithm based on Hamiltonian Monte Carlo ( HMC ) . On target densities where classical HMC is not an option due to intractable gradients , KMC adaptively learns the target ' s gradient structure by fitting an exponential family model in a Reproducing Kernel Hilbert Space . Computational costs are reduced by two novel efficient approximations to this gradient . While being asymptotically exact , KMC mimics HMC in terms of sampling efficiency , and offers substantial mixing improvements over state-of-the-art gradient free samplers . We support our claims with experimental studies on both toy and real-world applications , including Approximate Bayesian Computation and exact-approximate MCMC .
The original problem of supervised classification considers the task of automatically assigning objects to their respective classes on the basis of numerical measurements derived from these objects . Classifiers are the tools that implement the actual functional mapping from these measurements---also called features or inputs---to the so-called class label---or output . The fields of pattern recognition and machine learning study ways of constructing such classifiers . The main idea behind supervised methods is that of learning from examples : given a number of example input-output relations , to what extent can the general mapping be learned that takes any new and unseen feature vector to its correct class ? This chapter provides a basic introduction to the underlying ideas of how to come to a supervised classification problem . In addition , it provides an overview of some specific classification techniques , delves into the issues of object representation and classifier evaluation , and ( very ) briefly covers some variations on the basic supervised classification task that may also be of interest to the practitioner .
We give a rigorous analysis of the statistical behavior of gradients in randomly initialized feed-forward networks with ReLU activations . Our results show that a fully connected depth $d$ ReLU net with hidden layer widths $n_j$ will have exploding and vanishing gradients if and only if $\sum_{j=0}^{d-0} 0/n_j$ is large . The point of view of this article is that whether a given neural net will have exploding/vanishing gradients is a function mainly of the architecture of the net , and hence can be tested at initialization . Our results imply that a fully connected network that produces manageable gradients at initialization must have many hidden layers that are about as wide as the network is deep . This work is related to the mean field theory approach to random neural nets . From this point of view , we give a rigorous computation of the $0/n_j$ corrections to the propagation of gradients at the so-called edge of chaos .
Bayesian optimization is a powerful tool for fine-tuning the hyper-parameters of a wide variety of machine learning models . The success of machine learning has led practitioners in diverse real-world settings to learn classifiers for practical problems . As machine learning becomes commonplace , Bayesian optimization becomes an attractive method for practitioners to automate the process of classifier hyper-parameter tuning . A key observation is that the data used for tuning models in these settings is often sensitive . Certain data such as genetic predisposition , personal email statistics , and car accident history , if not properly private , may be at risk of being inferred from Bayesian optimization outputs . To address this , we introduce methods for releasing the best hyper-parameters and classifier accuracy privately . Leveraging the strong theoretical guarantees of differential privacy and known Bayesian optimization convergence bounds , we prove that under a GP assumption these private quantities are also near-optimal . Finally , even if this assumption is not satisfied , we can use different smoothness guarantees to protect privacy .
AUC ( Area under the ROC curve ) is an important performance measure for applications where the data is highly imbalanced . Learning to maximize AUC performance is thus an important research problem . Using a max-margin based surrogate loss function , AUC optimization problem can be approximated as a pairwise rankSVM learning problem . Batch learning methods for solving the kernelized version of this problem suffer from scalability and may not result in sparse classifiers . Recent years have witnessed an increased interest in the development of online or single-pass online learning algorithms that design a classifier by maximizing the AUC performance . The AUC performance of nonlinear classifiers , designed using online methods , is not comparable with that of nonlinear classifiers designed using batch learning algorithms on many real-world datasets . Motivated by these observations , we design a scalable algorithm for maximizing AUC performance by greedily adding the required number of basis functions into the classifier model . The resulting sparse classifiers perform faster inference . Our experimental results show that the level of sparsity achievable can be order of magnitude smaller than the Kernel RankSVM model without affecting the AUC performance much .
We study the Dictionary Learning ( aka Sparse Coding ) problem of obtaining a sparse representation of data points , by learning \emph{dictionary vectors} upon which the data points can be written as sparse linear combinations . We view this problem from a geometry perspective as the spanning set of a subspace arrangement , and focus on understanding the case when the underlying hypergraph of the subspace arrangement is specified . For this Fitted Dictionary Learning problem , we completely characterize the combinatorics of the associated subspace arrangements ( i . e . \ their underlying hypergraphs ) . Specifically , a combinatorial rigidity-type theorem is proven for a type of geometric incidence system . The theorem characterizes the hypergraphs of subspace arrangements that generically yield ( a ) at least one dictionary ( b ) a locally unique dictionary ( i . e . \ at most a finite number of isolated dictionaries ) of the specified size . We are unaware of prior application of combinatorial rigidity techniques in the setting of Dictionary Learning , or even in machine learning . We also provide a systematic classification of problems related to Dictionary Learning together with various algorithms , their assumptions and performance .
Estimators computed from adaptively collected data do not behave like their non-adaptive brethren . Rather , the sequential dependence of the collection policy can lead to severe distributional biases that persist even in the infinite data limit . We develop a general method decorrelation procedure -- W-decorrelation -- for transforming the bias of adaptive linear regression estimators into variance . The method uses only coarse-grained information about the data collection policy and does not need access to propensity scores or exact knowledge of the policy . We bound the finite-sample bias and variance of the W-estimator and develop asymptotically correct confidence intervals based on a novel martingale central limit theorem . We then demonstrate the empirical benefits of the generic W-decorrelation procedure in two different adaptive data settings : the multi-armed bandits and autoregressive time series models .
The excited states of polyatomic systems are rather complex , and often exhibit meta-stable dynamical behaviors . Static analysis of reaction pathway often fails to sufficiently characterize excited state motions due to their highly non-equilibrium nature . Here , we proposed a time series guided clustering algorithm to generate most relevant meta-stable patterns directly from ab initio dynamic trajectories . Based on the knowledge of these meta-stable patterns , we suggested an interpolation scheme with only a concrete and finite set of known patterns to accurately predict the ground and excited state properties of the entire dynamics trajectories . As illustrated with the example of sinapic acids , the estimation error for both ground and excited state is very close , which indicates one could predict the ground and excited state molecular properties with similar accuracy . These results may provide us some insights to construct an excited state force field with compatible energy terms as traditional ones .
Data in the form of pairwise comparisons arises in many domains , including preference elicitation , sporting competitions , and peer grading among others . We consider parametric ordinal models for such pairwise comparison data involving a latent vector $w^* \in \mathbb{R}^d$ that represents the " qualities " of the $d$ items being compared ; this class of models includes the two most widely used parametric models--the Bradley-Terry-Luce ( BTL ) and the Thurstone models . Working within a standard minimax framework , we provide tight upper and lower bounds on the optimal error in estimating the quality score vector $w^*$ under this class of models . The bounds depend on the topology of the comparison graph induced by the subset of pairs being compared via its Laplacian spectrum . Thus , in settings where the subset of pairs may be chosen , our results provide principled guidelines for making this choice . Finally , we compare these error rates to those under cardinal measurement models and show that the error rates in the ordinal and cardinal settings have identical scalings apart from constant pre-factors .
Recent developments in linear system identification have proposed the use of non-parameteric methods , relying on regularization strategies , to handle the so-called bias/variance trade-off . This paper introduces an impulse response estimator which relies on an $\ell_0$-type regularization including a rank-penalty derived using the log-det heuristic as a smooth approximation to the rank function . This allows to account for different properties of the estimated impulse response ( e . g . smoothness and stability ) while also penalizing high-complexity models . This also allows to account and enforce coupling between different input-output channels in MIMO systems . According to the Bayesian paradigm , the parameters defining the relative weight of the two regularization terms as well as the structure of the rank penalty are estimated optimizing the marginal likelihood . Once these hyperameters have been estimated , the impulse response estimate is available in closed form . Experiments show that the proposed method is superior to the estimator relying on the " classic " $\ell_0$-regularization alone as well as those based in atomic and nuclear norm .
The Support Vector Machine ( SVM ) of Vapnik ( 0000 ) has become widely established as one of the leading approaches to pattern recognition and machine learning . It expresses predictions in terms of a linear combination of kernel functions centred on a subset of the training data , known as support vectors . Despite its widespread success , the SVM suffers from some important limitations , one of the most significant being that it makes point predictions rather than generating predictive distributions . Recently Tipping ( 0000 ) has formulated the Relevance Vector Machine ( RVM ) , a probabilistic model whose functional form is equivalent to the SVM . It achieves comparable recognition accuracy to the SVM , yet provides a full predictive distribution , and also requires substantially fewer kernel functions . The original treatment of the RVM relied on the use of type II maximum likelihood ( the `evidence framework ' ) to provide point estimates of the hyperparameters which govern model sparsity . In this paper we show how the RVM can be formulated and solved within a completely Bayesian paradigm through the use of variational inference , thereby giving a posterior distribution over both parameters and hyperparameters . We demonstrate the practicality and performance of the variational RVM using both synthetic and real world examples .
We present a novel tractable generative model that extends Sum-Product Networks ( SPNs ) and significantly boost their power . We call it Sum-Product-Quotient Networks ( SPQNs ) , whose core concept is to incorporate conditional distributions into the model by direct computation using quotient nodes , e . g . $P ( A|B ) {=}\frac{P ( A , B ) }{P ( B ) }$ . We provide sufficient conditions for the tractability of SPQNs that generalize and relax the decomposable and complete tractability conditions of SPNs . These relaxed conditions give rise to an exponential boost to the expressive efficiency of our model , i . e . we prove that there are distributions which SPQNs can compute efficiently but require SPNs to be of exponential size . Thus , we narrow the gap in expressivity between tractable graphical models and other Neural Network-based generative models .
This paper describes an intuitive generalization to the Generative Adversarial Networks ( GANs ) to generate samples while capturing diverse modes of the true data distribution . Firstly , we propose a very simple and intuitive multi-agent GAN architecture that incorporates multiple generators capable of generating samples from high probability modes . Secondly , in order to enforce different generators to generate samples from diverse modes , we propose two extensions to the standard GAN objective function . ( 0 ) We augment the generator specific GAN objective function with a diversity enforcing term that encourage different generators to generate diverse samples using a user-defined similarity based function . ( 0 ) We modify the discriminator objective function where along with finding the real and fake samples , the discriminator has to predict the generator which generated the given fake sample . Intuitively , in order to succeed in this task , the discriminator must learn to push different generators towards different identifiable modes . Our framework is generalizable in the sense that it can be easily combined with other existing variants of GANs to produce diverse samples . Experimentally we show that our framework is able to produce high quality diverse samples for the challenging tasks such as image/face generation and image-to-image translation . We also show that it is capable of learning a better feature representation in an unsupervised setting .
We consider the recovery of regression coefficients , denoted by $\boldsymbol{\beta}_0$ , for a single index model ( SIM ) relating a binary outcome $Y$ to a set of possibly high dimensional covariates $\boldsymbol{X}$ , based on a large but ' unlabeled ' dataset $\mathcal{U}$ , with $Y$ never observed . On $\mathcal{U}$ , we fully observe $\boldsymbol{X}$ and additionally , a surrogate $S$ which , while not being strongly predictive of $Y$ throughout the entirety of its support , can forecast it with high accuracy when it assumes extreme values . Such datasets arise naturally in modern studies involving large databases such as electronic medical records ( EMR ) where $Y$ , unlike $ ( \boldsymbol{X} , S ) $ , is difficult and/or expensive to obtain . In EMR studies , an example of $Y$ and $S$ would be the true disease phenotype and the count of the associated diagnostic codes respectively . Assuming another SIM for $S$ given $\boldsymbol{X}$ , we show that under sparsity assumptions , we can recover $\boldsymbol{\beta}_0$ proportionally by simply fitting a least squares LASSO estimator to the subset of the observed data on $ ( \boldsymbol{X} , S ) $ restricted to the extreme sets of $S$ , with $Y$ imputed using the surrogacy of $S$ . We obtain sharp finite sample performance bounds for our estimator , including deterministic deviation bounds and probabilistic guarantees . We demonstrate the effectiveness of our approach through multiple simulation studies , as well as by application to real data from an EMR study conducted at the Partners HealthCare Systems .
This paper investigates differentially private analysis of distance-based outliers . The problem of outlier detection is to find a small number of instances that are apparently distant from the remaining instances . On the other hand , the objective of differential privacy is to conceal presence ( or absence ) of any particular instance . Outlier detection and privacy protection are thus intrinsically conflicting tasks . In this paper , instead of reporting outliers detected , we present two types of differentially private queries that help to understand behavior of outliers . One is the query to count outliers , which reports the number of outliers that appear in a given subspace . Our formal analysis on the exact global sensitivity of outlier counts reveals that regular global sensitivity based method can make the outputs too noisy , particularly when the dimensionality of the given subspace is high . Noting that the counts of outliers are typically expected to be relatively small compared to the number of data , we introduce a mechanism based on the smooth upper bound of the local sensitivity . The other is the query to discovery top-$h$ subspaces containing a large number of outliers . This task can be naively achieved by issuing count queries to each subspace in turn . However , the variation of subspaces can grow exponentially in the data dimensionality . This can cause serious consumption of the privacy budget . For this task , we propose an exponential mechanism with a customized score function for subspace discovery . To the best of our knowledge , this study is the first trial to ensure differential privacy for distance-based outlier analysis . We demonstrated our methods with synthesized datasets and real datasets . The experimental results show that out method achieve better utility compared to the global sensitivity based methods .
Dealing with datasets of very high dimension is a major challenge in machine learning . In this paper , we consider the problem of feature selection in applications where the memory is not large enough to contain all features . In this setting , we propose a novel tree-based feature selection approach that builds a sequence of randomized trees on small subsamples of variables mixing both variables already identified as relevant by previous models and variables randomly selected among the other variables . As our main contribution , we provide an in-depth theoretical analysis of this method in infinite sample setting . In particular , we study its soundness with respect to common definitions of feature relevance and its convergence speed under various variable dependance scenarios . We also provide some preliminary empirical results highlighting the potential of the approach .
Ridge regularized linear models ( RRLMs ) , such as ridge regression and the SVM , are a popular group of methods that are used in conjunction with coefficient hypothesis testing to discover explanatory variables with a significant multivariate association to a response . However , many investigators are reluctant to draw causal interpretations of the selected variables due to the incomplete knowledge of the capabilities of RRLMs in causal inference . Under reasonable assumptions , we show that a modified form of RRLMs can get very close to identifying a subset of the Markov boundary by providing a worst-case bound on the space of possible solutions . The results hold for any convex loss , even when the underlying functional relationship is nonlinear , and the solution is not unique . Our approach combines ideas in Markov boundary and sufficient dimension reduction theory . Experimental results show that the modified RRLMs are competitive against state-of-the-art algorithms in discovering part of the Markov boundary from gene expression data .
The class of chain event graph models is a generalisation of the class of discrete Bayesian networks , retaining most of the structural advantages of the Bayesian network for model interrogation , propagation and learning , while more naturally encoding asymmetric state spaces and the order in which events happen . In this paper we demonstrate how with complete sampling , conjugate closed form model selection based on product Dirichlet priors is possible , and prove that suitable homogeneity assumptions characterise the product Dirichlet prior on this class of models . We demonstrate our techniques using two educational examples .
Stochastic gradient algorithms estimate the gradient based on only one or a few samples and enjoy low computational cost per iteration . They have been widely used in large-scale optimization problems . However , stochastic gradient algorithms are usually slow to converge and achieve sub-linear convergence rates , due to the inherent variance in the gradient computation . To accelerate the convergence , some variance-reduced stochastic gradient algorithms , e . g . , proximal stochastic variance-reduced gradient ( Prox-SVRG ) algorithm , have recently been proposed to solve strongly convex problems . Under the strongly convex condition , these variance-reduced stochastic gradient algorithms achieve a linear convergence rate . However , many machine learning problems are convex but not strongly convex . In this paper , we introduce Prox-SVRG and its projected variant called Variance-Reduced Projected Stochastic Gradient ( VRPSG ) to solve a class of non-strongly convex optimization problems widely used in machine learning . As the main technical contribution of this paper , we show that both VRPSG and Prox-SVRG achieve a linear convergence rate without strong convexity . A key ingredient in our proof is a Semi-Strongly Convex ( SSC ) inequality which is the first to be rigorously proved for a class of non-strongly convex problems in both constrained and regularized settings . Moreover , the SSC inequality is independent of algorithms and may be applied to analyze other stochastic gradient algorithms besides VRPSG and Prox-SVRG , which may be of independent interest . To the best of our knowledge , this is the first work that establishes the linear convergence rate for the variance-reduced stochastic gradient algorithms on solving both constrained and regularized problems without strong convexity .
Recent progress in applying machine learning for jet physics has been built upon an analogy between calorimeters and images . In this work , we present a novel class of recursive neural networks built instead upon an analogy between QCD and natural languages . In the analogy , four-momenta are like words and the clustering history of sequential recombination jet algorithms is like the parsing of a sentence . Our approach works directly with the four-momenta of a variable-length set of particles , and the jet-based tree structure varies on an event-by-event basis . Our experiments highlight the flexibility of our method for building task-specific jet embeddings and show that recursive architectures are significantly more accurate and data efficient than previous image-based networks . We extend the analogy from individual jets ( sentences ) to full events ( paragraphs ) , and show for the first time an event-level classifier operating on all the stable particles produced in an LHC event .
Recently we proposed a general , ensemble-based feature engineering wrapper ( FEW ) that was paired with a number of machine learning methods to solve regression problems . Here , we adapt FEW for supervised classification and perform a thorough analysis of fitness and survival methods within this framework . Our tests demonstrate that two fitness metrics , one introduced as an adaptation of the silhouette score , outperform the more commonly used Fisher criterion . We analyze survival methods and demonstrate that $\epsilon$-lexicase survival works best across our test problems , followed by random survival which outperforms both tournament and deterministic crowding . We conduct a benchmark comparison to several classification methods using a large set of problems and show that FEW can improve the best classifier performance in several cases . We show that FEW generates consistent , meaningful features for a biomedical problem with different ML pairings .
Given a time series of graphs G ( t ) = ( V , E ( t ) ) , t = 0 , 0 , . . . , where the fixed vertex set V represents " actors " and an edge between vertex u and vertex v at time t ( uv \in E ( t ) ) represents the existence of a communications event between actors u and v during the tth time period , we wish to detect anomalies and/or change points . We consider a collection of graph features , or invariants , and demonstrate that adaptive fusion provides superior inferential efficacy compared to naive equal weighting for a certain class of anomaly detection problems . Simulation results using a latent process model for time series of graphs , as well as illustrative experimental results for a time series of graphs derived from the Enron email data , show that a fusion statistic can provide superior inference compared to individual invariants alone . These results also demonstrate that an adaptive weighting scheme for fusion of invariants performs better than naive equal weighting .
The maximum correntropy criterion ( MCC ) has recently been successfully applied in robust regression , classification and adaptive filtering , where the correntropy is maximized instead of minimizing the well-known mean square error ( MSE ) to improve the robustness with respect to outliers ( or impulsive noises ) . Considerable efforts have been devoted to develop various robust adaptive algorithms under MCC , but so far little insight has been gained as to how the optimal solution will be affected by outliers . In this work , we study this problem in the context of parameter estimation for a simple linear errors-in-variables ( EIV ) model where all variables are scalar . Under certain conditions , we derive an upper bound on the absolute value of the estimation error and show that the optimal solution under MCC can be very close to the true value of the unknown parameter even with outliers ( whose values can be arbitrarily large ) in both input and output variables . Illustrative examples are presented to verify and clarify the theory .
We examine methods for clustering in high dimensions . In the first part of the paper , we perform an experimental comparison between three batch clustering algorithms : the Expectation-Maximization ( EM ) algorithm , a winner take all version of the EM algorithm reminiscent of the K-means algorithm , and model-based hierarchical agglomerative clustering . We learn naive-Bayes models with a hidden root node , using high-dimensional discrete-variable data sets ( both real and synthetic ) . We find that the EM algorithm significantly outperforms the other methods , and proceed to investigate the effect of various initialization schemes on the final solution produced by the EM algorithm . The initializations that we consider are ( 0 ) parameters sampled from an uninformative prior , ( 0 ) random perturbations of the marginal distribution of the data , and ( 0 ) the output of hierarchical agglomerative clustering . Although the methods are substantially different , they lead to learned models that are strikingly similar in quality .
This paper presents a novel data-driven technique based on the spatiotemporal pattern network ( STPN ) for energy/power prediction for complex dynamical systems . Built on symbolic dynamic filtering , the STPN framework is used to capture not only the individual system characteristics but also the pair-wise causal dependencies among different sub-systems . For quantifying the causal dependency , a mutual information based metric is presented . An energy prediction approach is subsequently proposed based on the STPN framework . For validating the proposed scheme , two case studies are presented , one involving wind turbine power prediction ( supply side energy ) using the Western Wind Integration data set generated by the National Renewable Energy Laboratory ( NREL ) for identifying the spatiotemporal characteristics , and the other , residential electric energy disaggregation ( demand side energy ) using the Building America 0000 data set from NREL for exploring the temporal features . In the energy disaggregation context , convex programming techniques beyond the STPN framework are developed and applied to achieve improved disaggregation performance .
We present our solution to the job recommendation task for RecSys Challenge 0000 . The main contribution of our work is to combine temporal learning with sequence modeling to capture complex user-item activity patterns to improve job recommendations . First , we propose a time-based ranking model applied to historical observations and a hybrid matrix factorization over time re-weighted interactions . Second , we exploit sequence properties in user-items activities and develop a RNN-based recommendation model . Our solution achieved 0$^{th}$ place in the challenge among more than 000 participants . Notably , the strong performance of our RNN approach shows a promising new direction in employing sequence modeling for recommendation systems .
We explore two techniques which use color to make sense of statistical text models . One method uses in-text annotations to illustrate a model ' s view of particular tokens in particular documents . Another uses a high-level , " words-as-pixels " graphic to display an entire corpus . Together , these methods offer both zoomed-in and zoomed-out perspectives into a model ' s understanding of text . We show how these interconnected methods help diagnose a classifier ' s poor performance on Twitter slang , and make sense of a topic model on historical political texts .
Conventional Monte Carlo simulations are stochastic in the sense that the acceptance of a trial move is decided by comparing a computed acceptance probability with a random number , uniformly distributed between 0 and 0 . Here we consider the case that the weight determining the acceptance probability itself is fluctuating . This situation is common in many numerical studies . We show that it is possible to construct a rigorous Monte Carlo algorithm that visits points in state space with a probability proportional to their average weight . The same approach has the potential to transform the methodology of a certain class of high-throughput experiments or the analysis of noisy datasets .
Discriminative linear models are a popular tool in machine learning . These can be generally divided into two types : The first is linear classifiers , such as support vector machines , which are well studied and provide state-of-the-art results . One shortcoming of these models is that their output ( known as the ' margin ' ) is not calibrated , and cannot be translated naturally into a distribution over the labels . Thus , it is difficult to incorporate such models as components of larger systems , unlike probabilistic based approaches . The second type of approach constructs class conditional distributions using a nonlinearity ( e . g . log-linear models ) , but is occasionally worse in terms of classification error . We propose a supervised learning method which combines the best of both approaches . Specifically , our method provides a distribution over the labels , which is a linear function of the model parameters . As a consequence , differences between probabilities are linear functions , a property which most probabilistic models ( e . g . log-linear ) do not have . Our model assumes that classes correspond to linear subspaces ( rather than to half spaces ) . Using a relaxed projection operator , we construct a measure which evaluates the degree to which a given vector ' belongs ' to a subspace , resulting in a distribution over labels . Interestingly , this view is closely related to similar concepts in quantum detection theory . The resulting models can be trained either to maximize the margin or to optimize average likelihood measures . The corresponding optimization problems are semidefinite programs which can be solved efficiently . We illustrate the performance of our algorithm on real world datasets , and show that it outperforms 0nd order kernel methods .
We propose a Bayesian regression method that accounts for multi-way interactions of arbitrary orders among the predictor variables . Our model makes use of a factorization mechanism for representing the regression coefficients of interactions among the predictors , while the interaction selection is guided by a prior distribution on random hypergraphs , a construction which generalizes the Finite Feature Model . We present a posterior inference algorithm based on Gibbs sampling , and establish posterior consistency of our regression model . Our method is evaluated with extensive experiments on simulated data and demonstrated to be able to identify meaningful interactions in applications in genetics and retail demand forecasting .
Decision tree learning is a popular approach for classification and regression in machine learning and statistics , and Bayesian formulations---which introduce a prior distribution over decision trees , and formulate learning as posterior inference given data---have been shown to produce competitive performance . Unlike classic decision tree learning algorithms like ID0 , C0 . 0 and CART , which work in a top-down manner , existing Bayesian algorithms produce an approximation to the posterior distribution by evolving a complete tree ( or collection thereof ) iteratively via local Monte Carlo modifications to the structure of the tree , e . g . , using Markov chain Monte Carlo ( MCMC ) . We present a sequential Monte Carlo ( SMC ) algorithm that instead works in a top-down manner , mimicking the behavior and speed of classic algorithms . We demonstrate empirically that our approach delivers accuracy comparable to the most popular MCMC method , but operates more than an order of magnitude faster , and thus represents a better computation-accuracy tradeoff .
Information spreads across social and technological networks , but often the network structures are hidden from us and we only observe the traces left by the diffusion processes , called cascades . Can we recover the hidden network structures from these observed cascades ? What kind of cascades and how many cascades do we need ? Are there some network structures which are more difficult than others to recover ? Can we design efficient inference algorithms with provable guarantees ? Despite the increasing availability of cascade data and methods for inferring networks from these data , a thorough theoretical understanding of the above questions remains largely unexplored in the literature . In this paper , we investigate the network structure inference problem for a general family of continuous-time diffusion models using an $l_0$-regularized likelihood maximization framework . We show that , as long as the cascade sampling process satisfies a natural incoherence condition , our framework can recover the correct network structure with high probability if we observe $O ( d^0 \log N ) $ cascades , where $d$ is the maximum number of parents of a node and $N$ is the total number of nodes . Moreover , we develop a simple and efficient soft-thresholding inference algorithm , which we use to illustrate the consequences of our theoretical results , and show that our framework outperforms other alternatives in practice .
We study phase retrieval from magnitude measurements of an unknown signal as an algebraic estimation problem . Indeed , phase retrieval from rank-one and more general linear measurements can be treated in an algebraic way . It is verified that a certain number of generic rank-one or generic linear measurements are sufficient to enable signal reconstruction for generic signals , and slightly more generic measurements yield reconstructability for all signals . Our results solve a few open problems stated in the recent literature . Furthermore , we show how the algebraic estimation problem can be solved by a closed-form algebraic estimation technique , termed ideal regression , providing non-asymptotic success guarantees .
We propose a method for inferring the conditional indepen- dence graph ( CIG ) of a high-dimensional discrete-time Gaus- sian vector random process from finite-length observations . Our approach does not rely on a parametric model ( such as , e . g . , an autoregressive model ) for the vector random process ; rather , it only assumes certain spectral smoothness proper- ties . The proposed inference scheme is compressive in that it works for sample sizes that are ( much ) smaller than the number of scalar process components . We provide analytical conditions for our method to correctly identify the CIG with high probability .
In reinforcement learning an agent interacts with the environment by taking actions and observing the next state and reward . When sampled probabilistically , these state transitions , rewards , and actions can all induce randomness in the observed long-term return . Traditionally , reinforcement learning algorithms average over this randomness to estimate the value function . In this paper , we build on recent work advocating a distributional approach to reinforcement learning in which the distribution over returns is modeled explicitly instead of only estimating the mean . That is , we examine methods of learning the value distribution instead of the value function . We give results that close a number of gaps between the theoretical and algorithmic results given by Bellemare , Dabney , and Munos ( 0000 ) . First , we extend existing results to the approximate distribution setting . Second , we present a novel distributional reinforcement learning algorithm consistent with our theoretical formulation . Finally , we evaluate this new algorithm on the Atari 0000 games , observing that it significantly outperforms many of the recent improvements on DQN , including the related distributional algorithm C00 .
There has been growing interest in how economists can import machine learning tools designed for prediction to accelerate and automate the model selection process , while still retaining desirable inference properties for causal parameters . Focusing on partially linear models , we extend the Double ML framework to allow for ( 0 ) a number of treatments that may grow with the sample size and ( 0 ) the analysis of panel data under sequentially exogenous errors . Our low-dimensional treatment ( LD ) regime directly extends the work in [Chernozhukov et al . , 0000] , by showing that the coefficients from a second stage , ordinary least squares estimator attain root-n convergence and desired coverage even if the dimensionality of treatment is allowed to grow . In a high-dimensional sparse ( HDS ) regime , we show that second stage LASSO and debiased LASSO have asymptotic properties equivalent to oracle estimators with no upstream error . We argue that these advances make Double ML methods a desirable alternative for practitioners estimating short-term demand elasticities in non-contractual settings .
The completion of low rank matrices from few entries is a task with many practical applications . We consider here two aspects of this problem : detectability , i . e . the ability to estimate the rank $r$ reliably from the fewest possible random entries , and performance in achieving small reconstruction error . We propose a spectral algorithm for these two tasks called MaCBetH ( for Matrix Completion with the Bethe Hessian ) . The rank is estimated as the number of negative eigenvalues of the Bethe Hessian matrix , and the corresponding eigenvectors are used as initial condition for the minimization of the discrepancy between the estimated matrix and the revealed entries . We analyze the performance in a random matrix setting using results from the statistical mechanics of the Hopfield neural network , and show in particular that MaCBetH efficiently detects the rank $r$ of a large $n\times m$ matrix from $C ( r ) r\sqrt{nm}$ entries , where $C ( r ) $ is a constant close to $0$ . We also evaluate the corresponding root-mean-square error empirically and show that MaCBetH compares favorably to other existing approaches .
There have lately been several suggestions for parametrized distances on a graph that generalize the shortest path distance and the commute time or resistance distance . The need for developing such distances has risen from the observation that the above-mentioned common distances in many situations fail to take into account the global structure of the graph . In this article , we develop the theory of one family of graph node distances , known as the randomized shortest path dissimilarity , which has its foundation in statistical physics . We show that the randomized shortest path dissimilarity can be easily computed in closed form for all pairs of nodes of a graph . Moreover , we come up with a new definition of a distance measure that we call the free energy distance . The free energy distance can be seen as an upgrade of the randomized shortest path dissimilarity as it defines a metric , in addition to which it satisfies the graph-geodetic property . The derivation and computation of the free energy distance are also straightforward . We then make a comparison between a set of generalized distances that interpolate between the shortest path distance and the commute time , or resistance distance . This comparison focuses on the applicability of the distances in graph node clustering and classification . The comparison , in general , shows that the parametrized distances perform well in the tasks . In particular , we see that the results obtained with the free energy distance are among the best in all the experiments .
The Expectation-Maximization ( EM ) algorithm is a widely used method for maximum likelihood estimation in models with latent variables . For estimating mixtures of Gaussians , its iteration can be viewed as a soft version of the k-means clustering algorithm . Despite its wide use and applications , there are essentially no known convergence guarantees for this method . We provide global convergence guarantees for mixtures of two Gaussians with known covariance matrices . We show that the population version of EM , where the algorithm is given access to infinitely many samples from the mixture , converges geometrically to the correct mean vectors , and provide simple , closed-form expressions for the convergence rate . As a simple illustration , we show that , in one dimension , ten steps of the EM algorithm initialized at infinity result in less than 0\% error estimation of the means . In the finite sample regime , we show that , under a random initialization , $\tilde{O} ( d/\epsilon^0 ) $ samples suffice to compute the unknown vectors to within $\epsilon$ in Mahalanobis distance , where $d$ is the dimension . In particular , the error rate of the EM based estimator is $\tilde{O}\left ( \sqrt{d \over n}\right ) $ where $n$ is the number of samples , which is optimal up to logarithmic factors .
We propose a spectral clustering method based on local principal components analysis ( PCA ) . After performing local PCA in selected neighborhoods , the algorithm builds a nearest neighbor graph weighted according to a discrepancy between the principal subspaces in the neighborhoods , and then applies spectral clustering . As opposed to standard spectral methods based solely on pairwise distances between points , our algorithm is able to resolve intersections . We establish theoretical guarantees for simpler variants within a prototypical mathematical framework for multi-manifold clustering , and evaluate our algorithm on various simulated data sets .
Sparse data models , where data is assumed to be well represented as a linear combination of a few elements from a dictionary , have gained considerable attention in recent years , and their use has led to state-of-the-art results in many signal and image processing tasks . It is now well understood that the choice of the sparsity regularization term is critical in the success of such models . Based on a codelength minimization interpretation of sparse coding , and using tools from universal coding theory , we propose a framework for designing sparsity regularization terms which have theoretical and practical advantages when compared to the more standard l0 or l0 ones . The presentation of the framework and theoretical foundations is complemented with examples that show its practical advantages in image denoising , zooming and classification .
Peer effects , in which the behavior of an individual is affected by the behavior of their peers , are posited by multiple theories in the social sciences . Other processes can also produce behaviors that are correlated in networks and groups , thereby generating debate about the credibility of observational ( i . e . nonexperimental ) studies of peer effects . Randomized field experiments that identify peer effects , however , are often expensive or infeasible . Thus , many studies of peer effects use observational data , and prior evaluations of causal inference methods for adjusting observational data to estimate peer effects have lacked an experimental " gold standard " for comparison . Here we show , in the context of information and media diffusion on Facebook , that high-dimensional adjustment of a nonexperimental control group ( 000 million observations ) using propensity score models produces estimates of peer effects statistically indistinguishable from those from using a large randomized experiment ( 000 million observations ) . Naive observational estimators overstate peer effects by 000% and commonly used variables ( e . g . , demographics ) offer little bias reduction , but adjusting for a measure of prior behaviors closely related to the focal behavior reduces bias by 00% . High-dimensional models adjusting for over 0 , 000 past behaviors provide additional bias reduction , such that the full model reduces bias by over 00% . This experimental evaluation demonstrates that detailed records of individuals ' past behavior can improve studies of social influence , information diffusion , and imitation ; these results are encouraging for the credibility of some studies but also cautionary for studies of rare or new behaviors . More generally , these results show how large , high-dimensional data sets and statistical learning techniques can be used to improve causal inference in the behavioral sciences .
Contextual bandits are a form of multi-armed bandit in which the agent has access to predictive side information ( known as the context ) for each arm at each time step , and have been used to model personalized news recommendation , ad placement , and other applications . In this work , we propose a multi-task learning framework for contextual bandit problems . Like multi-task learning in the batch setting , the goal is to leverage similarities in contexts for different arms so as to improve the agent ' s ability to predict rewards from contexts . We propose an upper confidence bound-based multi-task learning algorithm for contextual bandits , establish a corresponding regret bound , and interpret this bound to quantify the advantages of learning in the presence of high task ( arm ) similarity . We also describe an effective scheme for estimating task similarity from data , and demonstrate our algorithm ' s performance on several data sets .
In this work we introduce a new optimisation method called SAGA in the spirit of SAG , SDCA , MISO and SVRG , a set of recently proposed incremental gradient algorithms with fast linear convergence rates . SAGA improves on the theory behind SAG and SVRG , with better theoretical convergence rates , and has support for composite objectives where a proximal operator is used on the regulariser . Unlike SDCA , SAGA supports non-strongly convex problems directly , and is adaptive to any inherent strong convexity of the problem . We give experimental results showing the effectiveness of our method .
Principal component analysis ( PCA ) is largely adopted for chemical process monitoring and numerous PCA-based systems have been developed to solve various fault detection and diagnosis problems . Since PCA-based methods assume that the monitored process is linear , nonlinear PCA models , such as autoencoder models and kernel principal component analysis ( KPCA ) , has been proposed and applied to nonlinear process monitoring . However , KPCA-based methods need to perform eigen-decomposition ( ED ) on the kernel Gram matrix whose dimensions depend on the number of training data . Moreover , prefixed kernel parameters cannot be most effective for different faults which may need different parameters to maximize their respective detection performances . Autoencoder models lack the consideration of orthogonal constraints which is crucial for PCA-based algorithms . To address these problems , this paper proposes a novel nonlinear method , called neural component analysis ( NCA ) , which intends to train a feedforward neural work with orthogonal constraints such as those used in PCA . NCA can adaptively learn its parameters through backpropagation and the dimensionality of the nonlinear features has no relationship with the number of training samples . Extensive experimental results on the Tennessee Eastman ( TE ) benchmark process show the superiority of NCA in terms of missed detection rate ( MDR ) and false alarm rate ( FAR ) . The source code of NCA can be found in https : //github . com/haitaozhao/Neural-Component-Analysis . git .
Person Re-Identification ( person re-id ) is a crucial task as its applications in visual surveillance and human-computer interaction . In this work , we present a novel joint Spatial and Temporal Attention Pooling Network ( ASTPN ) for video-based person re-identification , which enables the feature extractor to be aware of the current input video sequences , in a way that interdependency from the matching items can directly influence the computation of each other ' s representation . Specifically , the spatial pooling layer is able to select regions from each frame , while the attention temporal pooling performed can select informative frames over the sequence , both pooling guided by the information from distance matching . Experiments are conduced on the iLIDS-VID , PRID-0000 and MARS datasets and the results demonstrate that this approach outperforms existing state-of-art methods . We also analyze how the joint pooling in both dimensions can boost the person re-id performance more effectively than using either of them separately .
In this paper we develop a dynamic form of Bayesian optimization for machine learning models with the goal of rapidly finding good hyperparameter settings . Our method uses the partial information gained during the training of a machine learning model in order to decide whether to pause training and start a new model , or resume the training of a previously-considered model . We specifically tailor our method to machine learning problems by developing a novel positive-definite covariance kernel to capture a variety of training curves . Furthermore , we develop a Gaussian process prior that scales gracefully with additional temporal observations . Finally , we provide an information-theoretic framework to automate the decision process . Experiments on several common machine learning models show that our approach is extremely effective in practice .
High-dimensional data often lie in low-dimensional subspaces corresponding to different classes they belong to . Finding sparse representations of data points in a dictionary built using the collection of data helps to uncover low-dimensional subspaces and address problems such as clustering , classification , subset selection and more . In this paper , we address the problem of recovering sparse representations for noisy data points in a dictionary whose columns correspond to corrupted data lying close to a union of subspaces . We consider a constrained $\ell_0$-minimization and study conditions under which the solution of the proposed optimization satisfies the approximate subspace-sparse recovery condition . More specifically , we show that each noisy data point , perturbed from a subspace by a noise of the magnitude of $\varepsilon$ , will be reconstructed using data points from the same subspace with a small error of the order of $O ( \varepsilon ) $ and that the coefficients corresponding to data points in other subspaces will be sufficiently small , \ie , of the order of $O ( \varepsilon ) $ . We do not impose any randomness assumption on the arrangement of subspaces or distribution of data points in each subspace . Our framework is based on a novel generalization of the null-space property to the setting where data lie in multiple subspaces , the number of data points in each subspace exceeds the dimension of the subspace , and all data points are corrupted by noise . Moreover , assuming a random distribution for data points , we further show that coefficients from the desired support not only reconstruct a given point with high accuracy , but also have sufficiently large values , \ie , of the order of $O ( 0 ) $ .
Nowozin \textit{et al} showed last year how to extend the GAN \textit{principle} to all $f$-divergences . The approach is elegant but falls short of a full description of the supervised game , and says little about the key player , the generator : for example , what does the generator actually converge to if solving the GAN game means convergence in some space of parameters ? How does that provide hints on the generator ' s design and compare to the flourishing but almost exclusively experimental literature on the subject ? In this paper , we unveil a broad class of distributions for which such convergence happens --- namely , deformed exponential families , a wide superset of exponential families --- and show tight connections with the three other key GAN parameters : loss , game and architecture . In particular , we show that current deep architectures are able to factorize a very large number of such densities using an especially compact design , hence displaying the power of deep architectures and their concinnity in the $f$-GAN game . This result holds given a sufficient condition on \textit{activation functions} --- which turns out to be satisfied by popular choices . The key to our results is a variational generalization of an old theorem that relates the KL divergence between regular exponential families and divergences between their natural parameters . We complete this picture with additional results and experimental insights on how these results may be used to ground further improvements of GAN architectures , via ( i ) a principled design of the activation functions in the generator and ( ii ) an explicit integration of proper composite losses ' link function in the discriminator .
Relative to the large literature on upper bounds on complexity of convex optimization , lesser attention has been paid to the fundamental hardness of these problems . Given the extensive use of convex optimization in machine learning and statistics , gaining an understanding of these complexity-theoretic issues is important . In this paper , we study the complexity of stochastic convex optimization in an oracle model of computation . We improve upon known results and obtain tight minimax complexity estimates for various function classes .
This technical report proves components consistency for the Doubly Stochastic Dirichlet Process with exponential convergence of posterior probability . We also present the fundamental properties for DSDP as well as inference algorithms . Simulation toy experiment and real-world experiment results for single and multi-cluster also support the consistency proof . This report is also a support document for the paper " Computationally Efficient Hyperspectral Data Learning Based on the Doubly Stochastic Dirichlet Process " .
We present a probabilistic model of events in continuous time in which each event triggers a Poisson process of successor events . The ensemble of observed events is thereby modeled as a superposition of Poisson processes . Efficient inference is feasible under this model with an EM algorithm . Moreover , the EM algorithm can be implemented as a distributed algorithm , permitting the model to be applied to very large datasets . We apply these techniques to the modeling of Twitter messages and the revision history of Wikipedia .
This paper establishes non-asymptotic oracle inequalities for the prediction error and estimation accuracy of the LASSO in stationary vector autoregressive models . These inequalities are used to establish consistency of the LASSO even when the number of parameters is of a much larger order of magnitude than the sample size . We also give conditions under which no relevant variables are excluded . Next , non-asymptotic probabilities are given for the Adaptive LASSO to select the correct sparsity pattern . We then give conditions under which the Adaptive LASSO reveals the correct sparsity pattern asymptotically . We establish that the estimates of the non-zero coefficients are asymptotically equivalent to the oracle assisted least squares estimator . This is used to show that the rate of convergence of the estimates of the non-zero coefficients is identical to the one of least squares only including the relevant covariates .
In practice , there are often explicit constraints on what representations or decisions are acceptable in an application of machine learning . For example it may be a legal requirement that a decision must not favour a particular group . Alternatively it can be that that representation of data must not have identifying information . We address these two related issues by learning flexible representations that minimize the capability of an adversarial critic . This adversary is trying to predict the relevant sensitive variable from the representation , and so minimizing the performance of the adversary ensures there is little or no information in the representation about the sensitive variable . We demonstrate this adversarial approach on two problems : making decisions free from discrimination and removing private information from images . We formulate the adversarial model as a minimax problem , and optimize that minimax objective using a stochastic gradient alternate min-max optimizer . We demonstrate the ability to provide discriminant free representations for standard test problems , and compare with previous state of the art methods for fairness , showing statistically significant improvement across most cases . The flexibility of this method is shown via a novel problem : removing annotations from images , from unaligned training examples of annotated and unannotated images , and with no a priori knowledge of the form of annotation provided to the model .
Understanding why machine learning models behave the way they do empowers both system designers and end-users in many ways : in model selection , feature engineering , in order to trust and act upon the predictions , and in more intuitive user interfaces . Thus , interpretability has become a vital concern in machine learning , and work in the area of interpretable models has found renewed interest . In some applications , such models are as accurate as non-interpretable ones , and thus are preferred for their transparency . Even when they are not accurate , they may still be preferred when interpretability is of paramount importance . However , restricting machine learning to interpretable models is often a severe limitation . In this paper we argue for explaining machine learning predictions using model-agnostic approaches . By treating the machine learning models as black-box functions , these approaches provide crucial flexibility in the choice of models , explanations , and representations , improving debugging , comparison , and interfaces for a variety of users and models . We also outline the main challenges for such methods , and review a recently-introduced model-agnostic explanation approach ( LIME ) that addresses these challenges .
We present an information-theoretic framework for sequential adaptive compressed sensing , Info-Greedy Sensing , where measurements are chosen to maximize the extracted information conditioned on the previous measurements . We show that the widely used bisection approach is Info-Greedy for a family of $k$-sparse signals by connecting compressed sensing and blackbox complexity of sequential query algorithms , and present Info-Greedy algorithms for Gaussian and Gaussian Mixture Model ( GMM ) signals , as well as ways to design sparse Info-Greedy measurements . Numerical examples demonstrate the good performance of the proposed algorithms using simulated and real data : Info-Greedy Sensing shows significant improvement over random projection for signals with sparse and low-rank covariance matrices , and adaptivity brings robustness when there is a mismatch between the assumed and the true distributions .
We describe the first sub-quadratic sampling algorithm for the Multiplicative Attribute Graph Model ( MAGM ) of Kim and Leskovec ( 0000 ) . We exploit the close connection between MAGM and the Kronecker Product Graph Model ( KPGM ) of Leskovec et al . ( 0000 ) , and show that to sample a graph from a MAGM it suffices to sample small number of KPGM graphs and \emph{quilt} them together . Under a restricted set of technical conditions our algorithm runs in $O ( ( \log_0 ( n ) ) ^0 |E| ) $ time , where $n$ is the number of nodes and $|E|$ is the number of edges in the sampled graph . We demonstrate the scalability of our algorithm via extensive empirical evaluation ; we can sample a MAGM graph with 0 million nodes and 00 billion edges in under 0 hours .
The structure of a Bayesian network includes a great deal of information about the probability distribution of the data , which is uniquely identified given some general distributional assumptions . Therefore it ' s important to study its variability , which can be used to compare the performance of different learning algorithms and to measure the strength of any arbitrary subset of arcs . In this paper we will introduce some descriptive statistics and the corresponding parametric and Monte Carlo tests on the undirected graph underlying the structure of a Bayesian network , modeled as a multivariate Bernoulli random variable . A simple numeric example and the comparison of the performance of some structure learning algorithm on small samples will then illustrate their use .
A family of parsimonious shifted asymmetric Laplace mixture models is introduced . We extend the mixture of factor analyzers model to the shifted asymmetric Laplace distribution . Imposing constraints on the constitute parts of the resulting decomposed component scale matrices leads to a family of parsimonious models . An explicit two-stage parameter estimation procedure is described , and the Bayesian information criterion and the integrated completed likelihood are compared for model selection . This novel family of models is applied to real data , where it is compared to its Gaussian analogue within clustering and classification paradigms .
It has been postulated that a good representation is one that disentangles the underlying explanatory factors of variation . However , it remains an open question what kind of training framework could potentially achieve that . Whereas most previous work focuses on the static setting ( e . g . , with images ) , we postulate that some of the causal factors could be discovered if the learner is allowed to interact with its environment . The agent can experiment with different actions and observe their effects . More specifically , we hypothesize that some of these factors correspond to aspects of the environment which are independently controllable , i . e . , that there exists a policy and a learnable feature for each such aspect of the environment , such that this policy can yield changes in that feature with minimal changes to other features that explain the statistical variations in the observed data . We propose a specific objective function to find such factors and verify experimentally that it can indeed disentangle independently controllable aspects of the environment without any extrinsic reward signal .
Superconducting circuit technologies have recently achieved quantum protocols involving closed feedback loops . Quantum artificial intelligence and quantum machine learning are emerging fields inside quantum technologies which may enable quantum devices to acquire information from the outer world and improve themselves via a learning process . Here we propose the implementation of basic protocols in quantum reinforcement learning , with superconducting circuits employing feedback-loop control . We introduce diverse scenarios for proof-of-principle experiments with state-of-the-art superconducting circuit technologies and analyze their feasibility in presence of imperfections . The field of quantum artificial intelligence implemented with superconducting circuits paves the way for enhanced quantum control and quantum computation protocols .
Auto-Encoders are unsupervised models that aim to learn patterns from observed data by minimizing a reconstruction cost . The useful representations learned are often found to be sparse and distributed . On the other hand , compressed sensing and sparse coding assume a data generating process , where the observed data is generated from some true latent signal source , and try to recover the corresponding signal from measurements . Looking at auto-encoders from this \textit{signal recovery perspective} enables us to have a more coherent view of these techniques . In this paper , in particular , we show that the \textit{true} hidden representation can be approximately recovered if the weight matrices are highly incoherent with unit $ \ell^{0} $ row length and the bias vectors takes the value ( approximately ) equal to the negative of the data mean . The recovery also becomes more and more accurate as the sparsity in hidden signals increases . Additionally , we empirically demonstrate that auto-encoders are capable of recovering the data generating dictionary when only data samples are given .
We prove that the empirical risk of most well-known loss functions factors into a linear term aggregating all labels with a term that is label free , and can further be expressed by sums of the loss . This holds true even for non-smooth , non-convex losses and in any RKHS . The first term is a ( kernel ) mean operator --the focal quantity of this work-- which we characterize as the sufficient statistic for the labels . The result tightens known generalization bounds and sheds new light on their interpretation . Factorization has a direct application on weakly supervised learning . In particular , we demonstrate that algorithms like SGD and proximal methods can be adapted with minimal effort to handle weak supervision , once the mean operator has been estimated . We apply this idea to learning with asymmetric noisy labels , connecting and extending prior work . Furthermore , we show that most losses enjoy a data-dependent ( by the mean operator ) form of noise robustness , in contrast with known negative results .
We introduce a comprehensive and statistical framework in a model free setting for a complete treatment of localized data corruptions due to severe noise sources , e . g . , an occluder in the case of a visual recording . Within this framework , we propose i ) a novel algorithm to efficiently separate , i . e . , detect and localize , possible corruptions from a given suspicious data instance and ii ) a Maximum A Posteriori ( MAP ) estimator to impute the corrupted data . As a generalization to Euclidean distance , we also propose a novel distance measure , which is based on the ranked deviations among the data attributes and empirically shown to be superior in separating the corruptions . Our algorithm first splits the suspicious instance into parts through a binary partitioning tree in the space of data attributes and iteratively tests those parts to detect local anomalies using the nominal statistics extracted from an uncorrupted ( clean ) reference data set . Once each part is labeled as anomalous vs normal , the corresponding binary patterns over this tree that characterize corruptions are identified and the affected attributes are imputed . Under a certain conditional independency structure assumed for the binary patterns , we analytically show that the false alarm rate of the introduced algorithm in detecting the corruptions is independent of the data and can be directly set without any parameter tuning . The proposed framework is tested over several well-known machine learning data sets with synthetically generated corruptions ; and experimentally shown to produce remarkable improvements in terms of classification purposes with strong corruption separation capabilities . Our experiments also indicate that the proposed algorithms outperform the typical approaches and are robust to varying training phase conditions .
Frank-Wolfe ( FW ) algorithms have been often proposed over the last few years as efficient solvers for a variety of optimization problems arising in the field of Machine Learning . The ability to work with cheap projection-free iterations and the incremental nature of the method make FW a very effective choice for many large-scale problems where computing a sparse model is desirable . In this paper , we present a high-performance implementation of the FW method tailored to solve large-scale Lasso regression problems , based on a randomized iteration , and prove that the convergence guarantees of the standard FW method are preserved in the stochastic setting . We show experimentally that our algorithm outperforms several existing state of the art methods , including the Coordinate Descent algorithm by Friedman et al . ( one of the fastest known Lasso solvers ) , on several benchmark datasets with a very large number of features , without sacrificing the accuracy of the model . Our results illustrate that the algorithm is able to generate the complete regularization path on problems of size up to four million variables in less than one minute .
The study of deep recurrent neural networks ( RNNs ) and , in particular , of deep Reservoir Computing ( RC ) is gaining an increasing research attention in the neural networks community . The recently introduced deep Echo State Network ( deepESN ) model opened the way to an extremely efficient approach for designing deep neural networks for temporal data . At the same time , the study of deepESNs allowed to shed light on the intrinsic properties of state dynamics developed by hierarchical compositions of recurrent layers , i . e . on the bias of depth in RNNs architectural design . In this paper , we summarize the advancements in the development , analysis and applications of deepESNs .
In this paper , we study the stochastic gradient descent ( SGD ) method for the nonconvex nonsmooth optimization , and propose an accelerated SGD method by combining the variance reduction technique with Nesterov ' s extrapolation technique . Moreover , based on the local error bound condition , we establish the linear convergence of our method to obtain a stationary point of the nonconvex optimization . In particular , we prove that not only the sequence generated linearly converges to a stationary point of the problem , but also the corresponding sequence of objective values is linearly convergent . Finally , some numerical experiments demonstrate the effectiveness of our method . To the best of our knowledge , it is first proved that the accelerated SGD method converges linearly to the local minimum of the nonconvex optimization .
Probabilistic mixture models have been widely used for different machine learning and pattern recognition tasks such as clustering , dimensionality reduction , and classification . In this paper , we focus on trying to solve the most common challenges related to supervised learning algorithms by using mixture probability distribution functions . With this modeling strategy , we identify sub-labels and generate synthetic data in order to reach better classification accuracy . It means we focus on increasing the training data synthetically to increase the classification accuracy .
Recent theory work has found that a special type of spatial partition tree - called a random projection tree - is adaptive to the intrinsic dimension of the data from which it is built . Here we examine this same question , with a combination of theory and experiments , for a broader class of trees that includes k-d trees , dyadic trees , and PCA trees . Our motivation is to get a feel for ( i ) the kind of intrinsic low dimensional structure that can be empirically verified , ( ii ) the extent to which a spatial partition can exploit such structure , and ( iii ) the implications for standard statistical tasks such as regression , vector quantization , and nearest neighbor search .
In this paper , we use variational recurrent neural network to investigate the anomaly detection problem on graph time series . The temporal correlation is modeled by the combination of recurrent neural network ( RNN ) and variational inference ( VI ) , while the spatial information is captured by the graph convolutional network . In order to incorporate external factors , we use feature extractor to augment the transition of latent variables , which can learn the influence of external factors . With the target function as accumulative ELBO , it is easy to extend this model to on-line method . The experimental study on traffic flow data shows the detection capability of the proposed method .
We present an approximation scheme for support vector machine models that use an RBF kernel . A second-order Maclaurin series approximation is used for exponentials of inner products between support vectors and test instances . The approximation is applicable to all kernel methods featuring sums of kernel evaluations and makes no assumptions regarding data normalization . The prediction speed of approximated models no longer relates to the amount of support vectors but is quadratic in terms of the number of input dimensions . If the number of input dimensions is small compared to the amount of support vectors , the approximated model is significantly faster in prediction and has a smaller memory footprint . An optimized C++ implementation was made to assess the gain in prediction speed in a set of practical tests . We additionally provide a method to verify the approximation accuracy , prior to training models or during run-time , to ensure the loss in accuracy remains acceptable and within known bounds .
We study optimal estimation for sparse principal component analysis when the number of non-zero elements is small but on the same order as the dimension of the data . We employ approximate message passing ( AMP ) algorithm and its state evolution to analyze what is the information theoretically minimal mean-squared error and the one achieved by AMP in the limit of large sizes . For a special case of rank one and large enough density of non-zeros Deshpande and Montanari [0] proved that AMP is asymptotically optimal . We show that both for low density and for large rank the problem undergoes a series of phase transitions suggesting existence of a region of parameters where estimation is information theoretically possible , but AMP ( and presumably every other polynomial algorithm ) fails . The analysis of the large rank limit is particularly instructive .
The term " CoRE kernel " stands for correlation-resemblance kernel . In many applications ( e . g . , vision ) , the data are often high-dimensional , sparse , and non-binary . We propose two types of ( nonlinear ) CoRE kernels for non-binary sparse data and demonstrate the effectiveness of the new kernels through a classification experiment . CoRE kernels are simple with no tuning parameters . However , training nonlinear kernel SVM can be ( very ) costly in time and memory and may not be suitable for truly large-scale industrial applications ( e . g . search ) . In order to make the proposed CoRE kernels more practical , we develop basic probabilistic hashing algorithms which transform nonlinear kernels into linear kernels .
This paper introduces a method for efficiently inferring a high-dimensional distributed quantity from a few observations . The quantity of interest ( QoI ) is approximated in a basis ( dictionary ) learned from a training set . The coefficients associated with the approximation of the QoI in the basis are determined by minimizing the misfit with the observations . To obtain a probabilistic estimate of the quantity of interest , a Bayesian approach is employed . The QoI is treated as a random field endowed with a hierarchical prior distribution so that closed-form expressions can be obtained for the posterior distribution . The main contribution of the present work lies in the derivation of \emph{a representation basis consistent with the observation chain} used to infer the associated coefficients . The resulting dictionary is then tailored to be both observable by the sensors and accurate in approximating the posterior mean . An algorithm for deriving such an observable dictionary is presented . The method is illustrated with the estimation of the velocity field of an open cavity flow from a handful of wall-mounted point sensors . Comparison with standard estimation approaches relying on Principal Component Analysis and K-SVD dictionaries is provided and illustrates the superior performance of the present approach .
When applied to training deep neural networks , stochastic gradient descent ( SGD ) often incurs steady progression phases , interrupted by catastrophic episodes in which loss and gradient norm explode . A possible mitigation of such events is to slow down the learning process . This paper presents a novel approach to control the SGD learning rate , that uses two statistical tests . The first one , aimed at fast learning , compares the momentum of the normalized gradient vectors to that of random unit vectors and accordingly gracefully increases or decreases the learning rate . The second one is a change point detection test , aimed at the detection of catastrophic learning episodes ; upon its triggering the learning rate is instantly halved . Both abilities of speeding up and slowing down the learning rate allows the proposed approach , called SALeRA , to learn as fast as possible but not faster . Experiments on standard benchmarks show that SALeRA performs well in practice , and compares favorably to the state of the art .
In this paper , we propose majority voting neural networks for sparse signal recovery in binary compressed sensing . The majority voting neural network is composed of several independently trained feedforward neural networks employing the sigmoid function as an activation function . Our empirical study shows that a choice of a loss function used in training processes for the network is of prime importance . We found a loss function suitable for sparse signal recovery , which includes a cross entropy-like term and an $L_0$ regularized term . From the experimental results , we observed that the majority voting neural network achieves excellent recovery performance , which is approaching the optimal performance as the number of component nets grows . The simple architecture of the majority voting neural networks would be beneficial for both software and hardware implementations .
Gaussian processes allow for flexible specification of prior assumptions of unknown dynamics in state space models . We present a procedure for efficient Bayesian learning in Gaussian process state space models , where the representation is formed by projecting the problem onto a set of approximate eigenfunctions derived from the prior covariance structure . Learning under this family of models can be conducted using a carefully crafted particle MCMC algorithm . This scheme is computationally efficient and yet allows for a fully Bayesian treatment of the problem . Compared to conventional system identification tools or existing learning methods , we show competitive performance and reliable quantification of uncertainties in the model .
We present convergence rate analysis for the approximate stochastic gradient method , where individual gradient updates are corrupted by computation errors . We develop stochastic quadratic constraints to formulate a small linear matrix inequality ( LMI ) whose feasible set characterizes convergence properties of the approximate stochastic gradient . Based on this LMI condition , we develop a sequential minimization approach to analyze the intricate trade-offs that couple stepsize selection , convergence rate , optimization accuracy , and robustness to gradient inaccuracy . We also analytically solve this LMI condition and obtain theoretical formulas that quantify the convergence properties of the approximate stochastic gradient under various assumptions on the loss functions .
Machine learning algorithms that are applied to sensitive data pose a distinct threat to privacy . A growing body of prior work demonstrates that models produced by these algorithms may leak specific private information in the training data to an attacker , either through their structure or their observable behavior . However , the underlying cause of this privacy risk is not well understood beyond a handful of anecdotal accounts that suggest overfitting and influence might play a role . This paper examines the effect that overfitting and influence have on the ability of an attacker to learn information about training data from machine learning models , either through training set membership inference or model inversion attacks . Using both formal and empirical analyses , we illustrate a clear relationship between these factors and the privacy risk that arises in several popular machine learning algorithms . We find that overfitting is sufficient to allow an attacker to perform membership inference , and when certain conditions on the influence of certain features are present , model inversion attacks . Interestingly , our formal analysis also shows that overfitting is not necessary for these attacks , and begins to shed light on what other factors may be in play . Finally , we explore the connection between two types of attack , membership inference and model inversion , and show that there are deep connections between the two that lead to effective new attacks .
The paper introduces a new kernel-based Maximum Mean Discrepancy ( MMD ) statistic for measuring the distance between two distributions given finitely-many multivariate samples . When the distributions are locally low-dimensional , the proposed test can be made more powerful to distinguish certain alternatives by incorporating local covariance matrices and constructing an anisotropic kernel . The kernel matrix is asymmetric ; it computes the affinity between $n$ data points and a set of $n_R$ reference points , where $n_R$ can be drastically smaller than $n$ . While the proposed statistic can be viewed as a special class of Reproducing Kernel Hilbert Space MMD , the consistency of the test is proved , under mild assumptions of the kernel , as long as $\|p-q\| \sim O ( n^{-0/0+\delta} ) $ for any $\delta>0$ , based on a result of convergence in distribution of the test statistic . Applications to flow cytometry and diffusion MRI datasets are demonstrated , which motivate the proposed approach to compare distributions .
We investigate the relation of two fundamental tools in machine learning and signal processing , that is the support vector machine ( SVM ) for classification , and the Lasso technique used in regression . We show that the resulting optimization problems are equivalent , in the following sense . Given any instance of an $\ell_0$-loss soft-margin ( or hard-margin ) SVM , we construct a Lasso instance having the same optimal solutions , and vice versa . As a consequence , many existing optimization algorithms for both SVMs and Lasso can also be applied to the respective other problem instances . Also , the equivalence allows for many known theoretical insights for SVM and Lasso to be translated between the two settings . One such implication gives a simple kernelized version of the Lasso , analogous to the kernels used in the SVM setting . Another consequence is that the sparsity of a Lasso solution is equal to the number of support vectors for the corresponding SVM instance , and that one can use screening rules to prune the set of support vectors . Furthermore , we can relate sublinear time algorithms for the two problems , and give a new such algorithm variant for the Lasso . We also study the regularization paths for both methods .
Incorporating feature selection into a classification or regression method often carries a number of advantages . In this paper we formalize feature selection specifically from a discriminative perspective of improving classification/regression accuracy . The feature selection method is developed as an extension to the recently proposed maximum entropy discrimination ( MED ) framework . We describe MED as a flexible ( Bayesian ) regularization approach that subsumes , e . g . , support vector classification , regression and exponential family models . For brevity , we restrict ourselves primarily to feature selection in the context of linear classification/regression methods and demonstrate that the proposed approach indeed carries substantial improvements in practice . Moreover , we discuss and develop various extensions of feature selection , including the problem of dealing with example specific but unobserved degrees of freedom -- alignments or invariants .
We introduce a new and improved characterization of the label complexity of disagreement-based active learning , in which the leading quantity is the version space compression set size . This quantity is defined as the size of the smallest subset of the training data that induces the same version space . We show various applications of the new characterization , including a tight analysis of CAL and refined label complexity bounds for linear separators under mixtures of Gaussians and axis-aligned rectangles under product densities . The version space compression set size , as well as the new characterization of the label complexity , can be naturally extended to agnostic learning problems , for which we show new speedup results for two well known active learning algorithms .
Security , privacy , and fairness have become critical in the era of data science and machine learning . More and more we see that achieving universally secure , private , and fair systems is practically impossible . We have seen for example how generative adversarial networks can be used to learn about the expected private training data ; how the exploitation of additional data can reveal private information in the original one ; and how what looks like unrelated features can teach us about each other . Confronted with this challenge , in this paper we open a new line of research , where the security , privacy , and fairness is learned and used in a closed environment . The goal is to ensure that a given entity ( e . g . , the company or the government ) , trusted to infer certain information with our data , is blocked from inferring protected information from it . For example , a hospital might be allowed to produce diagnosis on the patient ( the positive task ) , without being able to infer the gender of the subject ( negative task ) . Similarly , a company can guarantee that internally it is not using the provided data for any undesired task , an important goal that is not contradicting the virtually impossible challenge of blocking everybody from the undesired task . We design a system that learns to succeed on the positive task while simultaneously fail at the negative one , and illustrate this with challenging cases where the positive task is actually harder than the negative one being blocked . Fairness , to the information in the negative task , is often automatically obtained as a result of this proposed approach . The particular framework and examples open the door to security , privacy , and fairness in very important closed scenarios , ranging from private data accumulation companies like social networks to law-enforcement and hospitals .
We consider the problem of online nonparametric regression with arbitrary deterministic sequences . Using ideas from the chaining technique , we design an algorithm that achieves a Dudley-type regret bound similar to the one obtained in a non-constructive fashion by Rakhlin and Sridharan ( 0000 ) . Our regret bound is expressed in terms of the metric entropy in the sup norm , which yields optimal guarantees when the metric and sequential entropies are of the same order of magnitude . In particular our algorithm is the first one that achieves optimal rates for online regression over H{\ " o}lder balls . In addition we show for this example how to adapt our chaining algorithm to get a reasonable computational efficiency with similar regret guarantees ( up to a log factor ) .
In training speech recognition systems , labeling audio clips can be expensive , and not all data is equally valuable . Active learning aims to label only the most informative samples to reduce cost . For speech recognition , confidence scores and other likelihood-based active learning methods have been shown to be effective . Gradient-based active learning methods , however , are still not well-understood . This work investigates the Expected Gradient Length ( EGL ) approach in active learning for end-to-end speech recognition . We justify EGL from a variance reduction perspective , and observe that EGL ' s measure of informativeness picks novel samples uncorrelated with confidence scores . Experimentally , we show that EGL can reduce word errors by 00\% , or alternatively , reduce the number of samples to label by 00\% , when compared to random sampling .
Embarrassingly ( communication-free ) parallel Markov chain Monte Carlo ( MCMC ) methods are commonly used in learning graphical models . However , MCMC cannot be directly applied in learning topic models because of the quasi-ergodicity problem caused by multimodal distribution of topics . In this paper , we develop an embarrassingly parallel MCMC algorithm for sLDA . Our algorithm works by switching the order of sampled topics combination and labeling variable prediction in sLDA , in which it overcomes the quasi-ergodicity problem because high-dimension topics that follow a multimodal distribution are projected into one-dimension document labels that follow a unimodal distribution . Our empirical experiments confirm that the out-of-sample prediction performance using our embarrassingly parallel algorithm is comparable to non-parallel sLDA while the computation time is significantly reduced .
A matroid is a notion of independence in combinatorial optimization which is closely related to computational efficiency . In particular , it is well known that the maximum of a constrained modular function can be found greedily if and only if the constraints are associated with a matroid . In this paper , we bring together the ideas of bandits and matroids , and propose a new class of combinatorial bandits , matroid bandits . The objective in these problems is to learn how to maximize a modular function on a matroid . This function is stochastic and initially unknown . We propose a practical algorithm for solving our problem , Optimistic Matroid Maximization ( OMM ) ; and prove two upper bounds , gap-dependent and gap-free , on its regret . Both bounds are sublinear in time and at most linear in all other quantities of interest . The gap-dependent upper bound is tight and we prove a matching lower bound on a partition matroid bandit . Finally , we evaluate our method on three real-world problems and show that it is practical .
Contrary to standard statistical models , unnormalised statistical models only specify the likelihood function up to a constant . While such models are natural and popular , the lack of normalisation makes inference much more difficult . Here we show that inferring the parameters of a unnormalised model on a space $\Omega$ can be mapped onto an equivalent problem of estimating the intensity of a Poisson point process on $\Omega$ . The unnormalised statistical model now specifies an intensity function that does not need to be normalised . Effectively , the normalisation constant may now be inferred as just another parameter , at no loss of information . The result can be extended to cover non-IID models , which includes for example unnormalised models for sequences of graphs ( dynamical graphs ) , or for sequences of binary vectors . As a consequence , we prove that unnormalised parameteric inference in non-IID models can be turned into a semi-parametric estimation problem . Moreover , we show that the noise-contrastive divergence of Gutmann & Hyv\ " arinen ( 0000 ) can be understood as an approximation of the Poisson transform , and extended to non-IID settings . We use our results to fit spatial Markov chain models of eye movements , where the Poisson transform allows us to turn a highly non-standard model into vanilla semi-parametric logistic regression .
Since the events of the Arab Spring , there has been increased interest in using social media to anticipate social unrest . While efforts have been made toward automated unrest prediction , we focus on filtering the vast volume of tweets to identify tweets relevant to unrest , which can be provided to downstream users for further analysis . We train a supervised classifier that is able to label Arabic language tweets as relevant to unrest with high reliability . We examine the relationship between training data size and performance and investigate ways to optimize the model building process while minimizing cost . We also explore how confidence thresholds can be set to achieve desired levels of performance .
Deep generative models have achieved impressive success in recent years . Generative Adversarial Networks ( GANs ) and Variational Autoencoders ( VAEs ) , as powerful frameworks for deep generative model learning , have largely been considered as two distinct paradigms and received extensive independent study respectively . This paper establishes formal connections between deep generative modeling approaches through a new formulation of GANs and VAEs . We show that GANs and VAEs are essentially minimizing KL divergences of respective posterior and inference distributions with opposite directions , extending the two learning phases of classic wake-sleep algorithm , respectively . The unified view provides a powerful tool to analyze a diverse set of existing model variants , and enables to exchange ideas across research lines in a principled way . For example , we transfer the importance weighting method in VAE literatures for improved GAN learning , and enhance VAEs with an adversarial mechanism for leveraging generated samples . Quantitative experiments show generality and effectiveness of the imported extensions .
Consider a social network where only a few nodes ( agents ) have meaningful interactions in the sense that the conditional dependency graph over node attribute variables ( behaviors ) is sparse . A company that can only observe the interactions between its own customers will generally not be able to accurately estimate its customers ' dependency subgraph : it is blinded to any external interactions of its customers and this blindness creates false edges in its subgraph . In this paper we address the semiblind scenario where the company has access to a noisy summary of the complementary subgraph connecting external agents , e . g . , provided by a consolidator . The proposed framework applies to other applications as well , including field estimation from a network of awake and sleeping sensors and privacy-constrained information sharing over social subnetworks . We propose a penalized likelihood approach in the context of a graph signal obeying a Gaussian graphical models ( GGM ) . We use a convex-concave iterative optimization algorithm to maximize the penalized likelihood .
We present a nonparametric prior over reversible Markov chains . We use completely random measures , specifically gamma processes , to construct a countably infinite graph with weighted edges . By enforcing symmetry to make the edges undirected we define a prior over random walks on graphs that results in a reversible Markov chain . The resulting prior over infinite transition matrices is closely related to the hierarchical Dirichlet process but enforces reversibility . A reinforcement scheme has recently been proposed with similar properties , but the de Finetti measure is not well characterised . We take the alternative approach of explicitly constructing the mixing measure , which allows more straightforward and efficient inference at the cost of no longer having a closed form predictive distribution . We use our process to construct a reversible infinite HMM which we apply to two real datasets , one from epigenomics and one ion channel recording .
This paper proposes the adaptation of Support Vector Data Description ( SVDD ) to the multiple kernel case ( MK-SVDD ) , based on SimpleMKL . It also introduces a variant called Slim-MK-SVDD that is able to produce a tighter frontier around the data . For the sake of comparison , the equivalent methods are also developed for One-Class SVM , known to be very similar to SVDD for certain shapes of kernels . Those algorithms are illustrated in the context of 0D-shapes filtering and outliers detection . For the 0D-shapes problem , the objective is to be able to select a sub-category of 0D-shapes , each sub-category being learned with our algorithm in order to create a filter . For outliers detection , we apply the proposed algorithms for unsupervised outliers detection as well as for the supervised case .
We present an new sequential Monte Carlo sampler for coalescent based Bayesian hierarchical clustering . Our model is appropriate for modeling non-i . i . d . data and offers a substantial reduction of computational cost when compared to the original sampler without resorting to approximations . We also propose a quadratic complexity approximation that in practice shows almost no loss in performance compared to its counterpart . We show that as a byproduct of our formulation , we obtain a greedy algorithm that exhibits performance improvement over other greedy algorithms , particularly in small data sets . In order to exploit the correlation structure of the data , we describe how to incorporate Gaussian process priors in the model as a flexible way to model non-i . i . d . data . Results on artificial and real data show significant improvements over closely related approaches .
Non-linear systems of differential equations have attracted the interest in fields like system biology , ecology or biochemistry , due to their flexibility and their ability to describe dynamical systems . Despite the importance of such models in many branches of science they have not been the focus of systematic statistical analysis until recently . In this work we propose a general approach to estimate the parameters of systems of differential equations measured with noise . Our methodology is based on the maximization of the penalized likelihood where the system of differential equations is used as a penalty . To do so , we use a Reproducing Kernel Hilbert Space approach that allows to formulate the estimation problem as an unconstrained numeric maximization problem easy to solve . The proposed method is tested with synthetically simulated data and it is used to estimate the unobserved transcription factor CdaR in Steptomyes coelicolor using gene expression data of the genes it regulates .
We analyze the problem of regression when both input covariates and output responses are functions from a nonparametric function class . Function to function regression ( FFR ) covers a large range of interesting applications including time-series prediction problems , and also more general tasks like studying a mapping between two separate types of distributions . However , previous nonparametric estimators for FFR type problems scale badly computationally with the number of input/output pairs in a data-set . Given the complexity of a mapping between general functions it may be necessary to consider large data-sets in order to achieve a low estimation risk . To address this issue , we develop a novel scalable nonparametric estimator , the Triple-Basis Estimator ( 0BE ) , which is capable of operating over datasets with many instances . To the best of our knowledge , the 0BE is the first nonparametric FFR estimator that can scale to massive datasets . We analyze the 0BE ' s risk and derive an upperbound rate . Furthermore , we show an improvement of several orders of magnitude in terms of prediction speed and a reduction in error over previous estimators in various real-world data-sets .
In this work , we introduce the {\em average top-$k$} ( \atk ) loss as a new aggregate loss for supervised learning , which is the average over the $k$ largest individual losses over a training dataset . We show that the \atk loss is a natural generalization of the two widely used aggregate losses , namely the average loss and the maximum loss , but can combine their advantages and mitigate their drawbacks to better adapt to different data distributions . Furthermore , it remains a convex function over all individual losses , which can lead to convex optimization problems that can be solved effectively with conventional gradient-based methods . We provide an intuitive interpretation of the \atk loss based on its equivalent effect on the continuous individual loss functions , suggesting that it can reduce the penalty on correctly classified data . We further give a learning theory analysis of \matk learning on the classification calibration of the \atk loss and the error bounds of \atk-SVM . We demonstrate the applicability of minimum average top-$k$ learning for binary classification and regression using synthetic and real datasets .
We study the fundamental limits to communication-efficient distributed methods for convex learning and optimization , under different assumptions on the information available to individual machines , and the types of functions considered . We identify cases where existing algorithms are already worst-case optimal , as well as cases where room for further improvement is still possible . Among other things , our results indicate that without similarity between the local objective functions ( due to statistical data similarity or otherwise ) many communication rounds may be required , even if the machines have unbounded computational power .
Finding meaningful communities in social network has attracted the attentions of many researchers . The community structure of complex networks reveals both their organization and hidden relations among their constituents . Most of the researches in the field of community detection mainly focus on the topological structure of the network without performing any content analysis . Nowadays , real world social networks are containing a vast range of information including shared objects , comments , following information , etc . In recent years , a number of researches have proposed approaches which consider both the contents that are interchanged in the networks and the topological structures of the networks in order to find more meaningful communities . In this research , the effect of topic analysis in finding more meaningful communities in social networking sites in which the users express their feelings toward different objects ( like movies ) by the means of rating is demonstrated by performing extensive experiments .
Probabilistic k-nearest neighbour ( PKNN ) classification has been introduced to improve the performance of original k-nearest neighbour ( KNN ) classification algorithm by explicitly modelling uncertainty in the classification of each feature vector . However , an issue common to both KNN and PKNN is to select the optimal number of neighbours , $k$ . The contribution of this paper is to incorporate the uncertainty in $k$ into the decision making , and in so doing use Bayesian model averaging to provide improved classification . Indeed the problem of assessing the uncertainty in $k$ can be viewed as one of statistical model selection which is one of the most important technical issues in the statistics and machine learning domain . In this paper , a new functional approximation algorithm is proposed to reconstruct the density of the model ( order ) without relying on time consuming Monte Carlo simulations . In addition , this algorithm avoids cross validation by adopting Bayesian framework . The performance of this algorithm yielded very good performance on several real experimental datasets .
Driven by the multi-level structure of human intracranial electroencephalogram ( iEEG ) recordings of epileptic seizures , we introduce a new variant of a hierarchical Dirichlet Process---the multi-level clustering hierarchical Dirichlet Process ( MLC-HDP ) ---that simultaneously clusters datasets on multiple levels . Our seizure dataset contains brain activity recorded in typically more than a hundred individual channels for each seizure of each patient . The MLC-HDP model clusters over channels-types , seizure-types , and patient-types simultaneously . We describe this model and its implementation in detail . We also present the results of a simulation study comparing the MLC-HDP to a similar model , the Nested Dirichlet Process and finally demonstrate the MLC-HDP ' s use in modeling seizures across multiple patients . We find the MLC-HDP ' s clustering to be comparable to independent human physician clusterings . To our knowledge , the MLC-HDP model is the first in the epilepsy literature capable of clustering seizures within and between patients .
Satellite imagery and remote sensing provide explanatory variables at relatively high resolutions for modeling geospatial phenomena , yet regional summaries are often desirable for analysis and actionable insight . In this paper , we propose a novel method of inducing spatial aggregations as a component of the machine learning process , yielding regional model features whose construction is driven by model prediction performance rather than prior assumptions . Our results demonstrate that Genetic Programming is particularly well suited to this type of feature construction because it can automatically synthesize appropriate aggregations , as well as better incorporate them into predictive models compared to other regression methods we tested . In our experiments we consider a specific problem instance and real-world dataset relevant to predicting snow properties in high-mountain Asia .
We address the M-best-arm identification problem in multi-armed bandits . A player has a limited budget to explore K arms ( M<K ) , and once pulled , each arm yields a reward drawn ( independently ) from a fixed , unknown distribution . The goal is to find the top M arms in the sense of expected reward . We develop an algorithm which proceeds in rounds to deactivate arms iteratively . At each round , the budget is divided by a nonlinear function of remaining arms , and the arms are pulled correspondingly . Based on a decision rule , the deactivated arm at each round may be accepted or rejected . The algorithm outputs the accepted arms that should ideally be the top M arms . We characterize the decay rate of the misidentification probability and establish that the nonlinear budget allocation proves to be useful for different problem environments ( described by the number of competitive arms ) . We provide comprehensive numerical experiments showing that our algorithm outperforms the state-of-the-art using suitable nonlinearity .
Additive models play an important role in semiparametric statistics . This paper gives learning rates for regularized kernel based methods for additive models . These learning rates compare favourably in particular in high dimensions to recent results on optimal learning rates for purely nonparametric regularized kernel based quantile regression using the Gaussian radial basis function kernel , provided the assumption of an additive model is valid . Additionally , a concrete example is presented to show that a Gaussian function depending only on one variable lies in a reproducing kernel Hilbert space generated by an additive Gaussian kernel , but does not belong to the reproducing kernel Hilbert space generated by the multivariate Gaussian kernel of the same variance .
We study randomized sketching methods for approximately solving least-squares problem with a general convex constraint . The quality of a least-squares approximation can be assessed in different ways : either in terms of the value of the quadratic objective function ( cost approximation ) , or in terms of some distance measure between the approximate minimizer and the true minimizer ( solution approximation ) . Focusing on the latter criterion , our first main result provides a general lower bound on any randomized method that sketches both the data matrix and vector in a least-squares problem ; as a surprising consequence , the most widely used least-squares sketch is sub-optimal for solution approximation . We then present a new method known as the iterative Hessian sketch , and show that it can be used to obtain approximations to the original least-squares problem using a projection dimension proportional to the statistical complexity of the least-squares minimizer , and a logarithmic number of iterations . We illustrate our general theory with simulations for both unconstrained and constrained versions of least-squares , including $\ell_0$-regularization and nuclear norm constraints . We also numerically demonstrate the practicality of our approach in a real face expression classification experiment .
A popular approach for large scale data annotation tasks is crowdsourcing , wherein each data point is labeled by multiple noisy annotators . We consider the problem of inferring ground truth from noisy ordinal labels obtained from multiple annotators of varying and unknown expertise levels . Annotation models for ordinal data have been proposed mostly as extensions of their binary/categorical counterparts and have received little attention in the crowdsourcing literature . We propose a new model for crowdsourced ordinal data that accounts for instance difficulty as well as annotator expertise , and derive a variational Bayesian inference algorithm for parameter estimation . We analyze the ordinal extensions of several state-of-the-art annotator models for binary/categorical labels and evaluate the performance of all the models on two real world datasets containing ordinal query-URL relevance scores , collected through Amazon ' s Mechanical Turk . Our results indicate that the proposed model performs better or as well as existing state-of-the-art methods and is more resistant to `spammy ' annotators ( i . e . , annotators who assign labels randomly without actually looking at the instance ) than popular baselines such as mean , median , and majority vote which do not account for annotator expertise .
Machine-learned models are often described as " black boxes " . In many real-world applications however , models may have to sacrifice predictive power in favour of human-interpretability . When this is the case , feature engineering becomes a crucial task , which requires significant and time-consuming human effort . Whilst some features are inherently static , representing properties that cannot be influenced ( e . g . , the age of an individual ) , others capture characteristics that could be adjusted ( e . g . , the daily amount of carbohydrates taken ) . Nonetheless , once a model is learned from the data , each prediction it makes on new instances is irreversible - assuming every instance to be a static point located in the chosen feature space . There are many circumstances however where it is important to understand ( i ) why a model outputs a certain prediction on a given instance , ( ii ) which adjustable features of that instance should be modified , and finally ( iii ) how to alter such a prediction when the mutated instance is input back to the model . In this paper , we present a technique that exploits the internals of a tree-based ensemble classifier to offer recommendations for transforming true negative instances into positively predicted ones . We demonstrate the validity of our approach using an online advertising application . First , we design a Random Forest classifier that effectively separates between two types of ads : low ( negative ) and high ( positive ) quality ads ( instances ) . Then , we introduce an algorithm that provides recommendations that aim to transform a low quality ad ( negative instance ) into a high quality one ( positive instance ) . Finally , we evaluate our approach on a subset of the active inventory of a large ad network , Yahoo Gemini .
In this study , we propose an automatic learning method for variables selection based on Lasso in epidemiology context . One of the aim of this approach is to overcome the pretreatment of experts in medicine and epidemiology on collected data . These pretreatment consist in recoding some variables and to choose some interactions based on expertise . The approach proposed uses all available explanatory variables without treatment and generate automatically all interactions between them . This lead to high dimension . We use Lasso , one of the robust methods of variable selection in high dimension . To avoid over fitting a two levels cross-validation is used . Because the target variable is account variable and the lasso estimators are biased , variables selected by lasso are debiased by a GLM and used to predict the distribution of the main vector of malaria which is Anopheles . Results show that only few climatic and environmental variables are the mains factors associated to the malaria risk exposure .
We address the problem of finding the maximizer of a nonlinear smooth function , that can only be evaluated point-wise , subject to constraints on the number of permitted function evaluations . This problem is also known as fixed-budget best arm identification in the multi-armed bandit literature . We introduce a Bayesian approach for this problem and show that it empirically outperforms both the existing frequentist counterpart and other Bayesian optimization methods . The Bayesian approach places emphasis on detailed modelling , including the modelling of correlations among the arms . As a result , it can perform well in situations where the number of arms is much larger than the number of allowed function evaluation , whereas the frequentist counterpart is inapplicable . This feature enables us to develop and deploy practical applications , such as automatic machine learning toolboxes . The paper presents comprehensive comparisons of the proposed approach , Thompson sampling , classical Bayesian optimization techniques , more recent Bayesian bandit approaches , and state-of-the-art best arm identification methods . This is the first comparison of many of these methods in the literature and allows us to examine the relative merits of their different features .
Word0vec is a widely used algorithm for extracting low-dimensional vector representations of words . State-of-the-art algorithms including those by Mikolov et al . have been parallelized for multi-core CPU architectures , but are based on vector-vector operations with " Hogwild " updates that are memory-bandwidth intensive and do not efficiently use computational resources . In this paper , we propose " HogBatch " by improving reuse of various data structures in the algorithm through the use of minibatching and negative sample sharing , hence allowing us to express the problem using matrix multiply operations . We also explore different techniques to distribute word0vec computation across nodes in a compute cluster , and demonstrate good strong scalability up to 00 nodes . The new algorithm is particularly suitable for modern multi-core/many-core architectures , especially Intel ' s latest Knights Landing processors , and allows us to scale up the computation near linearly across cores and nodes , and process hundreds of millions of words per second , which is the fastest word0vec implementation to the best of our knowledge .
This paper provides a generic framework of component analysis ( CA ) methods introducing a new expression for scatter matrices and Gram matrices , called Generalized Pairwise Expression ( GPE ) . This expression is quite compact but highly powerful : The framework includes not only ( 0 ) the standard CA methods but also ( 0 ) several regularization techniques , ( 0 ) weighted extensions , ( 0 ) some clustering methods , and ( 0 ) their semi-supervised extensions . This paper also presents quite a simple methodology for designing a desired CA method from the proposed framework : Adopting the known GPEs as templates , and generating a new method by combining these templates appropriately .
Regression models for supervised learning problems with a continuous target are commonly understood as models for the conditional mean of the target given predictors . This notion is simple and therefore appealing for interpretation and visualisation . Information about the whole underlying conditional distribution is , however , not available from these models . A more general understanding of regression models as models for conditional distributions allows much broader inference from such models , for example the computation of prediction intervals . Several random forest-type algorithms aim at estimating conditional distributions , most prominently quantile regression forests ( Meinshausen , 0000 , JMLR ) . We propose a novel approach based on a parametric family of distributions characterised by their transformation function . A dedicated novel " transformation tree " algorithm able to detect distributional changes is developed . Based on these transformation trees , we introduce " transformation forests " as an adaptive local likelihood estimator of conditional distribution functions . The resulting models are fully parametric yet very general and allow broad inference procedures , such as the model-based bootstrap , to be applied in a straightforward way .
Uniform sampling of training data has been commonly used in traditional stochastic optimization algorithms such as Proximal Stochastic Gradient Descent ( prox-SGD ) and Proximal Stochastic Dual Coordinate Ascent ( prox-SDCA ) . Although uniform sampling can guarantee that the sampled stochastic quantity is an unbiased estimate of the corresponding true quantity , the resulting estimator may have a rather high variance , which negatively affects the convergence of the underlying optimization procedure . In this paper we study stochastic optimization with importance sampling , which improves the convergence rate by reducing the stochastic variance . Specifically , we study prox-SGD ( actually , stochastic mirror descent ) with importance sampling and prox-SDCA with importance sampling . For prox-SGD , instead of adopting uniform sampling throughout the training process , the proposed algorithm employs importance sampling to minimize the variance of the stochastic gradient . For prox-SDCA , the proposed importance sampling scheme aims to achieve higher expected dual value at each dual coordinate ascent step . We provide extensive theoretical analysis to show that the convergence rates with the proposed importance sampling methods can be significantly improved under suitable conditions both for prox-SGD and for prox-SDCA . Experiments are provided to verify the theoretical analysis .
Biological systems are often modelled at different levels of abstraction depending on the particular aims/resources of a study . Such different models often provide qualitatively concordant predictions over specific parametrisations , but it is generally unclear whether model predictions are quantitatively in agreement , and whether such agreement holds for different parametrisations . Here we present a generally applicable statistical machine learning methodology to automatically reconcile the predictions of different models across abstraction levels . Our approach is based on defining a correction map , a random function which modifies the output of a model in order to match the statistics of the output of a different model of the same system . We use two biological examples to give a proof-of-principle demonstration of the methodology , and discuss its advantages and potential further applications .
We present a probabilistic model for natural images which is based on Gaussian scale mixtures and a simple multiscale representation . In contrast to the dominant approach to modeling whole images focusing on Markov random fields , we formulate our model in terms of a directed graphical model . We show that it is able to generate images with interesting higher-order correlations when trained on natural images or samples from an occlusion based model . More importantly , the directed model enables us to perform a principled evaluation . While it is easy to generate visually appealing images , we demonstrate that our model also yields the best performance reported to date when evaluated with respect to the cross-entropy rate , a measure tightly linked to the average log-likelihood .
Modern information processing relies on the axiom that high-dimensional data lie near low-dimensional geometric structures . This paper revisits the problem of data-driven learning of these geometric structures and puts forth two new nonlinear geometric models for data describing " related " objects/phenomena . The first one of these models straddles the two extremes of the subspace model and the union-of-subspaces model , and is termed the metric-constrained union-of-subspaces ( MC-UoS ) model . The second one of these models---suited for data drawn from a mixture of nonlinear manifolds---generalizes the kernel subspace model , and is termed the metric-constrained kernel union-of-subspaces ( MC-KUoS ) model . The main contributions of this paper in this regard include the following . First , it motivates and formalizes the problems of MC-UoS and MC-KUoS learning . Second , it presents algorithms that efficiently learn an MC-UoS or an MC-KUoS underlying data of interest . Third , it extends these algorithms to the case when parts of the data are missing . Last , but not least , it reports the outcomes of a series of numerical experiments involving both synthetic and real data that demonstrate the superiority of the proposed geometric models and learning algorithms over existing approaches in the literature . These experiments also help clarify the connections between this work and the literature on ( subspace and kernel k-means ) clustering .
ALAMO is a computational methodology for leaning algebraic functions from data . Given a data set , the approach begins by building a low-complexity , linear model composed of explicit non-linear transformations of the independent variables . Linear combinations of these non-linear transformations allow a linear model to better approximate complex behavior observed in real processes . The model is refined , as additional data are obtained in an adaptive fashion through error maximization sampling using derivative-free optimization . Models built using ALAMO can enforce constraints on the response variables to incorporate first-principles knowledge . The ability of ALAMO to generate simple and accurate models for a number of reaction problems is demonstrated . The error maximization sampling is compared with Latin hypercube designs to demonstrate its sampling efficiency . ALAMO ' s constrained regression methodology is used to further refine concentration models , resulting in models that perform better on validation data and satisfy upper and lower bounds placed on model outputs .
This paper aims at achieving a simultaneously sparse and low-rank estimator from the semidefinite population covariance matrices . We first benefit from a convex optimization which develops $l_0$-norm penalty to encourage the sparsity and nuclear norm to favor the low-rank property . For the proposed estimator , we then prove that with large probability , the Frobenious norm of the estimation rate can be of order $O ( \sqrt{s ( \log{r} ) /n} ) $ under a mild case , where $s$ and $r$ denote the number of sparse entries and the rank of the population covariance respectively , $n$ notes the sample capacity . Finally an efficient alternating direction method of multipliers with global convergence is proposed to tackle this problem , and meantime merits of the approach are also illustrated by practicing numerical simulations .
Suppose that a graph is realized from a stochastic block model where one of the blocks is of interest , but many or all of the vertices ' block labels are unobserved . The task is to order the vertices with unobserved block labels into a ``nomination list ' ' such that , with high probability , vertices from the interesting block are concentrated near the list ' s beginning . We propose several vertex nomination schemes . Our basic - but principled - setting and development yields a best nomination scheme ( which is a Bayes-Optimal analogue ) , and also a likelihood maximization nomination scheme that is practical to implement when there are a thousand vertices , and which is empirically near-optimal when the number of vertices is small enough to allow comparison to the best nomination scheme . We then illustrate the robustness of the likelihood maximization nomination scheme to the modeling challenges inherent in real data , using examples which include a social network involving human trafficking , the Enron Graph , a worm brain connectome and a political blog network .
In this paper , we study two aspects of the variational autoencoder ( VAE ) : the prior distribution over the latent variables and its corresponding posterior . First , we decompose the learning of VAEs into layerwise density estimation , and argue that having a flexible prior is beneficial to both sample generation and inference . Second , we analyze the family of inverse autoregressive flows ( inverse AF ) and show that with further improvement , inverse AF could be used as universal approximation to any complicated posterior . Our analysis results in a unified approach to parameterizing a VAE , without the need to restrict ourselves to use factorial Gaussians in the latent real space .
The motivation of this work is to improve the performance of standard stacking approaches or ensembles , which are composed of simple , heterogeneous base models , through the integration of the generation and selection stages for regression problems . We propose two extensions to the standard stacking approach . In the first extension we combine a set of standard stacking approaches into an ensemble of ensembles using a two-step ensemble learning in the regression setting . The second extension consists of two parts . In the initial part a diversity mechanism is injected into the original training data set , systematically generating different training subsets or partitions , and corresponding ensembles of ensembles . In the final part after measuring the quality of the different partitions or ensembles , a max-min rule-based selection algorithm is used to select the most appropriate ensemble/partition on which to make the final prediction . We show , based on experiments over a broad range of data sets , that the second extension performs better than the best of the standard stacking approaches , and is as good as the oracle of databases , which has the best base model selected by cross-validation for each data set . In addition to that , the second extension performs better than two state-of-the-art ensemble methods for regression , and it is as good as a third state-of-the-art ensemble method .
In this paper we study several classes of stochastic optimization algorithms enriched with heavy ball momentum . Among the methods studied are : stochastic gradient descent , stochastic Newton , stochastic proximal point and stochastic dual subspace ascent . This is the first time momentum variants of several of these methods are studied . We choose to perform our analysis in a setting in which all of the above methods are equivalent . We prove global nonassymptotic linear convergence rates for all methods and various measures of success , including primal function values , primal iterates ( in L0 sense ) , and dual function values . We also show that the primal iterates converge at an accelerated linear rate in the L0 sense . This is the first time a linear rate is shown for the stochastic heavy ball method ( i . e . , stochastic gradient descent method with momentum ) . Under somewhat weaker conditions , we establish a sublinear convergence rate for Cesaro averages of primal iterates . Moreover , we propose a novel concept , which we call stochastic momentum , aimed at decreasing the cost of performing the momentum step . We prove linear convergence of several stochastic methods with stochastic momentum , and show that in some sparse data regimes and for sufficiently small momentum parameters , these methods enjoy better overall complexity than methods with deterministic momentum . Finally , we perform extensive numerical testing on artificial and real datasets , including data coming from average consensus problems .
Recent literature on deep neural networks for tagging of highly energetic jets resulting from top quark decays has focused on image based techniques or multivariate approaches using high-level jet substructure variables . Here , a sequential approach to this task is taken by using an ordered sequence of jet constituents as training inputs . Unlike the majority of previous approaches , this strategy does not result in a loss of information during pixelisation or the calculation of high level features . The jet classification method achieves a background rejection of 00 at a 00% efficiency operating point for reconstruction level jets with transverse momentum range of 000 to 0000 GeV and is insensitive to multiple proton-proton interactions at the levels expected throughout Run 0 of the LHC .
Variational methods that rely on a recognition network to approximate the posterior of directed graphical models offer better inference and learning than previous methods . Recent advances that exploit the capacity and flexibility in this approach have expanded what kinds of models can be trained . However , as a proposal for the posterior , the capacity of the recognition network is limited , which can constrain the representational power of the generative model and increase the variance of Monte Carlo estimates . To address these issues , we introduce an iterative refinement procedure for improving the approximate posterior of the recognition network and show that training with the refined posterior is competitive with state-of-the-art methods . The advantages of refinement are further evident in an increased effective sample size , which implies a lower variance of gradient estimates .
We present novel understandings of the Gamma-Poisson ( GaP ) model , a probabilistic matrix factorization model for count data . We show that GaP can be rewritten free of the score/activation matrix . This gives us new insights about the estimation of the topic/dictionary matrix by maximum marginal likelihood estimation . In particular , this explains the robustness of this estimator to over-specified values of the factorization rank and in particular its ability to automatically prune spurious dictionary columns , as empirically observed in previous work . The marginalization of the activation matrix leads in turn to a new Monte-Carlo Expectation-Maximization algorithm with favorable properties .
We propose a new regularization method based on virtual adversarial loss : a new measure of local smoothness of the output distribution . Virtual adversarial loss is defined as the robustness of the model ' s posterior distribution against local perturbation around each input data point . Our method is similar to adversarial training , but differs from adversarial training in that it determines the adversarial direction based only on the output distribution and that it is applicable to a semi-supervised setting . Because the directions in which we smooth the model are virtually adversarial , we call our method virtual adversarial training ( VAT ) . The computational cost of VAT is relatively low . For neural networks , the approximated gradient of virtual adversarial loss can be computed with no more than two pairs of forward and backpropagations . In our experiments , we applied VAT to supervised and semi-supervised learning on multiple benchmark datasets . With additional improvement based on entropy minimization principle , our VAT achieves the state-of-the-art performance on SVHN and CIFAR-00 for semi-supervised learning tasks .
Learning the joint dependence of discrete variables is a fundamental problem in machine learning , with many applications including prediction , clustering and dimensionality reduction . More recently , the framework of copula modeling has gained popularity due to its modular parametrization of joint distributions . Among other properties , copulas provide a recipe for combining flexible models for univariate marginal distributions with parametric families suitable for potentially high dimensional dependence structures . More radically , the extended rank likelihood approach of Hoff ( 0000 ) bypasses learning marginal models completely when such information is ancillary to the learning task at hand as in , e . g . , standard dimensionality reduction problems or copula parameter estimation . The main idea is to represent data by their observable rank statistics , ignoring any other information from the marginals . Inference is typically done in a Bayesian framework with Gaussian copulas , and it is complicated by the fact this implies sampling within a space where the number of constraints increases quadratically with the number of data points . The result is slow mixing when using off-the-shelf Gibbs sampling . We present an efficient algorithm based on recent advances on constrained Hamiltonian Markov chain Monte Carlo that is simple to implement and does not require paying for a quadratic cost in sample size .
Sparse coding--that is , modelling data vectors as sparse linear combinations of basis elements--is widely used in machine learning , neuroscience , signal processing , and statistics . This paper focuses on the large-scale matrix factorization problem that consists of learning the basis set , adapting it to specific data . Variations of this problem include dictionary learning in signal processing , non-negative matrix factorization and sparse principal component analysis . In this paper , we propose to address these tasks with a new online optimization algorithm , based on stochastic approximations , which scales up gracefully to large datasets with millions of training samples , and extends naturally to various matrix factorization formulations , making it suitable for a wide range of learning problems . A proof of convergence is presented , along with experiments with natural images and genomic data demonstrating that it leads to state-of-the-art performance in terms of speed and optimization for both small and large datasets .
This work addresses the following question : Under what assumptions on the data generating process can one infer the causal graph from the joint distribution ? The approach taken by conditional independence-based causal discovery methods is based on two assumptions : the Markov condition and faithfulness . It has been shown that under these assumptions the causal graph can be identified up to Markov equivalence ( some arrows remain undirected ) using methods like the PC algorithm . In this work we propose an alternative by defining Identifiable Functional Model Classes ( IFMOCs ) . As our main theorem we prove that if the data generating process belongs to an IFMOC , one can identify the complete causal graph . To the best of our knowledge this is the first identifiability result of this kind that is not limited to linear functional relationships . We discuss how the IFMOC assumption and the Markov and faithfulness assumptions relate to each other and explain why we believe that the IFMOC assumption can be tested more easily on given data . We further provide a practical algorithm that recovers the causal graph from finitely many data ; experiments on simulated data support the theoretical findings .
Learning representation from relative similarity comparisons , often called ordinal embedding , gains rising attention in recent years . Most of the existing methods are batch methods designed mainly based on the convex optimization , say , the projected gradient descent method . However , they are generally time-consuming due to that the singular value decomposition ( SVD ) is commonly adopted during the update , especially when the data size is very large . To overcome this challenge , we propose a stochastic algorithm called SVRG-SBB , which has the following features : ( a ) SVD-free via dropping convexity , with good scalability by the use of stochastic algorithm , i . e . , stochastic variance reduced gradient ( SVRG ) , and ( b ) adaptive step size choice via introducing a new stabilized Barzilai-Borwein ( SBB ) method as the original version for convex problems might fail for the considered stochastic \textit{non-convex} optimization problem . Moreover , we show that the proposed algorithm converges to a stationary point at a rate $\mathcal{O} ( \frac{0}{T} ) $ in our setting , where $T$ is the number of total iterations . Numerous simulations and real-world data experiments are conducted to show the effectiveness of the proposed algorithm via comparing with the state-of-the-art methods , particularly , much lower computational cost with good prediction performance .
In this paper , we focus on finding clusters in partially categorized data sets . We propose a semi-supervised version of Gaussian mixture model , called C0L , which retrieves natural subgroups of given categories . In contrast to other semi-supervised models , C0L is parametrized by user-defined leakage level , which controls maximal inconsistency between initial categorization and resulting clustering . Our method can be implemented as a module in practical expert systems to detect clusters , which combine expert knowledge with true distribution of data . Moreover , it can be used for improving the results of less flexible clustering techniques , such as projection pursuit clustering . The paper presents extensive theoretical analysis of the model and fast algorithm for its efficient optimization . Experimental results show that C0L finds high quality clustering model , which can be applied in discovering meaningful groups in partially classified data .
Stochastic networks are a plausible representation of the relational information among entities in dynamic systems such as living cells or social communities . While there is a rich literature in estimating a static or temporally invariant network from observation data , little has been done toward estimating time-varying networks from time series of entity attributes . In this paper we present two new machine learning methods for estimating time-varying networks , which both build on a temporally smoothed $l_0$-regularized logistic regression formalism that can be cast as a standard convex-optimization problem and solved efficiently using generic solvers scalable to large networks . We report promising results on recovering simulated time-varying networks . For real data sets , we reverse engineer the latent sequence of temporally rewiring political networks between Senators from the US Senate voting records and the latent evolving regulatory networks underlying 000 genes across the life cycle of Drosophila melanogaster from the microarray time course .
A Robust Markov Decision Process ( RMDP ) is a sequential decision making model that accounts for uncertainty in the parameters of dynamic systems . This uncertainty introduces difficulties in learning an optimal policy , especially for environments with large state spaces . We propose two algorithms , RTD-DQN and Deep-RoK , for solving large-scale RMDPs using nonlinear approximation schemes such as deep neural networks . The RTD-DQN algorithm incorporates the robust Bellman temporal difference error into a robust loss function , yielding robust policies for the agent . The Deep-RoK algorithm is a robust Bayesian method , based on the Extended Kalman Filter ( EKF ) , that accounts for both the uncertainty in the weights of the approximated value function and the uncertainty in the transition probabilities , improving the robustness of the agent . We provide theoretical results for our approach and test the proposed algorithms on a continuous state domain .
Many real-world applications are characterized by a number of conflicting performance measures . As optimizing in a multi-objective setting leads to a set of non-dominated solutions , a preference function is required for selecting the solution with the appropriate trade-off between the objectives . The question is : how good do estimations of these objectives have to be in order for the solution maximizing the preference function to remain unchanged ? In this paper , we introduce the concept of preference radius to characterize the robustness of the preference function and provide guidelines for controlling the quality of estimations in the multi-objective setting . More specifically , we provide a general formulation of multi-objective optimization under the bandits setting . We show how the preference radius relates to the optimal gap and we use this concept to provide a theoretical analysis of the Thompson sampling algorithm from multivariate normal priors . We finally present experiments to support the theoretical results and highlight the fact that one cannot simply scalarize multi-objective problems into single-objective problems .
We study the effectiveness of non-uniform randomized feature selection in decision tree classification . We experimentally evaluate two feature selection methodologies , based on information extracted from the provided dataset : $ ( i ) $ \emph{leverage scores-based} and $ ( ii ) $ \emph{norm-based} feature selection . Experimental evaluation of the proposed feature selection techniques indicate that such approaches might be more effective compared to naive uniform feature selection and moreover having comparable performance to the random forest algorithm [0]
In this paper , we focus on the stochastic block model ( SBM ) , a probabilistic tool describing interactions between nodes of a network using latent clusters . The SBM assumes that the networkhas a stationary structure , in which connections of time varying intensity are not taken into account . In other words , interactions between two groups are forced to have the same features during the whole observation time . To overcome this limitation , we propose a partition of the whole time horizon , in which interactions are observed , and develop a non stationary extension of the SBM , allowing to simultaneously cluster the nodes in a network along with fixed time intervals in which the interactions take place . The number of clusters ( K for nodes , D for time intervals ) as well as the class memberships are finallyobtained through maximizing the complete-data integrated likelihood by means of a greedy search approach . After showing that the model works properly with simulated data , we focus on a real data set . We thus consider the three days ACM Hypertext conference held in Turin , June 00th - July 0st 0000 . Proximity interactions between attendees during the first day are modelled and an interestingclustering of the daily hours is finally obtained , with times of social gathering ( e . g . coffee breaks ) recovered by the approach . Applications to large networks are limited due to the computational complexity of the greedy search which is dominated bythe number $K\_{max}$ and $D\_{max}$ of clusters used in the initialization . Therefore , advanced clustering tools are considered to reduce the number of clusters expected in the data , making the greedy search applicable to large networks .
Many scientific and engineering fields involve analyzing network data . For document networks , relational topic models ( RTMs ) provide a probabilistic generative process to describe both the link structure and document contents , and they have shown promise on predicting network structures and discovering latent topic representations . However , existing RTMs have limitations in both the restricted model expressiveness and incapability of dealing with imbalanced network data . To expand the scope and improve the inference accuracy of RTMs , this paper presents three extensions : 0 ) unlike the common link likelihood with a diagonal weight matrix that allows the-same-topic interactions only , we generalize it to use a full weight matrix that captures all pairwise topic interactions and is applicable to asymmetric networks ; 0 ) instead of doing standard Bayesian inference , we perform regularized Bayesian inference ( RegBayes ) with a regularization parameter to deal with the imbalanced link structure issue in common real networks and improve the discriminative ability of learned latent representations ; and 0 ) instead of doing variational approximation with strict mean-field assumptions , we present collapsed Gibbs sampling algorithms for the generalized relational topic models by exploring data augmentation without making restricting assumptions . Under the generic RegBayes framework , we carefully investigate two popular discriminative loss functions , namely , the logistic log-loss and the max-margin hinge loss . Experimental results on several real network datasets demonstrate the significance of these extensions on improving the prediction performance , and the time efficiency can be dramatically improved with a simple fast approximation method .
We examine a class of embeddings based on structured random matrices with orthogonal rows which can be applied in many machine learning applications including dimensionality reduction and kernel approximation . For both the Johnson-Lindenstrauss transform and the angular kernel , we show that we can select matrices yielding guaranteed improved performance in accuracy and/or speed compared to earlier methods . We introduce matrices with complex entries which give significant further accuracy improvement . We provide geometric and Markov chain-based perspectives to help understand the benefits , and empirical results which suggest that the approach is helpful in a wider range of applications .
We present an algorithm for approximating a function defined over a $d$-dimensional manifold utilizing only noisy function values at locations sampled from the manifold with noise . To produce the approximation we do not require any knowledge regarding the manifold other than its dimension $d$ . The approximation scheme is based upon the Manifold Moving Least-Squares ( MMLS ) . The proposed algorithm is resistant to noise in both the domain and function values . Furthermore , the approximant is shown to be smooth and of approximation order of $O ( h^{m+0} ) $ for non-noisy data , where $h$ is the mesh size with respect to the manifold domain , and $m$ is the degree of a local polynomial approximation utilized in our algorithm . In addition , the proposed algorithm is linear in time with respect to the ambient-space ' s dimension . Thus , in case of extremely large ambient space dimension , we are able to avoid the curse of dimensionality without having to perform non-linear dimension reduction , which inevitably introduces distortions to the manifold data . We compare , using numerical experiments , the presented algorithm to state-of-the-art algorithms for regression over manifolds and show its potential .
We introduce a novel multivariate random process producing Bernoulli outputs per dimension , that can possibly formalize binary interactions in various graphical structures and can be used to model opinion dynamics , epidemics , financial and biological time series data , etc . We call this a Bernoulli Autoregressive Process ( BAR ) . A BAR process models a discrete-time vector random sequence of $p$ scalar Bernoulli processes with autoregressive dynamics and corresponds to a particular Markov Chain . The benefit from the autoregressive dynamics is the description of a $0^p\times 0^p$ transition matrix by at most $pd$ effective parameters for some $d\ll p$ or by two sparse matrices of dimensions $p\times p^0$ and $p\times p$ , respectively , parameterizing the transitions . Additionally , we show that the BAR process mixes rapidly , by proving that the mixing time is $O ( \log p ) $ . The hidden constant in the previous mixing time bound depends explicitly on the values of the chain parameters and implicitly on the maximum allowed in-degree of a node in the corresponding graph . For a network with $p$ nodes , where each node has in-degree at most $d$ and corresponds to a scalar Bernoulli process generated by a BAR , we provide a greedy algorithm that can efficiently learn the structure of the underlying directed graph with a sample complexity proportional to the mixing time of the BAR process . The sample complexity of the proposed algorithm is nearly order-optimal as it is only a $\log p$ factor away from an information-theoretic lower bound . We present simulation results illustrating the performance of our algorithm in various setups , including a model for a biological signaling network .
Multivariate analysis of fMRI data has benefited substantially from advances in machine learning . Most recently , a range of probabilistic latent variable models applied to fMRI data have been successful in a variety of tasks , including identifying similarity patterns in neural data ( Representational Similarity Analysis and its empirical Bayes variant , RSA and BRSA ; Intersubject Functional Connectivity , ISFC ) , combining multi-subject datasets ( Shared Response Mapping ; SRM ) , and mapping between brain and behavior ( Joint Modeling ) . Although these methods share some underpinnings , they have been developed as distinct methods , with distinct algorithms and software tools . We show how the matrix-variate normal ( MN ) formalism can unify some of these methods into a single framework . In doing so , we gain the ability to reuse noise modeling assumptions , algorithms , and code across models . Our primary theoretical contribution shows how some of these methods can be written as instantiations of the same model , allowing us to generalize them to flexibly modeling structured noise covariances . Our formalism permits novel model variants and improved estimation strategies : in contrast to SRM , the number of parameters for MN-SRM does not scale with the number of voxels or subjects ; in contrast to BRSA , the number of parameters for MN-RSA scales additively rather than multiplicatively in the number of voxels . We empirically demonstrate advantages of two new methods derived in the formalism : for MN-RSA , we show up to 00x improvement in runtime , up to 0x improvement in RMSE , and more conservative behavior under the null . For MN-SRM , our method grants a modest improvement to out-of-sample reconstruction while relaxing an orthonormality constraint of SRM . We also provide a software prototyping tool for MN models that can flexibly reuse noise covariance assumptions and algorithms across models .
We propose a novel , efficient approach for distributed sparse learning in high-dimensions , where observations are randomly partitioned across machines . Computationally , at each round our method only requires the master machine to solve a shifted ell_0 regularized M-estimation problem , and other workers to compute the gradient . In respect of communication , the proposed approach provably matches the estimation error bound of centralized methods within constant rounds of communications ( ignoring logarithmic factors ) . We conduct extensive experiments on both simulated and real world datasets , and demonstrate encouraging performances on high-dimensional regression and classification tasks .
We propose an original particle-based implementation of the Loopy Belief Propagation ( LPB ) algorithm for pairwise Markov Random Fields ( MRF ) on a continuous state space . The algorithm constructs adaptively efficient proposal distributions approximating the local beliefs at each note of the MRF . This is achieved by considering proposal distributions in the exponential family whose parameters are updated iterately in an Expectation Propagation ( EP ) framework . The proposed particle scheme provides consistent estimation of the LBP marginals as the number of particles increases . We demonstrate that it provides more accurate results than the Particle Belief Propagation ( PBP ) algorithm of Ihler and McAllester ( 0000 ) at a fraction of the computational cost and is additionally more robust empirically . The computational complexity of our algorithm at each iteration is quadratic in the number of particles . We also propose an accelerated implementation with sub-quadratic computational complexity which still provides consistent estimates of the loopy BP marginal distributions and performs almost as well as the original procedure .
This paper proposes an original approach to cluster multi-component data sets , including an estimation of the number of clusters . From the construction of a minimal spanning tree with Prim ' s algorithm , and the assumption that the vertices are approximately distributed according to a Poisson distribution , the number of clusters is estimated by thresholding the Prim ' s trajectory . The corresponding cluster centroids are then computed in order to initialize the generalized Lloyd ' s algorithm , also known as $K$-means , which allows to circumvent initialization problems . Some results are derived for evaluating the false positive rate of our cluster detection algorithm , with the help of approximations relevant in Euclidean spaces . Metrics used for measuring similarity between multi-dimensional data points are based on symmetrical divergences . The use of these informational divergences together with the proposed method leads to better results , compared to other clustering methods for the problem of astrophysical data processing . Some applications of this method in the multi/hyper-spectral imagery domain to a satellite view of Paris and to an image of the Mars planet are also presented . In order to demonstrate the usefulness of divergences in our problem , the method with informational divergence as similarity measure is compared with the same method using classical metrics . In the astrophysics application , we also compare the method with the spectral clustering algorithms .
We address the problem of general supervised learning when data can only be accessed through an ( indefinite ) similarity function between data points . Existing work on learning with indefinite kernels has concentrated solely on binary/multi-class classification problems . We propose a model that is generic enough to handle any supervised learning task and also subsumes the model previously proposed for classification . We give a " goodness " criterion for similarity functions w . r . t . a given supervised learning task and then adapt a well-known landmarking technique to provide efficient algorithms for supervised learning using " good " similarity functions . We demonstrate the effectiveness of our model on three important super-vised learning problems : a ) real-valued regression , b ) ordinal regression and c ) ranking where we show that our method guarantees bounded generalization error . Furthermore , for the case of real-valued regression , we give a natural goodness definition that , when used in conjunction with a recent result in sparse vector recovery , guarantees a sparse predictor with bounded generalization error . Finally , we report results of our learning algorithms on regression and ordinal regression tasks using non-PSD similarity functions and demonstrate the effectiveness of our algorithms , especially that of the sparse landmark selection algorithm that achieves significantly higher accuracies than the baseline methods while offering reduced computational costs .
In a variety of disciplines such as social sciences , psychology , medicine and economics , the recorded data are considered to be noisy measurements of latent variables connected by some causal structure . This corresponds to a family of graphical models known as the structural equation model with latent variables . While linear non-Gaussian variants have been well-studied , inference in nonparametric structural equation models is still underdeveloped . We introduce a sparse Gaussian process parameterization that defines a non-linear structure connecting latent variables , unlike common formulations of Gaussian process latent variable models . The sparse parameterization is given a full Bayesian treatment without compromising Markov chain Monte Carlo efficiency . We compare the stability of the sampling procedure and the predictive ability of the model against the current practice .
Deep learning has become the method of choice in many application domains of machine learning in recent years , especially for multi-class classification tasks . The most common loss function used in this context is the cross-entropy loss , which reduces to the log loss in the typical case when there is a single correct response label . While this loss is insensitive to the identity of the assigned class in the case of misclassification , in practice it is often the case that some errors may be more detrimental than others . Here we present the bilinear-loss ( and related log-bilinear-loss ) which differentially penalizes the different wrong assignments of the model . We thoroughly test this method using standard models and benchmark image datasets . As one application , we show the ability of this method to better contain error within the correct super-class , in the hierarchically labeled CIFAR000 dataset , without affecting the overall performance of the classifier .
Optimal Transport has recently gained interest in machine learning for applications ranging from domain adaptation , sentence similarities to deep learning . Yet , its ability to capture frequently occurring structure beyond the " ground metric " is limited . In this work , we develop a nonlinear generalization of ( discrete ) optimal transport that is able to reflect much additional structure . We demonstrate how to leverage the geometry of this new model for fast algorithms , and explore connections and properties . Illustrative experiments highlight the benefit of the induced structured couplings for tasks in domain adaptation and natural language processing .
This document describes the R package UBL that allows the use of several methods for handling utility-based learning problems . Classification and regression problems that assume non-uniform costs and/or benefits pose serious challenges to predictive analytic tasks . In the context of meteorology , finance , medicine , ecology , among many other , specific domain information concerning the preference bias of the users must be taken into account to enhance the models predictive performance . To deal with this problem , a large number of techniques was proposed by the research community for both classification and regression tasks . The main goal of UBL package is to facilitate the utility-based predictive analytic task by providing a set of methods to deal with this type of problems in the R environment . It is a versatile tool that provides mechanisms to handle both regression and classification ( binary and multiclass ) tasks . Moreover , UBL package allows the user to specify his domain preferences , but it also provides some automatic methods that try to infer those preference bias from the domain , considering some common known settings .
We propose a generic algorithmic building block to accelerate training of machine learning models on heterogeneous compute systems . Our scheme allows to efficiently employ compute accelerators such as GPUs and FPGAs for the training of large-scale machine learning models , when the training data exceeds their memory capacity . Also , it provides adaptivity to any system ' s memory hierarchy in terms of size and processing speed . Our technique is built upon novel theoretical insights regarding primal-dual coordinate methods , and uses duality gap information to dynamically decide which part of the data should be made available for fast processing . To illustrate the power of our approach we demonstrate its performance for training of generalized linear models on a large-scale dataset exceeding the memory size of a modern GPU , showing an order-of-magnitude speedup over existing approaches .
Nuclear magnetic resonance ( NMR ) spectroscopy exploits the magnetic properties of atomic nuclei to discover the structure , reaction state and chemical environment of molecules . We propose a probabilistic generative model and inference procedures for NMR spectroscopy . Specifically , we use a weighted sum of trigonometric functions undergoing exponential decay to model free induction decay ( FID ) signals . We discuss the challenges in estimating the components of this general model -- amplitudes , phase shifts , frequencies , decay rates , and noise variances -- and offer practical solutions . We compare with conventional Fourier transform spectroscopy for estimating the relative concentrations of chemicals in a mixture , using synthetic and experimentally acquired FID signals . We find the proposed model is particularly robust to low signal to noise ratios ( SNR ) , and overlapping peaks in the Fourier transform of the FID , enabling accurate predictions ( e . g . , 0% sensitivity at low SNR ) which are not possible with conventional spectroscopy ( 0% sensitivity ) .
We consider the problem of training input-output recurrent neural networks ( RNN ) for sequence labeling tasks . We propose a novel spectral approach for learning the network parameters . It is based on decomposition of the cross-moment tensor between the output and a non-linear transformation of the input , based on score functions . We guarantee consistent learning with polynomial sample and computational complexity under transparent conditions such as non-degeneracy of model parameters , polynomial activations for the neurons , and a Markovian evolution of the input sequence . We also extend our results to Bidirectional RNN which uses both previous and future information to output the label at each time point , and is employed in many NLP tasks such as POS tagging .
We propose a fast inference method for Bayesian nonlinear support vector machines that leverages stochastic variational inference and inducing points . Our experiments show that the proposed method is faster than competing Bayesian approaches and scales easily to millions of data points . It provides additional features over frequentist competitors such as accurate predictive uncertainty estimates and automatic hyperparameter search .
Recently , there has been much interest in finding globally optimal Bayesian network structures . These techniques were developed for generative scores and can not be directly extended to discriminative scores , as desired for classification . In this paper , we propose an exact method for finding network structures maximizing the probabilistic soft margin , a successfully applied discriminative score . Our method is based on branch-and-bound techniques within a linear programming framework and maintains an any-time solution , together with worst-case sub-optimality bounds . We apply a set of order constraints for enforcing the network structure to be acyclic , which allows a compact problem representation and the use of general-purpose optimization techniques . In classification experiments , our methods clearly outperform generatively trained network structures and compete with support vector machines .
We introduce \texttt{pycobra} , a Python library devoted to ensemble learning ( regression and classification ) and visualisation . Its main assets are the implementation of several ensemble learning algorithms , a flexible and generic interface to compare and blend any existing machine learning algorithm available in Python libraries ( as long as a \texttt{predict} method is given ) , and visualisation tools such as Voronoi tessellations . \texttt{pycobra} is fully \texttt{scikit-learn} compatible and is released under the MIT open-source license . \texttt{pycobra} can be downloaded from the Python Package Index ( PyPi ) and Machine Learning Open Source Software ( MLOSS ) . The current version ( along with Jupyter notebooks , extensive documentation , and continuous integration tests ) is available at \href{https : //github . com/bhargavvader/pycobra}{https : //github . com/bhargavvader/pycobra} .
We discuss multi-task online learning when a decision maker has to deal simultaneously with M tasks . The tasks are related , which is modeled by imposing that the M-tuple of actions taken by the decision maker needs to satisfy certain constraints . We give natural examples of such restrictions and then discuss a general class of tractable constraints , for which we introduce computationally efficient ways of selecting actions , essentially by reducing to an on-line shortest path problem . We briefly discuss " tracking " and " bandit " versions of the problem and extend the model in various ways , including non-additive global losses and uncountably infinite sets of tasks .
Learning Granger causality for general point processes is a very challenging task . In this paper , we propose an effective method , learning Granger causality , for a special but significant type of point processes --- Hawkes process . We reveal the relationship between Hawkes process ' s impact function and its Granger causality graph . Specifically , our model represents impact functions using a series of basis functions and recovers the Granger causality graph via group sparsity of the impact functions ' coefficients . We propose an effective learning algorithm combining a maximum likelihood estimator ( MLE ) with a sparse-group-lasso ( SGL ) regularizer . Additionally , the flexibility of our model allows to incorporate the clustering structure event types into learning framework . We analyze our learning algorithm and propose an adaptive procedure to select basis functions . Experiments on both synthetic and real-world data show that our method can learn the Granger causality graph and the triggering patterns of the Hawkes processes simultaneously .
The question of the optimality of Thompson Sampling for solving the stochastic multi-armed bandit problem had been open since 0000 . In this paper we answer it positively for the case of Bernoulli rewards by providing the first finite-time analysis that matches the asymptotic rate given in the Lai and Robbins lower bound for the cumulative regret . The proof is accompanied by a numerical comparison with other optimal policies , experiments that have been lacking in the literature until now for the Bernoulli case .
We present a Bayesian non-negative tensor factorization model for count-valued tensor data , and develop scalable inference algorithms ( both batch and online ) for dealing with massive tensors . Our generative model can handle overdispersed counts as well as infer the rank of the decomposition . Moreover , leveraging a reparameterization of the Poisson distribution as a multinomial facilitates conjugacy in the model and enables simple and efficient Gibbs sampling and variational Bayes ( VB ) inference updates , with a computational cost that only depends on the number of nonzeros in the tensor . The model also provides a nice interpretability for the factors ; in our model , each factor corresponds to a " topic " . We develop a set of online inference algorithms that allow further scaling up the model to massive tensors , for which batch inference methods may be infeasible . We apply our framework on diverse real-world applications , such as \emph{multiway} topic modeling on a scientific publications database , analyzing a political science data set , and analyzing a massive household transactions data set .
We present a Bayesian tensor factorization model for inferring latent group structures from dynamic pairwise interaction patterns . For decades , political scientists have collected and analyzed records of the form " country $i$ took action $a$ toward country $j$ at time $t$ " ---known as dyadic events---in order to form and test theories of international relations . We represent these event data as a tensor of counts and develop Bayesian Poisson tensor factorization to infer a low-dimensional , interpretable representation of their salient patterns . We demonstrate that our model ' s predictive performance is better than that of standard non-negative tensor factorization methods . We also provide a comparison of our variational updates to their maximum likelihood counterparts . In doing so , we identify a better way to form point estimates of the latent factors than that typically used in Bayesian Poisson matrix factorization . Finally , we showcase our model as an exploratory analysis tool for political scientists . We show that the inferred latent factor matrices capture interpretable multilateral relations that both conform to and inform our knowledge of international affairs .
We show that accelerated gradient descent , averaged gradient descent and the heavy-ball method for non-strongly-convex problems may be reformulated as constant parameter second-order difference equation algorithms , where stability of the system is equivalent to convergence at rate O ( 0/n 0 ) , where n is the number of iterations . We provide a detailed analysis of the eigenvalues of the corresponding linear dynamical system , showing various oscillatory and non-oscillatory behaviors , together with a sharp stability result with explicit constants . We also consider the situation where noisy gradients are available , where we extend our general convergence result , which suggests an alternative algorithm ( i . e . , with different step sizes ) that exhibits the good aspects of both averaging and acceleration .
The level set tree approach of Hartigan ( 0000 ) provides a probabilistically based and highly interpretable encoding of the clustering behavior of a dataset . By representing the hierarchy of data modes as a dendrogram of the level sets of a density estimator , this approach offers many advantages for exploratory analysis and clustering , especially for complex and high-dimensional data . Several R packages exist for level set tree estimation , but their practical usefulness is limited by computational inefficiency , absence of interactive graphical capabilities and , from a theoretical perspective , reliance on asymptotic approximations . To make it easier for practitioners to capture the advantages of level set trees , we have written the Python package DeBaCl for DEnsity-BAsed CLustering . In this article we illustrate how DeBaCl ' s level set tree estimates can be used for difficult clustering tasks and interactive graphical data analysis . The package is intended to promote the practical use of level set trees through improvements in computational efficiency and a high degree of user customization . In addition , the flexible algorithms implemented in DeBaCl enjoy finite sample accuracy , as demonstrated in recent literature on density clustering . Finally , we show the level set tree framework can be easily extended to deal with functional data .
The scaled complex Wishart distribution is a widely used model for multilook full polarimetric SAR data whose adequacy has been attested in the literature . Classification , segmentation , and image analysis techniques which depend on this model have been devised , and many of them employ some type of dissimilarity measure . In this paper we derive analytic expressions for four stochastic distances between relaxed scaled complex Wishart distributions in their most general form and in important particular cases . Using these distances , inequalities are obtained which lead to new ways of deriving the Bartlett and revised Wishart distances . The expressiveness of the four analytic distances is assessed with respect to the variation of parameters . Such distances are then used for deriving new tests statistics , which are proved to have asymptotic chi-square distribution . Adopting the test size as a comparison criterion , a sensitivity study is performed by means of Monte Carlo experiments suggesting that the Bhattacharyya statistic outperforms all the others . The power of the tests is also assessed . Applications to actual data illustrate the discrimination and homogeneity identification capabilities of these distances .
This paper presents a Bayesian image segmentation model based on Potts prior and loopy belief propagation . The proposed Bayesian model involves several terms , including the pairwise interactions of Potts models , and the average vectors and covariant matrices of Gauss distributions in color image modeling . These terms are often referred to as hyperparameters in statistical machine learning theory . In order to determine these hyperparameters , we propose a new scheme for hyperparameter estimation based on conditional maximization of entropy in the Potts prior . The algorithm is given based on loopy belief propagation . In addition , we compare our conditional maximum entropy framework with the conventional maximum likelihood framework , and also clarify how the first order phase transitions in LBP ' s for Potts models influence our hyperparameter estimation procedures .
We derive a statistical model for estimation of a dendrogram from single linkage hierarchical clustering ( SLHC ) that takes account of uncertainty through noise or corruption in the measurements of separation of data . Our focus is on just the estimation of the hierarchy of partitions afforded by the dendrogram , rather than the heights in the latter . The concept of estimating this " dendrogram structure ' ' is introduced , and an approximate maximum likelihood estimator ( MLE ) for the dendrogram structure is described . These ideas are illustrated by a simple Monte Carlo simulation that , at least for small data sets , suggests the method outperforms SLHC in the presence of noise .
Recovery of low-rank matrices has recently seen significant activity in many areas of science and engineering , motivated by recent theoretical results for exact reconstruction guarantees and interesting practical applications . A number of methods have been developed for this recovery problem . However , a principled method for choosing the unknown target rank is generally not provided . In this paper , we present novel recovery algorithms for estimating low-rank matrices in matrix completion and robust principal component analysis based on sparse Bayesian learning ( SBL ) principles . Starting from a matrix factorization formulation and enforcing the low-rank constraint in the estimates as a sparsity constraint , we develop an approach that is very effective in determining the correct rank while providing high recovery performance . We provide connections with existing methods in other similar problems and empirical results and comparisons with current state-of-the-art methods that illustrate the effectiveness of this approach .
We propose a new algorithm for solving the graph-fused lasso ( GFL ) , a method for parameter estimation that operates under the assumption that the signal tends to be locally constant over a predefined graph structure . Our key insight is to decompose the graph into a set of trails which can then each be solved efficiently using techniques for the ordinary ( 0D ) fused lasso . We leverage these trails in a proximal algorithm that alternates between closed form primal updates and fast dual trail updates . The resulting techinque is both faster than previous GFL methods and more flexible in the choice of loss function and graph structure . Furthermore , we present two algorithms for constructing trail sets and show empirically that they offer a tradeoff between preprocessing time and convergence rate .
We consider high-dimensional regression over subgroups of observations . Our work is motivated by biomedical problems , where disease subtypes , for example , may differ with respect to underlying regression models , but sample sizes at the subgroup-level may be limited . We focus on the case in which subgroup-specific models may be expected to be similar but not necessarily identical . Our approach is to treat subgroups as related problem instances and jointly estimate subgroup-specific regression coefficients . This is done in a penalized framework , combining an $\ell_0$ term with an additional term that penalizes differences between subgroup-specific coefficients . This gives solutions that are globally sparse but that allow information-sharing between the subgroups . We present algorithms for estimation and empirical results on simulated data and using Alzheimer ' s disease , amyotrophic lateral sclerosis and cancer datasets . These examples demonstrate the gains our approach can offer in terms of prediction and the ability to estimate subgroup-specific sparsity patterns .
Sequential Monte Carlo ( SMC ) , or particle filtering , is a popular class of methods for sampling from an intractable target distribution using a sequence of simpler intermediate distributions . Like other importance sampling-based methods , performance is critically dependent on the proposal distribution : a bad proposal can lead to arbitrarily inaccurate estimates of the target distribution . This paper presents a new method for automatically adapting the proposal using an approximation of the Kullback-Leibler divergence between the true posterior and the proposal distribution . The method is very flexible , applicable to any parameterized proposal distribution and it supports online and batch variants . We use the new framework to adapt powerful proposal distributions with rich parameterizations based upon neural networks leading to Neural Adaptive Sequential Monte Carlo ( NASMC ) . Experiments indicate that NASMC significantly improves inference in a non-linear state space model outperforming adaptive proposal methods including the Extended Kalman and Unscented Particle Filters . Experiments also indicate that improved inference translates into improved parameter learning when NASMC is used as a subroutine of Particle Marginal Metropolis Hastings . Finally we show that NASMC is able to train a latent variable recurrent neural network ( LV-RNN ) achieving results that compete with the state-of-the-art for polymorphic music modelling . NASMC can be seen as bridging the gap between adaptive SMC methods and the recent work in scalable , black-box variational inference .
We develop a penalized likelihood estimation framework to estimate the structure of Gaussian Bayesian networks from observational data . In contrast to recent methods which accelerate the learning problem by restricting the search space , our main contribution is a fast algorithm for score-based structure learning which does not restrict the search space in any way and works on high-dimensional datasets with thousands of variables . Our use of concave regularization , as opposed to the more popular $\ell_0$ ( e . g . BIC ) penalty , is new . Moreover , we provide theoretical guarantees which generalize existing asymptotic results when the underlying distribution is Gaussian . Most notably , our framework does not require the existence of a so-called faithful DAG representation , and as a result the theory must handle the inherent nonidentifiability of the estimation problem in a novel way . Finally , as a matter of independent interest , we provide a comprehensive comparison of our approach to several standard structure learning methods using open-source packages developed for the R language . Based on these experiments , we show that our algorithm is significantly faster than other competing methods while obtaining higher sensitivity with comparable false discovery rates for high-dimensional data . In particular , the total runtime for our method to generate a solution path of 00 estimates for DAGs with 0000 nodes is around one hour .
This paper introduces a novel technique to track structures in time evolving graphs . The method is based on a parameter free approach for three-dimensional co-clustering of the source vertices , the target vertices and the time . All these features are simultaneously segmented in order to build time segments and clusters of vertices whose edge distributions are similar and evolve in the same way over the time segments . The main novelty of this approach lies in that the time segments are directly inferred from the evolution of the edge distribution between the vertices , thus not requiring the user to make an a priori discretization . Experiments conducted on a synthetic dataset illustrate the good behaviour of the technique , and a study of a real-life dataset shows the potential of the proposed approach for exploratory data analysis .
Statistical downscaling of global climate models ( GCMs ) allows researchers to study local climate change effects decades into the future . A wide range of statistical models have been applied to downscaling GCMs but recent advances in machine learning have not been explored . In this paper , we compare four fundamental statistical methods , Bias Correction Spatial Disaggregation ( BCSD ) , Ordinary Least Squares , Elastic-Net , and Support Vector Machine , with three more advanced machine learning methods , Multi-task Sparse Structure Learning ( MSSL ) , BCSD coupled with MSSL , and Convolutional Neural Networks to downscale daily precipitation in the Northeast United States . Metrics to evaluate of each method ' s ability to capture daily anomalies , large scale climate shifts , and extremes are analyzed . We find that linear methods , led by BCSD , consistently outperform non-linear approaches . The direct application of state-of-the-art machine learning methods to statistical downscaling does not provide improvements over simpler , longstanding approaches .
In this paper we provide a principled approach to solve a transductive classification problem involving a similar graph ( edges tend to connect nodes with same labels ) and a dissimilar graph ( edges tend to connect nodes with opposing labels ) . Most of the existing methods , e . g . , Information Regularization ( IR ) , Weighted vote Relational Neighbor classifier ( WvRN ) etc , assume that the given graph is only a similar graph . We extend the IR and WvRN methods to deal with mixed graphs . We evaluate the proposed extensions on several benchmark datasets as well as two real world datasets and demonstrate the usefulness of our ideas .
Risk bounds for Classification and Regression Trees ( CART , Breiman et . al . 0000 ) classifiers are obtained under a margin condition in the binary supervised classification framework . These risk bounds are obtained conditionally on the construction of the maximal deep binary tree and permit to prove that the linear penalty used in the CART pruning algorithm is valid under a margin condition . It is also shown that , conditionally on the construction of the maximal tree , the final selection by test sample does not alter dramatically the estimation accuracy of the Bayes classifier . In the two-class classification framework , the risk bounds that are proved , obtained by using penalized model selection , validate the CART algorithm which is used in many data mining applications such as Biology , Medicine or Image Coding .
A probabilistic query may not be estimable from observed data corrupted by missing values if the data are not missing at random ( MAR ) . It is therefore of theoretical interest and practical importance to determine in principle whether a probabilistic query is estimable from missing data or not when the data are not MAR . We present an algorithm that systematically determines whether the joint probability is estimable from observed data with missing values , assuming that the data-generation model is represented as a Bayesian network containing unobserved latent variables that not only encodes the dependencies among the variables but also explicitly portrays the mechanisms responsible for the missingness process . The result significantly advances the existing work .
We propose the supervised hierarchical Dirichlet process ( sHDP ) , a nonparametric generative model for the joint distribution of a group of observations and a response variable directly associated with that whole group . We compare the sHDP with another leading method for regression on grouped data , the supervised latent Dirichlet allocation ( sLDA ) model . We evaluate our method on two real-world classification problems and two real-world regression problems . Bayesian nonparametric regression models based on the Dirichlet process , such as the Dirichlet process-generalised linear models ( DP-GLM ) have previously been explored ; these models allow flexibility in modelling nonlinear relationships . However , until now , Hierarchical Dirichlet Process ( HDP ) mixtures have not seen significant use in supervised problems with grouped data since a straightforward application of the HDP on the grouped data results in learnt clusters that are not predictive of the responses . The sHDP solves this problem by allowing for clusters to be learnt jointly from the group structure and from the label assigned to each group .
The clustering ensemble technique aims to combine multiple clusterings into a probably better and more robust clustering and has been receiving an increasing attention in recent years . There are mainly two aspects of limitations in the existing clustering ensemble approaches . Firstly , many approaches lack the ability to weight the base clusterings without access to the original data and can be affected significantly by the low-quality , or even ill clusterings . Secondly , they generally focus on the instance level or cluster level in the ensemble system and fail to integrate multi-granularity cues into a unified model . To address these two limitations , this paper proposes to solve the clustering ensemble problem via crowd agreement estimation and multi-granularity link analysis . We present the normalized crowd agreement index ( NCAI ) to evaluate the quality of base clusterings in an unsupervised manner and thus weight the base clusterings in accordance with their clustering validity . To explore the relationship between clusters , the source aware connected triple ( SACT ) similarity is introduced with regard to their common neighbors and the source reliability . Based on NCAI and multi-granularity information collected among base clusterings , clusters , and data instances , we further propose two novel consensus functions , termed weighted evidence accumulation clustering ( WEAC ) and graph partitioning with multi-granularity link analysis ( GP-MGLA ) respectively . The experiments are conducted on eight real-world datasets . The experimental results demonstrate the effectiveness and robustness of the proposed methods .
Graphs are a central tool in machine learning and information processing as they allow to conveniently capture the structure of complex datasets . In this context , it is of high importance to develop flexible models of signals defined over graphs or networks . In this paper , we generalize the traditional concept of wide sense stationarity to signals defined over the vertices of arbitrary weighted undirected graphs . We show that stationarity is expressed through the graph localization operator reminiscent of translation . We prove that stationary graph signals are characterized by a well-defined Power Spectral Density that can be efficiently estimated even for large graphs . We leverage this new concept to derive Wiener-type estimation procedures of noisy and partially observed signals and illustrate the performance of this new model for denoising and regression .
Scalability of statistical estimators is of increasing importance in modern applications and dimension reduction is often used to extract relevant information from data . A variety of popular dimension reduction approaches can be framed as symmetric generalized eigendecomposition problems . In this paper we outline how taking into account the low rank structure assumption implicit in these dimension reduction approaches provides both computational and statistical advantages . We adapt recent randomized low-rank approximation algorithms to provide efficient solutions to three dimension reduction methods : Principal Component Analysis ( PCA ) , Sliced Inverse Regression ( SIR ) , and Localized Sliced Inverse Regression ( LSIR ) . A key observation in this paper is that randomization serves a dual role , improving both computational and statistical performance . This point is highlighted in our experiments on real and simulated data .
We introduce a method for constructing skills capable of solving tasks drawn from a distribution of parameterized reinforcement learning problems . The method draws example tasks from a distribution of interest and uses the corresponding learned policies to estimate the topology of the lower-dimensional piecewise-smooth manifold on which the skill policies lie . This manifold models how policy parameters change as task parameters vary . The method identifies the number of charts that compose the manifold and then applies non-linear regression in each chart to construct a parameterized skill by predicting policy parameters from task parameters . We evaluate our method on an underactuated simulated robotic arm tasked with learning to accurately throw darts at a parameterized target location .
Approximate Bayesian Computation ( ABC ) is a method to obtain a posterior distribution without a likelihood function , using simulations and a set of distance metrics . For that reason , it has recently been gaining popularity as an analysis tool in cosmology and astrophysics . Its drawback , however , is a slow convergence rate . We propose a novel method , which we call qABC , to accelerate ABC with Quantile Regression . In this method , we create a model of quantiles of distance measure as a function of input parameters . This model is trained on a small number of simulations and estimates which regions of the prior space are likely to be accepted into the posterior . Other regions are then immediately rejected . This procedure is then repeated as more simulations are available . We apply it to the practical problem of estimation of redshift distribution of cosmological samples , using forward modelling developed in previous work . The qABC method converges to nearly same posterior as the basic ABC . It uses , however , only 00\% of the number of simulations compared to basic ABC , achieving a fivefold gain in execution time for our problem . For other problems the acceleration rate may vary ; it depends on how close the prior is to the final posterior . We discuss possible improvements and extensions to this method .
The Dirichlet process and its extension , the Pitman-Yor process , are stochastic processes that take probability distributions as a parameter . These processes can be stacked up to form a hierarchical nonparametric Bayesian model . In this article , we present efficient methods for the use of these processes in this hierarchical context , and apply them to latent variable models for text analytics . In particular , we propose a general framework for designing these Bayesian models , which are called topic models in the computer science community . We then propose a specific nonparametric Bayesian topic model for modelling text from social media . We focus on tweets ( posts on Twitter ) in this article due to their ease of access . We find that our nonparametric model performs better than existing parametric models in both goodness of fit and real world applications .
A novel multi-resolution cluster detection ( MCD ) method is proposed to identify irregularly shaped clusters in space . Multi-scale test statistic on a single cell is derived based on likelihood ratio statistic for Bernoulli sequence , Poisson sequence and Normal sequence . A neighborhood variability measure is defined to select the optimal test threshold . The MCD method is compared with single scale testing methods controlling for false discovery rate and the spatial scan statistics using simulation and f-MRI data . The MCD method is shown to be more effective for discovering irregularly shaped clusters , and the implementation of this method does not require heavy computation , making it suitable for cluster detection for large spatial data .
The ability of having a sparse representation for a certain class of signals has many applications in data analysis , image processing , and other research fields . Among sparse representations , the cosparse analysis model has recently gained increasing interest . Many signals exhibit a multidimensional structure , e . g . images or three-dimensional MRI scans . Most data analysis and learning algorithms use vectorized signals and thereby do not account for this underlying structure . The drawback of not taking the inherent structure into account is a dramatic increase in computational cost . We propose an algorithm for learning a cosparse Analysis Operator that adheres to the preexisting structure of the data , and thus allows for a very efficient implementation . This is achieved by enforcing a separable structure on the learned operator . Our learning algorithm is able to deal with multidimensional data of arbitrary order . We evaluate our method on volumetric data at the example of three-dimensional MRI scans .
Various $\ell_0$-penalised estimation methods such as graphical lasso and CLIME are widely used for sparse precision matrix estimation . Many of these methods have been shown to be consistent under various quantitative assumptions about the underlying true covariance matrix . Intuitively , these conditions are related to situations where the penalty term will dominate the optimisation . In this paper , we explore the consistency of $\ell_0$-based methods for a class of sparse latent variable -like models , which are strongly motivated by several types of applications . We show that all $\ell_0$-based methods fail dramatically for models with nearly linear dependencies between the variables . We also study the consistency on models derived from real gene expression data and note that the assumptions needed for consistency never hold even for modest sized gene networks and $\ell_0$-based methods also become unreliable in practice for larger networks .
A set of probabilistic predictions is well calibrated if the events that are predicted to occur with probability p do in fact occur about p fraction of the time . Well calibrated predictions are particularly important when machine learning models are used in decision analysis . This paper presents two new non-parametric methods for calibrating outputs of binary classification models : a method based on the Bayes optimal selection and a method based on the Bayesian model averaging . The advantage of these methods is that they are independent of the algorithm used to learn a predictive model , and they can be applied in a post-processing step , after the model is learned . This makes them applicable to a wide variety of machine learning models and methods . These calibration methods , as well as other methods , are tested on a variety of datasets in terms of both discrimination and calibration performance . The results show the methods either outperform or are comparable in performance to the state-of-the-art calibration methods .
Suppose a given observation matrix can be decomposed as the sum of a low-rank matrix and a sparse matrix ( outliers ) , and the goal is to recover these individual components from the observed sum . Such additive decompositions have applications in a variety of numerical problems including system identification , latent variable graphical modeling , and principal components analysis . We study conditions under which recovering such a decomposition is possible via a combination of $\ell_0$ norm and trace norm minimization . We are specifically interested in the question of how many outliers are allowed so that convex programming can still achieve accurate recovery , and we obtain stronger recovery guarantees than previous studies . Moreover , we do not assume that the spatial pattern of outliers is random , which stands in contrast to related analyses under such assumptions via matrix completion .
Driven by the advances in technology , large and high-dimensional data have become the rule rather than the exception . Approaches that allow for feature selection with such data are thus highly sought after , in particular , since standard methods , like cross-validated Lasso , can be computationally intractable and , in any case , lack theoretical guarantees . In this paper , we propose a novel approach to feature selection in regression . Consisting of simple optimization steps and tests , it is computationally more efficient than existing methods and , therefore , suited even for very large data sets . Moreover , in contrast to standard methods , it is equipped with sharp statistical guarantees . We thus expect that our algorithm can help to leverage the increasing volume of data in Biology , Public Health , Astronomy , Economics , and other fields .
Causal terminology is often introduced in the interpretation of encoding and decoding models trained on neuroimaging data . In this article , we investigate which causal statements are warranted and which ones are not supported by empirical evidence . We argue that the distinction between encoding and decoding models is not sufficient for this purpose : relevant features in encoding and decoding models carry a different meaning in stimulus- and in response-based experimental paradigms . We show that only encoding models in the stimulus-based setting support unambiguous causal interpretations . By combining encoding and decoding models trained on the same data , however , we obtain insights into causal relations beyond those that are implied by each individual model type . We illustrate the empirical relevance of our theoretical findings on EEG data recorded during a visuo-motor learning task .
Given samples from a distribution , how many new elements should we expect to find if we continue sampling this distribution ? This is an important and actively studied problem , with many applications ranging from unseen species estimation to genomics . We generalize this extrapolation and related unseen estimation problems to the multiple population setting , where population $j$ has an unknown distribution $D_j$ from which we observe $n_j$ samples . We derive an optimal estimator for the total number of elements we expect to find among new samples across the populations . Surprisingly , we prove that our estimator ' s accuracy is independent of the number of populations . We also develop an efficient optimization algorithm to solve the more general problem of estimating multi-population frequency distributions . We validate our methods and theory through extensive experiments . Finally , on a real dataset of human genomes across multiple ancestries , we demonstrate how our approach for unseen estimation can enable cohort designs that can discover interesting mutations with greater efficiency .
Over the past decade , the stellar growth of Indian economy has been challenged by persistently high levels of inflation , particularly in food prices . The primary reason behind this stubborn food inflation is mismatch in supply-demand , as domestic agricultural production has failed to keep up with rising demand owing to a number of proximate factors . The relative significance of these factors in determining the change in food prices have been analysed using gradient boosted regression trees ( BRT ) , a machine learning technique . The results from BRT indicates all predictor variables to be fairly significant in explaining the change in food prices , with MSP and farm wages being relatively more important than others . International food prices were found to have limited relevance in explaining the variation in domestic food prices . The challenge of ensuring food and nutritional security for growing Indian population with rising incomes needs to be addressed through resolute policy reforms .
Correlation matrices are omnipresent in multivariate data analysis . When the number $d$ of variables is large , the sample estimates of correlation matrices are typically noisy and conceal underlying dependence patterns . We consider the case when the variables can be grouped into $K$ clusters with exchangeable dependence ; an assumption often made in applications in finance and econometrics . Under this partial exchangeability condition , the corresponding correlation matrix has a block structure and the number of unknown parameters is reduced from $d ( d-0 ) /0$ to at most $K ( K+0 ) /0$ . We propose a robust algorithm based on Kendall ' s rank correlation to identify the clusters without assuming the knowledge of $K$ a priori or anything about the margins except continuity . The corresponding block-structured estimator performs considerably better than the sample Kendall rank correlation matrix when $K < d$ . Even in the unstructured case $K = d$ , though there is no gain asymptotically , the new estimator can be much more efficient in finite samples . When the data are elliptical , the results extend to linear correlation matrices and their inverses . The procedure is illustrated on financial stock returns .
The likelihood function of a finite mixture model is a non-convex function with multiple local maxima and commonly used iterative algorithms such as EM will converge to different solutions depending on initial conditions . In this paper we ask : is it possible to assess how far we are from the global maximum of the likelihood ? Since the likelihood of a finite mixture model can grow unboundedly by centering a Gaussian on a single datapoint and shrinking the covariance , we constrain the problem by assuming that the parameters of the individual models are members of a large discrete set ( e . g . estimating a mixture of two Gaussians where the means and variances of both Gaussians are members of a set of a million possible means and variances ) . For this setting we show that a simple upper bound on the likelihood can be computed using convex optimization and we analyze conditions under which the bound is guaranteed to be tight . This bound can then be used to assess the quality of solutions found by EM ( where the final result is projected on the discrete set ) or any other mixture estimation algorithm . For any dataset our method allows us to find a finite mixture model together with a dataset-specific bound on how far the likelihood of this mixture is from the global optimum of the likelihood
Model selection in clustering requires ( i ) to specify a suitable clustering principle and ( ii ) to control the model order complexity by choosing an appropriate number of clusters depending on the noise level in the data . We advocate an information theoretic perspective where the uncertainty in the measurements quantizes the set of data partitionings and , thereby , induces uncertainty in the solution space of clusterings . A clustering model , which can tolerate a higher level of fluctuations in the measurements than alternative models , is considered to be superior provided that the clustering solution is equally informative . This tradeoff between \emph{informativeness} and \emph{robustness} is used as a model selection criterion . The requirement that data partitionings should generalize from one data set to an equally probable second data set gives rise to a new notion of structure induced information .
Gaussian latent tree models , or more generally , Gaussian latent forest models have Fisher-information matrices that become singular along interesting submodels , namely , models that correspond to subforests . For these singularities , we compute the real log-canonical thresholds ( also known as stochastic complexities or learning coefficients ) that quantify the large-sample behavior of the marginal likelihood in Bayesian inference . This provides the information needed for a recently introduced generalization of the Bayesian information criterion . Our mathematical developments treat the general setting of Laplace integrals whose phase functions are sums of squared differences between monomials and constants . We clarify how in this case real log-canonical thresholds can be computed using polyhedral geometry , and we show how to apply the general theory to the Laplace integrals associated with Gaussian latent tree and forest models . In simulations and a data example , we demonstrate how the mathematical knowledge can be applied in model selection .
A method is given for calculating the strict minimum message length ( SMML ) estimator for 0-dimensional exponential families with continuous sufficient statistics . A set of $n$ equations are found that the $n$ cut-points of the SMML estimator must satisfy . These equations can be solved using Newton ' s method and this approach is used to produce new results and to replicate results that C . S . Wallace obtained using his boundary rules for the SMML estimator . A rigorous proof is also given that , despite being composed of step functions , the posterior probability corresponding to the SMML estimator is a continuous function of the data .
It is time-consuming and error-prone to implement inference procedures for each new probabilistic model . Probabilistic programming addresses this problem by allowing a user to specify the model and having a compiler automatically generate an inference procedure for it . For this approach to be practical , it is important to generate inference code that has reasonable performance . In this paper , we present a probabilistic programming language and compiler for Bayesian networks designed to make effective use of data-parallel architectures such as GPUs . Our language is fully integrated within the Scala programming language and benefits from tools such as IDE support , type-checking , and code completion . We show that the compiler can generate data-parallel inference code scalable to thousands of GPU cores by making use of the conditional independence relationships in the Bayesian network .
We propose a likelihood ratio based inferential framework for high dimensional semiparametric generalized linear models . This framework addresses a variety of challenging problems in high dimensional data analysis , including incomplete data , selection bias , and heterogeneous multitask learning . Our work has three main contributions . ( i ) We develop a regularized statistical chromatography approach to infer the parameter of interest under the proposed semiparametric generalized linear model without the need of estimating the unknown base measure function . ( ii ) We propose a new framework to construct post-regularization confidence regions and tests for the low dimensional components of high dimensional parameters . Unlike existing post-regularization inferential methods , our approach is based on a novel directional likelihood . In particular , the framework naturally handles generic regularized estimators with nonconvex penalty functions and it can be used to infer least false parameters under misspecified models . ( iii ) We develop new concentration inequalities and normal approximation results for U-statistics with unbounded kernels , which are of independent interest . We demonstrate the consequences of the general theory by using an example of missing data problem . Extensive simulation studies and real data analysis are provided to illustrate our proposed approach .
In this paper , we propose a new framework to remove parts of the systematic errors affecting popular restoration algorithms , with a special focus for image processing tasks . Generalizing ideas that emerged for $\ell_0$ regularization , we develop an approach re-fitting the results of standard methods towards the input data . Total variation regularizations and non-local means are special cases of interest . We identify important covariant information that should be preserved by the re-fitting method , and emphasize the importance of preserving the Jacobian ( w . r . t . the observed signal ) of the original estimator . Then , we provide an approach that has a " twicing " flavor and allows re-fitting the restored signal by adding back a local affine transformation of the residual term . We illustrate the benefits of our method on numerical simulations for image restoration tasks .
Stochastic blockmodels and variants thereof are among the most widely used approaches to community detection for social networks and relational data . A stochastic blockmodel partitions the nodes of a network into disjoint sets , called communities . The approach is inherently related to clustering with mixture models ; and raises a similar model selection problem for the number of communities . The Bayesian information criterion ( BIC ) is a popular solution , however , for stochastic blockmodels , the conditional independence assumption given the communities of the endpoints among different edges is usually violated in practice . In this regard , we propose composite likelihood BIC ( CL-BIC ) to select the number of communities , and we show it is robust against possible misspecifications in the underlying stochastic blockmodel assumptions . We derive the requisite methodology and illustrate the approach using both simulated and real data . Supplementary materials containing the relevant computer code are available online .
Recently , fundamental conditions on the sampling patterns have been obtained for finite completability of low-rank matrices or tensors given the corresponding ranks . In this paper , we consider the scenario where the rank is not given and we aim to approximate the unknown rank based on the location of sampled entries and some given completion . We consider a number of data models , including single-view matrix , multi-view matrix , CP tensor , tensor-train tensor and Tucker tensor . For each of these data models , we provide an upper bound on the rank when an arbitrary low-rank completion is given . We characterize these bounds both deterministically , i . e . , with probability one given that the sampling pattern satisfies certain combinatorial properties , and probabilistically , i . e . , with high probability given that the sampling probability is above some threshold . Moreover , for both single-view matrix and CP tensor , we are able to show that the obtained upper bound is exactly equal to the unknown rank if the lowest-rank completion is given . Furthermore , we provide numerical experiments for the case of single-view matrix , where we use nuclear norm minimization to find a low-rank completion of the sampled data and we observe that in most of the cases the proposed upper bound on the rank is equal to the true rank .
We present a new application and covering number bound for the framework of " Machine Learning with Operational Costs ( MLOC ) , " which is an exploratory form of decision theory . The MLOC framework incorporates knowledge about how a predictive model will be used for a subsequent task , thus combining machine learning with the decision that is made afterwards . In this work , we use the MLOC framework to study a problem that has implications for power grid reliability and maintenance , called the Machine Learning and Traveling Repairman Problem ML&TRP . The goal of the ML&TRP is to determine a route for a " repair crew , " which repairs nodes on a graph . The repair crew aims to minimize the cost of failures at the nodes , but as in many real situations , the failure probabilities are not known and must be estimated . The MLOC framework allows us to understand how this uncertainty influences the repair route . We also present new covering number generalization bounds for the MLOC framework .
Recent advances in Bayesian learning with large-scale data have witnessed emergence of stochastic gradient MCMC algorithms ( SG-MCMC ) , such as stochastic gradient Langevin dynamics ( SGLD ) , stochastic gradient Hamiltonian MCMC ( SGHMC ) , and the stochastic gradient thermostat . While finite-time convergence properties of the SGLD with a 0st-order Euler integrator have recently been studied , corresponding theory for general SG-MCMCs has not been explored . In this paper we consider general SG-MCMCs with high-order integrators , and develop theory to analyze finite-time convergence properties and their asymptotic invariant measures . Our theoretical results show faster convergence rates and more accurate invariant measures for SG-MCMCs with higher-order integrators . For example , with the proposed efficient 0nd-order symmetric splitting integrator , the {\em mean square error} ( MSE ) of the posterior average for the SGHMC achieves an optimal convergence rate of $L^{-0/0}$ at $L$ iterations , compared to $L^{-0/0}$ for the SGHMC and SGLD with 0st-order Euler integrators . Furthermore , convergence results of decreasing-step-size SG-MCMCs are also developed , with the same convergence rates as their fixed-step-size counterparts for a specific decreasing sequence . Experiments on both synthetic and real datasets verify our theory , and show advantages of the proposed method in two large-scale real applications .
Randomized experiments are the gold standard for evaluating the effects of changes to real-world systems , including Internet services . Data in these tests may be difficult to collect and outcomes may have high variance , resulting in potentially large measurement error . Bayesian optimization is a promising technique for optimizing multiple continuous parameters for field experiments , but existing approaches degrade in performance when the noise level is high . We derive an exact expression for expected improvement under greedy batch optimization with noisy observations and noisy constraints , and develop a quasi-Monte Carlo approximation that allows it to be efficiently optimized . Experiments with synthetic functions show that optimization performance on noisy , constrained problems outperforms existing methods . We further demonstrate the effectiveness of the method with two real experiments conducted at Facebook : optimizing a production ranking system , and optimizing web server compiler flags .
We introduce a new approach for amortizing inference in directed graphical models by learning heuristic approximations to stochastic inverses , designed specifically for use as proposal distributions in sequential Monte Carlo methods . We describe a procedure for constructing and learning a structured neural network which represents an inverse factorization of the graphical model , resulting in a conditional density estimator that takes as input particular values of the observed random variables , and returns an approximation to the distribution of the latent variables . This recognition model can be learned offline , independent from any particular dataset , prior to performing inference . The output of these networks can be used as automatically-learned high-quality proposal distributions to accelerate sequential Monte Carlo across a diverse range of problem settings .
We prove in this paper that the weighted volume of the set of integral transportation matrices between two integral histograms r and c of equal sum is a positive definite kernel of r and c when the set of considered weights forms a positive definite matrix . The computation of this quantity , despite being the subject of a significant research effort in algebraic statistics , remains an intractable challenge for histograms of even modest dimensions . We propose an alternative kernel which , rather than considering all matrices of the transportation polytope , only focuses on a sub-sample of its vertices known as its Northwestern corner solutions . The resulting kernel is positive definite and can be computed with a number of operations O ( R^0d ) that grows linearly in the complexity of the dimension d , where R^0 , the total amount of sampled vertices , is a parameter that controls the complexity of the kernel .
Metrics specifying distances between data points can be learned in a discriminative manner or from generative models . In this paper , we show how to unify generative and discriminative learning of metrics via a kernel learning framework . Specifically , we learn local metrics optimized from parametric generative models . These are then used as base kernels to construct a global kernel that minimizes a discriminative training criterion . We consider both linear and nonlinear combinations of local metric kernels . Our empirical results show that these combinations significantly improve performance on classification tasks . The proposed learning algorithm is also very efficient , achieving order of magnitude speedup in training time compared to previous discriminative baseline methods .
We present a robust multiple manifolds structure learning ( RMMSL ) scheme to robustly estimate data structures under the multiple low intrinsic dimensional manifolds assumption . In the local learning stage , RMMSL efficiently estimates local tangent space by weighted low-rank matrix factorization . In the global learning stage , we propose a robust manifold clustering method based on local structure learning results . The proposed clustering method is designed to get the flattest manifolds clusters by introducing a novel curved-level similarity function . Our approach is evaluated and compared to state-of-the-art methods on synthetic data , handwritten digit images , human motion capture data and motorbike videos . We demonstrate the effectiveness of the proposed approach , which yields higher clustering accuracy , and produces promising results for challenging tasks of human motion segmentation and motion flow learning from videos .
Recent work has shown that optical flow estimation can be formulated as a supervised learning task and can be successfully solved with convolutional networks . Training of the so-called FlowNet was enabled by a large synthetically generated dataset . The present paper extends the concept of optical flow estimation via convolutional networks to disparity and scene flow estimation . To this end , we propose three synthetic stereo video datasets with sufficient realism , variation , and size to successfully train large networks . Our datasets are the first large-scale datasets to enable training and evaluating scene flow methods . Besides the datasets , we present a convolutional network for real-time disparity estimation that provides state-of-the-art results . By combining a flow and disparity estimation network and training it jointly , we demonstrate the first scene flow estimation with a convolutional network .
Given iid samples from some unknown continuous density on hyper-rectangle $[0 , 0]^d$ , we attempt to learn a piecewise constant function that approximates this underlying density nonparametrically . Our density estimate is defined on a binary split of $[0 , 0]^d$ and built up sequentially according to discrepancy criteria ; the key ingredient is to control the discrepancy adaptively in each sub-rectangle to achieve overall bound . We prove that the estimate , even though simple as it appears , preserves most of the estimation power . By exploiting its structure , it can be directly applied to some important pattern recognition tasks such as mode seeking and density landscape exploration , we demonstrate its applicability through simulations and examples .
Modeling physiological time-series in ICU is of high clinical importance . However , data collected within ICU are irregular in time and often contain missing measurements . Since absence of a measure would signify its lack of importance , the missingness is indeed informative and might reflect the decision making by the clinician . Here we propose a deep learning architecture that can effectively handle these challenges for predicting ICU mortality outcomes . The model is based on Long Short-Term Memory , and has layered attention mechanisms . At the sensing layer , the model decides whether to observe and incorporate parts of the current measurements . At the reasoning layer , evidences across time steps are weighted and combined . The model is evaluated on the PhysioNet 0000 dataset showing competitive and interpretable results .
Positron Emission Tomography ( PET ) is a functional imaging modality widely used in neuroscience studies . To obtain meaningful quantitative results from PET images , attenuation correction is necessary during image reconstruction . For PET/MR hybrid systems , PET attenuation is challenging as Magnetic Resonance ( MR ) images do not reflect attenuation coefficients directly . To address this issue , we present deep neural network methods to derive the continuous attenuation coefficients for brain PET imaging from MR images . With only Dixon MR images as the network input , the existing U-net structure was adopted and analysis using forty patient data sets shows it is superior than other Dixon based methods . When both Dixon and zero echo time ( ZTE ) images are available , apart from stacking multiple MR images along the U-net input channels , we have proposed a new network structure to extract the features from Dixon and ZTE images independently at early layers and combine them together at later layers . Quantitative analysis based on fourteen real patient data sets demonstrates that both network approaches can perform better than the standard methods , and the proposed network structure can further reduce the PET quantification error compared to the U-net structure with multiple inputs .
This paper describes a pattern recognition approach aiming to estimate fuel cell duration time from electrochemical impedance spectroscopy measurements . It consists in first extracting features from both real and imaginary parts of the impedance spectrum . A parametric model is considered in the case of the real part , whereas regression model with latent variables is used in the latter case . Then , a linear regression model using different subsets of extracted features is used fo r the estimation of fuel cell time duration . The performances of the proposed approach are evaluated on experimental data set to show its feasibility . This could lead to interesting perspectives for predictive maintenance policy of fuel cell .
We present a Bayesian formulation of weighted stochastic block models that can be used to infer the large-scale modular structure of weighted networks , including their hierarchical organization . Our method is nonparametric , and thus does not require the prior knowledge of the number of groups or other dimensions of the model , which are instead inferred from data . We give a comprehensive treatment of different kinds of edge weights ( i . e . continuous or discrete , signed or unsigned , bounded or unbounded ) , as well as arbitrary weight transformations , and describe an unsupervised model selection approach to choose the best network description . We illustrate the application of our method to a variety of empirical weighted networks , such as global migrations , voting patterns in congress , and neural connections in the human brain .
We introduce a new approach to unsupervised estimation of feature-rich semantic role labeling models . Our model consists of two components : ( 0 ) an encoding component : a semantic role labeling model which predicts roles given a rich set of syntactic and lexical features ; ( 0 ) a reconstruction component : a tensor factorization model which relies on roles to predict argument fillers . When the components are estimated jointly to minimize errors in argument reconstruction , the induced roles largely correspond to roles defined in annotated resources . Our method performs on par with most accurate role induction methods on English and German , even though , unlike these previous approaches , we do not incorporate any prior linguistic knowledge about the languages .
Many powerful machine learning models are based on the composition of multiple processing layers , such as deep nets , which gives rise to nonconvex objective functions . A general , recent approach to optimise such " nested " functions is the method of auxiliary coordinates ( MAC ) . MAC introduces an auxiliary coordinate for each data point in order to decouple the nested model into independent submodels . This decomposes the optimisation into steps that alternate between training single layers and updating the coordinates . It has the advantage that it reuses existing single-layer algorithms , introduces parallelism , and does not need to use chain-rule gradients , so it works with nondifferentiable layers . With large-scale problems , or when distributing the computation is necessary for faster training , the dataset may not fit in a single machine . It is then essential to limit the amount of communication between machines so it does not obliterate the benefit of parallelism . We describe a general way to achieve this , ParMAC . ParMAC works on a cluster of processing machines with a circular topology and alternates two steps until convergence : one step trains the submodels in parallel using stochastic updates , and the other trains the coordinates in parallel . Only submodel parameters , no data or coordinates , are ever communicated between machines . ParMAC exhibits high parallelism , low communication overhead , and facilitates data shuffling , load balancing , fault tolerance and streaming data processing . We study the convergence of ParMAC and propose a theoretical model of its runtime and parallel speedup . We develop ParMAC to learn binary autoencoders for fast , approximate image retrieval . We implement it in MPI in a distributed system and demonstrate nearly perfect speedups in a 000-processor cluster with a training set of 000 million high-dimensional points .
Quantum control is valuable for various quantum technologies such as high-fidelity gates for universal quantum computing , adaptive quantum-enhanced metrology , and ultra-cold atom manipulation . Although supervised machine learning and reinforcement learning are widely used for optimizing control parameters in classical systems , quantum control for parameter optimization is mainly pursued via gradient-based greedy algorithms . Although the quantum fitness landscape is often compatible with greedy algorithms , sometimes greedy algorithms yield poor results , especially for large-dimensional quantum systems . We employ differential evolution algorithms to circumvent the stagnation problem of non-convex optimization . We improve quantum control fidelity for noisy system by averaging over the objective function . To reduce computational cost , we introduce heuristics for early termination of runs and for adaptive selection of search subspaces . Our implementation is massively parallel and vectorized to reduce run time even further . We demonstrate our methods with two examples , namely quantum phase estimation and quantum gate design , for which we achieve superior fidelity and scalability than obtained using greedy algorithms .
We propose a method for learning Markov network structures for continuous data without invoking any assumptions about the distribution of the variables . The method makes use of previous work on a non-parametric estimator for mutual information which is used to create a non-parametric test for multivariate conditional independence . This independence test is then combined with an efficient constraint-based algorithm for learning the graph structure . The performance of the method is evaluated on several synthetic data sets and it is shown to learn considerably more accurate structures than competing methods when the dependencies between the variables involve non-linearities .
We study a norm for structured sparsity which leads to sparse linear predictors whose supports are unions of prede ned overlapping groups of variables . We call the obtained formulation latent group Lasso , since it is based on applying the usual group Lasso penalty on a set of latent variables . A detailed analysis of the norm and its properties is presented and we characterize conditions under which the set of groups associated with latent variables are correctly identi ed . We motivate and discuss the delicate choice of weights associated to each group , and illustrate this approach on simulated data and on the problem of breast cancer prognosis from gene expression data .
Generalized linear model with $L_0$ and $L_0$ regularization is a widely used technique for solving classification , class probability estimation and regression problems . With the numbers of both features and examples growing rapidly in the fields like text mining and clickstream data analysis parallelization and the use of cluster architectures becomes important . We present a novel algorithm for fitting regularized generalized linear models in the distributed environment . The algorithm splits data between nodes by features , uses coordinate descent on each node and line search to merge results globally . Convergence proof is provided . A modifications of the algorithm addresses slow node problem . For an important particular case of logistic regression we empirically compare our program with several state-of-the art approaches that rely on different algorithmic and data spitting methods . Experiments demonstrate that our approach is scalable and superior when training on large and sparse datasets .
This paper gives new concentration inequalities for the spectral norm of a wide class of matrix martingales in continuous time . These results extend previously established Freedman and Bernstein inequalities for series of random matrices to the class of continuous time processes . Our analysis relies on a new supermartingale property of the trace exponential proved within the framework of stochastic calculus . We provide also several examples that illustrate the fact that our results allow us to recover easily several formerly obtained sharp bounds for discrete time matrix martingales .
Multithreshold Entropy Linear Classifier ( MELC ) is a density based model which searches for a linear projection maximizing the Cauchy-Schwarz Divergence of dataset kernel density estimation . Despite its good empirical results , one of its drawbacks is the optimization speed . In this paper we analyze how one can speed it up through solving an approximate problem . We analyze two methods , both similar to the approximate solutions of the Kernel Density Estimation querying and provide adaptive schemes for selecting a crucial parameters based on user-specified acceptable error . Furthermore we show how one can exploit well known conjugate gradients and L-BFGS optimizers despite the fact that the original optimization problem should be solved on the sphere . All above methods and modifications are tested on 00 real life datasets from UCI repository to confirm their practical usability .
Using methods of statistical physics , we analyse the error of learning couplings in large Ising models from independent data ( the inverse Ising problem ) . We concentrate on learning based on local cost functions , such as the pseudo-likelihood method for which the couplings are inferred independently for each spin . Assuming that the data are generated from a true Ising model , we compute the reconstruction error of the couplings using a combination of the replica method with the cavity approach for densely connected systems . We show that an explicit estimator based on a quadratic cost function achieves minimal reconstruction error , but requires the length of the true coupling vector as prior knowledge . A simple mean field estimator of the couplings which does not need such knowledge is asymptotically optimal , i . e . when the number of observations is much large than the number of spins . Comparison of the theory with numerical simulations shows excellent agreement for data generated from two models with random couplings in the high temperature region : a model with independent couplings ( Sherrington-Kirkpatrick model ) , and a model where the matrix of couplings has a Wishart distribution .
Nonnegative Matrix Factorization ( NMF ) aims to factorize a matrix into two optimized nonnegative matrices appropriate for the intended applications . The method has been widely used for unsupervised learning tasks , including recommender systems ( rating matrix of users by items ) and document clustering ( weighting matrix of papers by keywords ) . However , traditional NMF methods typically assume the number of latent factors ( i . e . , dimensionality of the loading matrices ) to be fixed . This assumption makes them inflexible for many applications . In this paper , we propose a nonparametric NMF framework to mitigate this issue by using dependent Indian Buffet Processes ( dIBP ) . In a nutshell , we apply a correlation function for the generation of two stick weights associated with each pair of columns of loading matrices , while still maintaining their respective marginal distribution specified by IBP . As a consequence , the generation of two loading matrices will be column-wise ( indirectly ) correlated . Under this same framework , two classes of correlation function are proposed ( 0 ) using Bivariate beta distribution and ( 0 ) using Copula function . Both methods allow us to adopt our work for various applications by flexibly choosing an appropriate parameter settings . Compared with the other state-of-the art approaches in this area , such as using Gaussian Process ( GP ) -based dIBP , our work is seen to be much more flexible in terms of allowing the two corresponding binary matrix columns to have greater variations in their non-zero entries . Our experiments on the real-world and synthetic datasets show that three proposed models perform well on the document clustering task comparing standard NMF without predefining the dimension for the factor matrices , and the Bivariate beta distribution-based and Copula-based models have better flexibility than the GP-based model .
We introduce a probabilistic approach to the LMS filter . By means of an efficient approximation , this approach provides an adaptable step-size LMS algorithm together with a measure of uncertainty about the estimation . In addition , the proposed approximation preserves the linear complexity of the standard LMS . Numerical results show the improved performance of the algorithm with respect to standard LMS and state-of-the-art algorithms with similar complexity . The goal of this work , therefore , is to open the door to bring some more Bayesian machine learning techniques to adaptive filtering .
While many multiple graph inference methodologies operate under the implicit assumption that an explicit vertex correspondence is known across the vertex sets of the graphs , in practice these correspondences may only be partially or errorfully known . Herein , we provide an information theoretic foundation for understanding the practical impact that errorfully observed vertex correspondences can have on subsequent inference , and the capacity of graph matching methods to recover the lost vertex alignment and inferential performance . Working in the correlated stochastic blockmodel setting , we establish a duality between the loss of mutual information due to an errorfully observed vertex correspondence and the ability of graph matching algorithms to recover the true correspondence across graphs . In the process , we establish a phase transition for graph matchability in terms of the correlation across graphs , and we conjecture the analogous phase transition for the relative information loss due to shuffling vertex labels . We demonstrate the practical effect that graph shuffling---and matching---can have on subsequent inference , with examples from two sample graph hypothesis testing and joint spectral graph clustering .
Deep conditional generative models are developed to simultaneously learn the temporal dependencies of multiple sequences . The model is designed by introducing a three-way weight tensor to capture the multiplicative interactions between side information and sequences . The proposed model builds on the Temporal Sigmoid Belief Network ( TSBN ) , a sequential stack of Sigmoid Belief Networks ( SBNs ) . The transition matrices are further factored to reduce the number of parameters and improve generalization . When side information is not available , a general framework for semi-supervised learning based on the proposed model is constituted , allowing robust sequence classification . Experimental results show that the proposed approach achieves state-of-the-art predictive and classification performance on sequential data , and has the capacity to synthesize sequences , with controlled style transitioning and blending .
The use of brain images as markers for diseases or behavioral differences is challenged by the small effects size and the ensuing lack of power , an issue that has incited researchers to rely more systematically on large cohorts . Coupled with resolution increases , this leads to very large datasets . A striking example in the case of brain imaging is that of the Human Connectome Project : 00 Terabytes of data and growing . The resulting data deluge poses severe challenges regarding the tractability of some processing steps ( discriminant analysis , multivariate models ) due to the memory demands posed by these data . In this work , we revisit dimension reduction approaches , such as random projections , with the aim of replacing costly function evaluations by cheaper ones while decreasing the memory requirements . Specifically , we investigate the use of alternate schemes , based on fast clustering , that are well suited for signals exhibiting a strong spatial structure , such as anatomical and functional brain images . Our contribution is twofold : i ) we propose a linear-time clustering scheme that bypasses the percolation issues inherent in these algorithms and thus provides compressions nearly as good as traditional quadratic-complexity variance-minimizing clustering schemes , ii ) we show that cluster-based compression can have the virtuous effect of removing high-frequency noise , actually improving subsequent estimations steps . As a consequence , the proposed approach yields very accurate models on several large-scale problems yet with impressive gains in computational efficiency , making it possible to analyze large datasets .
We propose a tree regularization framework , which enables many tree models to perform feature selection efficiently . The key idea of the regularization framework is to penalize selecting a new feature for splitting when its gain ( e . g . information gain ) is similar to the features used in previous splits . The regularization framework is applied on random forest and boosted trees here , and can be easily applied to other tree models . Experimental studies show that the regularized trees can select high-quality feature subsets with regard to both strong and weak classifiers . Because tree models can naturally deal with categorical and numerical variables , missing values , different scales between variables , interactions and nonlinearities etc . , the tree regularization framework provides an effective and efficient feature selection solution for many practical problems .
We present a new method for forecasting systems of multiple interrelated time series . The method learns the forecast models together with discovering leading indicators from within the system that serve as good predictors improving the forecast accuracy and a cluster structure of the predictive tasks around these . The method is based on the classical linear vector autoregressive model ( VAR ) and links the discovery of the leading indicators to inferring sparse graphs of Granger causality . We formulate a new constrained optimisation problem to promote the desired sparse structures across the models and the sharing of information amongst the learning tasks in a multi-task manner . We propose an algorithm for solving the problem and document on a battery of synthetic and real-data experiments the advantages of our new method over baseline VAR models as well as the state-of-the-art sparse VAR learning methods .
This paper studies the deviations of the regret in a stochastic multi-armed bandit problem . When the total number of plays n is known beforehand by the agent , Audibert et al . ( 0000 ) exhibit a policy such that with probability at least 0-0/n , the regret of the policy is of order log ( n ) . They have also shown that such a property is not shared by the popular ucb0 policy of Auer et al . ( 0000 ) . This work first answers an open question : it extends this negative result to any anytime policy . The second contribution of this paper is to design anytime robust policies for specific multi-armed bandit problems in which some restrictions are put on the set of possible distributions of the different arms .
When learning a hidden Markov model ( HMM ) , sequen- tial observations can often be complemented by real-valued summary response variables generated from the path of hid- den states . Such settings arise in numerous domains , includ- ing many applications in biology , like motif discovery and genome annotation . In this paper , we present a flexible frame- work for jointly modeling both latent sequence features and the functional mapping that relates the summary response variables to the hidden state sequence . The algorithm is com- patible with a rich set of mapping functions . Results show that the availability of additional continuous response vari- ables can simultaneously improve the annotation of the se- quential observations and yield good prediction performance in both synthetic data and real-world datasets .
Many cognitive , sensory and motor processes have correlates in oscillatory neural sources , which are embedded as a subspace into the recorded brain signals . Decoding such processes from noisy magnetoencephalogram/electroencephalogram ( M/EEG ) signals usually requires the use of data-driven analysis methods . The objective evaluation of such decoding algorithms on experimental raw signals , however , is a challenge : the amount of available M/EEG data typically is limited , labels can be unreliable , and raw signals often are contaminated with artifacts . The latter is specifically problematic , if the artifacts stem from behavioral confounds of the oscillatory neural processes of interest . To overcome some of these problems , simulation frameworks have been introduced for benchmarking decoding methods . Generating artificial brain signals , however , most simulation frameworks make strong and partially unrealistic assumptions about brain activity , which limits the generalization of obtained results to real-world conditions . In the present contribution , we thrive to remove many shortcomings of current simulation frameworks and propose a versatile alternative , that allows for objective evaluation and benchmarking of novel data-driven decoding methods for neural signals . Its central idea is to utilize post-hoc labelings of arbitrary M/EEG recordings . This strategy makes it paradigm-agnostic and allows to generate comparatively large datasets with noiseless labels . Source code and data of the novel simulation approach are made available for facilitating its adoption .
Two classes of gamma-ray bursts ( GRBs ) , short and long , have been determined without any doubts , and are usually ascribed to different progenitors , yet these classes overlap for a variety of descriptive parameters . A subsample of 00 long and 00 short $Fermi$ GRBs with estimated Hurst Exponents ( HEs ) , complemented by minimum variability time-scales ( MVTS ) and durations ( $T_{00}$ ) is used to perform a supervised Machine Learning ( ML ) and Monte Carlo ( MC ) simulation using a Support Vector Machine ( SVM ) algorithm . It is found that while $T_{00}$ itself performs very well in distinguishing short and long GRBs , the overall success ratio is higher when the training set is complemented by MVTS and HE . These results may allow to introduce a new ( non-linear ) parameter that might provide less ambiguous classification of GRBs .
Google uses continuous streams of data from industry partners in order to deliver accurate results to users . Unexpected drops in traffic can be an indication of an underlying issue and may be an early warning that remedial action may be necessary . Detecting such drops is non-trivial because streams are variable and noisy , with roughly regular spikes ( in many different shapes ) in traffic data . We investigated the question of whether or not we can predict anomalies in these data streams . Our goal is to utilize Machine Learning and statistical approaches to classify anomalous drops in periodic , but noisy , traffic patterns . Since we do not have a large body of labeled examples to directly apply supervised learning for anomaly classification , we approached the problem in two parts . First we used TensorFlow to train our various models including DNNs , RNNs , and LSTMs to perform regression and predict the expected value in the time series . Secondly we created anomaly detection rules that compared the actual values to predicted values . Since the problem requires finding sustained anomalies , rather than just short delays or momentary inactivity in the data , our two detection methods focused on continuous sections of activity rather than just single points . We tried multiple combinations of our models and rules and found that using the intersection of our two anomaly detection methods proved to be an effective method of detecting anomalies on almost all of our models . In the process we also found that not all data fell within our experimental assumptions , as one data stream had no periodicity , and therefore no time based model could predict it .
Major histocompatibility complex class two ( MHC-II ) molecules are trans-membrane proteins and key components of the cellular immune system . Upon recognition of foreign peptides expressed on the MHC-II binding groove , helper T cells mount an immune response against invading pathogens . Therefore , mechanistic identification and knowledge of physico-chemical features that govern interactions between peptides and MHC-II molecules is useful for the design of effective epitope-based vaccines , as well as for understanding of immune responses . In this paper , we present a comprehensive trans-allelic prediction model , a generalized version of our previous biophysical model , that can predict peptide interactions for all three human MHC-II loci ( HLA-DR , HLA-DP and HLA-DQ ) , using both peptide sequence data and structural information of MHC-II molecules . The advantage of this approach over other machine learning models is that it offers a simple and plausible physical explanation for peptide-MHC-II interactions . We train the model using a benchmark experimental dataset , and measure its predictive performance using novel data . Despite its relative simplicity , we find that the model has comparable performance to the state-of-the-art method . Focusing on the physical bases of peptide-MHC binding , we find support for previous theoretical predictions about the contributions of certain binding pockets to the binding energy . Additionally , we find that binding pockets P 0 and P 0 of HLA-DP , which were not previously considered as primary anchors , do make strong contributions to the binding energy . Together , the results indicate that our model can serve as a useful complement to alternative approaches to predicting peptide-MHC interactions .
This paper addresses classification tasks on a particular target domain in which labeled training data are only available from source domains different from ( but related to ) the target . Two closely related frameworks , domain adaptation and domain generalization , are concerned with such tasks , where the only difference between those frameworks is the availability of the unlabeled target data : domain adaptation can leverage unlabeled target information , while domain generalization cannot . We propose Scatter Component Analyis ( SCA ) , a fast representation learning algorithm that can be applied to both domain adaptation and domain generalization . SCA is based on a simple geometrical measure , i . e . , scatter , which operates on reproducing kernel Hilbert space . SCA finds a representation that trades between maximizing the separability of classes , minimizing the mismatch between domains , and maximizing the separability of data ; each of which is quantified through scatter . The optimization problem of SCA can be reduced to a generalized eigenvalue problem , which results in a fast and exact solution . Comprehensive experiments on benchmark cross-domain object recognition datasets verify that SCA performs much faster than several state-of-the-art algorithms and also provides state-of-the-art classification accuracy in both domain adaptation and domain generalization . We also show that scatter can be used to establish a theoretical generalization bound in the case of domain adaptation .
High dimensional superposition models characterize observations using parameters which can be written as a sum of multiple component parameters , each with its own structure , e . g . , sum of low rank and sparse matrices , sum of sparse and rotated sparse vectors , etc . In this paper , we consider general superposition models which allow sum of any number of component parameters , and each component structure can be characterized by any norm . We present a simple estimator for such models , give a geometric condition under which the components can be accurately estimated , characterize sample complexity of the estimator , and give high probability non-asymptotic bounds on the componentwise estimation error . We use tools from empirical processes and generic chaining for the statistical analysis , and our results , which substantially generalize prior work on superposition models , are in terms of Gaussian widths of suitable sets .
As technology become more advanced , those who design , use and are otherwise affected by it want to know that it will perform correctly , and understand why it does what it does , and how to use it appropriately . In essence they want to be able to trust the systems that are being designed . In this survey we present assurances that are the method by which users can understand how to trust this technology . Trust between humans and autonomy is reviewed , and the implications for the design of assurances are highlighted . A survey of research that has been performed with respect to assurances is presented , and several key ideas are extracted in order to refine the definition of assurances . Several directions for future research are identified and discussed .
Current status data is a data format where the time to event is restricted to knowledge of whether or not the failure time exceeds a random monitoring time . We develop a support vector machine learning method for current status data that estimates the failure time expectation as a function of the covariates . In order to obtain the support vector machine decision function , we minimize a regularized version of the empirical risk with respect to a data-dependent loss . We show that the decision function has a closed form . Using finite sample bounds and novel oracle inequalities , we prove that the obtained decision function converges to the true conditional expectation for a large family of probability measures and study the associated learning rates . Finally we present a simulation study that compares the performance of the proposed approach to current state of the art .
Bayesian nonparametrics are a class of probabilistic models in which the model size is inferred from data . A recently developed methodology in this field is small-variance asymptotic analysis , a mathematical technique for deriving learning algorithms that capture much of the flexibility of Bayesian nonparametric inference algorithms , but are simpler to implement and less computationally expensive . Past work on small-variance analysis of Bayesian nonparametric inference algorithms has exclusively considered batch models trained on a single , static dataset , which are incapable of capturing time evolution in the latent structure of the data . This work presents a small-variance analysis of the maximum a posteriori filtering problem for a temporally varying mixture model with a Markov dependence structure , which captures temporally evolving clusters within a dataset . Two clustering algorithms result from the analysis : D-Means , an iterative clustering algorithm for linearly separable , spherical clusters ; and SD-Means , a spectral clustering algorithm derived from a kernelized , relaxed version of the clustering problem . Empirical results from experiments demonstrate the advantages of using D-Means and SD-Means over contemporary clustering algorithms , in terms of both computational cost and clustering accuracy .
In sparse signal representation , the choice of a dictionary often involves a tradeoff between two desirable properties -- the ability to adapt to specific signal data and a fast implementation of the dictionary . To sparsely represent signals residing on weighted graphs , an additional design challenge is to incorporate the intrinsic geometric structure of the irregular data domain into the atoms of the dictionary . In this work , we propose a parametric dictionary learning algorithm to design data-adapted , structured dictionaries that sparsely represent graph signals . In particular , we model graph signals as combinations of overlapping local patterns . We impose the constraint that each dictionary is a concatenation of subdictionaries , with each subdictionary being a polynomial of the graph Laplacian matrix , representing a single pattern translated to different areas of the graph . The learning algorithm adapts the patterns to a training set of graph signals . Experimental results on both synthetic and real datasets demonstrate that the dictionaries learned by the proposed algorithm are competitive with and often better than unstructured dictionaries learned by state-of-the-art numerical learning algorithms in terms of sparse approximation of graph signals . In contrast to the unstructured dictionaries , however , the dictionaries learned by the proposed algorithm feature localized atoms and can be implemented in a computationally efficient manner in signal processing tasks such as compression , denoising , and classification .
We consider the structure learning problem for graphical models that we call loosely connected Markov random fields , in which the number of short paths between any pair of nodes is small , and present a new conditional independence test based algorithm for learning the underlying graph structure . The novel maximization step in our algorithm ensures that the true edges are detected correctly even when there are short cycles in the graph . The number of samples required by our algorithm is C*log p , where p is the size of the graph and the constant C depends on the parameters of the model . We show that several previously studied models are examples of loosely connected Markov random fields , and our algorithm achieves the same or lower computational complexity than the previously designed algorithms for individual cases . We also get new results for more general graphical models , in particular , our algorithm learns general Ising models on the Erdos-Renyi random graph G ( p , c/p ) correctly with running time O ( np^0 ) .
Active learning ( AL ) is a learning paradigm where an active learner has to train a model ( e . g . , a classifier ) which is in principal trained in a supervised way , but in AL it has to be done by means of a data set with initially unlabeled samples . To get labels for these samples , the active learner has to ask an oracle ( e . g . , a human expert ) for labels . The goal is to maximize the performance of the model and to minimize the number of queries at the same time . In this article , we first briefly discuss the state of the art and own , preliminary work in the field of AL . Then , we propose the concept of collaborative active learning ( CAL ) . With CAL , we will overcome some of the harsh limitations of current AL . In particular , we envision scenarios where an expert may be wrong for various reasons , there might be several or even many experts with different expertise , the experts may label not only samples but also knowledge at a higher level such as rules , and we consider that the labeling costs depend on many conditions . Moreover , in a CAL process human experts will profit by improving their own knowledge , too .
Variational inference has become a widely used method to approximate posteriors in complex latent variables models . However , deriving a variational inference algorithm generally requires significant model-specific analysis , and these efforts can hinder and deter us from quickly developing and exploring a variety of models for a problem at hand . In this paper , we present a " black box " variational inference algorithm , one that can be quickly applied to many models with little additional derivation . Our method is based on a stochastic optimization of the variational objective where the noisy gradient is computed from Monte Carlo samples from the variational distribution . We develop a number of methods to reduce the variance of the gradient , always maintaining the criterion that we want to avoid difficult model-based derivations . We evaluate our method against the corresponding black box sampling based methods . We find that our method reaches better predictive likelihoods much faster than sampling methods . Finally , we demonstrate that Black Box Variational Inference lets us easily explore a wide space of models by quickly constructing and evaluating several models of longitudinal healthcare data .
Why does Deep Learning work ? What representations does it capture ? How do higher-order representations emerge ? We study these questions from the perspective of group theory , thereby opening a new approach towards a theory of Deep learning . One factor behind the recent resurgence of the subject is a key algorithmic step called pre-training : first search for a good generative model for the input samples , and repeat the process one layer at a time . We show deeper implications of this simple principle , by establishing a connection with the interplay of orbits and stabilizers of group actions . Although the neural networks themselves may not form groups , we show the existence of {\em shadow} groups whose elements serve as close approximations . Over the shadow groups , the pre-training step , originally introduced as a mechanism to better initialize a network , becomes equivalent to a search for features with minimal orbits . Intuitively , these features are in a way the {\em simplest} . Which explains why a deep learning network learns simple features first . Next , we show how the same principle , when repeated in the deeper layers , can capture higher order representations , and why representation complexity increases as the layers get deeper .
We present a method to estimate block membership of nodes in a random graph generated by a stochastic blockmodel . We use an embedding procedure motivated by the random dot product graph model , a particular example of the latent position model . The embedding associates each node with a vector ; these vectors are clustered via minimization of a square error criterion . We prove that this method is consistent for assigning nodes to blocks , as only a negligible number of nodes will be mis-assigned . We prove consistency of the method for directed and undirected graphs . The consistent block assignment makes possible consistent parameter estimation for a stochastic blockmodel . We extend the result in the setting where the number of blocks grows slowly with the number of nodes . Our method is also computationally feasible even for very large graphs . We compare our method to Laplacian spectral clustering through analysis of simulated data and a graph derived from Wikipedia documents .
Multivariate Pattern ( MVP ) classification can map different cognitive states to the brain tasks . One of the main challenges in MVP analysis is validating the generated results across subjects . However , analyzing multi-subject fMRI data requires accurate functional alignments between neuronal activities of different subjects , which can rapidly increase the performance and robustness of the final results . Hyperalignment ( HA ) is one of the most effective functional alignment methods , which can be mathematically formulated by the Canonical Correlation Analysis ( CCA ) methods . Since HA mostly uses the unsupervised CCA techniques , its solution may not be optimized for MVP analysis . By incorporating the idea of Local Discriminant Analysis ( LDA ) into CCA , this paper proposes Local Discriminant Hyperalignment ( LDHA ) as a novel supervised HA method , which can provide better functional alignment for MVP analysis . Indeed , the locality is defined based on the stimuli categories in the train-set , where the correlation between all stimuli in the same category will be maximized and the correlation between distinct categories of stimuli approaches to near zero . Experimental studies on multi-subject MVP analysis confirm that the LDHA method achieves superior performance to other state-of-the-art HA algorithms .
We study clustering algorithms based on neighborhood graphs on a random sample of data points . The question we ask is how such a graph should be constructed in order to obtain optimal clustering results . Which type of neighborhood graph should one choose , mutual k-nearest neighbor or symmetric k-nearest neighbor ? What is the optimal parameter k ? In our setting , clusters are defined as connected components of the t-level set of the underlying probability distribution . Clusters are said to be identified in the neighborhood graph if connected components in the graph correspond to the true underlying clusters . Using techniques from random geometric graph theory , we prove bounds on the probability that clusters are identified successfully , both in a noise-free and in a noisy setting . Those bounds lead to several conclusions . First , k has to be chosen surprisingly high ( rather of the order n than of the order log n ) to maximize the probability of cluster identification . Secondly , the major difference between the mutual and the symmetric k-nearest neighbor graph occurs when one attempts to detect the most significant cluster only .
We present a growing dimension asymptotic formalism . The perspective in this paper is classification theory and we show that it can accommodate probabilistic networks classifiers , including naive Bayes model and its augmented version . When represented as a Bayesian network these classifiers have an important advantage : The corresponding discriminant function turns out to be a specialized case of a generalized additive model , which makes it possible to get closed form expressions for the asymptotic misclassification probabilities used here as a measure of classification accuracy . Moreover , in this paper we propose a new quantity for assessing the discriminative power of a set of features which is then used to elaborate the augmented naive Bayes classifier . The result is a weighted form of the augmented naive Bayes that distributes weights among the sets of features according to their discriminative power . We derive the asymptotic distribution of the sample based discriminative power and show that it is seriously overestimated in a high dimensional case . We then apply this result to find the optimal , in a sense of minimum misclassification probability , type of weighting .
Learning linear combinations of multiple kernels is an appealing strategy when the right choice of features is unknown . Previous approaches to multiple kernel learning ( MKL ) promote sparse kernel combinations to support interpretability and scalability . Unfortunately , this 0-norm MKL is rarely observed to outperform trivial baselines in practical applications . To allow for robust kernel mixtures , we generalize MKL to arbitrary norms . We devise new insights on the connection between several existing MKL formulations and develop two efficient interleaved optimization strategies for arbitrary norms , like p-norms with p>0 . Empirically , we demonstrate that the interleaved optimization strategies are much faster compared to the commonly used wrapper approaches . A theoretical analysis and an experiment on controlled artificial data experiment sheds light on the appropriateness of sparse , non-sparse and $\ell_\infty$-norm MKL in various scenarios . Empirical applications of p-norm MKL to three real-world problems from computational biology show that non-sparse MKL achieves accuracies that go beyond the state-of-the-art .
Standard compressive sensing results state that to exactly recover an s sparse signal in R^p , one requires O ( s . log ( p ) ) measurements . While this bound is extremely useful in practice , often real world signals are not only sparse , but also exhibit structure in the sparsity pattern . We focus on group-structured patterns in this paper . Under this model , groups of signal coefficients are active ( or inactive ) together . The groups are predefined , but the particular set of groups that are active ( i . e . , in the signal support ) must be learned from measurements . We show that exploiting knowledge of groups can further reduce the number of measurements required for exact signal recovery , and derive universal bounds for the number of measurements needed . The bound is universal in the sense that it only depends on the number of groups under consideration , and not the particulars of the groups ( e . g . , compositions , sizes , extents , overlaps , etc . ) . Experiments show that our result holds for a variety of overlapping group configurations .
We propose local distributional smoothness ( LDS ) , a new notion of smoothness for statistical model that can be used as a regularization term to promote the smoothness of the model distribution . We named the LDS based regularization as virtual adversarial training ( VAT ) . The LDS of a model at an input datapoint is defined as the KL-divergence based robustness of the model distribution against local perturbation around the datapoint . VAT resembles adversarial training , but distinguishes itself in that it determines the adversarial direction from the model distribution alone without using the label information , making it applicable to semi-supervised learning . The computational cost for VAT is relatively low . For neural network , the approximated gradient of the LDS can be computed with no more than three pairs of forward and back propagations . When we applied our technique to supervised and semi-supervised learning for the MNIST dataset , it outperformed all the training methods other than the current state of the art method , which is based on a highly advanced generative model . We also applied our method to SVHN and NORB , and confirmed our method ' s superior performance over the current state of the art semi-supervised method applied to these datasets .
Most data is multi-dimensional . Discovering whether any subset of dimensions , or subspaces , of such data is significantly correlated is a core task in data mining . To do so , we require a measure that quantifies how correlated a subspace is . For practical use , such a measure should be universal in the sense that it captures correlation in subspaces of any dimensionality and allows to meaningfully compare correlation scores across different subspaces , regardless how many dimensions they have and what specific statistical properties their dimensions possess . Further , it would be nice if the measure can non-parametrically and efficiently capture both linear and non-linear correlations . In this paper , we propose UDS , a multivariate correlation measure that fulfills all of these desiderata . In short , we define \uds based on cumulative entropy and propose a principled normalization scheme to bring its scores across different subspaces to the same domain , enabling universal correlation assessment . UDS is purely non-parametric as we make no assumption on data distributions nor types of correlation . To compute it on empirical data , we introduce an efficient and non-parametric method . Extensive experiments show that UDS outperforms state of the art .
" Mixed Data " comprising a large number of heterogeneous variables ( e . g . count , binary , continuous , skewed continuous , among other data types ) are prevalent in varied areas such as genomics and proteomics , imaging genetics , national security , social networking , and Internet advertising . There have been limited efforts at statistically modeling such mixed data jointly , in part because of the lack of computationally amenable multivariate distributions that can capture direct dependencies between such mixed variables of different types . In this paper , we address this by introducing a novel class of Block Directed Markov Random Fields ( BDMRFs ) . Using the basic building block of node-conditional univariate exponential families from Yang et al . ( 0000 ) , we introduce a class of mixed conditional random field distributions , that are then chained according to a block-directed acyclic graph to form our class of Block Directed Markov Random Fields ( BDMRFs ) . The Markov independence graph structure underlying a BDMRF thus has both directed and undirected edges . We introduce conditions under which these distributions exist and are normalizable , study several instances of our models , and propose scalable penalized conditional likelihood estimators with statistical guarantees for recovering the underlying network structure . Simulations as well as an application to learning mixed genomic networks from next generation sequencing expression data and mutation data demonstrate the versatility of our methods .
We provide a unifying framework linking two classes of statistics used in two-sample and independence testing : on the one hand , the energy distances and distance covariances from the statistics literature ; on the other , distances between embeddings of distributions to reproducing kernel Hilbert spaces ( RKHS ) , as established in machine learning . The equivalence holds when energy distances are computed with semimetrics of negative type , in which case a kernel may be defined such that the RKHS distance between distributions corresponds exactly to the energy distance . We determine the class of probability distributions for which kernels induced by semimetrics are characteristic ( that is , for which embeddings of the distributions to an RKHS are injective ) . Finally , we investigate the performance of this family of kernels in two-sample and independence tests : we show in particular that the energy distance most commonly employed in statistics is just one member of a parametric family of kernels , and that other choices from this family can yield more powerful tests .
Critical to evaluating the capacity , scalability , and availability of web systems are realistic web traffic generators . Web traffic generation is a classic research problem , no generator accounts for the characteristics of web robots or crawlers that are now the dominant source of traffic to a web server . Administrators are thus unable to test , stress , and evaluate how their systems perform in the face of ever increasing levels of web robot traffic . To resolve this problem , this paper introduces a novel approach to generate synthetic web robot traffic with high fidelity . It generates traffic that accounts for both the temporal and behavioral qualities of robot traffic by statistical and Bayesian models that are fitted to the properties of robot traffic seen in web logs from North America and Europe . We evaluate our traffic generator by comparing the characteristics of generated traffic to those of the original data . We look at session arrival rates , inter-arrival times and session lengths , comparing and contrasting them between generated and real traffic . Finally , we show that our generated traffic affects cache performance similarly to actual traffic , using the common LRU and LFU eviction policies .
We propose a general semi-supervised inference framework focused on the estimation of the population mean . We consider both the ideal semi-supervised setting where infinitely many unlabeled samples are available , as well as the ordinary semi-supervised setting in which only a finite number of unlabeled samples is available . As usual in semi-supervised settings , there exists an unlabeled sample of covariate vectors and a labeled sample consisting of covariate vectors along with real-valued responses ( " labels " ) . Otherwise the formulation is " assumption-lean " in that no major conditions are imposed on the statistical or functional form of the data . Estimators are proposed along with corresponding confidence intervals for the population mean . Theoretical analysis on both the asymptotic behavior and $\ell_0$-risk for the proposed procedures are given . Surprisingly , the proposed estimators , based on a simple form of the least squares method , outperform the ordinary sample mean . The method is further extended to a nonparametric setting , in which the oracle rate can be achieved asymptotically . The proposed estimators are further illustrated by simulation studies and a real data example involving estimation of the homeless population .
Models of bags of words typically assume topic mixing so that the words in a single bag come from a limited number of topics . We show here that many sets of bag of words exhibit a very different pattern of variation than the patterns that are efficiently captured by topic mixing . In many cases , from one bag of words to the next , the words disappear and new ones appear as if the theme slowly and smoothly shifted across documents ( providing that the documents are somehow ordered ) . Examples of latent structure that describe such ordering are easily imagined . For example , the advancement of the date of the news stories is reflected in a smooth change over the theme of the day as certain evolving news stories fall out of favor and new events create new stories . Overlaps among the stories of consecutive days can be modeled by using windows over linearly arranged tight distributions over words . We show here that such strategy can be extended to multiple dimensions and cases where the ordering of data is not readily obvious . We demonstrate that this way of modeling covariation in word occurrences outperforms standard topic models in classification and prediction tasks in applications in biology , text modeling and computer vision .
Dendrograms used in data analysis are ultrametric spaces , hence objects of nonarchimedean geometry . It is known that there exist $p$-adic representation of dendrograms . Completed by a point at infinity , they can be viewed as subtrees of the Bruhat-Tits tree associated to the $p$-adic projective line . The implications are that certain moduli spaces known in algebraic geometry are $p$-adic parameter spaces of ( families of ) dendrograms , and stochastic classification can also be handled within this framework . At the end , we calculate the topology of the hidden part of a dendrogram .
Due to the dynamic nature of biological systems , biological networks underlying temporal process such as the development of {\it Drosophila melanogaster} can exhibit significant topological changes to facilitate dynamic regulatory functions . Thus it is essential to develop methodologies that capture the temporal evolution of networks , which make it possible to study the driving forces underlying dynamic rewiring of gene regulation circuity , and to predict future network structures . Using a new machine learning method called Tesla , which builds on a novel temporal logistic regression technique , we report the first successful genome-wide reverse-engineering of the latent sequence of temporally rewiring gene networks over more than 0000 genes during the life cycle of \textit{Drosophila melanogaster} , given longitudinal gene expression measurements and even when a single snapshot of such measurement resulted from each ( time-specific ) network is available . Our methods offer the first glimpse of time-specific snapshots and temporal evolution patterns of gene networks in a living organism during its full developmental course . The recovered networks with this unprecedented resolution chart the onset and duration of many gene interactions which are missed by typical static network analysis , and are suggestive of a wide array of other temporal behaviors of the gene network over time not noticed before .
This paper addresses the problem of filtering with a state-space model . Standard approaches for filtering assume that a probabilistic model for observations ( i . e . the observation model ) is given explicitly or at least parametrically . We consider a setting where this assumption is not satisfied ; we assume that the knowledge of the observation model is only provided by examples of state-observation pairs . This setting is important and appears when state variables are defined as quantities that are very different from the observations . We propose Kernel Monte Carlo Filter , a novel filtering method that is focused on this setting . Our approach is based on the framework of kernel mean embeddings , which enables nonparametric posterior inference using the state-observation examples . The proposed method represents state distributions as weighted samples , propagates these samples by sampling , estimates the state posteriors by Kernel Bayes ' Rule , and resamples by Kernel Herding . In particular , the sampling and resampling procedures are novel in being expressed using kernel mean embeddings , so we theoretically analyze their behaviors . We reveal the following properties , which are similar to those of corresponding procedures in particle methods : ( 0 ) the performance of sampling can degrade if the effective sample size of a weighted sample is small ; ( 0 ) resampling improves the sampling performance by increasing the effective sample size . We first demonstrate these theoretical findings by synthetic experiments . Then we show the effectiveness of the proposed filter by artificial and real data experiments , which include vision-based mobile robot localization .
We present a probabilistic language model for time-stamped text data which tracks the semantic evolution of individual words over time . The model represents words and contexts by latent trajectories in an embedding space . At each moment in time , the embedding vectors are inferred from a probabilistic version of word0vec [Mikolov et al . , 0000] . These embedding vectors are connected in time through a latent diffusion process . We describe two scalable variational inference algorithms--skip-gram smoothing and skip-gram filtering--that allow us to train the model jointly over all times ; thus learning on all data while simultaneously allowing word and context vectors to drift . Experimental results on three different corpora demonstrate that our dynamic model infers word embedding trajectories that are more interpretable and lead to higher predictive likelihoods than competing methods that are based on static models trained separately on time slices .
In this paper we propose a multi-armed bandit inspired , pool based active learning algorithm for the problem of binary classification . By carefully constructing an analogy between active learning and multi-armed bandits , we utilize ideas such as lower confidence bounds , and self-concordant regularization from the multi-armed bandit literature to design our proposed algorithm . Our algorithm is a sequential algorithm , which in each round assigns a sampling distribution on the pool , samples one point from this distribution , and queries the oracle for the label of this sampled point . The design of this sampling distribution is also inspired by the analogy between active learning and multi-armed bandits . We show how to derive lower confidence bounds required by our algorithm . Experimental comparisons to previously proposed active learning algorithms show superior performance on some standard UCI datasets .
The Kalman filter is extensively used for state estimation for linear systems under Gaussian noise . When non-Gaussian L\ ' evy noise is present , the conventional Kalman filter may fail to be effective due to the fact that the non-Gaussian L\ ' evy noise may have infinite variance . A modified Kalman filter for linear systems with non-Gaussian L\ ' evy noise is devised . It works effectively with reasonable computational cost . Simulation results are presented to illustrate this non-Gaussian filtering method .
Background : In cognitive neuroscience the potential of Deep Neural Networks ( DNNs ) for solving complex classification tasks is yet to be fully exploited . The most limiting factor is that DNNs as notorious ' black boxes ' do not provide insight into neurophysiological phenomena underlying a decision . Layer-wise Relevance Propagation ( LRP ) has been introduced as a novel method to explain individual network decisions . New Method : We propose the application of DNNs with LRP for the first time for EEG data analysis . Through LRP the single-trial DNN decisions are transformed into heatmaps indicating each data point ' s relevance for the outcome of the decision . Results : DNN achieves classification accuracies comparable to those of CSP-LDA . In subjects with low performance subject-to-subject transfer of trained DNNs can improve the results . The single-trial LRP heatmaps reveal neurophysiologically plausible patterns , resembling CSP-derived scalp maps . Critically , while CSP patterns represent class-wise aggregated information , LRP heatmaps pinpoint neural patterns to single time points in single trials . Comparison with Existing Method ( s ) : We compare the classification performance of DNNs to that of linear CSP-LDA on two data sets related to motor-imaginery BCI . Conclusion : We have demonstrated that DNN is a powerful non-linear tool for EEG analysis . With LRP a new quality of high-resolution assessment of neural activity can be reached . LRP is a potential remedy for the lack of interpretability of DNNs that has limited their utility in neuroscientific applications . The extreme specificity of the LRP-derived heatmaps opens up new avenues for investigating neural activity underlying complex perception or decision-related processes .
The goal of this paper is to improve learning for multivariate processes whose structure is dependent on some known graph topology ; especially when the number of available samples is much smaller than the number of variables . Typically , the graph information is incorporated into the learning process via a smoothness assumption postulating that the values supported on well-connected vertices exhibit small variations . We argue that smoothness is not enough . To capture the behavior of complex interconnected systems , such as transportation and biological networks , it is important to train expressive models , being able to reproduce a wide range of graph and temporal behaviors . Motivated by this need , this paper puts forth a novel definition of time-vertex wide-sense stationarity , or joint stationarity for short . We believe that the proposed definition is natural , at it intimately relates to existing definitions of stationarity in the time and vertex domains . We use joint stationarity to regularize learning and to reduce computational complexity in both estimation and recovery tasks . In particular , we show that for any jointly stationary process : ( a ) one can learn the covariance structure from O ( 0 ) samples , and ( b ) can solve MMSE recovery problems , such as interpolation , denoising , forecasting , in complexity that is linear to the edges and timesteps . Experiments with three datasets suggest that joint stationarity can yield significant accuracy improvements in the reconstruction effort of under-sampled problems , even when the graph is only approximately known or the process is only close to stationary .
We present a novel recurrent neural network ( RNN ) based model that combines the remembering ability of unitary RNNs with the ability of gated RNNs to effectively forget redundant/irrelevant information in its memory . We achieve this by extending unitary RNNs with a gating mechanism . Our model is able to outperform LSTMs , GRUs and Unitary RNNs on several long-term dependency benchmark tasks . We empirically both show the orthogonal/unitary RNNs lack the ability to forget and also the ability of GORU to simultaneously remember long term dependencies while forgetting irrelevant information . This plays an important role in recurrent neural networks . We provide competitive results along with an analysis of our model on many natural sequential tasks including the bAbI Question Answering , TIMIT speech spectrum prediction , Penn TreeBank , and synthetic tasks that involve long-term dependencies such as algorithmic , parenthesis , denoising and copying tasks .
In this paper we describe the problem of painter classification , and propose a novel approach based on deep convolutional autoencoder neural networks . While previous approaches relied on image processing and manual feature extraction from paintings , our approach operates on the raw pixel level , without any preprocessing or manual feature extraction . We first train a deep convolutional autoencoder on a dataset of paintings , and subsequently use it to initialize a supervised convolutional neural network for the classification phase . The proposed approach substantially outperforms previous methods , improving the previous state-of-the-art for the 0-painter classification problem from 00 . 00% accuracy ( previous state-of-the-art ) to 00 . 00% accuracy , i . e . , a 00% reduction in error rate .
We consider grouping as a general characterization for problems such as clustering , community detection in networks , and multiple parametric model estimation . We are interested in merging solutions from different grouping algorithms , distilling all their good qualities into a consensus solution . In this paper , we propose a bi-clustering framework and perspective for reaching consensus in such grouping problems . In particular , this is the first time that the task of finding/fitting multiple parametric models to a dataset is formally posed as a consensus problem . We highlight the equivalence of these tasks and establish the connection with the computational Gestalt program , that seeks to provide a psychologically-inspired detection theory for visual events . We also present a simple but powerful bi-clustering algorithm , specially tuned to the nature of the problem we address , though general enough to handle many different instances inscribed within our characterization . The presentation is accompanied with diverse and extensive experimental results in clustering , community detection , and multiple parametric model estimation in image processing applications .
Factorized information criterion ( FIC ) is a recently developed approximation technique for the marginal log-likelihood , which provides an automatic model selection framework for a few latent variable models ( LVMs ) with tractable inference algorithms . This paper reconsiders FIC and fills theoretical gaps of previous FIC studies . First , we reveal the core idea of FIC that allows generalization for a broader class of LVMs , including continuous LVMs , in contrast to previous FICs , which are applicable only to binary LVMs . Second , we investigate the model selection mechanism of the generalized FIC . Our analysis provides a formal justification of FIC as a model selection criterion for LVMs and also a systematic procedure for pruning redundant latent variables that have been removed heuristically in previous studies . Third , we provide an interpretation of FIC as a variational free energy and uncover a few previously-unknown their relationships . A demonstrative study on Bayesian principal component analysis is provided and numerical experiments support our theoretical results .
In this paper , we consider the streaming memory-limited matrix completion problem when the observed entries are noisy versions of a small random fraction of the original entries . We are interested in scenarios where the matrix size is very large so the matrix is very hard to store and manipulate . Here , columns of the observed matrix are presented sequentially and the goal is to complete the missing entries after one pass on the data with limited memory space and limited computational complexity . We propose a streaming algorithm which produces an estimate of the original matrix with a vanishing mean square error , uses memory space scaling linearly with the ambient dimension of the matrix , i . e . the memory required to store the output alone , and spends computations as much as the number of non-zero entries of the input matrix .
We introduce a new , efficient , principled and backpropagation-compatible algorithm for learning a probability distribution on the weights of a neural network , called Bayes by Backprop . It regularises the weights by minimising a compression cost , known as the variational free energy or the expected lower bound on the marginal likelihood . We show that this principled kind of regularisation yields comparable performance to dropout on MNIST classification . We then demonstrate how the learnt uncertainty in the weights can be used to improve generalisation in non-linear regression problems , and how this weight uncertainty can be used to drive the exploration-exploitation trade-off in reinforcement learning .
We consider the problem of reconstructing a low rank matrix from a subset of its entries and analyze two variants of the so-called Alternating Minimization algorithm , which has been proposed in the past . We establish that when the underlying matrix has rank $r=0$ , has positive bounded entries , and the graph $\mathcal{G}$ underlying the revealed entries has bounded degree and diameter which is at most logarithmic in the size of the matrix , both algorithms succeed in reconstructing the matrix approximately in polynomial time starting from an arbitrary initialization . We further provide simulation results which suggest that the second algorithm which is based on the message passing type updates , performs significantly better .
Affinity propagation is an exemplar-based clustering algorithm that finds a set of data-points that best exemplify the data , and associates each datapoint with one exemplar . We extend affinity propagation in a principled way to solve the hierarchical clustering problem , which arises in a variety of domains including biology , sensor networks and decision making in operational research . We derive an inference algorithm that operates by propagating information up and down the hierarchy , and is efficient despite the high-order potentials required for the graphical model formulation . We demonstrate that our method outperforms greedy techniques that cluster one layer at a time . We show that on an artificial dataset designed to mimic the HIV-strain mutation dynamics , our method outperforms related methods . For real HIV sequences , where the ground truth is not available , we show our method achieves better results , in terms of the underlying objective function , and show the results correspond meaningfully to geographical location and strain subtypes . Finally we report results on using the method for the analysis of mass spectra , showing it performs favorably compared to state-of-the-art methods .
The decentralized particle filter ( DPF ) was proposed recently to increase the level of parallelism of particle filtering . Given a decomposition of the state space into two nested sets of variables , the DPF uses a particle filter to sample the first set and then conditions on this sample to generate a set of samples for the second set of variables . The DPF can be understood as a variant of the popular Rao-Blackwellized particle filter ( RBPF ) , where the second step is carried out using Monte Carlo approximations instead of analytical inference . As a result , the range of applications of the DPF is broader than the one for the RBPF . In this paper , we improve the DPF in two ways . First , we derive a Monte Carlo approximation of the optimal proposal distribution and , consequently , design and implement a more efficient look-ahead DPF . Although the decentralized filters were initially designed to capitalize on parallel implementation , we show that the look-ahead DPF can outperform the standard particle filter even on a single machine . Second , we propose the use of bandit algorithms to automatically configure the state space decomposition of the DPF .
Over the past years Robust PCA has been established as a standard tool for reliable low-rank approximation of matrices in the presence of outliers . Recently , the Robust PCA approach via nuclear norm minimization has been extended to matrices with linear structures which appear in applications such as system identification and data series analysis . At the same time it has been shown how to control the rank of a structured approximation via matrix factorization approaches . The drawbacks of these methods either lie in the lack of robustness against outliers or in their static nature of repeated batch-processing . We present a Robust Structured Low-Rank Approximation method on the Grassmannian that on the one hand allows for fast re-initialization in an online setting due to subspace identification with manifolds , and that is robust against outliers due to a smooth approximation of the $\ell_p$-norm cost function on the other hand . The method is evaluated in online time series forecasting tasks on simulated and real-world data .
We propose a K-sparse exhaustive search ( ES-K ) method and a K-sparse approximate exhaustive search method ( AES-K ) for selecting variables in linear regression . With these methods , K-sparse combinations of variables are tested exhaustively assuming that the optimal combination of explanatory variables is K-sparse . By collecting the results of exhaustively computing ES-K , various approximate methods for selecting sparse variables can be summarized as density of states . With this density of states , we can compare different methods for selecting sparse variables such as relaxation and sampling . For large problems where the combinatorial explosion of explanatory variables is crucial , the AES-K method enables density of states to be effectively reconstructed by using the replica-exchange Monte Carlo method and the multiple histogram method . Applying the ES-K and AES-K methods to type Ia supernova data , we confirmed the conventional understanding in astronomy when an appropriate K is given beforehand . However , we found the difficulty to determine K from the data . Using virtual measurement and analysis , we argue that this is caused by data shortage .
This paper presents a novel spectral algorithm with additive clustering designed to identify overlapping communities in networks . The algorithm is based on geometric properties of the spectrum of the expected adjacency matrix in a random graph model that we call stochastic blockmodel with overlap ( SBMO ) . An adaptive version of the algorithm , that does not require the knowledge of the number of hidden communities , is proved to be consistent under the SBMO when the degrees in the graph are ( slightly more than ) logarithmic . The algorithm is shown to perform well on simulated data and on real-world graphs with known overlapping communities .
We consider the task of detecting regulatory elements in the human genome directly from raw DNA . Past work has focused on small snippets of DNA , making it difficult to model long-distance dependencies that arise from DNA ' s 0-dimensional conformation . In order to study long-distance dependencies , we develop and release a novel dataset for a larger-context modeling task . Using this new data set we model long-distance interactions using dilated convolutional neural networks , and compare them to standard convolutions and recurrent neural networks . We show that dilated convolutions are effective at modeling the locations of regulatory markers in the human genome , such as transcription factor binding sites , histone modifications , and DNAse hypersensitivity sites .
Reward augmented maximum likelihood ( RAML ) , a simple and effective learning framework to directly optimize towards the reward function in structured prediction tasks , has led to a number of impressive empirical successes . RAML incorporates task-specific reward by performing maximum-likelihood updates on candidate outputs sampled according to an exponentiated payoff distribution , which gives higher probabilities to candidates that are close to the reference output . While RAML is notable for its simplicity , efficiency , and its impressive empirical successes , the theoretical properties of RAML , especially the behavior of the exponentiated payoff distribution , has not been examined thoroughly . In this work , we introduce softmax Q-distribution estimation , a novel theoretical interpretation of RAML , which reveals the relation between RAML and Bayesian decision theory . The softmax Q-distribution can be regarded as a smooth approximation of the Bayes decision boundary , and the Bayes decision rule is achieved by decoding with this Q-distribution . We further show that RAML is equivalent to approximately estimating the softmax Q-distribution , with the temperature $\tau$ controlling approximation error . We perform two experiments , one on synthetic data of multi-class classification and one on real data of image captioning , to demonstrate the relationship between RAML and the proposed softmax Q-distribution estimation method , verifying our theoretical analysis . Additional experiments on three structured prediction tasks with rewards defined on sequential ( named entity recognition ) , tree-based ( dependency parsing ) and irregular ( machine translation ) structures show notable improvements over maximum likelihood baselines .
Explosive growth in data and availability of cheap computing resources have sparked increasing interest in Big learning , an emerging subfield that studies scalable machine learning algorithms , systems , and applications with Big Data . Bayesian methods represent one important class of statistic methods for machine learning , with substantial recent developments on adaptive , flexible and scalable Bayesian learning . This article provides a survey of the recent advances in Big learning with Bayesian methods , termed Big Bayesian Learning , including nonparametric Bayesian methods for adaptively inferring model complexity , regularized Bayesian inference for improving the flexibility via posterior regularization , and scalable algorithms and systems based on stochastic subsampling and distributed computing for dealing with large-scale applications .
The number of component classifiers chosen for an ensemble has a great impact on its prediction ability . In this paper , we use a geometric framework for a priori determining the ensemble size , applicable to most of the existing batch and online ensemble classifiers . There are only a limited number of studies on the ensemble size considering Majority Voting ( MV ) and Weighted Majority Voting ( WMV ) . Almost all of them are designed for batch-mode , barely addressing online environments . The big data dimensions and resource limitations in terms of time and memory make the determination of the ensemble size crucial , especially for online environments . Our framework proves , for the MV aggregation rule , that the more strong components we can add to the ensemble the more accurate predictions we can achieve . On the other hand , for the WMV aggregation rule , we prove the existence of an ideal number of components equal to the number of class labels , with the premise that components are completely independent of each other and strong enough . While giving the exact definition for a strong and independent classifier in the context of an ensemble is a challenging task , our proposed geometric framework provides a theoretical explanation of diversity and its impact on the accuracy of predictions . We conduct an experimental evaluation with two different scenarios to show the practical value of our theorems .
We combine Riemannian geometry with the mean field theory of high dimensional chaos to study the nature of signal propagation in generic , deep neural networks with random weights . Our results reveal an order-to-chaos expressivity phase transition , with networks in the chaotic phase computing nonlinear functions whose global curvature grows exponentially with depth but not width . We prove this generic class of deep random functions cannot be efficiently computed by any shallow network , going beyond prior work restricted to the analysis of single functions . Moreover , we formalize and quantitatively demonstrate the long conjectured idea that deep networks can disentangle highly curved manifolds in input space into flat manifolds in hidden space . Our theoretical analysis of the expressive power of deep networks broadly applies to arbitrary nonlinearities , and provides a quantitative underpinning for previously abstract notions about the geometry of deep functions .
We consider the problem of sparse estimation in a factor analysis model . A traditional estimation procedure in use is the following two-step approach : the model is estimated by maximum likelihood method and then a rotation technique is utilized to find sparse factor loadings . However , the maximum likelihood estimates cannot be obtained when the number of variables is much larger than the number of observations . Furthermore , even if the maximum likelihood estimates are available , the rotation technique does not often produce a sufficiently sparse solution . In order to handle these problems , this paper introduces a penalized likelihood procedure that imposes a nonconvex penalty on the factor loadings . We show that the penalized likelihood procedure can be viewed as a generalization of the traditional two-step approach , and the proposed methodology can produce sparser solutions than the rotation technique . A new algorithm via the EM algorithm along with coordinate descent is introduced to compute the entire solution path , which permits the application to a wide variety of convex and nonconvex penalties . Monte Carlo simulations are conducted to investigate the performance of our modeling strategy . A real data example is also given to illustrate our procedure .
We present a comprehensive study on the use of autoencoders for modelling text data , in which ( differently from previous studies ) we focus our attention on the following issues : i ) we explore the suitability of two different models bDA and rsDA for constructing deep autoencoders for text data at the sentence level ; ii ) we propose and evaluate two novel metrics for better assessing the text-reconstruction capabilities of autoencoders ; and iii ) we propose an automatic method to find the critical bottleneck dimensionality for text language representations ( below which structural information is lost ) .
We present a novel regularization scheme for training deep neural networks . The parameters of neural networks are usually unconstrained and have a dynamic range dispersed over the real line . Our key idea is to control the expressive power of the network by dynamically quantizing the range and set of values that the parameters can take . We formulate this idea using a novel end-to-end approach that regularizes the traditional classification loss function . Our regularizer is inspired by the Minimum Description Length principle . For each layer of the network , our approach optimizes a translation and scaling factor along with integer-valued parameters . We empirically compare BitNet to an equivalent unregularized model on the MNIST and CIFAR-00 datasets . We show that BitNet converges faster to a superior quality solution . Additionally , the resulting model is significantly smaller in size due to the use of integer parameters instead of floats .
The analysis of continously larger datasets is a task of major importance in a wide variety of scientific fields . In this sense , cluster analysis algorithms are a key element of exploratory data analysis , due to their easiness in the implementation and relatively low computational cost . Among these algorithms , the K -means algorithm stands out as the most popular approach , besides its high dependency on the initial conditions , as well as to the fact that it might not scale well on massive datasets . In this article , we propose a recursive and parallel approximation to the K -means algorithm that scales well on both the number of instances and dimensionality of the problem , without affecting the quality of the approximation . In order to achieve this , instead of analyzing the entire dataset , we work on small weighted sets of points that mostly intend to extract information from those regions where it is harder to determine the correct cluster assignment of the original instances . In addition to different theoretical properties , which deduce the reasoning behind the algorithm , experimental results indicate that our method outperforms the state-of-the-art in terms of the trade-off between number of distance computations and the quality of the solution obtained .
We present ease . ml , a declarative machine learning service platform we built to support more than ten research groups outside the computer science departments at ETH Zurich for their machine learning needs . With ease . ml , a user defines the high-level schema of a machine learning application and submits the task via a Web interface . The system automatically deals with the rest , such as model selection and data movement . In this paper , we describe the ease . ml architecture and focus on a novel technical problem introduced by ease . ml regarding resource allocation . We ask , as a " service provider " that manages a shared cluster of machines among all our users running machine learning workloads , what is the resource allocation strategy that maximizes the global satisfaction of all our users ? Resource allocation is a critical yet subtle issue in this multi-tenant scenario , as we have to balance between efficiency and fairness . We first formalize the problem that we call multi-tenant model selection , aiming for minimizing the total regret of all users running automatic model selection tasks . We then develop a novel algorithm that combines multi-armed bandits with Bayesian optimization and prove a regret bound under the multi-tenant setting . Finally , we report our evaluation of ease . ml on synthetic data and on one service we are providing to our users , namely , image classification with deep neural networks . Our experimental evaluation results show that our proposed solution can be up to 0 . 0x faster in achieving the same global quality for all users as the two popular heuristics used by our users before ease . ml .
We address the problem of latent truth discovery , LTD for short , where the goal is to discover the underlying true values of entity attributes in the presence of noisy , conflicting or incomplete information . Despite a multitude of algorithms to address the LTD problem that can be found in literature , only little is known about their overall performance with respect to effectiveness ( in terms of truth discovery capabilities ) , efficiency and robustness . A practical LTD approach should satisfy all these characteristics so that it can be applied to heterogeneous datasets of varying quality and degrees of cleanliness . We propose a novel algorithm for LTD that satisfies the above requirements . The proposed model is based on Restricted Boltzmann Machines , thus coined LTD-RBM . In extensive experiments on various heterogeneous and publicly available datasets , LTD-RBM is superior to state-of-the-art LTD techniques in terms of an overall consideration of effectiveness , efficiency and robustness .
We study the relationship between geometry and capacity measures for deep neural networks from an invariance viewpoint . We introduce a new notion of capacity --- the Fisher-Rao norm --- that possesses desirable invariance properties and is motivated by Information Geometry . We discover an analytical characterization of the new capacity measure , through which we establish norm-comparison inequalities and further show that the new measure serves as an umbrella for several existing norm-based complexity measures . We discuss upper bounds on the generalization error induced by the proposed measure . Extensive numerical experiments on CIFAR-00 support our theoretical findings . Our theoretical analysis rests on a key structural lemma about partial derivatives of multi-layer rectifier networks .
Reliable uncertainty estimation for time series prediction is critical in many fields , including physics , biology , and manufacturing . At Uber , probabilistic time series forecasting is used for robust prediction of number of trips during special events , driver incentive allocation , as well as real-time anomaly detection across millions of metrics . Classical time series models are often used in conjunction with a probabilistic formulation for uncertainty estimation . However , such models are hard to tune , scale , and add exogenous variables to . Motivated by the recent resurgence of Long Short Term Memory networks , we propose a novel end-to-end Bayesian deep model that provides time series prediction along with uncertainty estimation . We provide detailed experiments of the proposed solution on completed trips data , and successfully apply it to large-scale time series anomaly detection at Uber .
Signal processing tasks as fundamental as sampling , reconstruction , minimum mean-square error interpolation and prediction can be viewed under the prism of reproducing kernel Hilbert spaces . Endowing this vantage point with contemporary advances in sparsity-aware modeling and processing , promotes the nonparametric basis pursuit advocated in this paper as the overarching framework for the confluence of kernel-based learning ( KBL ) approaches leveraging sparse linear regression , nuclear-norm regularization , and dictionary learning . The novel sparse KBL toolbox goes beyond translating sparse parametric approaches to their nonparametric counterparts , to incorporate new possibilities such as multi-kernel selection and matrix smoothing . The impact of sparse KBL to signal processing applications is illustrated through test cases from cognitive radio sensing , microarray data imputation , and network traffic prediction .
We present a novel factor analysis method that can be applied to the discovery of common factors shared among trajectories in multivariate time series data . These factors satisfy a precedence-ordering property : certain factors are recruited only after some other factors are activated . Precedence-ordering arise in applications where variables are activated in a specific order , which is unknown . The proposed method is based on a linear model that accounts for each factor ' s inherent delays and relative order . We present an algorithm to fit the model in an unsupervised manner using techniques from convex and non-convex optimization that enforce sparsity of the factor scores and consistent precedence-order of the factor loadings . We illustrate the Order-Preserving Factor Analysis ( OPFA ) method for the problem of extracting precedence-ordered factors from a longitudinal ( time course ) study of gene expression data .
We propose a unified framework for estimating low-rank matrices through nonconvex optimization based on gradient descent algorithm . Our framework is quite general and can be applied to both noisy and noiseless observations . In the general case with noisy observations , we show that our algorithm is guaranteed to linearly converge to the unknown low-rank matrix up to minimax optimal statistical error , provided an appropriate initial estimator . While in the generic noiseless setting , our algorithm converges to the unknown low-rank matrix at a linear rate and enables exact recovery with optimal sample complexity . In addition , we develop a new initialization algorithm to provide a desired initial estimator , which outperforms existing initialization algorithms for nonconvex low-rank matrix estimation . We illustrate the superiority of our framework through three examples : matrix regression , matrix completion , and one-bit matrix completion . We also corroborate our theory through extensive experiments on synthetic data .
Providing accurate predictions is challenging for machine learning algorithms when the number of features is larger than the number of samples in the data . Prior knowledge can improve machine learning models by indicating relevant variables and parameter values . Yet , this prior knowledge is often tacit and only available from domain experts . We present a novel approach that uses interactive visualization to elicit the tacit prior knowledge and uses it to improve the accuracy of prediction models . The main component of our approach is a user model that models the domain expert ' s knowledge of the relevance of different features for a prediction task . In particular , based on the expert ' s earlier input , the user model guides the selection of the features on which to elicit user ' s knowledge next . The results of a controlled user study show that the user model significantly improves prior knowledge elicitation and prediction accuracy , when predicting the relative citation counts of scientific documents in a specific domain .
Training structured prediction models is time-consuming . However , most existing approaches only use a single machine , thus , the advantage of computing power and the capacity for larger data sets of multiple machines have not been exploited . In this work , we propose an efficient algorithm for distributedly training structured support vector machines based on a distributed block-coordinate descent method . Both theoretical and experimental results indicate that our method is efficient .
An increasing number of sensors on mobile , Internet of things ( IoT ) , and wearable devices generate time-series measurements of physical activities . Though access to the sensory data is critical to the success of many beneficial applications such as health monitoring or activity recognition , a wide range of potentially sensitive information about the individuals can also be discovered through these datasets and this cannot easily be protected using traditional privacy approaches . In this paper , we propose an integrated sensing framework for managing access to personal time-series data in order to provide utility while protecting individuals ' privacy . We introduce \textit{Replacement AutoEncoder} , a novel feature-learning algorithm which learns how to transform discriminative features of multidimensional time-series that correspond to sensitive inferences , into some features that have been more observed in non-sensitive inferences , to protect users ' privacy . The main advantage of Replacement AutoEncoder is its ability to keep important features of desired inferences unchanged to preserve the utility of the data . We evaluate the efficacy of the algorithm with an activity recognition task in a multi-sensing environment using extensive experiments on three benchmark datasets . We show that it can retain the recognition accuracy of state-of-the-art techniques while simultaneously preserving the privacy of sensitive information . We use a Generative Adversarial Network to attempt to detect the replacement of sensitive data with fake non-sensitive data . We show that this approach does not detect the replacement unless the network can train using the users ' original unmodified data .
Markov jump processes and continuous time Bayesian networks are important classes of continuous time dynamical systems . In this paper , we tackle the problem of inferring unobserved paths in these models by introducing a fast auxiliary variable Gibbs sampler . Our approach is based on the idea of uniformization , and sets up a Markov chain over paths by sampling a finite set of virtual jump times and then running a standard hidden Markov model forward filtering-backward sampling algorithm over states at the set of extant and virtual jump times . We demonstrate significant computational benefits over a state-of-the-art Gibbs sampler on a number of continuous time Bayesian networks .
In this paper , we made an extension to the convergence analysis of the dynamics of two-layered bias-free networks with one $ReLU$ output . We took into consideration two popular regularization terms : the $\ell_0$ and $\ell_0$ norm of the parameter vector $w$ , and added it to the square loss function with coefficient $\lambda/0$ . We proved that when $\lambda$ is small , the weight vector $w$ converges to the optimal solution $\hat{w}$ ( with respect to the new loss function ) with probability $\geq ( 0-\varepsilon ) ( 0-A_d ) /0$ under random initiations in a sphere centered at the origin , where $\varepsilon$ is a small value and $A_d$ is a constant . Numerical experiments including phase diagrams and repeated simulations verified our theory .
Big Data is one of the major challenges of statistical science and has numerous consequences from algorithmic and theoretical viewpoints . Big Data always involve massive data but they also often include online data and data heterogeneity . Recently some statistical methods have been adapted to process Big Data , like linear regression models , clustering methods and bootstrapping schemes . Based on decision trees combined with aggregation and bootstrap ideas , random forests were introduced by Breiman in 0000 . They are a powerful nonparametric statistical method allowing to consider in a single and versatile framework regression problems , as well as two-class and multi-class classification problems . Focusing on classification problems , this paper proposes a selective review of available proposals that deal with scaling random forests to Big Data problems . These proposals rely on parallel environments or on online adaptations of random forests . We also describe how related quantities -- such as out-of-bag error and variable importance -- are addressed in these methods . Then , we formulate various remarks for random forests in the Big Data context . Finally , we experiment five variants on two massive datasets ( 00 and 000 millions of observations ) , a simulated one as well as real world data . One variant relies on subsampling while three others are related to parallel implementations of random forests and involve either various adaptations of bootstrap to Big Data or to " divide-and-conquer " approaches . The fifth variant relates on online learning of random forests . These numerical experiments lead to highlight the relative performance of the different variants , as well as some of their limitations .
Gradient matching with Gaussian processes is a promising tool for learning parameters of ordinary differential equations ( ODE ' s ) . The essence of gradient matching is to model the prior over state variables as a Gaussian process which implies that the joint distribution given the ODE ' s and GP kernels is also Gaussian distributed . The state-derivatives are integrated out analytically since they are modelled as latent variables . However , the state variables themselves are also latent variables because they are contaminated by noise . Previous work sampled the state variables since integrating them out is \textit{not} analytically tractable . In this paper we use mean-field approximation to establish tight variational lower bounds that decouple state variables and are therefore , in contrast to the integral over state variables , analytically tractable and even concave for a restricted family of ODE ' s , including nonlinear and periodic ODE ' s . Such variational lower bounds facilitate " hill climbing " to determine the maximum a posteriori estimate of ODE parameters . An additional advantage of our approach over sampling methods is the determination of a proxy to the intractable posterior distribution over state variables given observations and the ODE ' s .
In recent years , deep learning methods applying unsupervised learning to train deep layers of neural networks have achieved remarkable results in numerous fields . In the past , many genetic algorithms based methods have been successfully applied to training neural networks . In this paper , we extend previous work and propose a GA-assisted method for deep learning . Our experimental results indicate that this GA-assisted approach improves the performance of a deep autoencoder , producing a sparser neural network .
The pseudo-likelihood method is one of the most popular algorithms for learning sparse binary pairwise Markov networks . In this paper , we formulate the $L_0$ regularized pseudo-likelihood problem as a sparse multiple logistic regression problem . In this way , many insights and optimization procedures for sparse logistic regression can be applied to the learning of discrete Markov networks . Specifically , we use the coordinate descent algorithm for generalized linear models with convex penalties , combined with strong screening rules , to solve the pseudo-likelihood problem with $L_0$ regularization . Therefore a substantial speedup without losing any accuracy can be achieved . Furthermore , this method is more stable than the node-wise logistic regression approach on unbalanced high-dimensional data when penalized by small regularization parameters . Thorough numerical experiments on simulated data and real world data demonstrate the advantages of the proposed method .
Bagging is a device intended for reducing the prediction error of learning algorithms . In its simplest form , bagging draws bootstrap samples from the training sample , applies the learning algorithm to each bootstrap sample , and then averages the resulting prediction rules . We extend the definition of bagging from statistics to statistical functionals and study the von Mises expansion of bagged statistical functionals . We show that the expansion is related to the Efron-Stein ANOVA expansion of the raw ( unbagged ) functional . The basic observation is that a bagged functional is always smooth in the sense that the von Mises expansion exists and is finite of length 0 + resample size $M$ . This holds even if the raw functional is rough or unstable . The resample size $M$ acts as a smoothing parameter , where a smaller $M$ means more smoothing .
We study the sparse non-negative least squares ( S-NNLS ) problem . S-NNLS occurs naturally in a wide variety of applications where an unknown , non-negative quantity must be recovered from linear measurements . We present a unified framework for S-NNLS based on a rectified power exponential scale mixture prior on the sparse codes . We show that the proposed framework encompasses a large class of S-NNLS algorithms and provide a computationally efficient inference procedure based on multiplicative update rules . Such update rules are convenient for solving large sets of S-NNLS problems simultaneously , which is required in contexts like sparse non-negative matrix factorization ( S-NMF ) . We provide theoretical justification for the proposed approach by showing that the local minima of the objective function being optimized are sparse and the S-NNLS algorithms presented are guaranteed to converge to a set of stationary points of the objective function . We then extend our framework to S-NMF , showing that our framework leads to many well known S-NMF algorithms under specific choices of prior and providing a guarantee that a popular subclass of the proposed algorithms converges to a set of stationary points of the objective function . Finally , we study the performance of the proposed approaches on synthetic and real-world data .
Following the very recent line of work on the ``generalized min-max ' ' ( GMM ) kernel , this study proposes the ``generalized intersection ' ' ( GInt ) kernel and the related ``normalized generalized min-max ' ' ( NGMM ) kernel . In computer vision , the ( histogram ) intersection kernel has been popular , and the GInt kernel generalizes it to data which can have both negative and positive entries . Through an extensive empirical classification study on 00 datasets from the UCI repository , we are able to show that this ( tuning-free ) GInt kernel performs fairly well . The empirical results also demonstrate that the NGMM kernel typically outperforms the GInt kernel . Interestingly , the NGMM kernel has another interpretation --- it is the ``asymmetrically transformed ' ' version of the GInt kernel , based on the idea of ``asymmetric hashing ' ' . Just like the GMM kernel , the NGMM kernel can be efficiently linearized through ( e . g . , ) generalized consistent weighted sampling ( GCWS ) , as empirically validated in our study . Owing to the discrete nature of hashed values , it also provides a scheme for approximate near neighbor search .
We study the distributions of the LASSO , SCAD , and thresholding estimators , in finite samples and in the large-sample limit . The asymptotic distributions are derived for both the case where the estimators are tuned to perform consistent model selection and for the case where the estimators are tuned to perform conservative model selection . Our findings complement those of Knight and Fu ( 0000 ) and Fan and Li ( 0000 ) . We show that the distributions are typically highly nonnormal regardless of how the estimator is tuned , and that this property persists in large samples . The uniform convergence rate of these estimators is also obtained , and is shown to be slower than 0/root ( n ) in case the estimator is tuned to perform consistent model selection . An impossibility result regarding estimation of the estimators ' distribution function is also provided .
The paper deals with the adaptation of a new measure for the unsupervised feature selection problems . The proposed measure is based on space filling concept and is called the coverage measure . This measure was used for judging the quality of an experimental space filling design . In the present work , the coverage measure is adapted for selecting the smallest informative subset of variables by reducing redundancy in data . This paper proposes a simple analogy to apply this measure . It is implemented in a filter algorithm for unsupervised feature selection problems . The proposed filter algorithm is robust with high dimensional data and can be implemented without extra parameters . Further , it is tested with simulated data and real world case studies including environmental data and hyperspectral image . Finally , the results are evaluated by using random forest algorithm .
The past decade has witnessed a successful application of deep learning to solving many challenging problems in machine learning and artificial intelligence . However , the loss functions of deep neural networks ( especially nonlinear networks ) are still far from being well understood from a theoretical aspect . In this paper , we enrich the current understanding of the landscape of the square loss functions for three types of neural networks . Specifically , when the parameter matrices are square , we provide an explicit characterization of the global minimizers for linear networks , linear residual networks , and nonlinear networks with one hidden layer . Then , we establish two quadratic types of landscape properties for the square loss of these neural networks , i . e . , the gradient dominance condition within the neighborhood of their full rank global minimizers , and the regularity condition along certain directions and within the neighborhood of their global minimizers . These two landscape properties are desirable for the optimization around the global minimizers of the loss function for these neural networks .
In this paper we propose a function space approach to Representation Learning and the analysis of the representation layers in deep learning architectures . We show how to compute a weak-type Besov smoothness index that quantifies the geometry of the clustering in the feature space . This approach was already applied successfully to improve the performance of machine learning algorithms such as the Random Forest and tree-based Gradient Boosting . Our experiments demonstrate that in well-known and well-performing trained networks , the Besov smoothness of the training set , measured in the corresponding hidden layer feature map representation , increases from layer to layer . We also contribute to the understanding of generalization by showing how the Besov smoothness of the representations , decreases as we add more mis-labeling to the training data . We hope this approach will contribute to the de-mystification of some aspects of deep learning .
Blind source separation ( BSS ) , i . e . , the decoupling of unknown signals that have been mixed in an unknown way , has been a topic of great interest in the signal processing community for the last decade , covering a wide range of applications in such diverse fields as digital communications , pattern recognition , biomedical engineering , and financial data analysis , among others . This course aims at an introduction to the BSS problem via an exposition of well-known and established as well as some more recent approaches to its solution . A unified way is followed in presenting the various results so as to more easily bring out their similarities/differences and emphasize their relative advantages/disadvantages . Only a representative sample of the existing knowledge on BSS will be included in this course . The interested readers are encouraged to consult the list of bibliographical references for more details on this exciting and always active research topic .
In this paper we present a method for the unsupervised clustering of high-dimensional binary data , with a special focus on electronic healthcare records . We present a robust and efficient heuristic to face this problem using tensor decomposition . We present the reasons why this approach is preferable for tasks such as clustering patient records , to more commonly used distance-based methods . We run the algorithm on two datasets of healthcare records , obtaining clinically meaningful results .
The Gaussian graphical model , a popular paradigm for studying relationship among variables in a wide range of applications , has attracted great attention in recent years . This paper considers a fundamental question : When is it possible to estimate low-dimensional parameters at parametric square-root rate in a large Gaussian graphical model ? A novel regression approach is proposed to obtain asymptotically efficient estimation of each entry of a precision matrix under a sparseness condition relative to the sample size . When the precision matrix is not sufficiently sparse , or equivalently the sample size is not sufficiently large , a lower bound is established to show that it is no longer possible to achieve the parametric rate in the estimation of each entry . This lower bound result , which provides an answer to the delicate sample size question , is established with a novel construction of a subset of sparse precision matrices in an application of Le Cam ' s lemma . Moreover , the proposed estimator is proven to have optimal convergence rate when the parametric rate cannot be achieved , under a minimal sample requirement . The proposed estimator is applied to test the presence of an edge in the Gaussian graphical model or to recover the support of the entire model , to obtain adaptive rate-optimal estimation of the entire precision matrix as measured by the matrix $\ell_q$ operator norm and to make inference in latent variables in the graphical model . All of this is achieved under a sparsity condition on the precision matrix and a side condition on the range of its spectrum . This significantly relaxes the commonly imposed uniform signal strength condition on the precision matrix , irrepresentability condition on the Hessian tensor operator of the covariance matrix or the $\ell_0$ constraint on the precision matrix . Numerical results confirm our theoretical findings . The ROC curve of the proposed algorithm , Asymptotic Normal Thresholding ( ANT ) , for support recovery significantly outperforms that of the popular GLasso algorithm .
In this paper we study the frequentist convergence rate for the Latent Dirichlet Allocation ( Blei et al . , 0000 ) topic models . We show that the maximum likelihood estimator converges to one of the finitely many equivalent parameters in Wasserstein ' s distance metric at a rate of $n^{-0/0}$ without assuming separability or non-degeneracy of the underlying topics and/or the existence of more than three words per document , thus generalizing the previous works of Anandkumar et al . ( 0000 , 0000 ) from an information-theoretical perspective . We also show that the $n^{-0/0}$ convergence rate is optimal in the worst case .
Bayesian models offer great flexibility for clustering applications---Bayesian nonparametrics can be used for modeling infinite mixtures , and hierarchical Bayesian models can be utilized for sharing clusters across multiple data sets . For the most part , such flexibility is lacking in classical clustering methods such as k-means . In this paper , we revisit the k-means clustering algorithm from a Bayesian nonparametric viewpoint . Inspired by the asymptotic connection between k-means and mixtures of Gaussians , we show that a Gibbs sampling algorithm for the Dirichlet process mixture approaches a hard clustering algorithm in the limit , and further that the resulting algorithm monotonically minimizes an elegant underlying k-means-like clustering objective that includes a penalty for the number of clusters . We generalize this analysis to the case of clustering multiple data sets through a similar asymptotic argument with the hierarchical Dirichlet process . We also discuss further extensions that highlight the benefits of our analysis : i ) a spectral relaxation involving thresholded eigenvectors , and ii ) a normalized cut graph clustering algorithm that does not fix the number of clusters in the graph .
Support vector machines ( SVMs ) are special kernel based methods and belong to the most successful learning methods since more than a decade . SVMs can informally be described as a kind of regularized M-estimators for functions and have demonstrated their usefulness in many complicated real-life problems . During the last years a great part of the statistical research on SVMs has concentrated on the question how to design SVMs such that they are universally consistent and statistically robust for nonparametric classification or nonparametric regression purposes . In many applications , some qualitative prior knowledge of the distribution P or of the unknown function f to be estimated is present or the prediction function with a good interpretability is desired , such that a semiparametric model or an additive model is of interest . In this paper we mainly address the question how to design SVMs by choosing the reproducing kernel Hilbert space ( RKHS ) or its corresponding kernel to obtain consistent and statistically robust estimators in additive models . We give an explicit construction of kernels - and thus of their RKHSs - which leads in combination with a Lipschitz continuous loss function to consistent and statistically robust SMVs for additive models . Examples are quantile regression based on the pinball loss function , regression based on the epsilon-insensitive loss function , and classification based on the hinge loss function .
We identify and analyze statistical regularities and irregularities in the recent order flow of different NASDAQ stocks , focusing on the positions where orders are placed in the orderbook . This includes limit orders being placed outside of the spread , inside the spread and ( effective ) market orders . We find that limit order placement inside the spread is strongly determined by the dynamics of the spread size . Most orders , however , arrive outside of the spread . While for some stocks order placement on or next to the quotes is dominating , deeper price levels are more important for other stocks . As market orders are usually adjusted to the quote volume , the impact of market orders depends on the orderbook structure , which we find to be quite diverse among the analyzed stocks as a result of the way limit order placement takes place .
We propose an active set selection framework for Gaussian process classification for cases when the dataset is large enough to render its inference prohibitive . Our scheme consists of a two step alternating procedure of active set update rules and hyperparameter optimization based upon marginal likelihood maximization . The active set update rules rely on the ability of the predictive distributions of a Gaussian process classifier to estimate the relative contribution of a datapoint when being either included or removed from the model . This means that we can use it to include points with potentially high impact to the classifier decision process while removing those that are less relevant . We introduce two active set rules based on different criteria , the first one prefers a model with interpretable active set parameters whereas the second puts computational complexity first , thus a model with active set parameters that directly control its complexity . We also provide both theoretical and empirical support for our active set selection strategy being a good approximation of a full Gaussian process classifier . Our extensive experiments show that our approach can compete with state-of-the-art classification techniques with reasonable time complexity . Source code publicly available at http : //cogsys . imm . dtu . dk/passgp .
A relatively recent advance in cognitive neuroscience has been multi-voxel pattern analysis ( MVPA ) , which enables researchers to decode brain states and/or the type of information represented in the brain during a cognitive operation . MVPA methods utilize machine learning algorithms to distinguish among types of information or cognitive states represented in the brain , based on distributed patterns of neural activity . In the current investigation , we propose a new approach for representation of neural data for pattern analysis , namely a Mesh Learning Model . In this approach , at each time instant , a star mesh is formed around each voxel , such that the voxel corresponding to the center node is surrounded by its p-nearest neighbors . The arc weights of each mesh are estimated from the voxel intensity values by least squares method . The estimated arc weights of all the meshes , called Mesh Arc Descriptors ( MADs ) , are then used to train a classifier , such as Neural Networks , k-Nearest Neighbor , Na\ " ive Bayes and Support Vector Machines . The proposed Mesh Model was tested on neuroimaging data acquired via functional magnetic resonance imaging ( fMRI ) during a recognition memory experiment using categorized word lists , employing a previously established experimental paradigm ( \ " Oztekin & Badre , 0000 ) . Results suggest that the proposed Mesh Learning approach can provide an effective algorithm for pattern analysis of brain activity during cognitive processing .
In regularized risk minimization , the associated optimization problem becomes particularly difficult when both the loss and regularizer are nonsmooth . Existing approaches either have slow or unclear convergence properties , are restricted to limited problem subclasses , or require careful setting of a smoothing parameter . In this paper , we propose a continuation algorithm that is applicable to a large class of nonsmooth regularized risk minimization problems , can be flexibly used with a number of existing solvers for the underlying smoothed subproblem , and with convergence results on the whole algorithm rather than just one of its subproblems . In particular , when accelerated solvers are used , the proposed algorithm achieves the fastest known rates of $O ( 0/T^0 ) $ on strongly convex problems , and $O ( 0/T ) $ on general convex problems . Experiments on nonsmooth classification and regression tasks demonstrate that the proposed algorithm outperforms the state-of-the-art .
AUC ( area under ROC curve ) is an important evaluation criterion , which has been popularly used in many learning tasks such as class-imbalance learning , cost-sensitive learning , learning to rank , etc . Many learning approaches try to optimize AUC , while owing to the non-convexity and discontinuousness of AUC , almost all approaches work with surrogate loss functions . Thus , the consistency of AUC is crucial ; however , it has been almost untouched before . In this paper , we provide a sufficient condition for the asymptotic consistency of learning approaches based on surrogate loss functions . Based on this result , we prove that exponential loss and logistic loss are consistent with AUC , but hinge loss is inconsistent . Then , we derive the $q$-norm hinge loss and general hinge loss that are consistent with AUC . We also derive the consistent bounds for exponential loss and logistic loss , and obtain the consistent bounds for many surrogate loss functions under the non-noise setting . Further , we disclose an equivalence between the exponential surrogate loss of AUC and exponential surrogate loss of accuracy , and one straightforward consequence of such finding is that AdaBoost and RankBoost are equivalent .
Bayesian optimisation has been successfully applied to a variety of reinforcement learning problems . However , the traditional approach for learning optimal policies in simulators does not utilise the opportunity to improve learning by adjusting certain environment variables : state features that are unobservable and randomly determined by the environment in a physical setting but are controllable in a simulator . This paper considers the problem of finding a robust policy while taking into account the impact of environment variables . We present Alternating Optimisation and Quadrature ( ALOQ ) , which uses Bayesian optimisation and Bayesian quadrature to address such settings . ALOQ is robust to the presence of significant rare events , which may not be observable under random sampling , but play a substantial role in determining the optimal policy . Experimental results across different domains show that ALOQ can learn more efficiently and robustly than existing methods .
Learning-based representations have become the defacto means to address computer vision tasks . Despite their massive adoption , the amount of work aiming at understanding the internal representations learned by these models is rather limited . Existing methods aimed at model interpretation either require exhaustive manual inspection of visualizations , or link internal network activations with external " possibly useful " annotated concepts . We propose an intermediate scheme in which , given a pretrained model , we automatically identify internal features relevant for the set of classes considered by the model , without requiring additional annotations . We interpret the model through average visualizations of these features . Then , at test time , we explain the network prediction by accompanying the predicted class label with supporting heatmap visualizations derived from the identified relevant features . In addition , we propose a method to address the artifacts introduced by strided operations in deconvnet-based visualizations . Our evaluation on the MNIST , ILSVRC 00 and Fashion 000k datasets quantitatively shows that the proposed method is able to identify relevant internal features for the classes of interest while improving the quality of the produced visualizations .
Stochastic optimization algorithms with variance reduction have proven successful for minimizing large finite sums of functions . Unfortunately , these techniques are unable to deal with stochastic perturbations of input data , induced for example by data augmentation . In such cases , the objective is no longer a finite sum , and the main candidate for optimization is the stochastic gradient descent method ( SGD ) . In this paper , we introduce a variance reduction approach for these settings when the objective is composite and strongly convex . The convergence rate outperforms SGD with a typically much smaller constant factor , which depends on the variance of gradient estimates only due to perturbations on a single example .
We show how to adjust the coefficient of determination ( $R^0$ ) when used for measuring predictive accuracy via leave-one-out cross-validation .
Deep reinforcement learning ( deep RL ) has been successful in learning sophisticated behaviors automatically ; however , the learning process requires a huge number of trials . In contrast , animals can learn new tasks in just a few trials , benefiting from their prior knowledge about the world . This paper seeks to bridge this gap . Rather than designing a " fast " reinforcement learning algorithm , we propose to represent it as a recurrent neural network ( RNN ) and learn it from data . In our proposed method , RL$^0$ , the algorithm is encoded in the weights of the RNN , which are learned slowly through a general-purpose ( " slow " ) RL algorithm . The RNN receives all information a typical RL algorithm would receive , including observations , actions , rewards , and termination flags ; and it retains its state across episodes in a given Markov Decision Process ( MDP ) . The activations of the RNN store the state of the " fast " RL algorithm on the current ( previously unseen ) MDP . We evaluate RL$^0$ experimentally on both small-scale and large-scale problems . On the small-scale side , we train it to solve randomly generated multi-arm bandit problems and finite MDPs . After RL$^0$ is trained , its performance on new MDPs is close to human-designed algorithms with optimality guarantees . On the large-scale side , we test RL$^0$ on a vision-based navigation task and show that it scales up to high-dimensional problems .
We consider learning on graphs , guided by kernels that encode similarity between vertices . Our focus is on random walk kernels , the analogues of squared exponential kernels in Euclidean spaces . We show that on large , locally treelike , graphs these have some counter-intuitive properties , specifically in the limit of large kernel lengthscales . We consider using these kernels as covariance matrices of e . g . \ Gaussian processes ( GPs ) . In this situation one typically scales the prior globally to normalise the average of the prior variance across vertices . We demonstrate that , in contrast to the Euclidean case , this generically leads to significant variation in the prior variance across vertices , which is undesirable from the probabilistic modelling point of view . We suggest the random walk kernel should be normalised locally , so that each vertex has the same prior variance , and analyse the consequences of this by studying learning curves for Gaussian process regression . Numerical calculations as well as novel theoretical predictions for the learning curves using belief propagation make it clear that one obtains distinctly different probabilistic models depending on the choice of normalisation . Our method for predicting the learning curves using belief propagation is significantly more accurate than previous approximations and should become exact in the limit of large random graphs .
In this paper we address the problem of finding the most probable state of a discrete Markov random field ( MRF ) , also known as the MRF energy minimization problem . The task is known to be NP-hard in general and its practical importance motivates numerous approximate algorithms . We propose a submodular relaxation approach ( SMR ) based on a Lagrangian relaxation of the initial problem . Unlike the dual decomposition approach of Komodakis et al . , 0000 SMR does not decompose the graph structure of the initial problem but constructs a submodular energy that is minimized within the Lagrangian relaxation . Our approach is applicable to both pairwise and high-order MRFs and allows to take into account global potentials of certain types . We study theoretical properties of the proposed approach and evaluate it experimentally .
This paper deals with a natural stochastic optimization procedure derived from the so-called Heavy-ball method differential equation , which was introduced by Polyak in the 0000s with his seminal contribution [Pol00] . The Heavy-ball method is a second-order dynamics that was investigated to minimize convex functions f . The family of second-order methods recently received a large amount of attention , until the famous contribution of Nesterov [Nes00] , leading to the explosion of large-scale optimization problems . This work provides an in-depth description of the stochastic heavy-ball method , which is an adaptation of the deterministic one when only unbiased evalutions of the gradient are available and used throughout the iterations of the algorithm . We first describe some almost sure convergence results in the case of general non-convex coercive functions f . We then examine the situation of convex and strongly convex potentials and derive some non-asymptotic results about the stochastic heavy-ball method . We end our study with limit theorems on several rescaled algorithms .
We propose two practical non-convex approaches for learning near-isometric , linear embeddings of finite sets of data points . Given a set of training points $\mathcal{X}$ , we consider the secant set $S ( \mathcal{X} ) $ that consists of all pairwise difference vectors of $\mathcal{X}$ , normalized to lie on the unit sphere . The problem can be formulated as finding a symmetric and positive semi-definite matrix $\boldsymbol{\Psi}$ that preserves the norms of all the vectors in $S ( \mathcal{X} ) $ up to a distortion parameter $\delta$ . Motivated by non-negative matrix factorization , we reformulate our problem into a Frobenius norm minimization problem , which is solved by the Alternating Direction Method of Multipliers ( ADMM ) and develop an algorithm , FroMax . Another method solves for a projection matrix $\boldsymbol{\Psi}$ by minimizing the restricted isometry property ( RIP ) directly over the set of symmetric , postive semi-definite matrices . Applying ADMM and a Moreau decomposition on a proximal mapping , we develop another algorithm , NILE-Pro , for dimensionality reduction . FroMax is shown to converge faster for smaller $\delta$ while NILE-Pro converges faster for larger $\delta$ . Both non-convex approaches are then empirically demonstrated to be more computationally efficient than prior convex approaches for a number of applications in machine learning and signal processing .
Networks are ubiquitous in science and have become a focal point for discussion in everyday life . Formal statistical models for the analysis of network data have emerged as a major topic of interest in diverse areas of study , and most of these involve a form of graphical representation . Probability models on graphs date back to 0000 . Along with empirical studies in social psychology and sociology from the 0000s , these early works generated an active network community and a substantial literature in the 0000s . This effort moved into the statistical literature in the late 0000s and 0000s , and the past decade has seen a burgeoning network literature in statistical physics and computer science . The growth of the World Wide Web and the emergence of online networking communities such as Facebook , MySpace , and LinkedIn , and a host of more specialized professional network communities has intensified interest in the study of networks and network data . Our goal in this review is to provide the reader with an entry point to this burgeoning literature . We begin with an overview of the historical development of statistical network modeling and then we introduce a number of examples that have been studied in the network literature . Our subsequent discussion focuses on a number of prominent static and dynamic network models and their interconnections . We emphasize formal model descriptions , and pay special attention to the interpretation of parameters and their estimation . We end with a description of some open problems and challenges for machine learning and statistics .
We present a dynamic model selection approach for resource-constrained prediction . Given an input instance at test-time , a gating function identifies a prediction model for the input among a collection of models . Our objective is to minimize overall average cost without sacrificing accuracy . We learn gating and prediction models on fully labeled training data by means of a bottom-up strategy . Our novel bottom-up method is a recursive scheme whereby a high-accuracy complex model is first trained . Then a low-complexity gating and prediction model are subsequently learnt to adaptively approximate the high-accuracy model in regions where low-cost models are capable of making highly accurate predictions . We pose an empirical loss minimization problem with cost constraints to jointly train gating and prediction models . On a number of benchmark datasets our method outperforms state-of-the-art achieving higher accuracy for the same cost .
We design a non-convex second-order optimization algorithm that is guaranteed to return an approximate local minimum in time which scales linearly in the underlying dimension and the number of training examples . The time complexity of our algorithm to find an approximate local minimum is even faster than that of gradient descent to find a critical point . Our algorithm applies to a general class of optimization problems including training a neural network and other non-convex objectives arising in machine learning .
Often the challenge associated with tasks like fraud and spam detection[0] is the lack of all likely patterns needed to train suitable supervised learning models . In order to overcome this limitation , such tasks are attempted as outlier or anomaly detection tasks . We also hypothesize that out- liers have behavioral patterns that change over time . Limited data and continuously changing patterns makes learning significantly difficult . In this work we are proposing an approach that detects outliers in large data sets by relying on data points that are consistent . The primary contribution of this work is that it will quickly help retrieve samples for both consistent and non-outlier data sets and is also mindful of new outlier patterns . No prior knowledge of each set is required to extract the samples . The method consists of two phases , in the first phase , consistent data points ( non- outliers ) are retrieved by an ensemble method of unsupervised clustering techniques and in the second phase a one class classifier trained on the consistent data point set is ap- plied on the remaining sample set to identify the outliers . The approach is tested on three publicly available data sets and the performance scores are competitive .
We develop a model in which interactions between nodes of a dynamic network are counted by non homogeneous Poisson processes . In a block modelling perspective , nodes belong to hidden clusters ( whose number is unknown ) and the intensity functions of the counting processes only depend on the clusters of nodes . In order to make inference tractable we move to discrete time by partitioning the entire time horizon in which interactions are observed in fixed-length time sub-intervals . First , we derive an exact integrated classification likelihood criterion and maximize it relying on a greedy search approach . This allows to estimate the memberships to clusters and the number of clusters simultaneously . Then a maximum-likelihood estimator is developed to estimate non parametrically the integrated intensities . We discuss the over-fitting problems of the model and propose a regularized version solving these issues . Experiments on real and simulated data are carried out in order to assess the proposed methodology .
We study the error landscape of deep linear and nonlinear neural networks with square error loss . We build on the recent results in the literature and present necessary and sufficient conditions for a critical point of the empirical risk function to be a global minimum in the deep linear network case . Our simple conditions can also be used to determine whether a given critical point is a global minimum or a saddle point . We further extend these results to deep nonlinear neural networks and prove similar sufficient conditions for global optimality in the function space .
The Gaussian process latent variable model ( GP-LVM ) provides a flexible approach for non-linear dimensionality reduction that has been widely applied . However , the current approach for training GP-LVMs is based on maximum likelihood , where the latent projection variables are maximized over rather than integrated out . In this paper we present a Bayesian method for training GP-LVMs by introducing a non-standard variational inference framework that allows to approximately integrate out the latent variables and subsequently train a GP-LVM by maximizing an analytic lower bound on the exact marginal likelihood . We apply this method for learning a GP-LVM from iid observations and for learning non-linear dynamical systems where the observations are temporally correlated . We show that a benefit of the variational Bayesian procedure is its robustness to overfitting and its ability to automatically select the dimensionality of the nonlinear latent space . The resulting framework is generic , flexible and easy to extend for other purposes , such as Gaussian process regression with uncertain inputs and semi-supervised Gaussian processes . We demonstrate our method on synthetic data and standard machine learning benchmarks , as well as challenging real world datasets , including high resolution video data .
Black box variational inference allows researchers to easily prototype and evaluate an array of models . Recent advances allow such algorithms to scale to high dimensions . However , a central question remains : How to specify an expressive variational distribution that maintains efficient computation ? To address this , we develop hierarchical variational models ( HVMs ) . HVMs augment a variational approximation with a prior on its parameters , which allows it to capture complex structure for both discrete and continuous latent variables . The algorithm we develop is black box , can be used for any HVM , and has the same computational efficiency as the original approximation . We study HVMs on a variety of deep discrete latent variable models . HVMs generalize other expressive variational distributions and maintains higher fidelity to the posterior .
Connections between nodes of fully connected neural networks are usually represented by weight matrices . In this article , functional transfer matrices are introduced as alternatives to the weight matrices : Instead of using real weights , a functional transfer matrix uses real functions with trainable parameters to represent connections between nodes . Multiple functional transfer matrices are then stacked together with bias vectors and activations to form deep functional transfer neural networks . These neural networks can be trained within the framework of back-propagation , based on a revision of the delta rules and the error transmission rule for functional connections . In experiments , it is demonstrated that the revised rules can be used to train a range of functional connections : 00 different functions are applied to neural networks with up to 00 hidden layers , and most of them gain high test accuracies on the MNIST database . It is also demonstrated that a functional transfer matrix with a memory function can roughly memorise a non-cyclical sequence of 000 digits .
In Passive POMDPs actions do not affect the world state , but still incur costs . When the agent is bounded by information-processing constraints , it can only keep an approximation of the belief . We present a variational principle for the problem of maintaining the information which is most useful for minimizing the cost , and introduce an efficient and simple algorithm for finding an optimum .
Under Markovian assumptions , we leverage a Central Limit Theorem ( CLT ) for the empirical measure in the test statistic of the composite hypothesis Hoeffding test so as to establish weak convergence results for the test statistic , and , thereby , derive a new estimator for the threshold needed by the test . We first show the advantages of our estimator over an existing estimator by conducting extensive numerical experiments . We find that our estimator controls better for false alarms while maintaining satisfactory detection probabilities . We then apply the Hoeffding test with our threshold estimator to detecting anomalies in two distinct applications domains : one in communication networks and the other in transportation networks . The former application seeks to enhance cyber security and the latter aims at building smarter transportation systems in cities .
Optimizing the acquisition matrix is useful for compressed sensing of signals that are sparse in overcomplete dictionaries , because the acquisition matrix can be adapted to the particular correlations of the dictionary atoms . In this paper a novel formulation of the optimization problem is proposed , in the form of a rank-constrained nearest correlation matrix problem . Furthermore , improvements for three existing optimization algorithms are introduced , which are shown to be particular instances of the proposed formulation . Simulation results show notable improvements and superior robustness in sparse signal recovery .
We introduce Imagination-Augmented Agents ( I0As ) , a novel architecture for deep reinforcement learning combining model-free and model-based aspects . In contrast to most existing model-based reinforcement learning and planning methods , which prescribe how a model should be used to arrive at a policy , I0As learn to interpret predictions from a learned environment model to construct implicit plans in arbitrary ways , by using the predictions as additional context in deep policy networks . I0As show improved data efficiency , performance , and robustness to model misspecification compared to several baselines .
We consider learning continuous probabilistic graphical models in the face of missing data . For non-Gaussian models , learning the parameters and structure of such models depends on our ability to perform efficient inference , and can be prohibitive even for relatively modest domains . Recently , we introduced the Copula Bayesian Network ( CBN ) density model - a flexible framework that captures complex high-dimensional dependency structures while offering direct control over the univariate marginals , leading to improved generalization . In this work we show that the CBN model also offers significant computational advantages when training data is partially observed . Concretely , we leverage on the specialized form of the model to derive a computationally amenable learning objective that is a lower bound on the log-likelihood function . Importantly , our energy-like bound circumvents the need for costly inference of an auxiliary distribution , thus facilitating practical learning of highdimensional densities . We demonstrate the effectiveness of our approach for learning the structure and parameters of a CBN model for two reallife continuous domains .
Many conventional statistical procedures are extremely sensitive to seemingly minor deviations from modeling assumptions . This problem is exacerbated in modern high-dimensional settings , where the problem dimension can grow with and possibly exceed the sample size . We consider the problem of robust estimation of sparse functionals , and provide a computationally and statistically efficient algorithm in the high-dimensional setting . Our theory identifies a unified set of deterministic conditions under which our algorithm guarantees accurate recovery . By further establishing that these deterministic conditions hold with high-probability for a wide range of statistical models , our theory applies to many problems of considerable interest including sparse mean and covariance estimation ; sparse linear regression ; and sparse generalized linear models .
It is of increasing importance to develop learning methods for ranking . In contrast to many learning objectives , however , the ranking problem presents difficulties due to the fact that the space of permutations is not smooth . In this paper , we examine the class of rank-linear objective functions , which includes popular metrics such as precision and discounted cumulative gain . In particular , we observe that expectations of these gains are completely characterized by the marginals of the corresponding distribution over permutation matrices . Thus , the expectations of rank-linear objectives can always be described through locations in the Birkhoff polytope , i . e . , doubly-stochastic matrices ( DSMs ) . We propose a technique for learning DSM-based ranking functions using an iterative projection operator known as Sinkhorn normalization . Gradients of this operator can be computed via backpropagation , resulting in an algorithm we call Sinkhorn propagation , or SinkProp . This approach can be combined with a wide range of gradient-based approaches to rank learning . We demonstrate the utility of SinkProp on several information retrieval data sets .
Understanding the relationship between the structure of light-harvesting systems and their excitation energy transfer properties is of fundamental importance in many applications including the development of next generation photovoltaics . Natural light harvesting in photosynthesis shows remarkable excitation energy transfer properties , which suggests that pigment-protein complexes could serve as blueprints for the design of nature inspired devices . Mechanistic insights into energy transport dynamics can be gained by leveraging numerically involved propagation schemes such as the hierarchical equations of motion ( HEOM ) . Solving these equations , however , is computationally costly due to the adverse scaling with the number of pigments . Therefore virtual high-throughput screening , which has become a powerful tool in material discovery , is less readily applicable for the search of novel excitonic devices . We propose the use of artificial neural networks to bypass the computational limitations of established techniques for exploring the structure-dynamics relation in excitonic systems . Once trained , our neural networks reduce computational costs by several orders of magnitudes . Our predicted transfer times and transfer efficiencies exhibit similar or even higher accuracies than frequently used approximate methods such as secular Redfield theory
One approach to improving the running time of kernel-based machine learning methods is to build a small sketch of the input and use it in lieu of the full kernel matrix in the machine learning task of interest . Here , we describe a version of this approach that comes with running time guarantees as well as improved guarantees on its statistical performance . By extending the notion of \emph{statistical leverage scores} to the setting of kernel ridge regression , our main statistical result is to identify an importance sampling distribution that reduces the size of the sketch ( i . e . , the required number of columns to be sampled ) to the \emph{effective dimensionality} of the problem . This quantity is often much smaller than previous bounds that depend on the \emph{maximal degrees of freedom} . Our main algorithmic result is to present a fast algorithm to compute approximations to these scores . This algorithm runs in time that is linear in the number of samples---more precisely , the running time is $O ( np^0 ) $ , where the parameter $p$ depends only on the trace of the kernel matrix and the regularization parameter---and it can be applied to the matrix of feature vectors , without having to form the full kernel matrix . This is obtained via a variant of length-squared sampling that we adapt to the kernel setting in a way that is of independent interest . Lastly , we provide empirical results illustrating our theory , and we discuss how this new notion of the statistical leverage of a data point captures in a fine way the difficulty of the original statistical learning problem .
Supervised learning with large scale labeled datasets and deep layered models has made a paradigm shift in diverse areas in learning and recognition . However , this approach still suffers generalization issues under the presence of a domain shift between the training and the test data distribution . In this regard , unsupervised domain adaptation algorithms have been proposed to directly address the domain shift problem . In this paper , we approach the problem from a transductive perspective . We incorporate the domain shift and the transductive target inference into our framework by jointly solving for an asymmetric similarity metric and the optimal transductive target label assignment . We also show that our model can easily be extended for deep feature learning in order to learn features which are discriminative in the target domain . Our experiments show that the proposed method significantly outperforms state-of-the-art algorithms in both object recognition and digit classification experiments by a large margin .
Chandrasekaran , Parrilo and Willsky ( 0000 ) proposed a convex optimization problem to characterize graphical model selection in the presence of unobserved variables . This convex optimization problem aims to estimate an inverse covariance matrix that can be decomposed into a sparse matrix minus a low-rank matrix from sample data . Solving this convex optimization problem is very challenging , especially for large problems . In this paper , we propose two alternating direction methods for solving this problem . The first method is to apply the classical alternating direction method of multipliers to solve the problem as a consensus problem . The second method is a proximal gradient based alternating direction method of multipliers . Our methods exploit and take advantage of the special structure of the problem and thus can solve large problems very efficiently . Global convergence result is established for the proposed methods . Numerical results on both synthetic data and gene expression data show that our methods usually solve problems with one million variables in one to two minutes , and are usually five to thirty five times faster than a state-of-the-art Newton-CG proximal point algorithm .
First steps towards a mathematical theory of deep convolutional neural networks for feature extraction were made---for the continuous-time case---in Mallat , 0000 , and Wiatowski and B\ " olcskei , 0000 . This paper considers the discrete case , introduces new convolutional neural network architectures , and proposes a mathematical framework for their analysis . Specifically , we establish deformation and translation sensitivity results of local and global nature , and we investigate how certain structural properties of the input signal are reflected in the corresponding feature vectors . Our theory applies to general filters and general Lipschitz-continuous non-linearities and pooling operators . Experiments on handwritten digit classification and facial landmark detection---including feature importance evaluation---complement the theoretical findings .
We consider the composition optimization with two expected-value functions in the form of $\frac{0}{n}\sum\nolimits_{i = 0}^n F_i ( \frac{0}{m}\sum\nolimits_{j = 0}^m G_j ( x ) ) +R ( x ) $ , { which formulates many important problems in statistical learning and machine learning such as solving Bellman equations in reinforcement learning and nonlinear embedding} . Full Gradient or classical stochastic gradient descent based optimization algorithms are unsuitable or computationally expensive to solve this problem due to the inner expectation $\frac{0}{m}\sum\nolimits_{j = 0}^m G_j ( x ) $ . We propose a duality-free based stochastic composition method that combines variance reduction methods to address the stochastic composition problem . We apply SVRG and SAGA based methods to estimate the inner function , and duality-free method to estimate the outer function . We prove the linear convergence rate not only for the convex composition problem , but also for the case that the individual outer functions are non-convex while the objective function is strongly-convex . We also provide the results of experiments that show the effectiveness of our proposed methods .
Machine learning and deep learning in particular has advanced tremendously on perceptual tasks in recent years . However , it remains vulnerable against adversarial perturbations of the input that have been crafted specifically to fool the system while being quasi-imperceptible to a human . In this work , we propose to augment deep neural networks with a small " detector " subnetwork which is trained on the binary classification task of distinguishing genuine data from data containing adversarial perturbations . Our method is orthogonal to prior work on addressing adversarial perturbations , which has mostly focused on making the classification network itself more robust . We show empirically that adversarial perturbations can be detected surprisingly well even though they are quasi-imperceptible to humans . Moreover , while the detectors have been trained to detect only a specific adversary , they generalize to similar and weaker adversaries . In addition , we propose an adversarial attack that fools both the classifier and the detector and a novel training procedure for the detector that counteracts this attack .
Real-world complex networks describe connections between objects ; in reality , those objects are often endowed with some kind of features . How does the presence or absence of such features interplay with the network link structure ? Although the situation here described is truly ubiquitous , there is a limited body of research dealing with large graphs of this kind . Many previous works considered homophily as the only possible transmission mechanism translating node features into links . Other authors , instead , developed more sophisticated models , that are able to handle complex feature interactions , but are unfit to scale to very large networks . We expand on the MGJ model , where interactions between pairs of features can foster or discourage link formation . In this work , we will investigate how to estimate the latent feature-feature interactions in this model . We shall propose two solutions : the first one assumes feature independence and it is essentially based on Naive Bayes ; the second one , which relaxes the independence assumption assumption , is based on perceptrons . In fact , we show it is possible to cast the model equation in order to see it as the prediction rule of a perceptron . We analyze how classical results for the perceptrons can be interpreted in this context ; then , we define a fast and simple perceptron-like algorithm for this task , which can process $00^0$ links in minutes . We then compare these two techniques , first with synthetic datasets that follows our model , gaining evidence that the Naive independence assumptions are detrimental in practice . Secondly , we consider a real , large-scale citation network where each node ( i . e . , paper ) can be described by different types of characteristics ; there , our algorithm can assess how well each set of features can explain the links , and thus finding meaningful latent feature-feature interactions .
Recently , many regularized procedures have been proposed for variable selection in linear regression , but their performance depends on the tuning parameter selection . Here a criterion for the tuning parameter selection is proposed , which combines the strength of both stability selection and cross-validation and therefore is referred as the prediction and stability selection ( PASS ) . The selection consistency is established assuming the data generating model is a subset of the full model , and the small sample performance is demonstrated through some simulation studies where the assumption is either held or violated .
We consider the problem of unveiling the implicit network structure of user interactions in a social network , based only on high-frequency timestamps . Our inference is based on the minimization of the least-squares loss associated with a multivariate Hawkes model , penalized by $\ell_0$ and trace norms . We provide a first theoretical analysis of the generalization error for this problem , that includes sparsity and low-rank inducing priors . This result involves a new data-driven concentration inequality for matrix martingales in continuous time with observable variance , which is a result of independent interest . A consequence of our analysis is the construction of sharply tuned $\ell_0$ and trace-norm penalizations , that leads to a data-driven scaling of the variability of information available for each users . Numerical experiments illustrate the strong improvements achieved by the use of such data-driven penalizations .
We study the performance of data-driven , a priori and random approaches to label space partitioning for multi-label classification with a Gaussian Naive Bayes classifier . Experiments were performed on 00 benchmark data sets and evaluated on 0 established measures of classification quality : micro and macro averaged F0 score , Subset Accuracy and Hamming loss . Data-driven methods are significantly better than an average run of the random baseline . In case of F0 scores and Subset Accuracy - data driven approaches were more likely to perform better than random approaches than otherwise in the worst case . There always exists a method that performs better than a priori methods in the worst case . The advantage of data-driven methods against a priori methods with a weak classifier is lesser than when tree classifiers are used .
Time series ( TS ) occur in many scientific and commercial applications , ranging from earth surveillance to industry automation to the smart grids . An important type of TS analysis is classification , which can , for instance , improve energy load forecasting in smart grids by detecting the types of electronic devices based on their energy consumption profiles recorded by automatic sensors . Such sensor-driven applications are very often characterized by ( a ) very long TS and ( b ) very large TS datasets needing classification . However , current methods to time series classification ( TSC ) cannot cope with such data volumes at acceptable accuracy ; they are either scalable but offer only inferior classification quality , or they achieve state-of-the-art classification quality but cannot scale to large data volumes . In this paper , we present WEASEL ( Word ExtrAction for time SEries cLassification ) , a novel TSC method which is both scalable and accurate . Like other state-of-the-art TSC methods , WEASEL transforms time series into feature vectors , using a sliding-window approach , which are then analyzed through a machine learning classifier . The novelty of WEASEL lies in its specific method for deriving features , resulting in a much smaller yet much more discriminative feature set . On the popular UCR benchmark of 00 TS datasets , WEASEL is more accurate than the best current non-ensemble algorithms at orders-of-magnitude lower classification and training times , and it is almost as accurate as ensemble classifiers , whose computational complexity makes them inapplicable even for mid-size datasets . The outstanding robustness of WEASEL is also confirmed by experiments on two real smart grid datasets , where it out-of-the-box achieves almost the same accuracy as highly tuned , domain-specific methods .
Motivated by problems of anomaly detection , this paper implements the Neyman-Pearson paradigm to deal with asymmetric errors in binary classification with a convex loss . Given a finite collection of classifiers , we combine them and obtain a new classifier that satisfies simultaneously the two following properties with high probability : ( i ) its probability of type I error is below a pre-specified level and ( ii ) , it has probability of type II error close to the minimum possible . The proposed classifier is obtained by solving an optimization problem with an empirical objective and an empirical constraint . New techniques to handle such problems are developed and have consequences on chance constrained programming .
The GANs are generative models whose random samples realistically reflect natural images . It also can generate samples with specific attributes by concatenating a condition vector into the input , yet research on this field is not well studied . We propose novel methods of conditioning generative adversarial networks ( GANs ) that achieve state-of-the-art results on MNIST and CIFAR-00 . We mainly introduce two models : an information retrieving model that extracts conditional information from the samples , and a spatial bilinear pooling model that forms bilinear features derived from the spatial cross product of an image and a condition vector . These methods significantly enhance log-likelihood of test data under the conditional distributions compared to the methods of concatenation .
This paper aims at achieving a " good " estimator for the gradient of a function on a high-dimensional space . Often such functions are not sensitive in all coordinates and the gradient of the function is almost sparse . We propose a method for gradient estimation that combines ideas from Spall ' s Simultaneous Perturbation Stochastic Approximation with compressive sensing . The aim is to obtain " good " estimator without too many function evaluations . Application to estimating gradient outer product matrix as well as standard optimization problems are illustrated via simulations .
Subset selection from massive data with noised information is increasingly popular for various applications . This problem is still highly challenging as current methods are generally slow in speed and sensitive to outliers . To address the above two issues , we propose an accelerated robust subset selection ( ARSS ) method . Specifically in the subset selection area , this is the first attempt to employ the $\ell_{p} ( 0<p\leq0 ) $-norm based measure for the representation loss , preventing large errors from dominating our objective . As a result , the robustness against outlier elements is greatly enhanced . Actually , data size is generally much larger than feature length , i . e . $N\gg L$ . Based on this observation , we propose a speedup solver ( via ALM and equivalent derivations ) to highly reduce the computational cost , theoretically from $O ( N^{0} ) $ to $O ( N{}^{0}L ) $ . Extensive experiments on ten benchmark datasets verify that our method not only outperforms state of the art methods , but also runs 00 , 000+ times faster than the most related method .
The spectral energy distribution ( SED ) is a relatively easy way for astronomers to distinguish between different astronomical objects such as galaxies , black holes , and stellar objects . By comparing the observations from a source at different frequencies with template models , astronomers are able to infer the type of this observed object . In this paper , we take a Bayesian model averaging perspective to learn astronomical objects , employing a Bayesian nonparametric approach to accommodate the deviation from convex combinations of known log-SEDs . To effectively use telescope time for observations , we then study Bayesian nonparametric sequential experimental design without conjugacy , in which we use sequential Monte Carlo as an efficient tool to maximize the volume of information stored in the posterior distribution of the parameters of interest . A new technique for performing inferences in log-Gaussian Cox processes called the Poisson log-normal approximation is also proposed . Simulations show the speed , accuracy , and usefulness of our method . While the strategy we propose in this paper is brand new in the astronomy literature , the inferential techniques developed apply to more general nonparametric sequential experimental design problems .
Unbalanced data arises in many learning tasks such as clustering of multi-class data , hierarchical divisive clustering and semisupervised learning . Graph-based approaches are popular tools for these problems . Graph construction is an important aspect of graph-based learning . We show that graph-based algorithms can fail for unbalanced data for many popular graphs such as k-NN , \epsilon-neighborhood and full-RBF graphs . We propose a novel graph construction technique that encodes global statistical information into node degrees through a ranking scheme . The rank of a data sample is an estimate of its p-value and is proportional to the total number of data samples with smaller density . This ranking scheme serves as a surrogate for density ; can be reliably estimated ; and indicates whether a data sample is close to valleys/modes . This rank-modulated degree ( RMD ) scheme is able to significantly sparsify the graph near valleys and provides an adaptive way to cope with unbalanced data . We then theoretically justify our method through limit cut analysis . Unsupervised and semi-supervised experiments on synthetic and real data sets demonstrate the superiority of our method .
Maximizing the speed and precision of communication while minimizing power dissipation is a fundamental engineering design goal . Also , biological systems achieve remarkable speed , precision and power efficiency using poorly understood physical design principles . Powerful theories like information theory and thermodynamics do not provide general limits on power , precision and speed . Here we go beyond these classical theories to prove that the product of precision and speed is universally bounded by power dissipation in any physical communication channel whose dynamics is faster than that of the signal . Moreover , our derivation involves a novel connection between friction and information geometry . These results may yield insight into both the engineering design of communication devices and the structure and function of biological signaling systems .
In recent years , optimization theory has been greatly impacted by the advent of sum of squares ( SOS ) optimization . The reliance of this technique on large-scale semidefinite programs however , has limited the scale of problems to which it can be applied . In this paper , we introduce DSOS and SDSOS optimization as more tractable alternatives to sum of squares optimization that rely instead on linear and second order cone programs respectively . These are optimization problems over certain subsets of sum of squares polynomials ( or equivalently subsets of positive semidefinite matrices ) , which can be of interest in general applications of semidefinite programming where scalability is a limitation . We show that some basic theorems from SOS optimization which rely on results from real algebraic geometry are still valid for DSOS and SDSOS optimization . Furthermore , we show with numerical experiments from diverse application areas---polynomial optimization , statistics and machine learning , derivative pricing , and control theory---that with reasonable tradeoffs in accuracy , we can handle problems at scales that are currently far beyond the reach of sum of squares approaches . Finally , we provide a review of recent techniques that bridge the gap between our DSOS/SDSOS approach and the SOS approach at the expense of additional running time . The appendix of the paper introduces an accompanying MATLAB package for DSOS and SDSOS optimization .
Anatomical and biophysical modeling of left atrium ( LA ) and proximal pulmonary veins ( PPVs ) is important for clinical management of several cardiac diseases . Magnetic resonance imaging ( MRI ) allows qualitative assessment of LA and PPVs through visualization . However , there is a strong need for an advanced image segmentation method to be applied to cardiac MRI for quantitative analysis of LA and PPVs . In this study , we address this unmet clinical need by exploring a new deep learning-based segmentation strategy for quantification of LA and PPVs with high accuracy and heightened efficiency . Our approach is based on a multi-view convolutional neural network ( CNN ) with an adaptive fusion strategy and a new loss function that allows fast and more accurate convergence of the backpropagation based optimization . After training our network from scratch by using more than 00K 0D MRI images ( slices ) , we have evaluated our segmentation strategy to the STACOM 0000 cardiac segmentation challenge benchmark . Qualitative and quantitative evaluations , obtained from the segmentation challenge , indicate that the proposed method achieved the state-of-the-art sensitivity ( 00% ) , specificity ( 00% ) , precision ( 00% ) , and efficiency levels ( 00 seconds in GPU , and 0 . 0 minutes in CPU ) .
We give algorithms for estimating the expectation of a given real-valued function $\phi : X\to {\bf R}$ on a sample drawn randomly from some unknown distribution $D$ over domain $X$ , namely ${\bf E}_{{\bf x}\sim D}[\phi ( {\bf x} ) ]$ . Our algorithms work in two well-studied models of restricted access to data samples . The first one is the statistical query ( SQ ) model in which an algorithm has access to an SQ oracle for the input distribution $D$ over $X$ instead of i . i . d . samples from $D$ . Given a query function $\phi : X \to [0 , 0]$ , the oracle returns an estimate of ${\bf E}_{{\bf x}\sim D}[\phi ( {\bf x} ) ]$ within some tolerance $\tau$ . The second , is a model in which only a single bit is communicated from each sample . In both of these models the error obtained using a naive implementation would scale polynomially with the range of the random variable $\phi ( {\bf x} ) $ ( which might even be infinite ) . In contrast , without restrictions on access to data the expected error scales with the standard deviation of $\phi ( {\bf x} ) $ . Here we give a simple algorithm whose error scales linearly in standard deviation of $\phi ( {\bf x} ) $ and logarithmically with an upper bound on the second moment of $\phi ( {\bf x} ) $ . As corollaries , we obtain algorithms for high dimensional mean estimation and stochastic convex optimization in these models that work in more general settings than previously known solutions .
We introduce a new graphical model for tracking radio-tagged animals and learning their movement patterns . The model provides a principled way to combine radio telemetry data with an arbitrary set of userdefined , spatial features . We describe an efficient stochastic gradient algorithm for fitting model parameters to data and demonstrate its effectiveness via asymptotic analysis and synthetic experiments . We also apply our model to real datasets , and show that it outperforms the most popular radio telemetry software package used in ecology . We conclude that integration of different data sources under a single statistical framework , coupled with appropriate parameter and state estimation procedures , produces both accurate location estimates and an interpretable statistical model of animal movement .
The goal of decentralized optimization over a network is to optimize a global objective formed by a sum of local ( possibly nonsmooth ) convex functions using only local computation and communication . It arises in various application domains , including distributed tracking and localization , multi-agent co-ordination , estimation in sensor networks , and large-scale optimization in machine learning . We develop and analyze distributed algorithms based on dual averaging of subgradients , and we provide sharp bounds on their convergence rates as a function of the network size and topology . Our method of analysis allows for a clear separation between the convergence of the optimization algorithm itself and the effects of communication constraints arising from the network structure . In particular , we show that the number of iterations required by our algorithm scales inversely in the spectral gap of the network . The sharpness of this prediction is confirmed both by theoretical lower bounds and simulations for various networks . Our approach includes both the cases of deterministic optimization and communication , as well as problems with stochastic optimization and/or communication .
Generative Adversarial Networks ( GANs ) represent a promising class of generative networks that combine neural networks with game theory . From generating realistic images and videos to assisting musical creation , GANs are transforming many fields of arts and sciences . However , their application to healthcare has not been fully realized , more specifically in generating electronic health records ( EHR ) data . In this paper , we propose a framework for exploring the value of GANs in the context of continuous laboratory time series data . We devise an unsupervised evaluation method that measures the predictive power of synthetic laboratory test time series . Further , we show that when it comes to predicting the impact of drug exposure on laboratory test data , incorporating representation learning of the training cohorts prior to training GAN models is beneficial .
Traditional Linear Genetic Programming ( LGP ) algorithms are based only on the selection mechanism to guide the search . Genetic operators combine or mutate random portions of the individuals , without knowing if the result will lead to a fitter individual . Probabilistic Model Building Genetic Programming ( PMB-GP ) methods were proposed to overcome this issue through a probability model that captures the structure of the fit individuals and use it to sample new individuals . This work proposes the use of LGP with a Stochastic Context-Free Grammar ( SCFG ) , that has a probability distribution that is updated according to selected individuals . We proposed a method for adapting the grammar into the linear representation of LGP . Tests performed with the proposed probabilistic method , and with two hybrid approaches , on several symbolic regression benchmark problems show that the results are statistically better than the obtained by the traditional LGP .
The maximum mean discrepancy ( MMD ) is a recently proposed test statistic for two-sample test . Its quadratic time complexity , however , greatly hampers its availability to large-scale applications . To accelerate the MMD calculation , in this study we propose an efficient method called FastMMD . The core idea of FastMMD is to equivalently transform the MMD with shift-invariant kernels into the amplitude expectation of a linear combination of sinusoid components based on Bochner ' s theorem and Fourier transform ( Rahimi & Recht , 0000 ) . Taking advantage of sampling of Fourier transform , FastMMD decreases the time complexity for MMD calculation from $O ( N^0 d ) $ to $O ( L N d ) $ , where $N$ and $d$ are the size and dimension of the sample set , respectively . Here $L$ is the number of basis functions for approximating kernels which determines the approximation accuracy . For kernels that are spherically invariant , the computation can be further accelerated to $O ( L N \log d ) $ by using the Fastfood technique ( Le et al . , 0000 ) . The uniform convergence of our method has also been theoretically proved in both unbiased and biased estimates . We have further provided a geometric explanation for our method , namely ensemble of circular discrepancy , which facilitates us to understand the insight of MMD , and is hopeful to help arouse more extensive metrics for assessing two-sample test . Experimental results substantiate that FastMMD is with similar accuracy as exact MMD , while with faster computation speed and lower variance than the existing MMD approximation methods .
This paper presents a novel deep learning-based method for learning a functional representation of mammalian neural images . The method uses a deep convolutional denoising autoencoder ( CDAE ) for generating an invariant , compact representation of in situ hybridization ( ISH ) images . While most existing methods for bio-imaging analysis were not developed to handle images with highly complex anatomical structures , the results presented in this paper show that functional representation extracted by CDAE can help learn features of functional gene ontology categories for their classification in a highly accurate manner . Using this CDAE representation , our method outperforms the previous state-of-the-art classification rate , by improving the average AUC from 0 . 00 to 0 . 00 , i . e . , achieving 00% reduction in error . The method operates on input images that were downsampled significantly with respect to the original ones to make it computationally feasible .
We introduce {\em vector diffusion maps} ( VDM ) , a new mathematical framework for organizing and analyzing massive high dimensional data sets , images and shapes . VDM is a mathematical and algorithmic generalization of diffusion maps and other non-linear dimensionality reduction methods , such as LLE , ISOMAP and Laplacian eigenmaps . While existing methods are either directly or indirectly related to the heat kernel for functions over the data , VDM is based on the heat kernel for vector fields . VDM provides tools for organizing complex data sets , embedding them in a low dimensional space , and interpolating and regressing vector fields over the data . In particular , it equips the data with a metric , which we refer to as the {\em vector diffusion distance} . In the manifold learning setup , where the data set is distributed on ( or near ) a low dimensional manifold $\MM^d$ embedded in $\RR^{p}$ , we prove the relation between VDM and the connection-Laplacian operator for vector fields over the manifold .
In this paper we provide a new analysis of the SEM algorithm . Unlike previous work , we focus on the analysis of a single run of the algorithm . First , we discuss the algorithm for general mixture distributions . Second , we consider Gaussian mixture models and show that with high probability the update equations of the EM algorithm and its stochastic variant are almost the same , given that the input set is sufficiently large . Our experiments confirm that this still holds for a large number of successive update steps . In particular , for Gaussian mixture models , we show that the stochastic variant runs nearly twice as fast .
In many applications , a finite mixture is a natural model , but it can be difficult to choose an appropriate number of components . To circumvent this choice , investigators are increasingly turning to Dirichlet process mixtures ( DPMs ) , and Pitman-Yor process mixtures ( PYMs ) , more generally . While these models may be well-suited for Bayesian density estimation , many investigators are using them for inferences about the number of components , by considering the posterior on the number of components represented in the observed data . We show that this posterior is not consistent --- that is , on data from a finite mixture , it does not concentrate at the true number of components . This result applies to a large class of nonparametric mixtures , including DPMs and PYMs , over a wide variety of families of component distributions , including essentially all discrete families , as well as continuous exponential families satisfying mild regularity conditions ( such as multivariate Gaussians ) .
The present work deals with active sampling of graph nodes representing training data for binary classification . The graph may be given or constructed using similarity measures among nodal features . Leveraging the graph for classification builds on the premise that labels across neighboring nodes are correlated according to a categorical Markov random field ( MRF ) . This model is further relaxed to a Gaussian ( G ) MRF with labels taking continuous values - an approximation that not only mitigates the combinatorial complexity of the categorical model , but also offers optimal unbiased soft predictors of the unlabeled nodes . The proposed sampling strategy is based on querying the node whose label disclosure is expected to inflict the largest change on the GMRF , and in this sense it is the most informative on average . Such a strategy subsumes several measures of expected model change , including uncertainty sampling , variance minimization , and sampling based on the $\Sigma-$optimality criterion . A simple yet effective heuristic is also introduced for increasing the exploration capabilities of the sampler , and reducing bias of the resultant classifier , by taking into account the confidence on the model label predictions . The novel sampling strategies are based on quantities that are readily available without the need for model retraining , rendering them computationally efficient and scalable to large graphs . Numerical tests using synthetic and real data demonstrate that the proposed methods achieve accuracy that is comparable or superior to the state-of-the-art even at reduced runtime .
Restricted Boltzman Machines ( RBMs ) have been successfully used in recommender systems . However , as with most of other collaborative filtering techniques , it cannot solve cold start problems for there is no rating for a new item . In this paper , we first apply conditional RBM ( CRBM ) which could take extra information into account and show that CRBM could solve cold start problem very well , especially for rating prediction task . CRBM naturally combine the content and collaborative data under a single framework which could be fitted effectively . Experiments show that CRBM can be compared favourably with matrix factorization models , while hidden features learned from the former models are more easy to be interpreted .
Graphical Gaussian models have proven to be useful tools for exploring network structures based on multivariate data . Applications to studies of gene expression have generated substantial interest in these models , and resulting recent progress includes the development of fitting methodology involving penalization of the likelihood function . In this paper we advocate the use of multivariate $t$-distributions for more robust inference of graphs . In particular , we demonstrate that penalized likelihood inference combined with an application of the EM algorithm provides a computationally efficient approach to model selection in the $t$-distribution case . We consider two versions of multivariate $t$-distributions , one of which requires the use of approximation techniques . For this distribution , we describe a Markov chain Monte Carlo EM algorithm based on a Gibbs sampler as well as a simple variational approximation that makes the resulting method feasible in large problems .
Adversarial training has been shown to regularize deep neural networks in addition to increasing their robustness to adversarial examples . However , its impact on very deep state of the art networks has not been fully investigated . In this paper , we present an efficient approach to perform adversarial training by perturbing intermediate layer activations and study the use of such perturbations as a regularizer during training . We use these perturbations to train very deep models such as ResNets and show improvement in performance both on adversarial and original test data . Our experiments highlight the benefits of perturbing intermediate layer activations compared to perturbing only the inputs . The results on CIFAR-00 and CIFAR-000 datasets show the merits of the proposed adversarial training approach . Additional results on WideResNets show that our approach provides significant improvement in classification accuracy for a given base model , outperforming dropout and other base models of larger size .
This paper introduces a novel parameter estimation method for the probability tables of Bayesian network classifiers ( BNCs ) , using hierarchical Dirichlet processes ( HDPs ) . The main result of this paper is to show that improved parameter estimation allows BNCs to outperform leading learning methods such as Random Forest for both 0-0 loss and RMSE , albeit just on categorical datasets . As data assets become larger , entering the hyped world of " big " , efficient accurate classification requires three main elements : ( 0 ) classifiers with low-bias that can capture the fine-detail of large datasets ( 0 ) out-of-core learners that can learn from data without having to hold it all in main memory and ( 0 ) models that can classify new data very efficiently . The latest Bayesian network classifiers ( BNCs ) satisfy these requirements . Their bias can be controlled easily by increasing the number of parents of the nodes in the graph . Their structure can be learned out of core with a limited number of passes over the data . However , as the bias is made lower to accurately model classification tasks , so is the accuracy of their parameters ' estimates , as each parameter is estimated from ever decreasing quantities of data . In this paper , we introduce the use of Hierarchical Dirichlet Processes for accurate BNC parameter estimation . We conduct an extensive set of experiments on 00 standard datasets and demonstrate that our resulting classifiers perform very competitively with Random Forest in terms of prediction , while keeping the out-of-core capability and superior classification time .
This survey is an introduction to positive definite kernels and the set of methods they have inspired in the machine learning literature , namely kernel methods . We first discuss some properties of positive definite kernels as well as reproducing kernel Hibert spaces , the natural extension of the set of functions $\{k ( x , \cdot ) , x\in\mathcal{X}\}$ associated with a kernel $k$ defined on a space $\mathcal{X}$ . We discuss at length the construction of kernel functions that take advantage of well-known statistical models . We provide an overview of numerous data-analysis methods which take advantage of reproducing kernel Hilbert spaces and discuss the idea of combining several kernels to improve the performance on certain tasks . We also provide a short cookbook of different kernels which are particularly useful for certain data-types such as images , graphs or speech segments .
While learning the maximum likelihood value of parameters of an undirected graphical model is hard , modelling the posterior distribution over parameters given data is harder . Yet , undirected models are ubiquitous in computer vision and text modelling ( e . g . conditional random fields ) . But where Bayesian approaches for directed models have been very successful , a proper Bayesian treatment of undirected models in still in its infant stages . We propose a new method for approximating the posterior of the parameters given data based on the Laplace approximation . This approximation requires the computation of the covariance matrix over features which we compute using the linear response approximation based in turn on loopy belief propagation . We develop the theory for conditional and ' unconditional ' random fields with or without hidden variables . In the conditional setting we introduce a new variant of bagging suitable for structured domains . Here we run the loopy max-product algorithm on a ' super-graph ' composed of graphs for individual models sampled from the posterior and connected by constraints . Experiments on real world data validate the proposed methods .
Despite the recent progress towards efficient multiple kernel learning ( MKL ) , the structured output case remains an open research front . Current approaches involve repeatedly solving a batch learning problem , which makes them inadequate for large scale scenarios . We propose a new family of online proximal algorithms for MKL ( as well as for group-lasso and variants thereof ) , which overcomes that drawback . We show regret , convergence , and generalization bounds for the proposed method . Experiments on handwriting recognition and dependency parsing testify for the successfulness of the approach .
Based on the Aristotelian concept of potentiality vs . actuality allowing for the study of energy and dynamics in language , we propose a field approach to lexical analysis . Falling back on the distributional hypothesis to statistically model word meaning , we used evolving fields as a metaphor to express time-dependent changes in a vector space model by a combination of random indexing and evolving self-organizing maps ( ESOM ) . To monitor semantic drifts within the observation period , an experiment was carried out on the term space of a collection of 00 . 0 million Amazon book reviews . For evaluation , the semantic consistency of ESOM term clusters was compared with their respective neighbourhoods in WordNet , and contrasted with distances among term vectors by random indexing . We found that at 0 . 00 level of significance , the terms in the clusters showed a high level of semantic consistency . Tracking the drift of distributional patterns in the term space across time periods , we found that consistency decreased , but not at a statistically significant level . Our method is highly scalable , with interpretations in philosophy .
Gaussian random fields are a powerful tool for modeling environmental processes . For high dimensional samples , classical approaches for estimating the covariance parameters require highly challenging and massive computations , such as the evaluation of the Cholesky factorization or solving linear systems . Recently , Anitescu , Chen and Stein \cite{M . Anitescu} proposed a fast and scalable algorithm which does not need such burdensome computations . The main focus of this article is to study the asymptotic behavior of the algorithm of Anitescu et al . ( ACS ) for regular and irregular grids in the increasing domain setting . Consistency , minimax optimality and asymptotic normality of this algorithm are proved under mild differentiability conditions on the covariance function . Despite the fact that ACS ' s method entails a non-concave maximization , our results hold for any stationary point of the objective function . A numerical study is presented to evaluate the efficiency of this algorithm for large data sets .
We study the information-theoretic lower bound of the sample complexity of the correct recovery of diffusion network structures . We introduce a discrete-time diffusion model based on the Independent Cascade model for which we obtain a lower bound of order $\Omega ( k \log p ) $ , for directed graphs of $p$ nodes , and at most $k$ parents per node . Next , we introduce a continuous-time diffusion model , for which a similar lower bound of order $\Omega ( k \log p ) $ is obtained . Our results show that the algorithm of Pouget-Abadie et al . is statistically optimal for the discrete-time regime . Our work also opens the question of whether it is possible to devise an optimal algorithm for the continuous-time regime .
Receiver algorithms which combine belief propagation ( BP ) with the mean field ( MF ) approximation are well-suited for inference of both continuous and discrete random variables . In wireless scenarios involving detection of multiple signals , the standard construction of the combined BP-MF framework includes the equalization or multi-user detection functions within the MF subgraph . In this paper , we show that the MF approximation is not particularly effective for multi-signal detection . We develop a new factor graph construction for application of the BP-MF framework to problems involving the detection of multiple signals . We then develop a low-complexity variant to the proposed construction in which Gaussian BP is applied to the equalization factors . In this case , the factor graph of the joint probability distribution is divided into three subgraphs : ( i ) a MF subgraph comprised of the observation factors and channel estimation , ( ii ) a Gaussian BP subgraph which is applied to multi-signal detection , and ( iii ) a discrete BP subgraph which is applied to demodulation and decoding . Expectation propagation is used to approximate discrete distributions with a Gaussian distribution and links the discrete BP and Gaussian BP subgraphs . The result is a probabilistic receiver architecture with strong theoretical justification which can be applied to multi-signal detection .
Randomized experiments have been critical tools of decision making for decades . However , subjects can show significant heterogeneity in response to treatments in many important applications . Therefore it is not enough to simply know which treatment is optimal for the entire population . What we need is a model that correctly customize treatment assignment base on subject characteristics . The problem of constructing such models from randomized experiments data is known as Uplift Modeling in the literature . Many algorithms have been proposed for uplift modeling and some have generated promising results on various data sets . Yet little is known about the theoretical properties of these algorithms . In this paper , we propose a new tree-based ensemble algorithm for uplift modeling . Experiments show that our algorithm can achieve competitive results on both synthetic and industry-provided data . In addition , by properly tuning the " node size " parameter , our algorithm is proved to be consistent under mild regularity conditions . This is the first consistent algorithm for uplift modeling that we are aware of .
Results of the application of pattern recognition techniques to the problem of identifying Giant Radio Sources ( GRS ) from the data in the NVSS catalog are presented and issues affecting the process are explored . Decision-tree pattern recognition software was applied to training set source pairs developed from known NVSS large angular size radio galaxies . The full training set consisted of 00 , 000 source pairs , 00 of which were known GRS for which each lobe was primarily represented by a single catalog component . The source pairs had a maximum separation of 00 arc minutes and a minimum component area of 0 . 00 square arc minutes at the 0 . 0 mJy level . The importance of comparing resulting probability distributions of the training and application sets for cases of unknown class ratio is demonstrated . The probability of correctly ranking a randomly selected ( GRS , non-GRS ) pair from the best of the tested classifiers was determined to be 00 . 0 +/- 0 . 0% . The best classifiers were applied to the over 000 , 000 candidate pairs from the entire catalog . Images of higher ranked sources were visually screened and a table of over sixteen hundred candidates , including morphological annotation , is presented . These systems include doubles and triples , Wide-Angle Tail ( WAT ) and Narrow-Angle Tail ( NAT ) , S- or Z-shaped systems , and core-jets and resolved cores . While some resolved lobe systems are recovered with this technique , generally it is expected that such systems would require a different approach .
A central goal of neuroscience is to understand how activity in the nervous system is related to features of the external world , or to features of the nervous system itself . A common approach is to model neural responses as a weighted combination of external features , or vice versa . The structure of the model weights can provide insight into neural representations . Often , neural input-output relationships are sparse , with only a few inputs contributing to the output . In part to account for such sparsity , structured regularizers are incorporated into model fitting optimization . However , by imposing priors , structured regularizers can make it difficult to interpret learned model parameters . Here , we investigate a simple , minimally structured model estimation method for accurate , unbiased estimation of sparse models based on Bootstrapped Adaptive Threshold Selection followed by ordinary least-squares refitting ( BoATS ) . Through extensive numerical investigations , we show that this method often performs favorably compared to L0 and L0 regularizers . In particular , for a variety of model distributions and noise levels , BoATS more accurately recovers the parameters of sparse models , leading to more parsimonious explanations of outputs . Finally , we apply this method to the task of decoding human speech production from ECoG recordings .
We show that the error probability of reconstructing kernel matrices from Random Fourier Features for any shift-invariant kernel function is at most $\mathcal{O} ( \exp ( -D ) ) $ , where $D$ is the number of random features . We also provide a matching information-theoretic method-independent lower bound of $\Omega ( \exp ( -D ) ) $ for standard Gaussian distributions . Compared to prior work , we are the first to show that the error probability for random Fourier features is independent of the dimensionality of data points as well as the size of their domain . As applications of our theory , we obtain dimension-independent bounds for kernel ridge regression and support vector machines .
Many deployed learned models are black boxes : given input , returns output . Internal information about the model , such as the architecture , optimisation procedure , or training data , is not disclosed explicitly as it might contain proprietary information or make the system more vulnerable . This work shows that such attributes of neural networks can be exposed from a sequence of queries . This has multiple implications . On the one hand , our work exposes the vulnerability of black-box neural networks to different types of attacks -- we show that the revealed internal information helps generate more effective adversarial examples against the black box model . On the other hand , this technique can be used for better protection of private content from automatic recognition models using adversarial examples . Our paper suggests that it is actually hard to draw a line between white box and black box models .
This article addresses the modeling of reverberant recording environments in the context of under-determined convolutive blind source separation . We model the contribution of each source to all mixture channels in the time-frequency domain as a zero-mean Gaussian random variable whose covariance encodes the spatial characteristics of the source . We then consider four specific covariance models , including a full-rank unconstrained model . We derive a family of iterative expectationmaximization ( EM ) algorithms to estimate the parameters of each model and propose suitable procedures to initialize the parameters and to align the order of the estimated sources across all frequency bins based on their estimated directions of arrival ( DOA ) . Experimental results over reverberant synthetic mixtures and live recordings of speech data show the effectiveness of the proposed approach .
Linear optimization is many times algorithmically simpler than non-linear convex optimization . Linear optimization over matroid polytopes , matching polytopes and path polytopes are example of problems for which we have simple and efficient combinatorial algorithms , but whose non-linear convex counterpart is harder and admits significantly less efficient algorithms . This motivates the computational model of convex optimization , including the offline , online and stochastic settings , using a linear optimization oracle . In this computational model we give several new results that improve over the previous state-of-the-art . Our main result is a novel conditional gradient algorithm for smooth and strongly convex optimization over polyhedral sets that performs only a single linear optimization step over the domain on each iteration and enjoys a linear convergence rate . This gives an exponential improvement in convergence rate over previous results . Based on this new conditional gradient algorithm we give the first algorithms for online convex optimization over polyhedral sets that perform only a single linear optimization step over the domain while having optimal regret guarantees , answering an open question of Kalai and Vempala , and Hazan and Kale . Our online algorithms also imply conditional gradient algorithms for non-smooth and stochastic convex optimization with the same convergence rates as projected ( sub ) gradient methods .
In this paper , we propose a simple , versatile model for learning the structure and parameters of multivariate distributions from a data set . Learning a Markov network from a given data set is not a simple problem , because Markov networks rigorously represent Markov properties , and this rigor imposes complex constraints on the design of the networks . Our proposed model removes these constraints , acquiring important aspects from the information geometry . The proposed parameter- and structure-learning algorithms are simple to execute as they are based solely on local computation at each node . Experiments demonstrate that our algorithms work appropriately .
To obtain uncertainty estimates with real-world Bayesian deep learning models , practical inference approximations are needed . Dropout variational inference ( VI ) for example has been used for machine vision and medical applications , but VI can severely underestimates model uncertainty . Alpha-divergences are alternative divergences to VI ' s KL objective , which are able to avoid VI ' s uncertainty underestimation . But these are hard to use in practice : existing techniques can only use Gaussian approximating distributions , and require existing models to be changed radically , thus are of limited use for practitioners . We propose a re-parametrisation of the alpha-divergence objectives , deriving a simple inference technique which , together with dropout , can be easily implemented with existing models by simply changing the loss of the model . We demonstrate improved uncertainty estimates and accuracy compared to VI in dropout networks . We study our model ' s epistemic uncertainty far away from the data using adversarial images , showing that these can be distinguished from non-adversarial images by examining our model ' s uncertainty .
Given a matrix $A$ , a linear feasibility problem ( of which linear classification is a special case ) aims to find a solution to a primal problem $w : A^Tw > \textbf{0}$ or a certificate for the dual problem which is a probability distribution $p : Ap = \textbf{0}$ . Inspired by the continued importance of " large-margin classifiers " in machine learning , this paper studies a condition measure of $A$ called its \textit{margin} that determines the difficulty of both the above problems . To aid geometrical intuition , we first establish new characterizations of the margin in terms of relevant balls , cones and hulls . Our second contribution is analytical , where we present generalizations of Gordan ' s theorem , and variants of Hoffman ' s theorems , both using margins . We end by proving some new results on a classical iterative scheme , the Perceptron , whose convergence rates famously depends on the margin . Our results are relevant for a deeper understanding of margin-based learning and proving convergence rates of iterative schemes , apart from providing a unifying perspective on this vast topic .
Training deep networks is a time-consuming process , with networks for object recognition often requiring multiple days to train . For this reason , leveraging the resources of a cluster to speed up training is an important area of work . However , widely-popular batch-processing computational frameworks like MapReduce and Spark were not designed to support the asynchronous and communication-intensive workloads of existing distributed deep learning systems . We introduce SparkNet , a framework for training deep networks in Spark . Our implementation includes a convenient interface for reading data from Spark RDDs , a Scala interface to the Caffe deep learning framework , and a lightweight multi-dimensional tensor library . Using a simple parallelization scheme for stochastic gradient descent , SparkNet scales well with the cluster size and tolerates very high-latency communication . Furthermore , it is easy to deploy and use with no parameter tuning , and it is compatible with existing Caffe models . We quantify the dependence of the speedup obtained by SparkNet on the number of machines , the communication frequency , and the cluster ' s communication overhead , and we benchmark our system ' s performance on the ImageNet dataset .
We propose a hybrid algorithmic strategy for complex stochastic optimization problems , which combines the use of scenario trees from multistage stochastic programming with machine learning techniques for learning a policy in the form of a statistical model , in the context of constrained vector-valued decisions . Such a policy allows one to run out-of-sample simulations over a large number of independent scenarios , and obtain a signal on the quality of the approximation scheme used to solve the multistage stochastic program . We propose to apply this fast simulation technique to choose the best tree from a set of scenario trees . A solution scheme is introduced , where several scenario trees with random branching structure are solved in parallel , and where the tree from which the best policy for the true problem could be learned is ultimately retained . Numerical tests show that excellent trade-offs can be achieved between run times and solution quality .
We consider the problem of estimating the expected value of information ( the knowledge gradient ) for Bayesian learning problems where the belief model is nonlinear in the parameters . Our goal is to maximize some metric , while simultaneously learning the unknown parameters of the nonlinear belief model , by guiding a sequential experimentation process which is expensive . We overcome the problem of computing the expected value of an experiment , which is computationally intractable , by using a sampled approximation , which helps to guide experiments but does not provide an accurate estimate of the unknown parameters . We then introduce a resampling process which allows the sampled model to adapt to new information , exploiting past experiments . We show theoretically that the method converges asymptotically to the true parameters , while simultaneously maximizing our metric . We show empirically that the process exhibits rapid convergence , yielding good results with a very small number of experiments .
We describe a seriation algorithm for ranking a set of items given pairwise comparisons between these items . Intuitively , the algorithm assigns similar rankings to items that compare similarly with all others . It does so by constructing a similarity matrix from pairwise comparisons , using seriation methods to reorder this matrix and construct a ranking . We first show that this spectral seriation algorithm recovers the true ranking when all pairwise comparisons are observed and consistent with a total order . We then show that ranking reconstruction is still exact when some pairwise comparisons are corrupted or missing , and that seriation based spectral ranking is more robust to noise than classical scoring methods . Finally , we bound the ranking error when only a random subset of the comparions are observed . An additional benefit of the seriation formulation is that it allows us to solve semi-supervised ranking problems . Experiments on both synthetic and real datasets demonstrate that seriation based spectral ranking achieves competitive and in some cases superior performance compared to classical ranking methods .
We introduce a new framework for unsupervised learning of representations based on a novel hierarchical decomposition of information . Intuitively , data is passed through a series of progressively fine-grained sieves . Each layer of the sieve recovers a single latent factor that is maximally informative about multivariate dependence in the data . The data is transformed after each pass so that the remaining unexplained information trickles down to the next layer . Ultimately , we are left with a set of latent factors explaining all the dependence in the original data and remainder information consisting of independent noise . We present a practical implementation of this framework for discrete variables and apply it to a variety of fundamental tasks in unsupervised learning including independent component analysis , lossy and lossless compression , and predicting missing values in data .
We propose Dirichlet Process mixtures of Generalized Linear Models ( DP-GLM ) , a new method of nonparametric regression that accommodates continuous and categorical inputs , and responses that can be modeled by a generalized linear model . We prove conditions for the asymptotic unbiasedness of the DP-GLM regression mean function estimate . We also give examples for when those conditions hold , including models for compactly supported continuous distributions and a model with continuous covariates and categorical response . We empirically analyze the properties of the DP-GLM and why it provides better results than existing Dirichlet process mixture regression models . We evaluate DP-GLM on several data sets , comparing it to modern methods of nonparametric regression like CART , Bayesian trees and Gaussian processes . Compared to existing techniques , the DP-GLM provides a single model ( and corresponding inference algorithms ) that performs well in many regression settings .
We obtain the first polynomial-time algorithm for exact tensor completion that improves over the bound implied by reduction to matrix completion . The algorithm recovers an unknown 0-tensor with $r$ incoherent , orthogonal components in $\mathbb R^n$ from $r\cdot \tilde O ( n^{0 . 0} ) $ randomly observed entries of the tensor . This bound improves over the previous best one of $r\cdot \tilde O ( n^{0} ) $ by reduction to exact matrix completion . Our bound also matches the best known results for the easier problem of approximate tensor completion ( Barak & Moitra , 0000 ) . Our algorithm and analysis extends seminal results for exact matrix completion ( Candes & Recht , 0000 ) to the tensor setting via the sum-of-squares method . The main technical challenge is to show that a small number of randomly chosen monomials are enough to construct a degree-0 polynomial with precisely planted orthogonal global optima over the sphere and that this fact can be certified within the sum-of-squares proof system .
We study a variant of the variational autoencoder model ( VAE ) with a Gaussian mixture as a prior distribution , with the goal of performing unsupervised clustering through deep generative models . We observe that the known problem of over-regularisation that has been shown to arise in regular VAEs also manifests itself in our model and leads to cluster degeneracy . We show that a heuristic called minimum information constraint that has been shown to mitigate this effect in VAEs can also be applied to improve unsupervised clustering performance with our model . Furthermore we analyse the effect of this heuristic and provide an intuition of the various processes with the help of visualizations . Finally , we demonstrate the performance of our model on synthetic data , MNIST and SVHN , showing that the obtained clusters are distinct , interpretable and result in achieving competitive performance on unsupervised clustering to the state-of-the-art results .
Regularized discriminant analysis ( RDA ) , proposed by Friedman ( 0000 ) , is a widely popular classifier that lacks interpretability and is impractical for high-dimensional data sets . Here , we present an interpretable and computationally efficient classifier called high-dimensional RDA ( HDRDA ) , designed for the small-sample , high-dimensional setting . For HDRDA , we show that each training observation , regardless of class , contributes to the class covariance matrix , resulting in an interpretable estimator that borrows from the pooled sample covariance matrix . Moreover , we show that HDRDA is equivalent to a classifier in a reduced-feature space with dimension approximately equal to the training sample size . As a result , the matrix operations employed by HDRDA are computationally linear in the number of features , making the classifier well-suited for high-dimensional classification in practice . We demonstrate that HDRDA is often superior to several sparse and regularized classifiers in terms of classification accuracy with three artificial and six real high-dimensional data sets . Also , timing comparisons between our HDRDA implementation in the sparsediscrim R package and the standard RDA formulation in the klaR R package demonstrate that as the number of features increases , the computational runtime of HDRDA is drastically smaller than that of RDA .
This paper describes a new approach , based on linear programming , for computing nonnegative matrix factorizations ( NMFs ) . The key idea is a data-driven model for the factorization where the most salient features in the data are used to express the remaining features . More precisely , given a data matrix X , the algorithm identifies a matrix C such that X approximately equals CX and some linear constraints . The constraints are chosen to ensure that the matrix C selects features ; these features can then be used to find a low-rank NMF of X . A theoretical analysis demonstrates that this approach has guarantees similar to those of the recent NMF algorithm of Arora et al . ( 0000 ) . In contrast with this earlier work , the proposed method extends to more general noise models and leads to efficient , scalable algorithms . Experiments with synthetic and real datasets provide evidence that the new approach is also superior in practice . An optimized C++ implementation can factor a multigigabyte matrix in a matter of minutes .
Statistical boosting algorithms have triggered a lot of research during the last decade . They combine a powerful machine-learning approach with classical statistical modelling , offering various practical advantages like automated variable selection and implicit regularization of effect estimates . They are extremely flexible , as the underlying base-learners ( regression functions defining the type of effect for the explanatory variables ) can be combined with any kind of loss function ( target function to be optimized , defining the type of regression setting ) . In this review article , we highlight the most recent methodological developments on statistical boosting regarding variable selection , functional regression and advanced time-to-event modelling . Additionally , we provide a short overview on relevant applications of statistical boosting in biomedicine .
In this work , we propose the marginal structured SVM ( MSSVM ) for structured prediction with hidden variables . MSSVM properly accounts for the uncertainty of hidden variables , and can significantly outperform the previously proposed latent structured SVM ( LSSVM ; Yu & Joachims ( 0000 ) ) and other state-of-art methods , especially when that uncertainty is large . Our method also results in a smoother objective function , making gradient-based optimization of MSSVMs converge significantly faster than for LSSVMs . We also show that our method consistently outperforms hidden conditional random fields ( HCRFs ; Quattoni et al . ( 0000 ) ) on both simulated and real-world datasets . Furthermore , we propose a unified framework that includes both our and several other existing methods as special cases , and provides insights into the comparison of different models in practice .
Predicting an individual ' s risk of experiencing a future clinical outcome is a statistical task with important consequences for both practicing clinicians and public health experts . Modern observational databases such as electronic health records ( EHRs ) provide an alternative to the longitudinal cohort studies traditionally used to construct risk models , bringing with them both opportunities and challenges . Large sample sizes and detailed covariate histories enable the use of sophisticated machine learning techniques to uncover complex associations and interactions , but observational databases are often ``messy , ' ' with high levels of missing data and incomplete patient follow-up . In this paper , we propose an adaptation of the well-known Naive Bayes ( NB ) machine learning approach for classification to time-to-event outcomes subject to censoring . We compare the predictive performance of our method to the Cox proportional hazards model which is commonly used for risk prediction in healthcare populations , and illustrate its application to prediction of cardiovascular risk using an EHR dataset from a large Midwest integrated healthcare system .
This article is concerned with Gaussian process quadratures , which are numerical integration methods based on Gaussian process regression methods , and sigma-point methods , which are used in advanced non-linear Kalman filtering and smoothing algorithms . We show that many sigma-point methods can be interpreted as Gaussian quadrature based methods with suitably selected covariance functions . We show that this interpretation also extends to more general multivariate Gauss--Hermite integration methods and related spherical cubature rules . Additionally , we discuss different criteria for selecting the sigma-point locations : exactness for multivariate polynomials up to a given order , minimum average error , and quasi-random point sets . The performance of the different methods is tested in numerical experiments .
Transformation models are a very important tool for applied statisticians and econometricians . In many applications , the dependent variable is transformed so that homogeneity or normal distribution of the error holds . In this paper , we analyze transformation models in a high-dimensional setting , where the set of potential covariates is large . We propose an estimator for the transformation parameter and we show that it is asymptotically normally distributed using an orthogonalized moment condition where the nuisance functions depend on the target parameter . In a simulation study , we show that the proposed estimator works well in small samples . A common practice in labor economics is to transform wage with the log-function . In this study , we test if this transformation holds in CPS data from the United States .
Learning from the crowd has become increasingly popular in the Web and social media . There is a wide variety of crowdlearning sites in which , on the one hand , users learn from the knowledge that other users contribute to the site , and , on the other hand , knowledge is reviewed and curated by the same users using assessment measures such as upvotes or likes . In this paper , we present a probabilistic modeling framework of crowdlearning , which uncovers the evolution of a user ' s expertise over time by leveraging other users ' assessments of her contributions . The model allows for both off-site and on-site learning and captures forgetting of knowledge . We then develop a scalable estimation method to fit the model parameters from millions of recorded learning and contributing events . We show the effectiveness of our model by tracing activity of ~00 thousand users in Stack Overflow over a 0 . 0 year period . We find that answers with high knowledge value are rare . Newbies and experts tend to acquire less knowledge than users in the middle range . Prolific learners tend to be also proficient contributors that post answers with high knowledge value .
Stochastic variational inference for collapsed models has recently been successfully applied to large scale topic modelling . In this paper , we propose a stochastic collapsed variational inference algorithm for hidden Markov models , in a sequential data setting . Given a collapsed hidden Markov Model , we break its long Markov chain into a set of short subchains . We propose a novel sum-product algorithm to update the posteriors of the subchains , taking into account their boundary transitions due to the sequential dependencies . Our experiments on two discrete datasets show that our collapsed algorithm is scalable to very large datasets , memory efficient and significantly more accurate than the existing uncollapsed algorithm .
Variational Bayesian inference and ( collapsed ) Gibbs sampling are the two important classes of inference algorithms for Bayesian networks . Both have their advantages and disadvantages : collapsed Gibbs sampling is unbiased but is also inefficient for large count values and requires averaging over many samples to reduce variance . On the other hand , variational Bayesian inference is efficient and accurate for large count values but suffers from bias for small counts . We propose a hybrid algorithm that combines the best of both worlds : it samples very small counts and applies variational updates to large counts . This hybridization is shown to significantly improve testset perplexity relative to variational inference at no computational cost .
Consider a linear regression model where the design matrix X has n rows and p columns . We assume ( a ) p is much large than n , ( b ) the coefficient vector beta is sparse in the sense that only a small fraction of its coordinates is nonzero , and ( c ) the Gram matrix G = X ' X is sparse in the sense that each row has relatively few large coordinates ( diagonals of G are normalized to 0 ) . The sparsity in G naturally induces the sparsity of the so-called graph of strong dependence ( GOSD ) . We find an interesting interplay between the signal sparsity and the graph sparsity , which ensures that in a broad context , the set of true signals decompose into many different small-size components of GOSD , where different components are disconnected . We propose Graphlet Screening ( GS ) as a new approach to variable selection , which is a two-stage Screen and Clean method . The key methodological innovation of GS is to use GOSD to guide both the screening and cleaning . Compared to m-variate brute-forth screening that has a computational cost of p^m , the GS only has a computational cost of p ( up to some multi-log ( p ) factors ) in screening . We measure the performance of any variable selection procedure by the minimax Hamming distance . We show that in a very broad class of situations , GS achieves the optimal rate of convergence in terms of the Hamming distance . Somewhat surprisingly , the well-known procedures subset selection and the lasso are rate non-optimal , even in very simple settings and even when their tuning parameters are ideally set .
The use of covariance kernels is ubiquitous in the field of spatial statistics . Kernels allow data to be mapped into high-dimensional feature spaces and can thus extend simple linear additive methods to nonlinear methods with higher order interactions . However , until recently , there has been a strong reliance on a limited class of stationary kernels such as the Matern or squared exponential , limiting the expressiveness of these modelling approaches . Recent machine learning research has focused on spectral representations to model arbitrary stationary kernels and introduced more general representations that include classes of nonstationary kernels . In this paper , we exploit the connections between Fourier feature representations , Gaussian processes and neural networks to generalise previous approaches and develop a simple and efficient framework to learn arbitrarily complex nonstationary kernel functions directly from the data , while taking care to avoid overfitting using state-of-the-art methods from deep learning . We highlight the very broad array of kernel classes that could be created within this framework . We apply this to a time series dataset and a remote sensing problem involving land surface temperature in Eastern Africa . We show that without increasing the computational or storage complexity , nonstationary kernels can be used to improve generalisation performance and provide more interpretable results .
Hyperparameter optimization undergoes extensive evaluations of validation errors in order to find its best configuration . Bayesian optimization is now popular for hyperparameter optimization , since it reduces the number of validation error evaluations required . Suppose that we are given a collection of datasets on which hyperparameters are already tuned by either humans with domain expertise or extensive trials of cross-validation . When a model is applied to a new dataset , it is desirable to let Bayesian optimization start from configurations that were successful on similar datasets . To this end , we construct a Siamese network with convolutional layers followed by bi-directional LSTM layers , to learn meta-features over image datasets . Learned meta-features are used to select a few datasets that are similar to the new dataset , so that a set of configurations in similar datasets is adopted as initialization to warm-start Bayesian hyperparameter optimization . Experiments on image datasets demonstrate that our learned meta-features are useful in optimizing hyperparameters in deep residual networks for image classification .
Dimensionality reduction is a topic of recent interest . In this paper , we present the classification constrained dimensionality reduction ( CCDR ) algorithm to account for label information . The algorithm can account for multiple classes as well as the semi-supervised setting . We present an out-of-sample expressions for both labeled and unlabeled data . For unlabeled data , we introduce a method of embedding a new point as preprocessing to a classifier . For labeled data , we introduce a method that improves the embedding during the training phase using the out-of-sample extension . We investigate classification performance using the CCDR algorithm on hyper-spectral satellite imagery data . We demonstrate the performance gain for both local and global classifiers and demonstrate a 00% improvement of the $k$-nearest neighbors algorithm performance . We present a connection between intrinsic dimension estimation and the optimal embedding dimension obtained using the CCDR algorithm .
We study the following generalized matrix rank estimation problem : given an $n \times n$ matrix and a constant $c \geq 0$ , estimate the number of eigenvalues that are greater than $c$ . In the distributed setting , the matrix of interest is the sum of $m$ matrices held by separate machines . We show that any deterministic algorithm solving this problem must communicate $\Omega ( n^0 ) $ bits , which is order-equivalent to transmitting the whole matrix . In contrast , we propose a randomized algorithm that communicates only $\widetilde O ( n ) $ bits . The upper bound is matched by an $\Omega ( n ) $ lower bound on the randomized communication complexity . We demonstrate the practical effectiveness of the proposed algorithm with some numerical experiments .
In medical domain , data features often contain missing values . This can create serious bias in the predictive modeling . Typical standard data mining methods often produce poor performance measures . In this paper , we propose a new method to simultaneously classify large datasets and reduce the effects of missing values . The proposed method is based on a multilevel framework of the cost-sensitive SVM and the expected maximization imputation method for missing values , which relies on iterated regression analyses . We compare classification results of multilevel SVM-based algorithms on public benchmark datasets with imbalanced classes and missing values as well as real data in health applications , and show that our multilevel SVM-based method produces fast , and more accurate and robust classification results .
Adaptive stochastic gradient methods such as AdaGrad have gained popularity in particular for training deep neural networks . The most commonly used and studied variant maintains a diagonal matrix approximation to second order information by accumulating past gradients which are used to tune the step size adaptively . In certain situations the full-matrix variant of AdaGrad is expected to attain better performance , however in high dimensions it is computationally impractical . We present Ada-LR and RadaGrad two computationally efficient approximations to full-matrix AdaGrad based on randomized dimensionality reduction . They are able to capture dependencies between features and achieve similar performance to full-matrix AdaGrad but at a much smaller computational cost . We show that the regret of Ada-LR is close to the regret of full-matrix AdaGrad which can have an up-to exponentially smaller dependence on the dimension than the diagonal variant . Empirically , we show that Ada-LR and RadaGrad perform similarly to full-matrix AdaGrad . On the task of training convolutional neural networks as well as recurrent neural networks , RadaGrad achieves faster convergence than diagonal AdaGrad .
A new geometrically-motivated algorithm for nonnegative matrix factorization is developed and applied to the discovery of latent " topics " for text and image " document " corpora . The algorithm is based on robustly finding and clustering extreme points of empirical cross-document word-frequencies that correspond to novel " words " unique to each topic . In contrast to related approaches that are based on solving non-convex optimization problems using suboptimal approximations , locally-optimal methods , or heuristics , the new algorithm is convex , has polynomial complexity , and has competitive qualitative and quantitative performance compared to the current state-of-the-art approaches on synthetic and real-world datasets .
In this paper we consider the problems of supervised classification and regression in the case where attributes and labels are functions : a data is represented by a set of functions , and the label is also a function . We focus on the use of reproducing kernel Hilbert space theory to learn from such functional data . Basic concepts and properties of kernel-based learning are extended to include the estimation of function-valued functions . In this setting , the representer theorem is restated , a set of rigorously defined infinite-dimensional operator-valued kernels that can be valuably applied when the data are functions is described , and a learning algorithm for nonlinear functional data analysis is introduced . The methodology is illustrated through speech and audio signal processing experiments .
The classification of time series data is a challenge common to all data-driven fields . However , there is no agreement about which are the most efficient techniques to group unlabeled time-ordered data . This is because a successful classification of time series patterns depends on the goal and the domain of interest , i . e . it is application-dependent . In this article , we study free-to-play game data . In this domain , clustering similar time series information is increasingly important due to the large amount of data collected by current mobile and web applications . We evaluate which methods cluster accurately time series of mobile games , focusing on player behavior data . We identify and validate several aspects of the clustering : the similarity measures and the representation techniques to reduce the high dimensionality of time series . As a robustness test , we compare various temporal datasets of player activity from two free-to-play video-games . With these techniques we extract temporal patterns of player behavior relevant for the evaluation of game events and game-business diagnosis . Our experiments provide intuitive visualizations to validate the results of the clustering and to determine the optimal number of clusters . Additionally , we assess the common characteristics of the players belonging to the same group . This study allows us to improve the understanding of player dynamics and churn behavior .
Sparsity-based representations have recently led to notable results in various visual recognition tasks . In a separate line of research , Riemannian manifolds have been shown useful for dealing with features and models that do not lie in Euclidean spaces . With the aim of building a bridge between the two realms , we address the problem of sparse coding and dictionary learning over the space of linear subspaces , which form Riemannian structures known as Grassmann manifolds . To this end , we propose to embed Grassmann manifolds into the space of symmetric matrices by an isometric mapping . This in turn enables us to extend two sparse coding schemes to Grassmann manifolds . Furthermore , we propose closed-form solutions for learning a Grassmann dictionary , atom by atom . Lastly , to handle non-linearity in data , we extend the proposed Grassmann sparse coding and dictionary learning algorithms through embedding into Hilbert spaces . Experiments on several classification tasks ( gender recognition , gesture classification , scene analysis , face recognition , action recognition and dynamic texture classification ) show that the proposed approaches achieve considerable improvements in discrimination accuracy , in comparison to state-of-the-art methods such as kernelized Affine Hull Method and graph-embedding Grassmann discriminant analysis .
Kiva is an online non-profit crowdsouring microfinance platform that raises funds for the poor in the third world . The borrowers on Kiva are small business owners and individuals in urgent need of money . To raise funds as fast as possible , they have the option to form groups and post loan requests in the name of their groups . While it is generally believed that group loans pose less risk for investors than individual loans do , we study whether this is the case in a philanthropic online marketplace . In particular , we measure the effect of group loans on funding time while controlling for the loan sizes and other factors . Because loan descriptions ( in the form of texts ) play an important role in lenders ' decision process on Kiva , we make use of this information through deep learning in natural language processing . In this aspect , this is the first paper that uses one of the most advanced deep learning techniques to deal with unstructured data in a way that can take advantage of its superior prediction power to answer causal questions . We find that on average , forming group loans speeds up the funding time by about 0 . 0 days .
We propose a new method of discovering causal relationships in temporal data based on the notion of causal compression . To this end , we adopt the Pearlian graph setting and the directed information as an information theoretic tool for quantifying causality . We introduce chain rule for directed information and use it to motivate causal sparsity . We show two applications of the proposed method : causal time series segmentation which selects time points capturing the incoming and outgoing causal flow between time points belonging to different signals , and causal bipartite graph recovery . We prove that modelling of causality in the adopted set-up only requires estimating the copula density of the data distribution and thus does not depend on its marginals . We evaluate the method on time resolved gene expression data .
We propose a new statistical model for computational linguistics . Rather than trying to estimate directly the probability distribution of a random sentence of the language , we define a Markov chain on finite sets of sentences with many finite recurrent communicating classes and define our language model as the invariant probability measures of the chain on each recurrent communicating class . This Markov chain , that we call a communication model , recombines at each step randomly the set of sentences forming its current state , using some grammar rules . When the grammar rules are fixed and known in advance instead of being estimated on the fly , we can prove supplementary mathematical properties . In particular , we can prove in this case that all states are recurrent states , so that the chain defines a partition of its state space into finite recurrent communicating classes . We show that our approach is a decisive departure from Markov models at the sentence level and discuss its relationships with Context Free Grammars . Although the toric grammars we use are closely related to Context Free Grammars , the way we generate the language from the grammar is qualitatively different . Our communication model has two purposes . On the one hand , it is used to define indirectly the probability distribution of a random sentence of the language . On the other hand it can serve as a ( crude ) model of language transmission from one speaker to another speaker through the communication of a ( large ) set of sentences .
We present a theoretical analysis and empirical evaluations of a novel set of techniques for computational cost reduction of classifiers that are based on learned transform and soft-threshold . By modifying optimization procedures for dictionary and classifier training , as well as the resulting dictionary entries , our techniques allow to reduce the bit precision and to replace each floating-point multiplication by a single integer bit shift . We also show how the optimization algorithms in some dictionary training methods can be modified to penalize higher-energy dictionaries . We applied our techniques with the classifier Learning Algorithm for Soft-Thresholding , testing on the datasets used in its original paper . Our results indicate it is feasible to use solely sums and bit shifts of integers to classify at test time with a limited reduction of the classification accuracy . These low power operations are a valuable trade off in FPGA implementations as they increase the classification throughput while decrease both energy consumption and manufacturing cost .
Extreme multi-label classification refers to supervised multi-label learning involving hundreds of thousands or even millions of labels . Datasets in extreme classification exhibit fit to power-law distribution , i . e . a large fraction of labels have very few positive instances in the data distribution . Most state-of-the-art approaches for extreme multi-label classification attempt to capture correlation among labels by embedding the label matrix to a low-dimensional linear sub-space . However , in the presence of power-law distributed extremely large and diverse label spaces , structural assumptions such as low rank can be easily violated . In this work , we present DiSMEC , which is a large-scale distributed framework for learning one-versus-rest linear classifiers coupled with explicit capacity control to control model size . Unlike most state-of-the-art methods , DiSMEC does not make any low rank assumptions on the label matrix . Using double layer of parallelization , DiSMEC can learn classifiers for datasets consisting hundreds of thousands labels within few hours . The explicit capacity control mechanism filters out spurious parameters which keep the model compact in size , without losing prediction accuracy . We conduct extensive empirical evaluation on publicly available real-world datasets consisting upto 000 , 000 labels . We compare DiSMEC with recent state-of-the-art approaches , including - SLEEC which is a leading approach for learning sparse local embeddings , and FastXML which is a tree-based approach optimizing ranking based loss function . On some of the datasets , DiSMEC can significantly boost prediction accuracies - 00% better compared to SLECC and 00% better compared to FastXML , in absolute terms .
We describe a new training methodology for generative adversarial networks . The key idea is to grow both the generator and discriminator progressively : starting from a low resolution , we add new layers that model increasingly fine details as training progresses . This both speeds the training up and greatly stabilizes it , allowing us to produce images of unprecedented quality , e . g . , CelebA images at 0000^0 . We also propose a simple way to increase the variation in generated images , and achieve a record inception score of 0 . 00 in unsupervised CIFAR00 . Additionally , we describe several implementation details that are important for discouraging unhealthy competition between the generator and discriminator . Finally , we suggest a new metric for evaluating GAN results , both in terms of image quality and variation . As an additional contribution , we construct a higher-quality version of the CelebA dataset .
This comment reexamines Simard et al . ' s work in [D . Simard , L . Nadeau , H . Kroger , Phys . Lett . A 000 ( 0000 ) 0-00] . We found that Simard et al . calculated mistakenly the local connectivity lengths Dlocal of networks . The right results of Dlocal are presented and the supervised learning performance of feedforward neural networks ( FNNs ) with different rewirings are re-investigated in this comment . This comment discredits Simard et al ' s work by two conclusions : 0 ) Rewiring connections of FNNs cannot generate networks with small-world connectivity ; 0 ) For different training sets , there do not exist networks with a certain number of rewirings generating reduced learning errors than networks with other numbers of rewiring .
A new Bayesian image segmentation algorithm is proposed by combining a loopy belief propagation with an inverse real space renormalization group transformation to reduce the computational time . In results of our experiment , we observe that the proposed method can reduce the computational time to less than one-tenth of that taken by conventional Bayesian approaches .
Many clustering algorithms exist that estimate a cluster centroid , such as K-means , K-medoids or mean-shift , but no algorithm seems to exist that clusters data by returning exactly K meaningful modes . We propose a natural definition of a K-modes objective function by combining the notions of density and cluster assignment . The algorithm becomes K-means and K-medoids in the limit of very large and very small scales . Computationally , it is slightly slower than K-means but much faster than mean-shift or K-medoids . Unlike K-means , it is able to find centroids that are valid patterns , truly representative of a cluster , even with nonconvex clusters , and appears robust to outliers and misspecification of the scale and number of clusters .
The aim of this work is to address the question of whether we can in principle design rational decision-making agents or artificial intelligences embedded in computable physics such that their decisions are optimal in reasonable mathematical senses . Recent developments in rare event probability estimation , recursive bayesian inference , neural networks , and probabilistic planning are sufficient to explicitly approximate reinforcement learners of the AIXI style with non-trivial model classes ( here , the class of resource-bounded Turing machines ) . Consideration of the effects of resource limitations in a concrete implementation leads to insights about possible architectures for learning systems using optimal decision makers as components .
We consider the problem of identifying the parameters of an unknown mixture of two arbitrary $d$-dimensional gaussians from a sequence of independent random samples . Our main results are upper and lower bounds giving a computationally efficient moment-based estimator with an optimal convergence rate , thus resolving a problem introduced by Pearson ( 0000 ) . Denoting by $\sigma^0$ the variance of the unknown mixture , we prove that $\Theta ( \sigma^{00} ) $ samples are necessary and sufficient to estimate each parameter up to constant additive error when $d=0 . $ Our upper bound extends to arbitrary dimension $d>0$ up to a ( provably necessary ) logarithmic loss in $d$ using a novel---yet simple---dimensionality reduction technique . We further identify several interesting special cases where the sample complexity is notably smaller than our optimal worst-case bound . For instance , if the means of the two components are separated by $\Omega ( \sigma ) $ the sample complexity reduces to $O ( \sigma^0 ) $ and this is again optimal . Our results also apply to learning each component of the mixture up to small error in total variation distance , where our algorithm gives strong improvements in sample complexity over previous work . We also extend our lower bound to mixtures of $k$ Gaussians , showing that $\Omega ( \sigma^{0k-0} ) $ samples are necessary to estimate each parameter up to constant additive error .
Predictive rate-distortion analysis suffers from the curse of dimensionality : clustering arbitrarily long pasts to retain information about arbitrarily long futures requires resources that typically grow exponentially with length . The challenge is compounded for infinite-order Markov processes , since conditioning on finite sequences cannot capture all of their past dependencies . Spectral arguments show that algorithms which cluster finite-length sequences fail dramatically when the underlying process has long-range temporal correlations and can fail even for processes generated by finite-memory hidden Markov models . We circumvent the curse of dimensionality in rate-distortion analysis of infinite-order processes by casting predictive rate-distortion objective functions in terms of the forward- and reverse-time causal states of computational mechanics . Examples demonstrate that the resulting causal rate-distortion theory substantially improves current predictive rate-distortion analyses .
We propose a latent self-exciting point process model that describes geographically distributed interactions between pairs of entities . In contrast to most existing approaches that assume fully observable interactions , here we consider a scenario where certain interaction events lack information about participants . Instead , this information needs to be inferred from the available observations . We develop an efficient approximate algorithm based on variational expectation-maximization to infer unknown participants in an event given the location and the time of the event . We validate the model on synthetic as well as real-world data , and obtain very promising results on the identity-inference task . We also use our model to predict the timing and participants of future events , and demonstrate that it compares favorably with baseline approaches .
Overlapping clustering problem is an important learning issue in which clusters are not mutually exclusive and each object may belongs simultaneously to several clusters . This paper presents a kernel based method that produces overlapping clusters on a high feature space using mercer kernel techniques to improve separability of input patterns . The proposed method , called OKM-K ( Overlapping $k$-means based kernel method ) , extends OKM ( Overlapping $k$-means ) method to produce overlapping schemes . Experiments are performed on overlapping dataset and empirical results obtained with OKM-K outperform results obtained with OKM .
Dropout is a very effective way of regularizing neural networks . Stochastically " dropping out " units with a certain probability discourages over-specific co-adaptations of feature detectors , preventing overfitting and improving network generalization . Besides , Dropout can be interpreted as an approximate model aggregation technique , where an exponential number of smaller networks are averaged in order to get a more powerful ensemble . In this paper , we show that using a fixed dropout probability during training is a suboptimal choice . We thus propose a time scheduling for the probability of retaining neurons in the network . This induces an adaptive regularization scheme that smoothly increases the difficulty of the optimization problem . This idea of " starting easy " and adaptively increasing the difficulty of the learning problem has its roots in curriculum learning and allows one to train better models . Indeed , we prove that our optimization strategy implements a very general curriculum scheme , by gradually adding noise to both the input and intermediate feature representations within the network architecture . Experiments on seven image classification datasets and different network architectures show that our method , named Curriculum Dropout , frequently yields to better generalization and , at worst , performs just as well as the standard Dropout method .
We study the use of " sign $\alpha$-stable random projections " ( where $0<\alpha\leq 0$ ) for building basic data processing tools in the context of large-scale machine learning applications ( e . g . , classification , regression , clustering , and near-neighbor search ) . After the processing by sign stable random projections , the inner products of the processed data approximate various types of nonlinear kernels depending on the value of $\alpha$ . Thus , this approach provides an effective strategy for approximating nonlinear learning algorithms essentially at the cost of linear learning . When $\alpha =0$ , it is known that the corresponding nonlinear kernel is the arc-cosine kernel . When $\alpha=0$ , the procedure approximates the arc-cos-$\chi^0$ kernel ( under certain condition ) . When $\alpha\rightarrow0+$ , it corresponds to the resemblance kernel . From practitioners ' perspective , the method of sign $\alpha$-stable random projections is ready to be tested for large-scale learning applications , where $\alpha$ can be simply viewed as a tuning parameter . What is missing in the literature is an extensive empirical study to show the effectiveness of sign stable random projections , especially for $\alpha\neq 0$ or 0 . The paper supplies such a study on a wide variety of classification datasets . In particular , we compare shoulder-by-shoulder sign stable random projections with the recently proposed " 0-bit consistent weighted sampling ( CWS ) " ( Li 0000 ) .
Phone sensors could be useful in assessing changes in gait that occur with alcohol consumption . This study determined ( 0 ) feasibility of collecting gait-related data during drinking occasions in the natural environment , and ( 0 ) how gait-related features measured by phone sensors relate to estimated blood alcohol concentration ( eBAC ) . Ten young adult heavy drinkers were prompted to complete a 0-step gait task every hour from 0pm to 00am over four consecutive weekends . We collected 0-xis accelerometer , gyroscope , and magnetometer data from phone sensors , and computed 00 gait-related features using a sliding window technique . eBAC levels were calculated at each time point based on Ecological Momentary Assessment ( EMA ) of alcohol use . We used an artificial neural network model to analyze associations between sensor features and eBACs in training ( 00% of the data ) and validation and test ( 00% of the data ) datasets . We analyzed 000 data points where both eBAC and gait-related sensor data was captured , either when not drinking ( n=00 ) , while eBAC was ascending ( n=00 ) or eBAC was descending ( n=00 ) . 00 data points were captured at times when the eBAC was greater than the legal limit ( 0 . 00 mg/dl ) . Using a Bayesian regularized neural network , gait-related phone sensor features showed a high correlation with eBAC ( Pearson ' s r > 0 . 0 ) , and >00% of estimated eBAC would fall between -0 . 000 and +0 . 000 of actual eBAC . It is feasible to collect gait-related data from smartphone sensors during drinking occasions in the natural environment . Sensor-based features can be used to infer gait changes associated with elevated blood alcohol content .
Generalised Degrees of Freedom ( GDF ) , as defined by Ye ( 0000 JASA 00 : 000-000 ) , represent the sensitivity of model fits to perturbations of the data . As such they can be computed for any statistical model , making it possible , in principle , to derive the number of parameters in machine-learning approaches . Defined originally for normally distributed data only , we here investigate the potential of this approach for Bernoulli-data . GDF-values for models of simulated and real data are compared to model complexity-estimates from cross-validation . Similarly , we computed GDF-based AICc for randomForest , neural networks and boosted regression trees and demonstrated its similarity to cross-validation . GDF-estimates for binary data were unstable and inconsistently sensitive to the number of data points perturbed simultaneously , while at the same time being extremely computer-intensive in their calculation . Repeated 00-fold cross-validation was more robust , based on fewer assumptions and faster to compute . Our findings suggest that the GDF-approach does not readily transfer to Bernoulli data and a wider range of regression approaches .
We propose an empirical Bayes estimator based on Dirichlet process mixture model for estimating the sparse normalized mean difference , which could be directly applied to the high dimensional linear classification . In theory , we build a bridge to connect the estimation error of the mean difference and the misclassification error , also provide sufficient conditions of sub-optimal classifiers and optimal classifiers . In implementation , a variational Bayes algorithm is developed to compute the posterior efficiently and could be parallelized to deal with the ultra-high dimensional case .
Kernel functions in support vector machines ( SVM ) are needed to assess the similarity of input samples in order to classify these samples , for instance . Besides standard kernels such as Gaussian ( i . e . , radial basis function , RBF ) or polynomial kernels , there are also specific kernels tailored to consider structure in the data for similarity assessment . In this article , we will capture structure in data by means of probabilistic mixture density models , for example Gaussian mixtures in the case of real-valued input spaces . From the distance measures that are inherently contained in these models , e . g . , Mahalanobis distances in the case of Gaussian mixtures , we derive a new kernel , the responsibility weighted Mahalanobis ( RWM ) kernel . Basically , this kernel emphasizes the influence of model components from which any two samples that are compared are assumed to originate ( that is , the " responsible " model components ) . We will see that this kernel outperforms the RBF kernel and other kernels capturing structure in data ( such as the LAP kernel in Laplacian SVM ) in many applications where partially labeled data are available , i . e . , for semi-supervised training of SVM . Other key advantages are that the RWM kernel can easily be used with standard SVM implementations and training algorithms such as sequential minimal optimization , and heuristics known for the parametrization of RBF kernels in a C-SVM can easily be transferred to this new kernel . Properties of the RWM kernel are demonstrated with 00 benchmark data sets and an increasing percentage of labeled samples in the training data .
This paper proposes a principled information theoretic analysis of classification for deep neural network structures , e . g . convolutional neural networks ( CNN ) . The output of convolutional filters is modeled as a random variable Y conditioned on the object class C and network filter bank F . The conditional entropy ( CENT ) H ( Y |C , F ) is shown in theory and experiments to be a highly compact and class-informative code , that can be computed from the filter outputs throughout an existing CNN and used to obtain higher classification results than the original CNN itself . Experiments demonstrate the effectiveness of CENT feature analysis in two separate CNN classification contexts . 0 ) In the classification of neurodegeneration due to Alzheimer ' s disease ( AD ) and natural aging from 0D magnetic resonance image ( MRI ) volumes , 0 CENT features result in an AUC=00 . 0% for whole-brain AD classification , the highest reported accuracy on the public OASIS dataset used and 00% higher than the softmax output of the original CNN trained for the task . 0 ) In the context of visual object classification from 0D photographs , transfer learning based on a small set of CENT features identified throughout an existing CNN leads to AUC values comparable to the 0000-feature softmax output of the original network when classifying previously unseen object categories . The general information theoretical analysis explains various recent CNN design successes , e . g . densely connected CNN architectures , and provides insights for future research directions in deep learning .
Perceptron is a classic online algorithm for learning a classification function . In this paper , we provide a novel extension of the perceptron algorithm to the learning to rank problem in information retrieval . We consider popular listwise performance measures such as Normalized Discounted Cumulative Gain ( NDCG ) and Average Precision ( AP ) . A modern perspective on perceptron for classification is that it is simply an instance of online gradient descent ( OGD ) , during mistake rounds , using the hinge loss function . Motivated by this interpretation , we propose a novel family of listwise , large margin ranking surrogates . Members of this family can be thought of as analogs of the hinge loss . Exploiting a certain self-bounding property of the proposed family , we provide a guarantee on the cumulative NDCG ( or AP ) induced loss incurred by our perceptron-like algorithm . We show that , if there exists a perfect oracle ranker which can correctly rank each instance in an online sequence of ranking data , with some margin , the cumulative loss of perceptron algorithm on that sequence is bounded by a constant , irrespective of the length of the sequence . This result is reminiscent of Novikoff ' s convergence theorem for the classification perceptron . Moreover , we prove a lower bound on the cumulative loss achievable by any deterministic algorithm , under the assumption of existence of perfect oracle ranker . The lower bound shows that our perceptron bound is not tight , and we propose another , \emph{purely online} , algorithm which achieves the lower bound . We provide empirical results on simulated and large commercial datasets to corroborate our theoretical results .
We consider the fundamental question of learnability of a hypotheses class in the supervised learning setting and in the general learning setting introduced by Vladimir Vapnik . We survey classic results characterizing learnability in term of suitable notions of complexity , as well as more recent results that establish the connection between learnability and stability of a learning algorithm .
We study the fundamental tradeoffs between computational tractability and statistical accuracy for a general family of hypothesis testing problems with combinatorial structures . Based upon an oracle model of computation , which captures the interactions between algorithms and data , we establish a general lower bound that explicitly connects the minimum testing risk under computational budget constraints with the intrinsic probabilistic and combinatorial structures of statistical problems . This lower bound mirrors the classical statistical lower bound by Le Cam ( 0000 ) and allows us to quantify the optimal statistical performance achievable given limited computational budgets in a systematic fashion . Under this unified framework , we sharply characterize the statistical-computational phase transition for two testing problems , namely , normal mean detection and sparse principal component detection . For normal mean detection , we consider two combinatorial structures , namely , sparse set and perfect matching . For these problems we identify significant gaps between the optimal statistical accuracy that is achievable under computational tractability constraints and the classical statistical lower bounds . Compared with existing works on computational lower bounds for statistical problems , which consider general polynomial-time algorithms on Turing machines , and rely on computational hardness hypotheses on problems like planted clique detection , we focus on the oracle computational model , which covers a broad range of popular algorithms , and do not rely on unproven hypotheses . Moreover , our result provides an intuitive and concrete interpretation for the intrinsic computational intractability of high-dimensional statistical problems . One byproduct of our result is a lower bound for a strict generalization of the matrix permanent problem , which is of independent interest .
The computer-aided analysis of medical scans is a longstanding goal in the medical imaging field . Currently , deep learning has became a dominant methodology for supporting pathologists and radiologist . Deep learning algorithms have been successfully applied to digital pathology and radiology , nevertheless , there are still practical issues that prevent these tools to be widely used in practice . The main obstacles are low number of available cases and large size of images ( a . k . a . the small n , large p problem in machine learning ) , and a very limited access to annotation at a pixel level that can lead to severe overfitting and large computational requirements . We propose to handle these issues by introducing a framework that processes a medical image as a collection of small patches using a single , shared neural network . The final diagnosis is provided by combining scores of individual patches using a permutation-invariant operator ( combination ) . In machine learning community such approach is called a multi-instance learning ( MIL ) .
We present a novel method for obtaining high-quality , domain-targeted multiple choice questions from crowd workers . Generating these questions can be difficult without trading away originality , relevance or diversity in the answer options . Our method addresses these problems by leveraging a large corpus of domain-specific text and a small set of existing questions . It produces model suggestions for document selection and answer distractor choice which aid the human question generation process . With this method we have assembled SciQ , a dataset of 00 . 0K multiple choice science exam questions ( Dataset available at http : //allenai . org/data . html ) . We demonstrate that the method produces in-domain questions by providing an analysis of this new dataset and by showing that humans cannot distinguish the crowdsourced questions from original questions . When using SciQ as additional training data to existing questions , we observe accuracy improvements on real science exams .
We present a new algorithm for community detection . The algorithm uses random walks to embed the graph in a space of measures , after which a modification of $k$-means in that space is applied . The algorithm is therefore fast and easily parallelizable . We evaluate the algorithm on standard random graph benchmarks , including some overlapping community benchmarks , and find its performance to be better or at least as good as previously known algorithms . We also prove a linear time ( in number of edges ) guarantee for the algorithm on a $p , q$-stochastic block model with $p \geq c\cdot N^{-\frac{0}{0} + \epsilon}$ and $p-q \geq c ' \sqrt{p N^{-\frac{0}{0} + \epsilon} \log N}$ .
Kalman Filters are one of the most influential models of time-varying phenomena . They admit an intuitive probabilistic interpretation , have a simple functional form , and enjoy widespread adoption in a variety of disciplines . Motivated by recent variational methods for learning deep generative models , we introduce a unified algorithm to efficiently learn a broad spectrum of Kalman filters . Of particular interest is the use of temporal generative models for counterfactual inference . We investigate the efficacy of such models for counterfactual inference , and to that end we introduce the " Healing MNIST " dataset where long-term structure , noise and actions are applied to sequences of digits . We show the efficacy of our method for modeling this dataset . We further show how our model can be used for counterfactual inference for patients , based on electronic health record data of 0 , 000 patients over 0 . 0 years .
In regression analysis of multivariate data , it is tacitly assumed that response and predictor variables in each observed response-predictor pair correspond to the same entity or unit . In this paper , we consider the situation of " permuted data " in which this basic correspondence has been lost . Several recent papers have considered this situation without further assumptions on the underlying permutation . In applications , the latter is often to known to have additional structure that can be leveraged . Specifically , we herein consider the common scenario of " sparsely permuted data " in which only a small fraction of the data is affected by a mismatch between response and predictors . However , an adverse effect already observed for sparsely permuted data is that the least squares estimator as well as other estimators not accounting for such partial mismatch are inconsistent . One approach studied in detail herein is to treat permuted data as outliers which motivates the use of robust regression formulations to estimate the regression parameter . The resulting estimate can subsequently be used to recover the permutation . A notable benefit of the proposed approach is its computational simplicity given the general lack of procedures for the above problem that are both statistically sound and computationally appealing .
Domain adaptation is transfer learning which aims to generalize a learning model across training and testing data with different distributions . Most previous research tackle this problem in seeking a shared feature representation between source and target domains while reducing the mismatch of their data distributions . In this paper , we propose a close yet discriminative domain adaptation method , namely CDDA , which generates a latent feature representation with two interesting properties . First , the discrepancy between the source and target domain , measured in terms of both marginal and conditional probability distribution via Maximum Mean Discrepancy is minimized so as to attract two domains close to each other . More importantly , we also design a repulsive force term , which maximizes the distances between each label dependent sub-domain to all others so as to drag different class dependent sub-domains far away from each other and thereby increase the discriminative power of the adapted domain . Moreover , given the fact that the underlying data manifold could have complex geometric structure , we further propose the constraints of label smoothness and geometric structure consistency for label propagation . Extensive experiments are conducted on 00 cross-domain image classification tasks over four public datasets . The comprehensive results show that the proposed method consistently outperforms the state-of-the-art methods with significant margins .
Subspace recovery from corrupted and missing data is crucial for various applications in signal processing and information theory . To complete missing values and detect column corruptions , existing robust Matrix Completion ( MC ) methods mostly concentrate on recovering a low-rank matrix from few corrupted coefficients w . r . t . standard basis , which , however , does not apply to more general basis , e . g . , Fourier basis . In this paper , we prove that the range space of an $m\times n$ matrix with rank $r$ can be exactly recovered from few coefficients w . r . t . general basis , though $r$ and the number of corrupted samples are both as high as $O ( \min\{m , n\}/\log^0 ( m+n ) ) $ . Our model covers previous ones as special cases , and robust MC can recover the intrinsic matrix with a higher rank . Moreover , we suggest a universal choice of the regularization parameter , which is $\lambda=0/\sqrt{\log n}$ . By our $\ell_{0 , 0}$ filtering algorithm , which has theoretical guarantees , we can further reduce the computational cost of our model . As an application , we also find that the solutions to extended robust Low-Rank Representation and to our extended robust MC are mutually expressible , so both our theory and algorithm can be applied to the subspace clustering problem with missing values under certain conditions . Experiments verify our theories .
The natural habitat of most Bayesian methods is data represented by exchangeable sequences of observations , for which de Finetti ' s theorem provides the theoretical foundation . Dirichlet process clustering , Gaussian process regression , and many other parametric and nonparametric Bayesian models fall within the remit of this framework ; many problems arising in modern data analysis do not . This article provides an introduction to Bayesian models of graphs , matrices , and other data that can be modeled by random structures . We describe results in probability theory that generalize de Finetti ' s theorem to such data and discuss their relevance to nonparametric Bayesian modeling . With the basic ideas in place , we survey example models available in the literature ; applications of such models include collaborative filtering , link prediction , and graph and network analysis . We also highlight connections to recent developments in graph theory and probability , and sketch the more general mathematical foundation of Bayesian methods for other types of data beyond sequences and arrays .
This paper presents a novel framework for generating texture mosaics with convolutional neural networks . Our method is called GANosaic and performs optimization in the latent noise space of a generative texture model , which allows the transformation of a content image into a mosaic exhibiting the visual properties of the underlying texture manifold . To represent that manifold , we use a state-of-the-art generative adversarial method for texture synthesis , which can learn expressive texture representations from data and produce mosaic images with very high resolution . This fully convolutional model generates smooth ( without any visible borders ) mosaic images which morph and blend different textures locally . In addition , we develop a new type of differentiable statistical regularization appropriate for optimization over the prior noise space of the PSGAN model .
We consider the problem of efficient randomized dimensionality reduction with norm-preservation guarantees . Specifically we prove data-dependent Johnson-Lindenstrauss-type geometry preservation guarantees for Ho ' s random subspace method : When data satisfy a mild regularity condition -- the extent of which can be estimated by sampling from the data -- then random subspace approximately preserves the Euclidean geometry of the data with high probability . Our guarantees are of the same order as those for random projection , namely the required dimension for projection is logarithmic in the number of data points , but have a larger constant term in the bound which depends upon this regularity . A challenging situation is when the original data have a sparse representation , since this implies a very large projection dimension is required : We show how this situation can be improved for sparse binary data by applying an efficient `densifying ' preprocessing , which neither changes the Euclidean geometry of the data nor requires an explicit matrix-matrix multiplication . We corroborate our theoretical findings with experiments on both dense and sparse high-dimensional datasets from several application domains .
One of the advantages that decision trees have over many other models is their ability to natively handle categorical predictors without having to first transform them ( e . g . , by using one-hot encoding ) . However , in this paper , we show how this capability can also lead to an inherent " absent levels " problem for decision tree based algorithms that , to the best of our knowledge , has never been thoroughly discussed , and whose consequences have never been carefully explored . This predicament occurs whenever there is indeterminacy in how to handle an observation that has reached a categorical split which was determined when the observation ' s level was absent during training . Although these incidents may appear to be innocuous , by using Leo Breiman and Adele Cutler ' s random forests FORTRAN code and the randomForest R package as motivating case studies , we show how overlooking the absent levels problem can systematically bias a model . Afterwards , we discuss some heuristics that can possibly be used to help mitigate the absent levels problem and , using three real data examples taken from public repositories , we demonstrate the superior performance and reliability of these heuristics over some of the existing approaches that are currently being employed in practice due to oversights in the software implementations of decision tree based algorithms . Given how extensively these algorithms have been used , it is conceivable that a sizable number of these models have been unknowingly and seriously affected by this issue---further emphasizing the need for the development of both theory and software that accounts for the absent levels problem .
We introduce overdispersed black-box variational inference , a method to reduce the variance of the Monte Carlo estimator of the gradient in black-box variational inference . Instead of taking samples from the variational distribution , we use importance sampling to take samples from an overdispersed distribution in the same exponential family as the variational approximation . Our approach is general since it can be readily applied to any exponential family distribution , which is the typical choice for the variational approximation . We run experiments on two non-conjugate probabilistic models to show that our method effectively reduces the variance , and the overhead introduced by the computation of the proposal parameters and the importance weights is negligible . We find that our overdispersed importance sampling scheme provides lower variance than black-box variational inference , even when the latter uses twice the number of samples . This results in faster convergence of the black-box inference procedure .
Computing partition function is the most important statistical inference task arising in applications of Graphical Models ( GM ) . Since it is computationally intractable , approximate methods have been used to resolve the issue in practice , where mean-field ( MF ) and belief propagation ( BP ) are arguably the most popular and successful approaches of a variational type . In this paper , we propose two new variational schemes , coined Gauged-MF ( G-MF ) and Gauged-BP ( G-BP ) , improving MF and BP , respectively . Both provide lower bounds for the partition function by utilizing the so-called gauge transformation which modifies factors of GM while keeping the partition function invariant . Moreover , we prove that both G-MF and G-BP are exact for GMs with a single loop of a special structure , even though the bare MF and BP perform badly in this case . Our extensive experiments , on complete GMs of relatively small size and on large GM ( up-to 000 variables ) confirm that the newly proposed algorithms outperform and generalize MF and BP .
The higher order singular value decomposition ( HOSVD ) of tensors is a generalization of matrix SVD . The perturbation analysis of HOSVD under random noise is more delicate than its matrix counterpart . Recent progress has been made in Richard and Montanari ( 0000 ) , Zhang and Xia ( 0000 ) and Liu et al . ( 0000 ) demonstrating that minimax optimal singular spaces estimation and low rank tensor recovery in $\ell_0$-norm can be obtained through polynomial time algorithms . In this paper , we analyze the HOSVD perturbation under Gaussian noise based on a second order method , which leads to an estimator of singular vectors with sharp bound in $\ell_\infty$-norm . A low rank tensor denoising estimator is then proposed which achieves a fast convergence rate characterizing the entry-wise deviations . The advantages of these $\ell_\infty$-norm bounds are displayed in applications including high dimensional clustering and sub-tensor localizations .
R\ ' enyi divergence is related to R\ ' enyi entropy much like Kullback-Leibler divergence is related to Shannon ' s entropy , and comes up in many settings . It was introduced by R\ ' enyi as a measure of information that satisfies almost the same axioms as Kullback-Leibler divergence , and depends on a parameter that is called its order . In particular , the R\ ' enyi divergence of order 0 equals the Kullback-Leibler divergence . We review and extend the most important properties of R\ ' enyi divergence and Kullback-Leibler divergence , including convexity , continuity , limits of $\sigma$-algebras and the relation of the special order 0 to the Gaussian dichotomy and contiguity . We also show how to generalize the Pythagorean inequality to orders different from 0 , and we extend the known equivalence between channel capacity and minimax redundancy to continuous channel inputs ( for all orders ) and present several other minimax results .
A Triangle Generative Adversarial Network ( $\Delta$-GAN ) is developed for semi-supervised cross-domain joint distribution matching , where the training data consists of samples from each domain , and supervision of domain correspondence is provided by only a few paired samples . $\Delta$-GAN consists of four neural networks , two generators and two discriminators . The generators are designed to learn the two-way conditional distributions between the two domains , while the discriminators implicitly define a ternary discriminative function , which is trained to distinguish real data pairs and two kinds of fake data pairs . The generators and discriminators are trained together using adversarial learning . Under mild assumptions , in theory the joint distributions characterized by the two generators concentrate to the data distribution . In experiments , three different kinds of domain pairs are considered , image-label , image-image and image-attribute pairs . Experiments on semi-supervised image classification , image-to-image translation and attribute-based image generation demonstrate the superiority of the proposed approach .
We have recently proposed a new information-based approach to model selection , the Frequentist Information Criterion ( FIC ) , that reconciles information-based and frequentist inference . The purpose of this current paper is to provide a simple example of the application of this criterion and a demonstration of the natural emergence of model complexities with both AIC-like ( $N^0$ ) and BIC-like ( $\log N$ ) scaling with observation number $N$ . The application developed is deliberately simplified to make the analysis analytically tractable .
We present five methods to the problem of network anomaly detection . These methods cover most of the common techniques in the anomaly detection field , including Statistical Hypothesis Tests ( SHT ) , Support Vector Machines ( SVM ) and clustering analysis . We evaluate all methods in a simulated network that consists of nominal data , three flow-level anomalies and one packet-level attack . Through analyzing the results , we point out the advantages and disadvantages of each method and conclude that combining the results of the individual methods can yield improved anomaly detection results .
ABC algorithms involve a large number of simulations from the model of interest , which can be very computationally costly . This paper summarises the lazy ABC algorithm of Prangle ( 0000 ) , which reduces the computational demand by abandoning many unpromising simulations before completion . By using a random stopping decision and reweighting the output sample appropriately , the target distribution is the same as for standard ABC . Lazy ABC is also extended here to the case of non-uniform ABC kernels , which is shown to simplify the process of tuning the algorithm effectively .
Clinical notes are a rich source of information about patient state . However , using them effectively presents many challenges . In this work we present two methods for summarizing clinical notes into patient-level representations . The resulting representations are evaluated on a range of prediction tasks and cohort sizes . The new representations offer significant predictive performance gains over the common baselines of Bag of Words and topic model representations across all tested tasks and cohort sizes .
We consider a non-stationary variant of a sequential stochastic optimization problem , in which the underlying cost functions may change along the horizon . We propose a measure , termed variation budget , that controls the extent of said change , and study how restrictions on this budget impact achievable performance . We identify sharp conditions under which it is possible to achieve long-run-average optimality and more refined performance measures such as rate optimality that fully characterize the complexity of such problems . In doing so , we also establish a strong connection between two rather disparate strands of literature : adversarial online convex optimization ; and the more traditional stochastic approximation paradigm ( couched in a non-stationary setting ) . This connection is the key to deriving well performing policies in the latter , by leveraging structure of optimal policies in the former . Finally , tight bounds on the minimax regret allow us to quantify the " price of non-stationarity , " which mathematically captures the added complexity embedded in a temporally changing environment versus a stationary one .
Data augmentation is a ubiquitous technique for increasing the size of labeled training sets by leveraging task-specific data transformations that preserve class labels . While it is often easy for domain experts to specify individual transformations , constructing and tuning the more sophisticated compositions typically needed to achieve state-of-the-art results is a time-consuming manual task in practice . We propose a method for automating this process by learning a generative sequence model over user-specified transformation functions using a generative adversarial approach . Our method can make use of arbitrary , non-deterministic transformation functions , is robust to misspecified user input , and is trained on unlabeled data . The learned transformation model can then be used to perform data augmentation for any end discriminative model . In our experiments , we show the efficacy of our approach on both image and text datasets , achieving improvements of 0 . 0 accuracy points on CIFAR-00 , 0 . 0 F0 points on the ACE relation extraction task , and 0 . 0 accuracy points when using domain-specific transformation operations on a medical imaging dataset as compared to standard heuristic augmentation approaches .
In most papers establishing consistency for learning algorithms it is assumed that the observations used for training are realizations of an i . i . d . process . In this paper we go far beyond this classical framework by showing that support vector machines ( SVMs ) essentially only require that the data-generating process satisfies a certain law of large numbers . We then consider the learnability of SVMs for $\a$-mixing ( not necessarily stationary ) processes for both classification and regression , where for the latter we explicitly allow unbounded noise .
Discovering statistical structure from links is a fundamental problem in the analysis of social networks . Choosing a misspecified model , or equivalently , an incorrect inference algorithm will result in an invalid analysis or even falsely uncover patterns that are in fact artifacts of the model . This work focuses on unifying two of the most widely used link-formation models : the stochastic blockmodel ( SBM ) and the small world ( or latent space ) model ( SWM ) . Integrating techniques from kernel learning , spectral graph theory , and nonlinear dimensionality reduction , we develop the first statistically sound polynomial-time algorithm to discover latent patterns in sparse graphs for both models . When the network comes from an SBM , the algorithm outputs a block structure . When it is from an SWM , the algorithm outputs estimates of each node ' s latent position .
In this paper , we study the problem of sparse multiple kernel learning ( MKL ) , where the goal is to efficiently learn a combination of a fixed small number of kernels from a large pool that could lead to a kernel classifier with a small prediction error . We develop an efficient algorithm based on the greedy coordinate descent algorithm , that is able to achieve a geometric convergence rate under appropriate conditions . The convergence rate is achieved by measuring the size of functional gradients by an empirical $\ell_0$ norm that depends on the empirical data distribution . This is in contrast to previous algorithms that use a functional norm to measure the size of gradients , which is independent from the data samples . We also establish a generalization error bound of the learned sparse kernel classifier using the technique of local Rademacher complexity .
An accurate model of patient-specific kidney graft survival distributions can help to improve shared-decision making in the treatment and care of patients . In this paper , we propose a deep learning method that directly models the survival function instead of estimating the hazard function to predict survival times for graft patients based on the principle of multi-task learning . By learning to jointly predict the time of the event , and its rank in the cox partial log likelihood framework , our deep learning approach outperforms , in terms of survival time prediction quality and concordance index , other common methods for survival analysis , including the Cox Proportional Hazards model and a network trained on the cox partial log-likelihood .
Stochastic gradient descent ( SGD ) is widely believed to perform implicit regularization when used to train deep neural networks , but the precise manner in which this occurs has thus far been elusive . We prove that SGD minimizes an average potential over the posterior distribution of weights along with an entropic regularization term . This potential is however not the original loss function in general . So SGD does perform variational inference , but for a different loss than the one used to compute the gradients . Even more surprisingly , SGD does not even converge in the classical sense : we show that the most likely trajectories of SGD for deep networks do not behave like Brownian motion around critical points . Instead , they resemble closed loops with deterministic components . We prove that such " out-of-equilibrium " behavior is a consequence of the fact that the gradient noise in SGD is highly non-isotropic ; the covariance matrix of mini-batch gradients has a rank as small as 0% of its dimension . We provide extensive empirical validation of these claims , proven in the appendix .
We consider the problem of identifying underlying community-like structures in graphs . Towards this end we study the Stochastic Block Model ( SBM ) on $k$-clusters : a random model on $n=km$ vertices , partitioned in $k$ equal sized clusters , with edges sampled independently across clusters with probability $q$ and within clusters with probability $p$ , $p>q$ . The goal is to recover the initial " hidden " partition of $[n]$ . We study semidefinite programming ( SDP ) based algorithms in this context . In the regime $p = \frac{\alpha \log ( m ) }{m}$ and $q = \frac{\beta \log ( m ) }{m}$ we show that a certain natural SDP based algorithm solves the problem of {\em exact recovery} in the $k$-community SBM , with high probability , whenever $\sqrt{\alpha} - \sqrt{\beta} > \sqrt{0}$ , as long as $k=o ( \log n ) $ . This threshold is known to be the information theoretically optimal . We also study the case when $k=\theta ( \log ( n ) ) $ . In this case however we achieve recovery guarantees that no longer match the optimal condition $\sqrt{\alpha} - \sqrt{\beta} > \sqrt{0}$ , thus leaving achieving optimality for this range an open question .
This paper proposes an organized generalization of Newman and Girvan ' s modularity measure for graph clustering . Optimized via a deterministic annealing scheme , this measure produces topologically ordered graph clusterings that lead to faithful and readable graph representations based on clustering induced graphs . Topographic graph clustering provides an alternative to more classical solutions in which a standard graph clustering method is applied to build a simpler graph that is then represented with a graph layout algorithm . A comparative study on four real world graphs ranging from 00 to 0 000 vertices shows the interest of the proposed approach with respect to classical solutions and to self-organizing maps for graphs .
We introduce a class of quadratic support ( QS ) functions , many of which play a crucial role in a variety of applications , including machine learning , robust statistical inference , sparsity promotion , and Kalman smoothing . Well known examples include the l0 , Huber , l0 and Vapnik losses . We build on a dual representation for QS functions using convex analysis , revealing the structure necessary for a QS function to be interpreted as the negative log of a probability density , and providing the foundation for statistical interpretation and analysis of QS loss functions . For a subclass of QS functions called piecewise linear quadratic ( PLQ ) penalties , we also develop efficient numerical estimation schemes . These components form a flexible statistical modeling framework for a variety of learning applications , together with a toolbox of efficient numerical methods for inference . In particular , for PLQ densities , interior point ( IP ) methods can be used . IP methods solve nonsmooth optimization problems by working directly with smooth systems of equations characterizing their optimality . The efficiency of the IP approach depends on the structure of particular applications . We consider the class of dynamic inverse problems using Kalman smoothing , where the aim is to reconstruct the state of a dynamical system with known process and measurement models starting from noisy output samples . In the classical case , Gaussian errors are assumed in the process and measurement models . The extended framework allows arbitrary PLQ densities to be used , and the proposed IP approach solves the generalized Kalman smoothing problem while maintaining the linear complexity in the size of the time series , just as in the Gaussian case . This extends the computational efficiency of classic algorithms to a much broader nonsmooth setting , and includes many recently proposed robust and sparse smoothers as special cases .
Markov state models ( MSMs ) and Master equation models are popular approaches to approximate molecular kinetics , equilibria , metastable states , and reaction coordinates in terms of a state space discretization usually obtained by clustering . Recently , a powerful generalization of MSMs has been introduced , the variational approach ( VA ) of molecular kinetics and its special case the time-lagged independent component analysis ( TICA ) , which allow us to approximate slow collective variables and molecular kinetics by linear combinations of smooth basis functions or order parameters . While it is known how to estimate MSMs from trajectories whose starting points are not sampled from an equilibrium ensemble , this has not yet been the case for TICA and the VA . Previous estimates from short trajectories , have been strongly biased and thus not variationally optimal . Here , we employ Koopman operator theory and ideas from dynamic mode decomposition ( DMD ) to extend the VA and TICA to non-equilibrium data . The main insight is that the VA and TICA provide a coefficient matrix that we call Koopman model , as it approximates the underlying dynamical ( Koopman ) operator in conjunction with the basis set used . This Koopman model can be used to compute a stationary vector to reweight the data to equilibrium . From such a Koopman-reweighted sample , equilibrium expectation values and variationally optimal reversible Koopman models can be constructed even with short simulations . The Koopman model can be used to propagate densities , and its eigenvalue decomposition provide estimates of relaxation timescales and slow collective variables for dimension reduction . Koopman models are generalizations of Markov state models , TICA and the linear VA and allow molecular kinetics to be described without a cluster discretization .
We consider a collection of prediction experiments , which are clustered in the sense that groups of experiments ex- hibit similar relationship between the predictor and response variables . The experiment clusters as well as the regres- sion relationships are unknown . The regression relation- ships define the experiment clusters , and in general , the predictor and response variables may not exhibit any clus- tering . We call this prediction problem clustered regres- sion with unknown clusters ( CRUC ) and in this paper we focus on linear regression . We study and compare several methods for CRUC , demonstrate their applicability to the Yahoo Learning-to-rank Challenge ( YLRC ) dataset , and in- vestigate an associated mathematical model . CRUC is at the crossroads of many prior works and we study several prediction algorithms with diverse origins : an adaptation of the expectation-maximization algorithm , an approach in- spired by K-means clustering , the singular value threshold- ing approach to matrix rank minimization under quadratic constraints , an adaptation of the Curds and Whey method in multiple regression , and a local regression ( LoR ) scheme reminiscent of neighborhood methods in collaborative filter- ing . Based on empirical evaluation on the YLRC dataset as well as simulated data , we identify the LoR method as a good practical choice : it yields best or near-best prediction performance at a reasonable computational load , and it is less sensitive to the choice of the algorithm parameter . We also provide some analysis of the LoR method for an asso- ciated mathematical model , which sheds light on optimal parameter choice and prediction performance .
Anomaly detection plays an important role in modern data-driven security applications , such as detecting suspicious access to a socket from a process . In many cases , such events can be described as a collection of categorical values that are considered as entities of different types , which we call heterogeneous categorical events . Due to the lack of intrinsic distance measures among entities , and the exponentially large event space , most existing work relies heavily on heuristics to calculate abnormal scores for events . Different from previous work , we propose a principled and unified probabilistic model APE ( Anomaly detection via Probabilistic pairwise interaction and Entity embedding ) that directly models the likelihood of events . In this model , we embed entities into a common latent space using their observed co-occurrence in different events . More specifically , we first model the compatibility of each pair of entities according to their embeddings . Then we utilize the weighted pairwise interactions of different entity types to define the event probability . Using Noise-Contrastive Estimation with " context-dependent " noise distribution , our model can be learned efficiently regardless of the large event space . Experimental results on real enterprise surveillance data show that our methods can accurately detect abnormal events compared to other state-of-the-art abnormal detection techniques .
Annealed importance sampling ( AIS ) is a common algorithm to estimate partition functions of useful stochastic models . One important problem for obtaining accurate AIS estimates is the selection of an annealing schedule . Conventionally , an annealing schedule is often determined heuristically or is simply set as a linearly increasing sequence . In this paper , we propose an algorithm for the optimal schedule by deriving a functional that dominates the AIS estimation error and by numerically minimizing this functional . We experimentally demonstrate that the proposed algorithm mostly outperforms conventional scheduling schemes with large quantization numbers .
The standard interpretation of importance-weighted autoencoders is that they maximize a tighter lower bound on the marginal likelihood than the standard evidence lower bound . We give an alternate interpretation of this procedure : that it optimizes the standard variational lower bound , but using a more complex distribution . We formally derive this result , present a tighter lower bound , and visualize the implicit importance-weighted distribution .
To recover a sparse signal from an underdetermined system , we often solve a constrained L0-norm minimization problem . In many cases , the signal sparsity and the recovery performance can be further improved by replacing the L0 norm with a " weighted " L0 norm . Without any prior information about nonzero elements of the signal , the procedure for selecting weights is iterative in nature . Common approaches update the weights at every iteration using the solution of a weighted L0 problem from the previous iteration . In this paper , we present two homotopy-based algorithms that efficiently solve reweighted L0 problems . First , we present an algorithm that quickly updates the solution of a weighted L0 problem as the weights change . Since the solution changes only slightly with small changes in the weights , we develop a homotopy algorithm that replaces the old weights with the new ones in a small number of computationally inexpensive steps . Second , we propose an algorithm that solves a weighted L0 problem by adaptively selecting the weights while estimating the signal . This algorithm integrates the reweighting into every step along the homotopy path by changing the weights according to the changes in the solution and its support , allowing us to achieve a high quality signal reconstruction by solving a single homotopy problem . We compare the performance of both algorithms , in terms of reconstruction accuracy and computational complexity , against state-of-the-art solvers and show that our methods have smaller computational cost . In addition , we will show that the adaptive selection of the weights inside the homotopy often yields reconstructions of higher quality .
Removing or filtering outliers and mislabeled instances prior to training a learning algorithm has been shown to increase classification accuracy . A popular approach for handling outliers and mislabeled instances is to remove any instance that is misclassified by a learning algorithm . However , an examination of which learning algorithms to use for filtering as well as their effects on multiple learning algorithms over a large set of data sets has not been done . Previous work has generally been limited due to the large computational requirements to run such an experiment , and , thus , the examination has generally been limited to learning algorithms that are computationally inexpensive and using a small number of data sets . In this paper , we examine 0 learning algorithms as filtering algorithms as well as examining the effects of filtering in the 0 chosen learning algorithms on a set of 00 data sets . In addition to using each learning algorithm individually as a filter , we also use the set of learning algorithms as an ensemble filter and use an adaptive algorithm that selects a subset of the learning algorithms for filtering for a specific task and learning algorithm . We find that for most cases , using an ensemble of learning algorithms for filtering produces the greatest increase in classification accuracy . We also compare filtering with a majority voting ensemble . The voting ensemble significantly outperforms filtering unless there are high amounts of noise present in the data set . Additionally , we find that a majority voting ensemble is robust to noise as filtering with a voting ensemble does not increase the classification accuracy of the voting ensemble .
Low rank tensor decompositions are a powerful tool for learning generative models , and uniqueness results give them a significant advantage over matrix decomposition methods . However , tensors pose significant algorithmic challenges and tensors analogs of much of the matrix algebra toolkit are unlikely to exist because of hardness results . Efficient decomposition in the overcomplete case ( where rank exceeds dimension ) is particularly challenging . We introduce a smoothed analysis model for studying these questions and develop an efficient algorithm for tensor decomposition in the highly overcomplete case ( rank polynomial in the dimension ) . In this setting , we show that our algorithm is robust to inverse polynomial error -- a crucial property for applications in learning since we are only allowed a polynomial number of samples . While algorithms are known for exact tensor decomposition in some overcomplete settings , our main contribution is in analyzing their stability in the framework of smoothed analysis . Our main technical contribution is to show that tensor products of perturbed vectors are linearly independent in a robust sense ( i . e . the associated matrix has singular values that are at least an inverse polynomial ) . This key result paves the way for applying tensor methods to learning problems in the smoothed setting . In particular , we use it to obtain results for learning multi-view models and mixtures of axis-aligned Gaussians where there are many more " components " than dimensions . The assumption here is that the model is not adversarially chosen , formalized by a perturbation of model parameters . We believe this an appealing way to analyze realistic instances of learning problems , since this framework allows us to overcome many of the usual limitations of using tensor methods .
In this paper , we consider the interpretability of the foundational Laplacian-based semi-supervised learning approaches on graphs . We introduce a novel flow-based learning framework that subsumes the foundational approaches and additionally provides a detailed , transparent , and easily understood expression of the learning process in terms of graph flows . As a result , one can visualize and interactively explore the precise subgraph along which the information from labeled nodes flows to an unlabeled node of interest . Surprisingly , the proposed framework avoids trading accuracy for interpretability , but in fact leads to improved prediction accuracy , which is supported both by theoretical considerations and empirical results . The flow-based framework guarantees the maximum principle by construction and can handle directed graphs in an out-of-the-box manner .
We study the problem of supervised linear dimensionality reduction , taking an information-theoretic viewpoint . The linear projection matrix is designed by maximizing the mutual information between the projected signal and the class label ( based on a Shannon entropy measure ) . By harnessing a recent theoretical result on the gradient of mutual information , the above optimization problem can be solved directly using gradient descent , without requiring simplification of the objective function . Theoretical analysis and empirical comparison are made between the proposed method and two closely related methods ( Linear Discriminant Analysis and Information Discriminant Analysis ) , and comparisons are also made with a method in which Renyi entropy is used to define the mutual information ( in this case the gradient may be computed simply , under a special parameter setting ) . Relative to these alternative approaches , the proposed method achieves promising results on real datasets .
Many machine learning models have important structural tuning parameters that cannot be directly estimated from the data . The common tactic for setting these parameters is to use resampling methods , such as cross--validation or the bootstrap , to evaluate a candidate set of values and choose the best based on some pre--defined criterion . Unfortunately , this process can be time consuming . However , the model tuning process can be streamlined by adaptively resampling candidate values so that settings that are clearly sub-optimal can be discarded . The notion of futility analysis is introduced in this context . An example is shown that illustrates how adaptive resampling can be used to reduce training time . Simulation studies are used to understand how the potential speed--up is affected by parallel processing techniques .
We provide novel theoretical results regarding local optima of regularized $M$-estimators , allowing for nonconvexity in both loss and penalty functions . Under restricted strong convexity on the loss and suitable regularity conditions on the penalty , we prove that \emph{any stationary point} of the composite objective function will lie within statistical precision of the underlying parameter vector . Our theory covers many nonconvex objective functions of interest , including the corrected Lasso for errors-in-variables linear models ; regression for generalized linear models with nonconvex penalties such as SCAD , MCP , and capped-$\ell_0$ ; and high-dimensional graphical model estimation . We quantify statistical accuracy by providing bounds on the $\ell_0$- , $\ell_0$- , and prediction error between stationary points and the population-level optimum . We also propose a simple modification of composite gradient descent that may be used to obtain a near-global optimum within statistical precision $\epsilon$ in $\log ( 0/\epsilon ) $ steps , which is the fastest possible rate of any first-order method . We provide simulation studies illustrating the sharpness of our theoretical results .
This paper addresses the problem of sparsity penalized least squares for applications in sparse signal processing , e . g . sparse deconvolution . This paper aims to induce sparsity more strongly than L0 norm regularization , while avoiding non-convex optimization . For this purpose , this paper describes the design and use of non-convex penalty functions ( regularizers ) constrained so as to ensure the convexity of the total cost function , F , to be minimized . The method is based on parametric penalty functions , the parameters of which are constrained to ensure convexity of F . It is shown that optimal parameters can be obtained by semidefinite programming ( SDP ) . This maximally sparse convex ( MSC ) approach yields maximally non-convex sparsity-inducing penalty functions constrained such that the total cost function , F , is convex . It is demonstrated that iterative MSC ( IMSC ) can yield solutions substantially more sparse than the standard convex sparsity-inducing approach , i . e . , L0 norm minimization .
We present a matrix-factorization algorithm that scales to input matrices with both huge number of rows and columns . Learned factors may be sparse or dense and/or non-negative , which makes our algorithm suitable for dictionary learning , sparse component analysis , and non-negative matrix factorization . Our algorithm streams matrix columns while subsampling them to iteratively learn the matrix factors . At each iteration , the row dimension of a new sample is reduced by subsampling , resulting in lower time complexity compared to a simple streaming algorithm . Our method comes with convergence guarantees to reach a stationary point of the matrix-factorization problem . We demonstrate its efficiency on massive functional Magnetic Resonance Imaging data ( 0 TB ) , and on patches extracted from hyperspectral images ( 000 GB ) . For both problems , which involve different penalties on rows and columns , we obtain significant speed-ups compared to state-of-the-art algorithms .
In this paper , we exploit minimal sensing information gathered from biologically inspired sensor networks to perform exploration and mapping in an unknown environment . A probabilistic motion model of mobile sensing nodes , inspired by motion characteristics of cockroaches , is utilized to extract weak encounter information in order to build a topological representation of the environment . Neighbor to neighbor interactions among the nodes are exploited to build point clouds representing spatial features of the manifold characterizing the environment based on the sampled data . To extract dominant features from sampled data , topological data analysis is used to produce persistence intervals for features , to be used for topological mapping . In order to improve robustness characteristics of the sampled data with respect to outliers , density based subsampling algorithms are employed . Moreover , a robust scale-invariant classification algorithm for persistence diagrams is proposed to provide a quantitative representation of desired features in the data . Furthermore , various strategies for defining encounter metrics with different degrees of information regarding agents ' motion are suggested to enhance the precision of the estimation and classification performance of the topological method .
Concept Hierarchies and Formal Concept Analysis are theoretically well grounded and largely experimented methods . They rely on line diagrams called Galois lattices for visualizing and analysing object-attribute sets . Galois lattices are visually seducing and conceptually rich for experts . However they present important drawbacks due to their concept oriented overall structure : analysing what they show is difficult for non experts , navigation is cumbersome , interaction is poor , and scalability is a deep bottleneck for visual interpretation even for experts . In this paper we introduce semantic probes as a means to overcome many of these problems and extend usability and application possibilities of traditional FCA visualization methods . Semantic probes are visual user centred objects which extract and organize reduced Galois sub-hierarchies . They are simpler , clearer , and they provide a better navigation support through a rich set of interaction possibilities . Since probe driven sub-hierarchies are limited to users focus , scalability is under control and interpretation is facilitated . After some successful experiments , several applications are being developed with the remaining problem of finding a compromise between simplicity and conceptual expressivity .
Data-driven Distributionally Robust Optimization ( DD-DRO ) via optimal transport has been shown to encompass a wide range of popular machine learning algorithms . The distributional uncertainty size is often shown to correspond to the regularization parameter . The type of regularization ( e . g . the norm used to regularize ) corresponds to the shape of the distributional uncertainty . We propose a data-driven robust optimization methodology to inform the transportation cost underlying the definition of the distributional uncertainty . We show empirically that this additional layer of robustification , which produces a method we called doubly robust data-driven distributionally robust optimization ( DD-R-DRO ) , allows to enhance the generalization properties of regularized estimators while reducing testing error relative to state-of-the-art classifiers in a wide range of data sets .
Optimization of high-dimensional black-box functions is an extremely challenging problem . While Bayesian optimization has emerged as a popular approach for optimizing black-box functions , its applicability has been limited to low-dimensional problems due to its computational and statistical challenges arising from high-dimensional settings . In this paper , we propose to tackle these challenges by ( 0 ) assuming a latent additive structure in the function and inferring it properly for more efficient and effective BO , and ( 0 ) performing multiple evaluations in parallel to reduce the number of iterations required by the method . Our novel approach learns the latent structure with Gibbs sampling and constructs batched queries using determinantal point processes . Experimental validations on both synthetic and real-world functions demonstrate that the proposed method outperforms the existing state-of-the-art approaches .
The use of machine-learning in neuroimaging offers new perspectives in early diagnosis and prognosis of brain diseases . Although such multivariate methods can capture complex relationships in the data , traditional approaches provide irregular ( l0 penalty ) or scattered ( l0 penalty ) predictive pattern with a very limited relevance . A penalty like Total Variation ( TV ) that exploits the natural 0D structure of the images can increase the spatial coherence of the weight map . However , TV penalization leads to non-smooth optimization problems that are hard to minimize . We propose an optimization framework that minimizes any combination of l0 , l0 , and TV penalties while preserving the exact l0 penalty . This algorithm uses Nesterov ' s smoothing technique to approximate the TV penalty with a smooth function such that the loss and the penalties are minimized with an exact accelerated proximal gradient algorithm . We propose an original continuation algorithm that uses successively smaller values of the smoothing parameter to reach a prescribed precision while achieving the best possible convergence rate . This algorithm can be used with other losses or penalties . The algorithm is applied on a classification problem on the ADNI dataset . We observe that the TV penalty does not necessarily improve the prediction but provides a major breakthrough in terms of support recovery of the predictive brain regions .
Fitting high-dimensional data involves a delicate tradeoff between faithful representation and the use of sparse models . Too often , sparsity assumptions on the fitted model are too restrictive to provide a faithful representation of the observed data . In this paper , we present a novel framework incorporating sparsity in different domains . We decompose the observed covariance matrix into a sparse Gaussian Markov model ( with a sparse precision matrix ) and a sparse independence model ( with a sparse covariance matrix ) . Our framework incorporates sparse covariance and sparse precision estimation as special cases and thus introduces a richer class of high-dimensional models . We characterize sufficient conditions for identifiability of the two models , \viz Markov and independence models . We propose an efficient decomposition method based on a modification of the popular $\ell_0$-penalized maximum-likelihood estimator ( $\ell_0$-MLE ) . We establish that our estimator is consistent in both the domains , i . e . , it successfully recovers the supports of both Markov and independence models , when the number of samples $n$ scales as $n = \Omega ( d^0 \log p ) $ , where $p$ is the number of variables and $d$ is the maximum node degree in the Markov model . Our experiments validate these results and also demonstrate that our models have better inference accuracy under simple algorithms such as loopy belief propagation .
Manifold matching works to identify embeddings of multiple disparate data spaces into the same low-dimensional space , where joint inference can be pursued . It is an enabling methodology for fusion and inference from multiple and massive disparate data sources . In this paper we focus on a method called Canonical Correlation Analysis ( CCA ) and its generalization Generalized Canonical Correlation Analysis ( GCCA ) , which belong to the more general Reduced Rank Regression ( RRR ) framework . We present an efficiency investigation of CCA and GCCA under different training conditions for a particular text document classification task .
Rgtsvm provides a fast and flexible support vector machine ( SVM ) implementation for the R language . The distinguishing feature of Rgtsvm is that support vector classification and support vector regression tasks are implemented on a graphical processing unit ( GPU ) , allowing the libraries to scale to millions of examples with >000-fold improvement in performance over existing implementations . Nevertheless , Rgtsvm retains feature parity and has an interface that is compatible with the popular e0000 SVM package in R . Altogether , Rgtsvm enables large SVM models to be created by both experienced and novice practitioners .
We present a generalization of independent component analysis ( ICA ) , where instead of looking for a linear transform that makes the data components independent , we look for a transform that makes the data components well fit by a tree-structured graphical model . Treating the problem as a semiparametric statistical problem , we show that the optimal transform is found by minimizing a contrast function based on mutual information , a function that directly extends the contrast function used for classical ICA . We provide two approximations of this contrast function , one using kernel density estimation , and another using kernel generalized variance . This tree-dependent component analysis framework leads naturally to an efficient general multivariate density estimation technique where only bivariate density estimation needs to be performed .
We present techniques for effective Gaussian process ( GP ) modelling of multiple short time series . These problems are common when applying GP models independently to each gene in a gene expression time series data set . Such sets typically contain very few time points . Naive application of common GP modelling techniques can lead to severe over-fitting or under-fitting in a significant fraction of the fitted models , depending on the details of the data set . We propose avoiding over-fitting by constraining the GP length-scale to values that focus most of the energy spectrum to frequencies below the Nyquist frequency corresponding to the sampling frequency in the data set . Under-fitting can be avoided by more informative priors on observation noise . Combining these methods allows applying GP methods reliably automatically to large numbers of independent instances of short time series . This is illustrated with experiments with both synthetic data and real gene expression data .
Uncertainty analysis in the form of probabilistic forecasting can significantly improve decision making processes in the smart power grid for better integrating renewable energy sources such as wind . Whereas point forecasting provides a single expected value , probabilistic forecasts provide more information in the form of quantiles , prediction intervals , or full predictive densities . This paper analyzes the effectiveness of a novel approach for nonparametric probabilistic forecasting of wind power that combines a smooth approximation of the pinball loss function with a neural network architecture and a weighting initialization scheme to prevent the quantile cross over problem . A numerical case study is conducted using publicly available wind data from the Global Energy Forecasting Competition 0000 . Multiple quantiles are estimated to form 00% , to 00% prediction intervals which are evaluated using a quantile score and reliability measures . Benchmark models such as the persistence and climatology distributions , multiple quantile regression , and support vector quantile regression are used for comparison where results demonstrate the proposed approach leads to improved performance while preventing the problem of overlapping quantile estimates .
Supervised machine learning models boast remarkable predictive capabilities . But can you trust your model ? Will it work in deployment ? What else can it tell you about the world ? We want models to be not only good , but interpretable . And yet the task of interpretation appears underspecified . Papers provide diverse and sometimes non-overlapping motivations for interpretability , and offer myriad notions of what attributes render models interpretable . Despite this ambiguity , many papers proclaim interpretability axiomatically , absent further explanation . In this paper , we seek to refine the discourse on interpretability . First , we examine the motivations underlying interest in interpretability , finding them to be diverse and occasionally discordant . Then , we address model properties and techniques thought to confer interpretability , identifying transparency to humans and post-hoc explanations as competing notions . Throughout , we discuss the feasibility and desirability of different notions , and question the oft-made assertions that linear models are interpretable and that deep neural networks are not .
Eradicating hunger and malnutrition is a key development goal of the 00st century . We address the problem of optimally identifying seed varieties to reliably increase crop yield within a risk-sensitive decision-making framework . Specifically , we introduce a novel hierarchical machine learning mechanism for predicting crop yield ( the yield of different seed varieties of the same crop ) . We integrate this prediction mechanism with a weather forecasting model , and propose three different approaches for decision making under uncertainty to select seed varieties for planting so as to balance yield maximization and risk . We apply our model to the problem of soybean variety selection given in the 0000 Syngenta Crop Challenge . Our prediction model achieves a median absolute error of 0 . 00 bushels per acre and thus provides good estimates for input into the decision models . Our decision models identify the selection of soybean varieties that appropriately balance yield and risk as a function of the farmer ' s risk aversion level . More generally , our models support farmers in decision making about which seed varieties to plant .
Convolutional Neural Networks ( CNNs ) have proven very effective in image classification and show promise for audio . We use various CNN architectures to classify the soundtracks of a dataset of 00M training videos ( 0 . 00 million hours ) with 00 , 000 video-level labels . We examine fully connected Deep Neural Networks ( DNNs ) , AlexNet [0] , VGG [0] , Inception [0] , and ResNet [0] . We investigate varying the size of both training set and label vocabulary , finding that analogs of the CNNs used in image classification do well on our audio classification task , and larger training and label sets help up to a point . A model using embeddings from these classifiers does much better than raw features on the Audio Set [0] Acoustic Event Detection ( AED ) classification task .
We study a spectral initialization method that serves a key role in recent work on estimating signals in nonconvex settings . Previous analysis of this method focuses on the phase retrieval problem and provides only performance bounds . In this paper , we consider arbitrary generalized linear sensing models and present a precise asymptotic characterization of the performance of the method in the high-dimensional limit . Our analysis also reveals a phase transition phenomenon that depends on the ratio between the number of samples and the signal dimension . When the ratio is below a minimum threshold , the estimates given by the spectral method are no better than random guesses drawn from a uniform distribution on the hypersphere , thus carrying no information ; above a maximum threshold , the estimates become increasingly aligned with the target signal . The computational complexity of the method , as measured by the spectral gap , is also markedly different in the two phases . Worked examples and numerical results are provided to illustrate and verify the analytical predictions . In particular , simulations show that our asymptotic formulas provide accurate predictions for the actual performance of the spectral method even at moderate signal dimensions .
Systematic and multifactor risk models are revisited via methods which were already successfully developed in signal processing and in automatic control . The results , which bypass the usual criticisms on those risk modeling , are illustrated by several successful computer experiments .
We consider the problem of distributed statistical machine learning in adversarial settings , where some unknown and time-varying subset of working machines may be compromised and behave arbitrarily to prevent an accurate model from being learned . This setting captures the potential adversarial attacks faced by Federated Learning -- a modern machine learning paradigm that is proposed by Google researchers and has been intensively studied for ensuring user privacy . Formally , we focus on a distributed system consisting of a parameter server and $m$ working machines . Each working machine keeps $N/m$ data samples , where $N$ is the total number of samples . The goal is to collectively learn the underlying true model parameter of dimension $d$ . In classical batch gradient descent methods , the gradients reported to the server by the working machines are aggregated via simple averaging , which is vulnerable to a single Byzantine failure . In this paper , we propose a Byzantine gradient descent method based on the geometric median of means of the gradients . We show that our method can tolerate $q \le ( m-0 ) /0$ Byzantine failures , and the parameter estimate converges in $O ( \log N ) $ rounds with an estimation error of $\sqrt{d ( 0q+0 ) /N}$ , hence approaching the optimal error rate $\sqrt{d/N}$ in the centralized and failure-free setting . The total computational complexity of our algorithm is of $O ( ( Nd/m ) \log N ) $ at each working machine and $O ( md + kd \log^0 N ) $ at the central server , and the total communication cost is of $O ( m d \log N ) $ . We further provide an application of our general results to the linear regression problem . A key challenge arises in the above problem is that Byzantine failures create arbitrary and unspecified dependency among the iterations and the aggregated gradients . We prove that the aggregated gradient converges uniformly to the true gradient function .
We establish a new framework for statistical estimation of directed acyclic graphs ( DAGs ) when data are generated from a linear , possibly non-Gaussian structural equation model . Our framework consists of two parts : ( 0 ) inferring the moralized graph from the support of the inverse covariance matrix ; and ( 0 ) selecting the best-scoring graph amongst DAGs that are consistent with the moralized graph . We show that when the error variances are known or estimated to close enough precision , the true DAG is the unique minimizer of the score computed using the reweighted squared l_0-loss . Our population-level results have implications for the identifiability of linear SEMs when the error covariances are specified up to a constant multiple . On the statistical side , we establish rigorous conditions for high-dimensional consistency of our two-part algorithm , defined in terms of a " gap " between the true DAG and the next best candidate . Finally , we demonstrate that dynamic programming may be used to select the optimal DAG in linear time when the treewidth of the moralized graph is bounded .
Dynamic trees are mixtures of tree structured belief networks . They solve some of the problems of fixed tree networks at the cost of making exact inference intractable . For this reason approximate methods such as sampling or mean field approaches have been used . However , mean field approximations assume a factorized distribution over node states . Such a distribution seems unlickely in the posterior , as nodes are highly correlated in the prior . Here a structured variational approach is used , where the posterior distribution over the non-evidential nodes is itself approximated by a dynamic tree . It turns out that this form can be used tractably and efficiently . The result is a set of update rules which can propagate information through the network to obtain both a full variational approximation , and the relevant marginals . The progagtion rules are more efficient than the mean field approach and give noticeable quantitative and qualitative improvement in the inference . The marginals calculated give better approximations to the posterior than loopy propagation on a small toy problem .
Most of previous work in knowledge base ( KB ) completion has focused on the problem of relation extraction . In this work , we focus on the task of inferring missing entity type instances in a KB , a fundamental task for KB competition yet receives little attention . Due to the novelty of this task , we construct a large-scale dataset and design an automatic evaluation methodology . Our knowledge base completion method uses information within the existing KB and external information from Wikipedia . We show that individual methods trained with a global objective that considers unobserved cells from both the entity and the type side gives consistently higher quality predictions compared to baseline methods . We also perform manual evaluation on a small subset of the data to verify the effectiveness of our knowledge base completion methods and the correctness of our proposed automatic evaluation method .
We connect shift-invariant characteristic kernels to infinitely divisible distributions on $\mathbb{R}^{d}$ . Characteristic kernels play an important role in machine learning applications with their kernel means to distinguish any two probability measures . The contribution of this paper is two-fold . First , we show , using the L\ ' evy-Khintchine formula , that any shift-invariant kernel given by a bounded , continuous and symmetric probability density function ( pdf ) of an infinitely divisible distribution on $\mathbb{R}^d$ is characteristic . We also present some closure property of such characteristic kernels under addition , pointwise product , and convolution . Second , in developing various kernel mean algorithms , it is fundamental to compute the following values : ( i ) kernel mean values $m_P ( x ) $ , $x \in \mathcal{X}$ , and ( ii ) kernel mean RKHS inner products ${\left\langle m_P , m_Q \right\rangle_{\mathcal{H}}}$ , for probability measures $P , Q$ . If $P , Q$ , and kernel $k$ are Gaussians , then computation ( i ) and ( ii ) results in Gaussian pdfs that is tractable . We generalize this Gaussian combination to more general cases in the class of infinitely divisible distributions . We then introduce a {\it conjugate} kernel and {\it convolution trick} , so that the above ( i ) and ( ii ) have the same pdf form , expecting tractable computation at least in some cases . As specific instances , we explore $\alpha$-stable distributions and a rich class of generalized hyperbolic distributions , where the Laplace , Cauchy and Student-t distributions are included .
In this paper , the problem of maximizing a black-box function $f : \mathcal{X} \to \mathbb{R}$ is studied in the Bayesian framework with a Gaussian Process ( GP ) prior . In particular , a new algorithm for this problem is proposed , and high probability bounds on its simple and cumulative regret are established . The query point selection rule in most existing methods involves an exhaustive search over an increasingly fine sequence of uniform discretizations of $\mathcal{X}$ . The proposed algorithm , in contrast , adaptively refines $\mathcal{X}$ which leads to a lower computational complexity , particularly when $\mathcal{X}$ is a subset of a high dimensional Euclidean space . In addition to the computational gains , sufficient conditions are identified under which the regret bounds of the new algorithm improve upon the known results . Finally an extension of the algorithm to the case of contextual bandits is proposed , and high probability bounds on the contextual regret are presented .
Multivariate regression model is a natural generalization of the classical univari- ate regression model for fitting multiple responses . In this paper , we propose a high- dimensional multivariate conditional regression model for constructing sparse estimates of the multivariate regression coefficient matrix that accounts for the dependency struc- ture among the multiple responses . The proposed method decomposes the multivariate regression problem into a series of penalized conditional log-likelihood of each response conditioned on the covariates and other responses . It allows simultaneous estimation of the sparse regression coefficient matrix and the sparse inverse covariance matrix . The asymptotic selection consistency and normality are established for the diverging dimension of the covariates and number of responses . The effectiveness of the pro- posed method is also demonstrated in a variety of simulated examples as well as an application to the Glioblastoma multiforme cancer data .
We develop an improved bound for the approximation error of the Nystr\ " {o}m method under the assumption that there is a large eigengap in the spectrum of kernel matrix . This is based on the empirical observation that the eigengap has a significant impact on the approximation error of the Nystr\ " {o}m method . Our approach is based on the concentration inequality of integral operator and the theory of matrix perturbation . Our analysis shows that when there is a large eigengap , we can improve the approximation error of the Nystr\ " {o}m method from $O ( N/m^{0/0} ) $ to $O ( N/m^{0/0} ) $ when measured in Frobenius norm , where $N$ is the size of the kernel matrix , and $m$ is the number of sampled columns .
Many unsupervised kernel methods rely on the estimation of the kernel covariance operator ( kernel CO ) or kernel cross-covariance operator ( kernel CCO ) . Both kernel CO and kernel CCO are sensitive to contaminated data , even when bounded positive definite kernels are used . To the best of our knowledge , there are few well-founded robust kernel methods for statistical unsupervised learning . In addition , while the influence function ( IF ) of an estimator can characterize its robustness , asymptotic properties and standard error , the IF of a standard kernel canonical correlation analysis ( standard kernel CCA ) has not been derived yet . To fill this gap , we first propose a robust kernel covariance operator ( robust kernel CO ) and a robust kernel cross-covariance operator ( robust kernel CCO ) based on a generalized loss function instead of the quadratic loss function . Second , we derive the IF for robust kernel CCO and standard kernel CCA . Using the IF of the standard kernel CCA , we can detect influential observations from two sets of data . Finally , we propose a method based on the robust kernel CO and the robust kernel CCO , called {\bf robust kernel CCA} , which is less sensitive to noise than the standard kernel CCA . The introduced principles can also be applied to many other kernel methods involving kernel CO or kernel CCO . Our experiments on synthesized data and imaging genetics analysis demonstrate that the proposed IF of standard kernel CCA can identify outliers . It is also seen that the proposed robust kernel CCA method performs better for ideal and contaminated data than the standard kernel CCA .
Crowdsourcing has become a popular method for collecting labeled training data . However , in many practical scenarios traditional labeling can be difficult for crowdworkers ( for example , if the data is high-dimensional or unintuitive , or the labels are continuous ) . In this work , we develop a novel model for crowdsourcing that can complement standard practices by exploiting people ' s intuitions about groups and relations between them . We employ a recent machine learning setting , called Ballpark Learning , that can estimate individual labels given only coarse , aggregated signal over groups of data points . To address the important case of continuous labels , we extend the Ballpark setting ( which focused on classification ) to regression problems . We formulate the problem as a convex optimization problem and propose fast , simple methods with an innate robustness to outliers . We evaluate our methods on real-world datasets , demonstrating how useful constraints about groups can be harnessed from a crowd of non-experts . Our methods can rival supervised models trained on many true labels , and can obtain considerably better results from the crowd than a standard label-collection process ( for a lower price ) . By collecting rough guesses on groups of instances and using machine learning to infer the individual labels , our lightweight framework is able to address core crowdsourcing challenges and train machine learning models in a cost-effective way .
Spinal cord stimulation has enabled humans with motor complete spinal cord injury ( SCI ) to independently stand and recover some lost autonomic function . Quantifying the quality of bipedal standing under spinal stimulation is important for spinal rehabilitation therapies and for new strategies that seek to combine spinal stimulation and rehabilitative robots ( such as exoskeletons ) in real time feedback . To study the potential for automated electromyography ( EMG ) analysis in SCI , we evaluated the standing quality of paralyzed patients undergoing electrical spinal cord stimulation using both video and multi-channel surface EMG recordings during spinal stimulation therapy sessions . The quality of standing under different stimulation settings was quantified manually by experienced clinicians . By correlating features of the recorded EMG activity with the expert evaluations , we show that multi-channel EMG recording can provide accurate , fast , and robust estimation for the quality of bipedal standing in spinally stimulated SCI patients . Moreover , our analysis shows that the total number of EMG channels needed to effectively predict standing quality can be reduced while maintaining high estimation accuracy , which provides more flexibility for rehabilitation robotic systems to incorporate EMG recordings .
We introduce the problem of reconstructing a sequence of multidimensional real vectors where some of the data are missing . This problem contains regression and mapping inversion as particular cases where the pattern of missing data is independent of the sequence index . The problem is hard because it involves possibly multivalued mappings at each vector in the sequence , where the missing variables can take more than one value given the present variables ; and the set of missing variables can vary from one vector to the next . To solve this problem , we propose an algorithm based on two redundancy assumptions : vector redundancy ( the data live in a low-dimensional manifold ) , so that the present variables constrain the missing ones ; and sequence redundancy ( e . g . continuity ) , so that consecutive vectors constrain each other . We capture the low-dimensional nature of the data in a probabilistic way with a joint density model , here the generative topographic mapping , which results in a Gaussian mixture . Candidate reconstructions at each vector are obtained as all the modes of the conditional distribution of missing variables given present variables . The reconstructed sequence is obtained by minimising a global constraint , here the sequence length , by dynamic programming . We present experimental results for a toy problem and for inverse kinematics of a robot arm .
Multi-task learning leverages shared information among data sets to improve the learning performance of individual tasks . The paper applies this framework for data where each task is a phase-shifted periodic time series . In particular , we develop a novel Bayesian nonparametric model capturing a mixture of Gaussian processes where each task is a sum of a group-specific function and a component capturing individual variation , in addition to each task being phase shifted . We develop an efficient \textsc{em} algorithm to learn the parameters of the model . As a special case we obtain the Gaussian mixture model and \textsc{em} algorithm for phased-shifted periodic time series . Furthermore , we extend the proposed model by using a Dirichlet Process prior and thereby leading to an infinite mixture model that is capable of doing automatic model selection . A Variational Bayesian approach is developed for inference in this model . Experiments in regression , classification and class discovery demonstrate the performance of the proposed models using both synthetic data and real-world time series data from astrophysics . Our methods are particularly useful when the time series are sparsely and non-synchronously sampled .
We discuss a multiple-play multi-armed bandit ( MAB ) problem in which several arms are selected at each round . Recently , Thompson sampling ( TS ) , a randomized algorithm with a Bayesian spirit , has attracted much attention for its empirically excellent performance , and it is revealed to have an optimal regret bound in the standard single-play MAB problem . In this paper , we propose the multiple-play Thompson sampling ( MP-TS ) algorithm , an extension of TS to the multiple-play MAB problem , and discuss its regret analysis . We prove that MP-TS for binary rewards has the optimal regret upper bound that matches the regret lower bound provided by Anantharam et al . ( 0000 ) . Therefore , MP-TS is the first computationally efficient algorithm with optimal regret . A set of computer simulations was also conducted , which compared MP-TS with state-of-the-art algorithms . We also propose a modification of MP-TS , which is shown to have better empirical performance .
Hard Thresholding Pursuit ( HTP ) is an iterative greedy selection procedure for finding sparse solutions of underdetermined linear systems . This method has been shown to have strong theoretical guarantee and impressive numerical performance . In this paper , we generalize HTP from compressive sensing to a generic problem setup of sparsity-constrained convex optimization . The proposed algorithm iterates between a standard gradient descent step and a hard thresholding step with or without debiasing . We prove that our method enjoys the strong guarantees analogous to HTP in terms of rate of convergence and parameter estimation accuracy . Numerical evidences show that our method is superior to the state-of-the-art greedy selection methods in sparse logistic regression and sparse precision matrix estimation tasks .
Reducing user attrition , i . e . churn , is a broad challenge faced by several industries . In mobile social games , decreasing churn is decisive to increase player retention and rise revenues . Churn prediction models allow to understand player loyalty and to anticipate when they will stop playing a game . Thanks to these predictions , several initiatives can be taken to retain those players who are more likely to churn . Survival analysis focuses on predicting the time of occurrence of a certain event , churn in our case . Classical methods , like regressions , could be applied only when all players have left the game . The challenge arises for datasets with incomplete churning information for all players , as most of them still connect to the game . This is called a censored data problem and is in the nature of churn . Censoring is commonly dealt with survival analysis techniques , but due to the inflexibility of the survival statistical algorithms , the accuracy achieved is often poor . In contrast , novel ensemble learning techniques , increasingly popular in a variety of scientific fields , provide high-class prediction results . In this work , we develop , for the first time in the social games domain , a survival ensemble model which provides a comprehensive analysis together with an accurate prediction of churn . For each player , we predict the probability of churning as function of time , which permits to distinguish various levels of loyalty profiles . Additionally , we assess the risk factors that explain the predicted player survival times . Our results show that churn prediction by survival ensembles significantly improves the accuracy and robustness of traditional analyses , like Cox regression .
Dropout-based regularization methods can be regarded as injecting random noise with pre-defined magnitude to different parts of the neural network during training . It was recently shown that Bayesian dropout procedure not only improves generalization but also leads to extremely sparse neural architectures by automatically setting the individual noise magnitude per weight . However , this sparsity can hardly be used for acceleration since it is unstructured . In the paper , we propose a new Bayesian model that takes into account the computational structure of neural networks and provides structured sparsity , e . g . removes neurons and/or convolutional channels in CNNs . To do this we inject noise to the neurons outputs while keeping the weights unregularized . We establish the probabilistic model with a proper truncated log-uniform prior over the noise and truncated log-normal variational approximation that ensures that the KL-term in the evidence lower bound is computed in closed-form . The model leads to structured sparsity by removing elements with a low SNR from the computation graph and provides significant acceleration on a number of deep neural architectures . The model is easy to implement as it can be formulated as a separate dropout-like layer .
Comma . ai ' s approach to Artificial Intelligence for self-driving cars is based on an agent that learns to clone driver behaviors and plans maneuvers by simulating future events in the road . This paper illustrates one of our research approaches for driving simulation . One where we learn to simulate . Here we investigate variational autoencoders with classical and learned cost functions using generative adversarial networks for embedding road frames . Afterwards , we learn a transition model in the embedded space using action conditioned Recurrent Neural Networks . We show that our approach can keep predicting realistic looking video for several frames despite the transition model being optimized without a cost function in the pixel space .
Mixture models are a fundamental tool in applied statistics and machine learning for treating data taken from multiple subpopulations . The current practice for estimating the parameters of such models relies on local search heuristics ( e . g . , the EM algorithm ) which are prone to failure , and existing consistent methods are unfavorable due to their high computational and sample complexity which typically scale exponentially with the number of mixture components . This work develops an efficient method of moments approach to parameter estimation for a broad class of high-dimensional mixture models with many components , including multi-view mixtures of Gaussians ( such as mixtures of axis-aligned Gaussians ) and hidden Markov models . The new method leads to rigorous unsupervised learning results for mixture models that were not achieved by previous works ; and , because of its simplicity , it offers a viable alternative to EM for practical deployment .
We design new algorithms for the combinatorial pure exploration problem in the multi-arm bandit framework . In this problem , we are given K distributions and a collection of subsets $\mathcal{V} \subset 0^K$ of these distributions , and we would like to find the subset $v \in \mathcal{V}$ that has largest cumulative mean , while collecting , in a sequential fashion , as few samples from the distributions as possible . We study both the fixed budget and fixed confidence settings , and our algorithms essentially achieve state-of-the-art performance in all settings , improving on previous guarantees for structures like matchings and submatrices that have large augmenting sets . Moreover , our algorithms can be implemented efficiently whenever the decision set V admits linear optimization . Our analysis involves precise concentration-of-measure arguments and a new algorithm for linear programming with exponentially many constraints .
We consider the problem of estimating a large rank-one tensor ${\boldsymbol u}^{\otimes k}\in ( {\mathbb R}^{n} ) ^{\otimes k}$ , $k\ge 0$ in Gaussian noise . Earlier work characterized a critical signal-to-noise ratio $\lambda_{Bayes}= O ( 0 ) $ above which an ideal estimator achieves strictly positive correlation with the unknown vector of interest . Remarkably no polynomial-time algorithm is known that achieved this goal unless $\lambda\ge C n^{ ( k-0 ) /0}$ and even powerful semidefinite programming relaxations appear to fail for $0\ll \lambda\ll n^{ ( k-0 ) /0}$ . In order to elucidate this behavior , we consider the maximum likelihood estimator , which requires maximizing a degree-$k$ homogeneous polynomial over the unit sphere in $n$ dimensions . We compute the expected number of critical points and local maxima of this objective function and show that it is exponential in the dimensions $n$ , and give exact formulas for the exponential growth rate . We show that ( for $\lambda$ larger than a constant ) critical points are either very close to the unknown vector ${\boldsymbol u}$ , or are confined in a band of width $\Theta ( \lambda^{-0/ ( k-0 ) } ) $ around the maximum circle that is orthogonal to ${\boldsymbol u}$ . For local maxima , this band shrinks to be of size $\Theta ( \lambda^{-0/ ( k-0 ) } ) $ . These `uninformative ' local maxima are likely to cause the failure of optimization algorithms .
Clustering is a widely used unsupervised learning method for finding structure in the data . However , the resulting clusters are typically presented without any guarantees on their robustness ; slightly changing the used data sample or re-running a clustering algorithm involving some stochastic component may lead to completely different clusters . There is , hence , a need for techniques that can quantify the instability of the generated clusters . In this study , we propose a technique for quantifying the instability of a clustering solution and for finding robust clusters , termed core clusters , which correspond to clusters where the co-occurrence probability of each data item within a cluster is at least $0 - \alpha$ . We demonstrate how solving the core clustering problem is linked to finding the largest maximal cliques in a graph . We show that the method can be used with both clustering and classification algorithms . The proposed method is tested on both simulated and real datasets . The results show that the obtained clusters indeed meet the guarantees on robustness .
Online selection of dynamic features has attracted intensive interest in recent years . However , existing online feature selection methods evaluate features individually and ignore the underlying structure of feature stream . For instance , in image analysis , features are generated in groups which represent color , texture and other visual information . Simply breaking the group structure in feature selection may degrade performance . Motivated by this fact , we formulate the problem as an online group feature selection . The problem assumes that features are generated individually but there are group structure in the feature stream . To the best of our knowledge , this is the first time that the correlation among feature stream has been considered in the online feature selection process . To solve this problem , we develop a novel online group feature selection method named OGFS . Our proposed approach consists of two stages : online intra-group selection and online inter-group selection . In the intra-group selection , we design a criterion based on spectral analysis to select discriminative features in each group . In the inter-group selection , we utilize a linear regression model to select an optimal subset . This two-stage procedure continues until there are no more features arriving or some predefined stopping conditions are met . %Our method has been applied Finally , we apply our method to multiple tasks including image classification % , face verification and face verification . Extensive empirical studies performed on real-world and benchmark data sets demonstrate that our method outperforms other state-of-the-art online feature selection %method methods .
This paper considers the problem of estimating the structure of multiple related directed acyclic graph ( DAG ) models . Building on recent developments in exact estimation of DAGs using integer linear programming ( ILP ) , we present an ILP approach for joint estimation over multiple DAGs , that does not require that the vertices in each DAG share a common ordering . Furthermore , we allow also for ( potentially unknown ) dependency structure between the DAGs . Results are presented on both simulated data and fMRI data obtained from multiple subjects .
Automatic summarisation is a popular approach to reduce a document to its main arguments . Recent research in the area has focused on neural approaches to summarisation , which can be very data-hungry . However , few large datasets exist and none for the traditionally popular domain of scientific publications , which opens up challenging research avenues centered on encoding large , complex documents . In this paper , we introduce a new dataset for summarisation of computer science publications by exploiting a large resource of author provided summaries and show straightforward ways of extending it further . We develop models on the dataset making use of both neural sentence encoding and traditionally used summarisation features and show that models which encode sentences as well as their local and global context perform best , significantly outperforming well-established baseline methods .
Local network community detection is the task of finding a single community of nodes concentrated around few given seed nodes in a localized way . Conductance is a popular objective function used in many algorithms for local community detection . This paper studies a continuous relaxation of conductance . We show that continuous optimization of this objective still leads to discrete communities . We investigate the relation of conductance with weighted kernel k-means for a single community , which leads to the introduction of a new objective function , $\sigma$-conductance . Conductance is obtained by setting $\sigma$ to $0$ . Two algorithms , EMc and PGDc , are proposed to locally optimize $\sigma$-conductance and automatically tune the parameter $\sigma$ . They are based on expectation maximization and projected gradient descent , respectively . We prove locality and give performance guarantees for EMc and PGDc for a class of dense and well separated communities centered around the seeds . Experiments are conducted on networks with ground-truth communities , comparing to state-of-the-art graph diffusion algorithms for conductance optimization . On large graphs , results indicate that EMc and PGDc stay localized and produce communities most similar to the ground , while graph diffusion algorithms generate large communities of lower quality .
Machine learning has emerged as an invaluable tool in many research areas . In the present work , we harness this power to predict highly accurate molecular infrared spectra with unprecedented computational efficiency . To account for vibrational anharmonic and dynamical effects -- typically neglected by conventional quantum chemistry approaches -- we base our machine learning strategy on ab initio molecular dynamics simulations . While these simulations are usually extremely time consuming even for small molecules , we overcome these limitations by leveraging the power of a variety of machine learning techniques , not only accelerating simulations by several orders of magnitude , but also greatly extending the size of systems that can be treated . To this end , we develop a molecular dipole moment model based on environment dependent neural network charges and combine it with the neural network potentials of Behler and Parrinello . Contrary to the prevalent big data philosophy , we are able to obtain very accurate machine learning models for the prediction of infrared spectra based on only a few hundreds of electronic structure reference points . This is made possible through the introduction of a fully automated sampling scheme and the use of molecular forces during neural network potential training . We demonstrate the power of our machine learning approach by applying it to model the infrared spectra of a methanol molecule , n-alkanes containing up to 000 atoms and the protonated alanine tripeptide , which at the same time represents the first application of machine learning techniques to simulate the dynamics of a peptide . In all these case studies we find excellent agreement between the infrared spectra predicted via machine learning models and the respective theoretical and experimental spectra .
Datasets containing large samples of time-to-event data arising from several small heterogeneous groups are commonly encountered in statistics . This presents problems as they cannot be pooled directly due to their heterogeneity or analyzed individually because of their small sample size . Bayesian nonparametric modelling approaches can be used to model such datasets given their ability to flexibly share information across groups . In this paper , we will compare three popular Bayesian nonparametric methods for modelling the survival functions of heterogeneous groups . Specifically , we will first compare the modelling accuracy of the Dirichlet process , the hierarchical Dirichlet process , and the nested Dirichlet process on simulated datasets of different sizes , where group survival curves differ in shape or in expectation . We , then , will compare the models on a real-world injury dataset .
While existing mathematical descriptions can accurately account for phenomena at microscopic scales ( e . g . molecular dynamics ) , these are often high-dimensional , stochastic and their applicability over macroscopic time scales of physical interest is computationally infeasible or impractical . In complex systems , with limited physical insight on the coherent behavior of their constituents , the only available information is data obtained from simulations of the trajectories of huge numbers of degrees of freedom over microscopic time scales . This paper discusses a Bayesian approach to deriving probabilistic coarse-grained models that simultaneously address the problems of identifying appropriate reduced coordinates and the effective dynamics in this lower-dimensional representation . At the core of the models proposed lie simple , low-dimensional dynamical systems which serve as the building blocks of the global model . These approximate the latent , generating sources and parameterize the reduced-order dynamics . We discuss parallelizable , online inference and learning algorithms that employ Sequential Monte Carlo samplers and scale linearly with the dimensionality of the observed dynamics . We propose a Bayesian adaptive time-integration scheme that utilizes probabilistic predictive estimates and enables rigorous concurrent s imulation over macroscopic time scales . The data-driven perspective advocated assimilates computational and experimental data and thus can materialize data-model fusion . It can deal with applications that lack a mathematical description and where only observational data is available . Furthermore , it makes non-intrusive use of existing computational models .
We describe our experience in the development of a probabilistic network for the diagnosis of acute cardiopulmonary diseases . A panel of expert physicians collaborated to specify the qualitative part , that is a directed acyclic graph defining a factorization of the joint probability distribution of domain variables . The quantitative part , that is the set of all conditional probability distributions defined by each factor , was estimated in the Bayesian paradigm : we applied a special formal representation , characterized by a low number of parameters and a parameterization intelligible for physicians , elicited the joint prior distribution of parameters from medical experts , and updated it by conditioning on a dataset of hospital patient records using Markov Chain Monte Carlo simulation . Refinement was cyclically performed until the probabilistic network provided satisfactory Concordance Index values for a selection of acute diseases and reasonable inference on six fictitious patient cases . The probabilistic network can be employed to perform medical diagnosis on a total of 00 diseases ( 00 acute and 00 chronic ) on the basis of up to 000 patient findings .
Our focus is on realistically modeling and forecasting dynamic networks of face-to-face contacts among individuals . Important aspects of such data that lead to problems with current methods include the tendency of the contacts to move between periods of slow and rapid changes , and the dynamic heterogeneity in the actors ' connectivity behaviors . Motivated by this application , we develop a novel method for Locally Adaptive DYnamic ( LADY ) network inference . The proposed model relies on a dynamic latent space representation in which each actor ' s position evolves in time via stochastic differential equations . Using a state space representation for these stochastic processes and P\ ' olya-gamma data augmentation , we develop an efficient MCMC algorithm for posterior inference along with tractable procedures for online updating and forecasting of future networks . We evaluate performance in simulation studies , and consider an application to face-to-face contacts among individuals in a primary school .
Adversarial learning of probabilistic models has recently emerged as a promising alternative to maximum likelihood . Implicit models such as generative adversarial networks ( GAN ) often generate better samples compared to explicit models trained by maximum likelihood . Yet , GANs sidestep the characterization of an explicit density which makes quantitative evaluations challenging . To bridge this gap , we propose Flow-GANs , a generative adversarial network for which we can perform exact likelihood evaluation , thus supporting both adversarial and maximum likelihood training . When trained adversarially , Flow-GANs generate high-quality samples but attain extremely poor log-likelihood scores , inferior even to a mixture model memorizing the training data ; the opposite is true when trained by maximum likelihood . Results on MNIST and CIFAR-00 demonstrate that hybrid training can attain high held-out likelihoods while retaining visual fidelity in the generated samples .
We extend the traditional worst-case , minimax analysis of stochastic convex optimization by introducing a localized form of minimax complexity for individual functions . Our main result gives function-specific lower and upper bounds on the number of stochastic subgradient evaluations needed to optimize either the function or its " hardest local alternative " to a given numerical precision . The bounds are expressed in terms of a localized and computational analogue of the modulus of continuity that is central to statistical minimax analysis . We show how the computational modulus of continuity can be explicitly calculated in concrete cases , and relates to the curvature of the function at the optimum . We also prove a superefficiency result that demonstrates it is a meaningful benchmark , acting as a computational analogue of the Fisher information in statistical estimation . The nature and practical implications of the results are demonstrated in simulations .
A generative Bayesian model is developed for deep ( multi-layer ) convolutional dictionary learning . A novel probabilistic pooling operation is integrated into the deep model , yielding efficient bottom-up and top-down probabilistic learning . After learning the deep convolutional dictionary , testing is implemented via deconvolutional inference . To speed up this inference , a new statistical approach is proposed to project the top-layer dictionary elements to the data level . Following this , only one layer of deconvolution is required during testing . Experimental results demonstrate powerful capabilities of the model to learn multi-layer features from images . Excellent classification results are obtained on both the MNIST and Caltech 000 datasets .
The pairwise influence matrix of Dobrushin has long been used as an analytical tool to bound the rate of convergence of Gibbs sampling . In this work , we use Dobrushin influence as the basis of a practical tool to certify and efficiently improve the quality of a discrete Gibbs sampler . Our Dobrushin-optimized Gibbs samplers ( DoGS ) offer customized variable selection orders for a given sampling budget and variable subset of interest , explicit bounds on total variation distance to stationarity , and certifiable improvements over the standard systematic and uniform random scan Gibbs samplers . In our experiments with joint image segmentation and object recognition , Markov chain Monte Carlo maximum likelihood estimation , and Ising model inference , DoGS consistently deliver higher-quality inferences with significantly smaller sampling budgets than standard Gibbs samplers .
The development of global sensitivity analysis of numerical model outputs has recently raised new issues on 0-dimensional Poincar\ ' e inequalities . Typically two kind of sensitivity indices are linked by a Poincar\ ' e type inequality , which provide upper bounds of the most interpretable index by using the other one , cheaper to compute . This allows performing a low-cost screening of unessential variables . The efficiency of this screening then highly depends on the accuracy of the upper bounds in Poincar\ ' e inequalities . The novelty in the questions concern the wide range of probability distributions involved , which are often truncated on intervals . After providing an overview of the existing knowledge and techniques , we add some theory about Poincar\ ' e constants on intervals , with improvements for symmetric intervals . Then we exploit the spectral interpretation for computing exact value of Poincar\ ' e constants of any admissible distribution on a given interval . We give semi-analytical results for some frequent distributions ( truncated exponential , triangular , truncated normal ) , and present a numerical method in the general case . Finally , an application is made to a hydrological problem , showing the benefits of the new results in Poincar\ ' e inequalities to sensitivity analysis .
We prove a \emph{query complexity} lower bound on rank-one principal component analysis ( PCA ) . We consider an oracle model where , given a symmetric matrix $M \in \mathbb{R}^{d \times d}$ , an algorithm is allowed to make $T$ \emph{exact} queries of the form $w^{ ( i ) } = Mv^{ ( i ) }$ for $i \in \{0 , \dots , T\}$ , where $v^{ ( i ) }$ is drawn from a distribution which depends arbitrarily on the past queries and measurements $\{v^{ ( j ) } , w^{ ( j ) }\}_{0 \le j \le i-0}$ . We show that for a small constant $\epsilon$ , any adaptive , randomized algorithm which can find a unit vector $\widehat{v}$ for which $\widehat{v}^{\top}M\widehat{v} \ge ( 0-\epsilon ) \|M\|$ , with even small probability , must make $T = \Omega ( \log d ) $ queries . In addition to settling a widely-held folk conjecture , this bound demonstrates a fundamental gap between convex optimization and " strict-saddle " non-convex optimization of which PCA is a canonical example : in the former , first-order methods can have dimension-free iteration complexity , whereas in PCA , the iteration complexity of gradient-based methods must necessarily grow with the dimension . Our argument proceeds via a reduction to estimating the rank-one spike in a deformed Wigner model . We establish lower bounds for this model by developing a " truncated " analogue of the $\chi^0$ Bayes-risk lower bound of Chen et al .
Semantic segmentation was seen as a challenging computer vision problem few years ago . Due to recent advancements in deep learning , relatively accurate solutions are now possible for its use in automated driving . In this paper , the semantic segmentation problem is explored from the perspective of automated driving . Most of the current semantic segmentation algorithms are designed for generic images and do not incorporate prior structure and end goal for automated driving . First , the paper begins with a generic taxonomic survey of semantic segmentation algorithms and then discusses how it fits in the context of automated driving . Second , the particular challenges of deploying it into a safety system which needs high level of accuracy and robustness are listed . Third , different alternatives instead of using an independent semantic segmentation module are explored . Finally , an empirical evaluation of various semantic segmentation architectures was performed on CamVid dataset in terms of accuracy and speed . This paper is a preliminary shorter version of a more detailed survey which is work in progress .
Inference in the presence of outliers is an important field of research as outliers are ubiquitous and may arise across a variety of problems and domains . Bayesian optimization is method that heavily relies on probabilistic inference . This allows outstanding sample efficiency because the probabilistic machinery provides a memory of the whole optimization process . However , that virtue becomes a disadvantage when the memory is populated with outliers , inducing bias in the estimation . In this paper , we present an empirical evaluation of Bayesian optimization methods in the presence of outliers . The empirical evidence shows that Bayesian optimization with robust regression often produces suboptimal results . We then propose a new algorithm which combines robust regression ( a Gaussian process with Student-t likelihood ) with outlier diagnostics to classify data points as outliers or inliers . By using an scheduler for the classification of outliers , our method is more efficient and has better convergence over the standard robust regression . Furthermore , we show that even in controlled situations with no expected outliers , our method is able to produce better results .
The paper briefly introduces multiple classifier systems and describes a new algorithm , which improves classification accuracy by means of recommendation of a proper algorithm to an object classification . This recommendation is done assuming that a classifier is likely to predict the label of the object correctly if it has correctly classified its neighbors . The process of assigning a classifier to each object is based on Formal Concept Analysis . We explain the idea of the algorithm with a toy example and describe our first experiments with real-world datasets .
We survey agglomerative hierarchical clustering algorithms and discuss efficient implementations that are available in R and other software environments . We look at hierarchical self-organizing maps , and mixture models . We review grid-based clustering , focusing on hierarchical density-based approaches . Finally we describe a recently developed very efficient ( linear time ) hierarchical clustering algorithm , which can also be viewed as a hierarchical grid-based algorithm .
In this paper we build on previous work which uses inferences techniques , in particular Markov Chain Monte Carlo ( MCMC ) methods , to solve parameterized control problems . We propose a number of modifications in order to make this approach more practical in general , higher-dimensional spaces . We first introduce a new target distribution which is able to incorporate more reward information from sampled trajectories . We also show how to break strong correlations between the policy parameters and sampled trajectories in order to sample more freely . Finally , we show how to incorporate these techniques in a principled manner to obtain estimates of the optimal policy .
The ubiquity of systems using artificial intelligence or " AI " has brought increasing attention to how those systems should be regulated . The choice of how to regulate AI systems will require care . AI systems have the potential to synthesize large amounts of data , allowing for greater levels of personalization and precision than ever before---applications range from clinical decision support to autonomous driving and predictive policing . That said , there exist legitimate concerns about the intentional and unintentional negative consequences of AI systems . There are many ways to hold AI systems accountable . In this work , we focus on one : explanation . Questions about a legal right to explanation from AI systems was recently debated in the EU General Data Protection Regulation , and thus thinking carefully about when and how explanation from AI systems might improve accountability is timely . In this work , we review contexts in which explanation is currently required under the law , and then list the technical considerations that must be considered if we desired AI systems that could provide kinds of explanations that are currently required of humans .
The beta-negative binomial process ( BNBP ) , an integer-valued stochastic process , is employed to partition a count vector into a latent random count matrix . As the marginal probability distribution of the BNBP that governs the exchangeable random partitions of grouped data has not yet been developed , current inference for the BNBP has to truncate the number of atoms of the beta process . This paper introduces an exchangeable partition probability function to explicitly describe how the BNBP clusters the data points of each group into a random number of exchangeable partitions , which are shared across all the groups . A fully collapsed Gibbs sampler is developed for the BNBP , leading to a novel nonparametric Bayesian topic model that is distinct from existing ones , with simple implementation , fast convergence , good mixing , and state-of-the-art predictive performance .
Existing MAP inference algorithms for determinantal point processes ( DPPs ) need to calculate determinants or conduct eigenvalue decomposition generally at the scale of the full kernel , which presents a great challenge for real-world applications . In this paper , we introduce a class of DPPs , called BwDPPs , that are characterized by an almost block diagonal kernel matrix and thus can allow efficient block-wise MAP inference . Furthermore , BwDPPs are successfully applied to address the difficulty of selecting change-points in the problem of change-point detection ( CPD ) , which results in a new BwDPP-based CPD method , named BwDppCpd . In BwDppCpd , a preliminary set of change-point candidates is first created based on existing well-studied metrics . Then , these change-point candidates are treated as DPP items , and DPP-based subset selection is conducted to give the final estimate of the change-points that favours both quality and diversity . The effectiveness of BwDppCpd is demonstrated through extensive experiments on five real-world datasets .
A treatment regime is a function that maps individual patient information to a recommended treatment , hence explicitly incorporating the heterogeneity in need for treatment across individuals . Patient responses are dichotomous and can be predicted through an unknown relationship that depends on the patient information and the selected treatment . The goal is to find the treatments that lead to the best patient responses on average . Each experiment is expensive , forcing us to learn the most from each experiment . We adopt a Bayesian approach both to incorporate possible prior information and to update our treatment regime continuously as information accrues , with the potential to allow smaller yet more informative trials and for patients to receive better treatment . By formulating the problem as contextual bandits , we introduce a knowledge gradient policy to guide the treatment assignment by maximizing the expected value of information , for which an approximation method is used to overcome computational challenges . We provide a detailed study on how to make sequential medical decisions under uncertainty to reduce health care costs on a real world knee replacement dataset . We use clustering and LASSO to deal with the intrinsic sparsity in health datasets . We show experimentally that even though the problem is sparse , through careful selection of physicians ( versus picking them at random ) , we can significantly improve the success rates .
Many problems in image processing and computer vision ( e . g . colorization , style transfer ) can be posed as ' manipulating ' an input image into a corresponding output image given a user-specified guiding signal . A holy-grail solution towards generic image manipulation should be able to efficiently alter an input image with any personalized signals ( even signals unseen during training ) , such as diverse paintings and arbitrary descriptive attributes . However , existing methods are either inefficient to simultaneously process multiple signals ( let alone generalize to unseen signals ) , or unable to handle signals from other modalities . In this paper , we make the first attempt to address the zero-shot image manipulation task . We cast this problem as manipulating an input image according to a parametric model whose key parameters can be conditionally generated from any guiding signal ( even unseen ones ) . To this end , we propose the Zero-shot Manipulation Net ( ZM-Net ) , a fully-differentiable architecture that jointly optimizes an image-transformation network ( TNet ) and a parameter network ( PNet ) . The PNet learns to generate key transformation parameters for the TNet given any guiding signal while the TNet performs fast zero-shot image manipulation according to both signal-dependent parameters from the PNet and signal-invariant parameters from the TNet itself . Extensive experiments show that our ZM-Net can perform high-quality image manipulation conditioned on different forms of guiding signals ( e . g . style images and attributes ) in real-time ( tens of milliseconds per image ) even for unseen signals . Moreover , a large-scale style dataset with over 00 , 000 style images is also constructed to promote further research .
We focus on the maximum regularization parameter for anisotropic total-variation denoising . It corresponds to the minimum value of the regularization parameter above which the solution remains constant . While this value is well know for the Lasso , such a critical value has not been investigated in details for the total-variation . Though , it is of importance when tuning the regularization parameter as it allows fixing an upper-bound on the grid for which the optimal parameter is sought . We establish a closed form expression for the one-dimensional case , as well as an upper-bound for the two-dimensional case , that appears reasonably tight in practice . This problem is directly linked to the computation of the pseudo-inverse of the divergence , which can be quickly obtained by performing convolutions in the Fourier domain .
Sum-product networks have recently emerged as an attractive representation due to their dual view as a special type of deep neural network with clear semantics and a special type of probabilistic graphical model for which inference is always tractable . Those properties follow from some conditions ( i . e . , completeness and decomposability ) that must be respected by the structure of the network . As a result , it is not easy to specify a valid sum-product network by hand and therefore structure learning techniques are typically used in practice . This paper describes the first online structure learning technique for continuous SPNs with Gaussian leaves . We also introduce an accompanying new parameter learning technique .
Neural connectomics has begun producing massive amounts of data , necessitating new analysis methods to discover the biological and computational structure . It has long been assumed that discovering neuron types and their relation to microcircuitry is crucial to understanding neural function . Here we developed a nonparametric Bayesian technique that identifies neuron types and microcircuitry patterns in connectomics data . It combines the information traditionally used by biologists , including connectivity , cell body location and the spatial distribution of synapses , in a principled and probabilistically-coherent manner . We show that the approach recovers known neuron types in the retina and enables predictions of connectivity , better than simpler algorithms . It also can reveal interesting structure in the nervous system of C . elegans , and automatically discovers the structure of a microprocessor . Our approach extracts structural meaning from connectomics , enabling new approaches of automatically deriving anatomical insights from these emerging datasets .
In this paper , we introduce a new concept of stability for cross-validation , called the $\left ( \beta , \varpi \right ) $-stability , and use it as a new perspective to build the general theory for cross-validation . The $\left ( \beta , \varpi \right ) $-stability mathematically connects the generalization ability and the stability of the cross-validated model via the Rademacher complexity . Our result reveals mathematically the effect of cross-validation from two sides : on one hand , cross-validation picks the model with the best empirical generalization ability by validating all the alternatives on test sets ; on the other hand , cross-validation may compromise the stability of the model selection by causing subsampling error . Moreover , the difference between training and test errors in q\textsuperscript{th} round , sometimes referred to as the generalization error , might be autocorrelated on q . Guided by the ideas above , the $\left ( \beta , \varpi \right ) $-stability help us derivd a new class of Rademacher bounds , referred to as the one-round/convoluted Rademacher bounds , for the stability of cross-validation in both the i . i . d . \ and non-i . i . d . \ cases . For both light-tail and heavy-tail losses , the new bounds quantify the stability of the one-round/average test error of the cross-validated model in terms of its one-round/average training error , the sample sizes $n$ , number of folds $K$ , the tail property of the loss ( encoded as Orlicz-$\Psi_\nu$ norms ) and the Rademacher complexity of the model class $\Lambda$ . The new class of bounds not only quantitatively reveals the stability of the generalization ability of the cross-validated model , it also shows empirically the optimal choice for number of folds $K$ , at which the upper bound of the one-round/average test error is lowest , or , to put it in another way , where the test error is most stable .
In this paper , we generalize Huber ' s criterion to multichannel sparse recovery problem of complex-valued measurements where the objective is to find good recovery of jointly sparse unknown signal vectors from the given multiple measurement vectors which are different linear combinations of the same known elementary vectors . This requires careful characterization of robust complex-valued loss functions as well as Huber ' s criterion function for the multivariate sparse regression problem . We devise a greedy algorithm based on simultaneous normalized iterative hard thresholding ( SNIHT ) algorithm . Unlike the conventional SNIHT method , our algorithm , referred to as HUB-SNIHT , is robust under heavy-tailed non-Gaussian noise conditions , yet has a negligible performance loss compared to SNIHT under Gaussian noise . Usefulness of the method is illustrated in source localization application with sensor arrays .
This paper proposes an alternating back-propagation algorithm for learning the generator network model . The model is a non-linear generalization of factor analysis . In this model , the mapping from the continuous latent factors to the observed signal is parametrized by a convolutional neural network . The alternating back-propagation algorithm iterates the following two steps : ( 0 ) Inferential back-propagation , which infers the latent factors by Langevin dynamics or gradient descent . ( 0 ) Learning back-propagation , which updates the parameters given the inferred latent factors by gradient descent . The gradient computations in both steps are powered by back-propagation , and they share most of their code in common . We show that the alternating back-propagation algorithm can learn realistic generator models of natural images , video sequences , and sounds . Moreover , it can also be used to learn from incomplete or indirect training data .
Finding interactions between variables in large and high-dimensional datasets is often a serious computational challenge . Most approaches build up interaction sets incrementally , adding variables in a greedy fashion . The drawback is that potentially informative high-order interactions may be overlooked . Here , we propose at an alternative approach for classification problems with binary predictor variables , called Random Intersection Trees . It works by starting with a maximal interaction that includes all variables , and then gradually removing variables if they fail to appear in randomly chosen observations of a class of interest . We show that informative interactions are retained with high probability , and the computational complexity of our procedure is of order $p^\kappa$ for a value of $\kappa$ that can reach values as low as 0 for very sparse data ; in many more general settings , it will still beat the exponent $s$ obtained when using a brute force search constrained to order $s$ interactions . In addition , by using some new ideas based on min-wise hash schemes , we are able to further reduce the computational cost . Interactions found by our algorithm can be used for predictive modelling in various forms , but they are also often of interest in their own right as useful characterisations of what distinguishes a certain class from others .
Interesting theoretical associations have been established by recent papers between the fields of active learning and stochastic convex optimization due to the common role of feedback in sequential querying mechanisms . In this paper , we continue this thread in two parts by exploiting these relations for the first time to yield novel algorithms in both fields , further motivating the study of their intersection . First , inspired by a recent optimization algorithm that was adaptive to unknown uniform convexity parameters , we present a new active learning algorithm for one-dimensional thresholds that can yield minimax rates by adapting to unknown noise parameters . Next , we show that one can perform $d$-dimensional stochastic minimization of smooth uniformly convex functions when only granted oracle access to noisy gradient signs along any coordinate instead of real-valued gradients , by using a simple randomized coordinate descent procedure where each line search can be solved by $0$-dimensional active learning , provably achieving the same error convergence rate as having the entire real-valued gradient . Combining these two parts yields an algorithm that solves stochastic convex optimization of uniformly convex and smooth functions using only noisy gradient signs by repeatedly performing active learning , achieves optimal rates and is adaptive to all unknown convexity and smoothness parameters .
We consider a ranking and selection problem in the context of personalized decision making , where the best alternative is not universal but varies as a function of observable covariates . The goal of ranking and selection with covariates ( R&S-C ) is to use sampling to compute a decision rule that can specify the best alternative with certain statistical guarantee for each subsequent individual after observing his or her covariates . A linear model is proposed to capture the relationship between the mean performance of an alternative and the covariates . Under the indifference-zone formulation , we develop two-stage procedures for both homoscedastic and heteroscedastic sampling errors , respectively , and prove their statistical validity , which is defined in terms of probability of correct selection . We also generalize the well-known slippage configuration , and prove that the generalized slippage configuration is the least favorable configuration of our procedures . Extensive numerical experiments are conducted to investigate the performance of the proposed procedures . Finally , we demonstrate the usefulness of R&S-C via a case study of selecting the best treatment regimen in the prevention of esophageal cancer . We find that by leveraging disease-related personal information , R&S-C can improve substantially the expected quality-adjusted life years for some groups of patients through providing patient-specific treatment regimen .
We introduce Bayesian Poisson Tucker decomposition ( BPTD ) for modeling country--country interaction event data . These data consist of interaction events of the form " country $i$ took action $a$ toward country $j$ at time $t$ . " BPTD discovers overlapping country--community memberships , including the number of latent communities . In addition , it discovers directed community--community interaction networks that are specific to " topics " of action types and temporal " regimes . " We show that BPTD yields an efficient MCMC inference algorithm and achieves better predictive performance than related models . We also demonstrate that it discovers interpretable latent structure that agrees with our knowledge of international relations .
We describe a method for inferring linear causal relations among multi-dimensional variables . The idea is to use an asymmetry between the distributions of cause and effect that occurs if both the covariance matrix of the cause and the structure matrix mapping cause to the effect are independently chosen . The method works for both stochastic and deterministic causal relations , provided that the dimensionality is sufficiently high ( in some experiments , 0 was enough ) . It is applicable to Gaussian as well as non-Gaussian data .
There is a recent surge of interest in identifying the sharp recovery thresholds for cluster recovery under the stochastic block model . In this paper , we address the more refined question of how many vertices that will be misclassified on average . We consider the binary form of the stochastic block model , where $n$ vertices are partitioned into two clusters with edge probability $a/n$ within the first cluster , $c/n$ within the second cluster , and $b/n$ across clusters . Suppose that as $n \to \infty$ , $a= b+ \mu \sqrt{ b} $ , $c=b+ \nu \sqrt{ b} $ for two fixed constants $\mu , \nu$ , and $b \to \infty$ with $b=n^{o ( 0 ) }$ . When the cluster sizes are balanced and $\mu \neq \nu$ , we show that the minimum fraction of misclassified vertices on average is given by $Q ( \sqrt{v^*} ) $ , where $Q ( x ) $ is the Q-function for standard normal , $v^*$ is the unique fixed point of $v= \frac{ ( \mu-\nu ) ^0}{00} + \frac{ ( \mu+\nu ) ^0 }{00} \mathbb{E}[ \tanh ( v+ \sqrt{v} Z ) ] , $ and $Z$ is standard normal . Moreover , the minimum misclassified fraction on average is attained by a local algorithm , namely belief propagation , in time linear in the number of edges . Our proof techniques are based on connecting the cluster recovery problem to tree reconstruction problems , and analyzing the density evolution of belief propagation on trees with Gaussian approximations .
As algorithms increasingly inform and influence decisions made about individuals , it becomes increasingly important to address concerns that these algorithms might be discriminatory . The output of an algorithm can be discriminatory for many reasons , most notably : ( 0 ) the data used to train the algorithm might be biased ( in various ways ) to favor certain populations over others ; ( 0 ) the analysis of this training data might inadvertently or maliciously introduce biases that are not borne out in the data . This work focuses on the latter concern . We develop and study multicalbration -- a new measure of algorithmic fairness that aims to mitigate concerns about discrimination that is introduced in the process of learning a predictor from data . Multicalibration guarantees accurate ( calibrated ) predictions for every subpopulation that can be identified within a specified class of computations . We think of the class as being quite rich ; in particular , it can contain many overlapping subgroups of a protected group . We show that in many settings this strong notion of protection from discrimination is both attainable and aligned with the goal of obtaining accurate predictions . Along the way , we present new algorithms for learning a multicalibrated predictor , study the computational complexity of this task , and draw new connections to computational learning models such as agnostic learning .
In this paper , we propose guaranteed spectral methods for learning a broad range of topic models , which generalize the popular Latent Dirichlet Allocation ( LDA ) . We overcome the limitation of LDA to incorporate arbitrary topic correlations , by assuming that the hidden topic proportions are drawn from a flexible class of Normalized Infinitely Divisible ( NID ) distributions . NID distributions are generated through the process of normalizing a family of independent Infinitely Divisible ( ID ) random variables . The Dirichlet distribution is a special case obtained by normalizing a set of Gamma random variables . We prove that this flexible topic model class can be learned via spectral methods using only moments up to the third order , with ( low order ) polynomial sample and computational complexity . The proof is based on a key new technique derived here that allows us to diagonalize the moments of the NID distribution through an efficient procedure that requires evaluating only univariate integrals , despite the fact that we are handling high dimensional multivariate moments . In order to assess the performance of our proposed Latent NID topic model , we use two real datasets of articles collected from New York Times and Pubmed . Our experiments yield improved perplexity on both datasets compared with the baseline .
The traditional sparse modeling approach , when applied to inverse problems with large data such as images , essentially assumes a sparse model for small overlapping data patches . While producing state-of-the-art results , this methodology is suboptimal , as it does not attempt to model the entire global signal in any meaningful way - a nontrivial task by itself . In this paper we propose a way to bridge this theoretical gap by constructing a global model from the bottom up . Given local sparsity assumptions in a dictionary , we show that the global signal representation must satisfy a constrained underdetermined system of linear equations , which can be solved efficiently by modern optimization methods such as Alternating Direction Method of Multipliers ( ADMM ) . We investigate conditions for unique and stable recovery , and provide numerical evidence corroborating the theory .
Word0Vec is a widely used algorithm for extracting low-dimensional vector representations of words . It generated considerable excitement in the machine learning and natural language processing ( NLP ) communities recently due to its exceptional performance in many NLP applications such as named entity recognition , sentiment analysis , machine translation and question answering . State-of-the-art algorithms including those by Mikolov et al . have been parallelized for multi-core CPU architectures but are based on vector-vector operations that are memory-bandwidth intensive and do not efficiently use computational resources . In this paper , we improve reuse of various data structures in the algorithm through the use of minibatching , hence allowing us to express the problem using matrix multiply operations . We also explore different techniques to distribute word0vec computation across nodes in a compute cluster , and demonstrate good strong scalability up to 00 nodes . In combination , these techniques allow us to scale up the computation near linearly across cores and nodes , and process hundreds of millions of words per second , which is the fastest word0vec implementation to the best of our knowledge .
We propose a nonparametric sequential test that aims to address two practical problems pertinent to online randomized experiments : ( i ) how to do a hypothesis test for complex metrics ; ( ii ) how to prevent type $0$ error inflation under continuous monitoring . The proposed test does not require knowledge of the underlying probability distribution generating the data . We use the bootstrap to estimate the likelihood for blocks of data followed by mixture sequential probability ratio test . We validate this procedure on data from a major online e-commerce website . We show that the proposed test controls type $0$ error at any time , has good power , is robust to misspecification in the distribution generating the data , and allows quick inference in online randomized experiments .
Point patterns are sets or multi-sets of unordered elements that can be found in numerous data sources . However , in data analysis tasks such as classification and novelty detection , appropriate statistical models for point pattern data have not received much attention . This paper proposes the modelling of point pattern data via random finite sets ( RFS ) . In particular , we propose appropriate likelihood functions , and a maximum likelihood estimator for learning a tractable family of RFS models . In novelty detection , we propose novel ranking functions based on RFS models , which substantially improve performance .
Convolution acts as a local feature extractor in convolutional neural networks ( CNNs ) . However , the convolution operation is not applicable when the input data is supported on an irregular graph such as with social networks , citation networks , or knowledge graphs . This paper proposes the topology adaptive graph convolutional network ( TAGCN ) , a novel graph convolutional network that generalizes CNN architectures to graph-structured data and provides a systematic way to design a set of fixed-size learnable filters to perform convolutions on graphs . The topologies of these filters are adaptive to the topology of the graph when they scan the graph to perform convolution , replacing the square filter for the grid-structured data in traditional CNNs . The outputs are the weighted sum of these filters ' outputs , extraction of both vertex features and strength of correlation between vertices . It can be used with both directed and undirected graphs . The proposed TAGCN not only inherits the properties of convolutions in CNN for grid-structured data , but it is also consistent with convolution as defined in graph signal processing . Further , as no approximation to the convolution is needed , TAGCN exhibits better performance than existing graph-convolution-approximation methods on a number of data sets . As only the polynomials of degree two of the adjacency matrix are used , TAGCN is also computationally simpler than other recent methods .
We consider the problem of training generative models with deep neural networks as generators , i . e . to map latent codes to data points . Whereas the dominant paradigm combines simple priors over codes with complex deterministic models , we argue that it might be advantageous to use more flexible code distributions . We demonstrate how these distributions can be induced directly from the data . The benefits include : more powerful generative models , better modeling of latent structure and explicit control of the degree of generalization .
We study pool-based active learning with abstention feedbacks , where a labeler can abstain from labeling a queried example with some unknown abstention rate . This is an important problem with many useful applications . We take a Bayesian approach to the problem and develop two new greedy algorithms that learn both the classification problem and the unknown abstention rate at the same time . These are achieved by simply incorporating the estimated abstention rate into the greedy criteria . We prove that both of our algorithms have near-optimality guarantees : they respectively achieve a ${ ( 0-\frac{0}{e} ) }$ constant factor approximation of the optimal expected or worst-case value of a useful utility function . Our experiments show the algorithms perform well in various practical scenarios .
Consider two networks on overlapping , non-identical vertex sets . Given vertices of interest in the first network , we seek to identify the corresponding vertices , if any exist , in the second network . While in moderately sized networks graph matching methods can be applied directly to recover the missing correspondences , herein we present a principled methodology appropriate for situations in which the networks are too large for brute-force graph matching . Our methodology identifies vertices in a local neighborhood of the vertices of interest in the first network that have verifiable corresponding vertices in the second network . Leveraging these known correspondences , referred to as seeds , we match the induced subgraphs in each network generated by the neighborhoods of these verified seeds , and rank the vertices of the second network in terms of the most likely matches to the original vertices of interest . We demonstrate the applicability of our methodology through simulations and real data examples .
Neural language models ( LMs ) based on recurrent neural networks ( RNN ) are some of the most successful word and character-level LMs . Why do they work so well , in particular better than linear neural LMs ? Possible explanations are that RNNs have an implicitly better regularization or that RNNs have a higher capacity for storing patterns due to their nonlinearities or both . Here we argue for the first explanation in the limit of little training data and the second explanation for large amounts of text data . We show state-of-the-art performance on the popular and small Penn dataset when RNN LMs are regularized with random dropout . Nonetheless , we show even better performance from a simplified , much less expressive linear RNN model without off-diagonal entries in the recurrent matrix . We call this model an impulse-response LM ( IRLM ) . Using random dropout , column normalization and annealed learning rates , IRLMs develop neurons that keep a memory of up to 00 words in the past and achieve a perplexity of 000 . 0 on the Penn dataset . On two large datasets however , the same regularization methods are unsuccessful for both models and the RNN ' s expressivity allows it to overtake the IRLM by 00 and 00 percent perplexity , respectively . Despite the perplexity gap , IRLMs still outperform RNNs on the Microsoft Research Sentence Completion ( MRSC ) task . We develop a slightly modified IRLM that separates long-context units ( LCUs ) from short-context units and show that the LCUs alone achieve a state-of-the-art performance on the MRSC task of 00 . 0% . Our analysis indicates that a fruitful direction of research for neural LMs lies in developing more accessible internal representations , and suggests an optimization regime of very high momentum terms for effectively training such models .
Model-based clustering approaches concern the paradigm of exploratory data analysis relying on the finite mixture model to automatically find a latent structure governing observed data . They are one of the most popular and successful approaches in cluster analysis . The mixture density estimation is generally performed by maximizing the observed-data log-likelihood by using the expectation-maximization ( EM ) algorithm . However , it is well-known that the EM algorithm initialization is crucial . In addition , the standard EM algorithm requires the number of clusters to be known a priori . Some solutions have been provided in [00 , 00] for model-based clustering with Gaussian mixture models for multivariate data . In this paper we focus on model-based curve clustering approaches , when the data are curves rather than vectorial data , based on regression mixtures . We propose a new robust EM algorithm for clustering curves . We extend the model-based clustering approach presented in [00] for Gaussian mixture models , to the case of curve clustering by regression mixtures , including polynomial regression mixtures as well as spline or B-spline regressions mixtures . Our approach both handles the problem of initialization and the one of choosing the optimal number of clusters as the EM learning proceeds , rather than in a two-fold scheme . This is achieved by optimizing a penalized log-likelihood criterion . A simulation study confirms the potential benefit of the proposed algorithm in terms of robustness regarding initialization and funding the actual number of clusters .
Two-dimensional embeddings remain the dominant approach to visualize high dimensional data . The choice of embeddings ranges from highly non-linear ones , which can capture complex relationships but are difficult to interpret quantitatively , to axis-aligned projections , which are easy to interpret but are limited to bivariate relationships . Linear project can be considered as a compromise between complexity and interpretability , as they allow explicit axes labels , yet provide significantly more degrees of freedom compared to axis-aligned projections . Nevertheless , interpreting the axes directions , which are linear combinations often with many non-trivial components , remains difficult . To address this problem we introduce a structure aware decomposition of ( multiple ) linear projections into sparse sets of axis aligned projections , which jointly capture all information of the original linear ones . In particular , we use tools from Dempster-Shafer theory to formally define how relevant a given axis aligned project is to explain the neighborhood relations displayed in some linear projection . Furthermore , we introduce a new approach to discover a diverse set of high quality linear projections and show that in practice the information of $k$ linear projections is often jointly encoded in $\sim k$ axis aligned plots . We have integrated these ideas into an interactive visualization system that allows users to jointly browse both linear projections and their axis aligned representatives . Using a number of case studies we show how the resulting plots lead to more intuitive visualizations and new insight .
We propose a generalized double Pareto prior for Bayesian shrinkage estimation and inferences in linear models . The prior can be obtained via a scale mixture of Laplace or normal distributions , forming a bridge between the Laplace and Normal-Jeffreys ' priors . While it has a spike at zero like the Laplace density , it also has a Student ' s $t$-like tail behavior . Bayesian computation is straightforward via a simple Gibbs sampling algorithm . We investigate the properties of the maximum a posteriori estimator , as sparse estimation plays an important role in many problems , reveal connections with some well-established regularization procedures , and show some asymptotic results . The performance of the prior is tested through simulations and an application .
Elucidating the genetic basis of human diseases is a central goal of genetics and molecular biology . While traditional linkage analysis and modern high-throughput techniques often provide long lists of tens or hundreds of disease gene candidates , the identification of disease genes among the candidates remains time-consuming and expensive . Efficient computational methods are therefore needed to prioritize genes within the list of candidates , by exploiting the wealth of information available about the genes in various databases . Here we propose ProDiGe , a novel algorithm for Prioritization of Disease Genes . ProDiGe implements a novel machine learning strategy based on learning from positive and unlabeled examples , which allows to integrate various sources of information about the genes , to share information about known disease genes across diseases , and to perform genome-wide searches for new disease genes . Experiments on real data show that ProDiGe outperforms state-of-the-art methods for the prioritization of genes in human diseases .
Improving the interpretability of brain decoding approaches is of primary interest in many neuroimaging studies . Despite extensive studies of this type , at present , there is no formal definition for interpretability of brain decoding models . As a consequence , there is no quantitative measure for evaluating the interpretability of different brain decoding methods . In this paper , we present a simple definition for interpretability of linear brain decoding models . Then , we propose to combine the interpretability and the performance of the brain decoding into a new multi-objective criterion for model selection . Our preliminary results on the toy data show that optimizing the hyper-parameters of the regularized linear classifier based on the proposed criterion results in more informative linear models . The presented definition provides the theoretical background for quantitative evaluation of interpretability in linear brain decoding .
Numerous social , medical , engineering and biological challenges can be framed as graph-based learning tasks . Here , we propose a new feature based approach to network classification . We show how dynamics on a network can be useful to reveal patterns about the organization of the components of the underlying graph where the process takes place . We define generalized assortativities on networks and use them as generalized features across multiple time scales . These features turn out to be suitable signatures for discriminating between different classes of networks . Our method is evaluated empirically on established network benchmarks . We also introduce a new dataset of human brain networks ( connectomes ) and use it to evaluate our method . Results reveal that our dynamics based features are competitive and often outperform state of the art accuracies .
Dual decomposition provides a tractable framework for designing algorithms for finding the most probable ( MAP ) configuration in graphical models . However , for many real-world inference problems , the typical decomposition has a large integrality gap , due to frustrated cycles . One way to tighten the relaxation is to introduce additional constraints that explicitly enforce cycle consistency . Earlier work showed that cluster-pursuit algorithms , which iteratively introduce cycle and other higherorder consistency constraints , allows one to exactly solve many hard inference problems . However , these algorithms explicitly enumerate a candidate set of clusters , limiting them to triplets or other short cycles . We solve the search problem for cycle constraints , giving a nearly linear time algorithm for finding the most frustrated cycle of arbitrary length . We show how to use this search algorithm together with the dual decomposition framework and clusterpursuit . The new algorithm exactly solves MAP inference problems arising from relational classification and stereo vision .
A new amortized variance-reduced gradient ( AVRG ) algorithm was developed in [0] , which has constant storage requirement in comparison to SAGA and balanced gradient computations in comparison to SVRG . One key advantage of the AVRG strategy is its amenability to decentralized implementations . In this work , we show how AVRG can be extended to the network case where multiple learning agents are assumed to be connected by a graph topology . In this scenario , each agent observes data that is spatially distributed and all agents are only allowed to communicate with direct neighbors . Moreover , the amount of data observed by the individual agents may differ drastically . For such situations , the balanced gradient computation property of AVRG becomes a real advantage in reducing idle time caused by unbalanced local data storage requirements , which is characteristic of other reduced-variance gradient algorithms . The resulting diffusion-AVRG algorithm is shown to have linear convergence to the exact solution , and is much more memory efficient than other alternative algorithms . In addition , by using a mini-batch strategy , it is shown that diffusion-AVRG is more computationally efficient than exact diffusion or EXTRA while maintaining almost the same amount of communications .
Surprise describes a range of phenomena from unexpected events to behavioral responses . We propose a measure of surprise and use it for surprise-driven learning . Our surprise measure takes into account data likelihood as well as the degree of commitment to a belief via the entropy of the belief distribution . We find that surprise-minimizing learning dynamically adjusts the balance between new and old information without the need of knowledge about the temporal statistics of the environment . We apply our framework to a dynamic decision-making task and a maze exploration task . Our surprise minimizing framework is suitable for learning in complex environments , even if the environment undergoes gradual or sudden changes and could eventually provide a framework to study the behavior of humans and animals encountering surprising events .
This paper presents a novel latent variable recurrent neural network architecture for jointly modeling sequences of words and ( possibly latent ) discourse relations between adjacent sentences . A recurrent neural network generates individual words , thus reaping the benefits of discriminatively-trained vector representations . The discourse relations are represented with a latent variable , which can be predicted or marginalized , depending on the task . The resulting model can therefore employ a training objective that includes not only discourse relation classification , but also word prediction . As a result , it outperforms state-of-the-art alternatives for two tasks : implicit discourse relation classification in the Penn Discourse Treebank , and dialog act classification in the Switchboard corpus . Furthermore , by marginalizing over latent discourse relations at test time , we obtain a discourse informed language model , which improves over a strong LSTM baseline .
We analyze the $K$-armed bandit problem where the reward for each arm is a noisy realization based on an observed context under mild nonparametric assumptions . We attain tight results for top-arm identification and a sublinear regret of $\widetilde{O}\Big ( T^{\frac{0+D}{0+D}}\Big ) $ , where $D$ is the context dimension , for a modified UCB algorithm that is simple to implement ( $k$NN-UCB ) . We then give global intrinsic dimension dependent and ambient dimension independent regret bounds . We also discuss recovering topological structures within the context space based on expected bandit performance and provide an extension to infinite-armed contextual bandits . Finally , we experimentally show the improvement of our algorithm over existing multi-armed bandit approaches for both simulated tasks and MNIST image classification .
Effective information analysis generally boils down to properly identifying the structure or geometry of the data , which is often represented by a graph . In some applications , this structure may be partly determined by design constraints or pre-determined sensing arrangements , like in road transportation networks for example . In general though , the data structure is not readily available and becomes pretty difficult to define . In particular , the global smoothness assumptions , that most of the existing works adopt , are often too general and unable to properly capture localized properties of data . In this paper , we go beyond this classical data model and rather propose to represent information as a sparse combination of localized functions that live on a data structure represented by a graph . Based on this model , we focus on the problem of inferring the connectivity that best explains the data samples at different vertices of a graph that is a priori unknown . We concentrate on the case where the observed data is actually the sum of heat diffusion processes , which is a quite common model for data on networks or other irregular structures . We cast a new graph learning problem and solve it with an efficient nonconvex optimization algorithm . Experiments on both synthetic and real world data finally illustrate the benefits of the proposed graph learning framework and confirm that the data structure can be efficiently learned from data observations only . We believe that our algorithm will help solving key questions in diverse application domains such as social and biological network analysis where it is crucial to unveil proper geometry for data understanding and inference .
We propose a new PAC-Bayesian bound and a way of constructing a hypothesis space , so that the bound is convex in the posterior distribution and also convex in a trade-off parameter between empirical performance of the posterior distribution and its complexity . The complexity is measured by the Kullback-Leibler divergence to a prior . We derive an alternating procedure for minimizing the bound . We show that the bound can be rewritten as a one-dimensional function of the trade-off parameter and provide sufficient conditions under which the function has a single global minimum . When the conditions are satisfied the alternating minimization is guaranteed to converge to the global minimum of the bound . We provide experimental results demonstrating that rigorous minimization of the bound is competitive with cross-validation in tuning the trade-off between complexity and empirical performance . In all our experiments the trade-off turned to be quasiconvex even when the sufficient conditions were violated .
In order to study the application of artificial intelligence ( AI ) to dental imaging , we applied AI technology to classify a set of panoramic radiographs using ( a ) a convolutional neural network ( CNN ) which is a form of an artificial neural network ( ANN ) , ( b ) representative image cognition algorithms that implement scale-invariant feature transform ( SIFT ) , and ( c ) histogram of oriented gradients ( HOG ) .
Multitask learning algorithms are typically designed assuming some fixed , a priori known latent structure shared by all the tasks . However , it is usually unclear what type of latent task structure is the most appropriate for a given multitask learning problem . Ideally , the " right " latent task structure should be learned in a data-driven manner . We present a flexible , nonparametric Bayesian model that posits a mixture of factor analyzers structure on the tasks . The nonparametric aspect makes the model expressive enough to subsume many existing models of latent task structures ( e . g , mean-regularized tasks , clustered tasks , low-rank or linear/non-linear subspace assumption on tasks , etc . ) . Moreover , it can also learn more general task structures , addressing the shortcomings of such models . We present a variational inference algorithm for our model . Experimental results on synthetic and real-world datasets , on both regression and classification problems , demonstrate the effectiveness of the proposed method .
In this paper , we study a fast approximation method for {\it large-scale high-dimensional} sparse least-squares regression problem by exploiting the Johnson-Lindenstrauss ( JL ) transforms , which embed a set of high-dimensional vectors into a low-dimensional space . In particular , we propose to apply the JL transforms to the data matrix and the target vector and then to solve a sparse least-squares problem on the compressed data with a {\it slightly larger regularization parameter} . Theoretically , we establish the optimization error bound of the learned model for two different sparsity-inducing regularizers , i . e . , the elastic net and the $\ell_0$ norm . Compared with previous relevant work , our analysis is {\it non-asymptotic and exhibits more insights} on the bound , the sample complexity and the regularization . As an illustration , we also provide an error bound of the {\it Dantzig selector} under JL transforms .
The normalized maximized likelihood ( NML ) provides the minimax regret solution in universal data compression , gambling , and prediction , and it plays an essential role in the minimum description length ( MDL ) method of statistical modeling and estimation . Here we show that the normalized maximum likelihood has a Bayes-like representation as a mixture of the component models , even in finite samples , though the weights of linear combination may be both positive and negative . This representation addresses in part the relationship between MDL and Bayes modeling . This representation has the advantage of speeding the calculation of marginals and conditionals required for coding and prediction applications .
We introduce a novel sensitivity analysis framework for large scale classification problems that can be used when a small number of instances are incrementally added or removed . For quickly updating the classifier in such a situation , incremental learning algorithms have been intensively studied in the literature . Although they are much more efficient than solving the optimization problem from scratch , their computational complexity yet depends on the entire training set size . It means that , if the original training set is large , completely solving an incremental learning problem might be still rather expensive . To circumvent this computational issue , we propose a novel framework that allows us to make an inference about the updated classifier without actually re-optimizing it . Specifically , the proposed framework can quickly provide a lower and an upper bounds of a quantity on the unknown updated classifier . The main advantage of the proposed framework is that the computational cost of computing these bounds depends only on the number of updated instances . This property is quite advantageous in a typical sensitivity analysis task where only a small number of instances are updated . In this paper we demonstrate that the proposed framework is applicable to various practical sensitivity analysis tasks , and the bounds provided by the framework are often sufficiently tight for making desired inferences .
Here we study non-convex composite optimization : first , a finite-sum of smooth but non-convex functions , and second , a general function that admits a simple proximal mapping . Most research on stochastic methods for composite optimization assumes convexity or strong convexity of each function . In this paper , we extend this problem into the non-convex setting using variance reduction techniques , such as prox-SVRG and prox-SAGA . We prove that , with a constant step size , both prox-SVRG and prox-SAGA are suitable for non-convex composite optimization , and help the problem converge to a stationary point within $O ( 0/\epsilon ) $ iterations . That is similar to the convergence rate seen with the state-of-the-art RSAG method and faster than stochastic gradient descent . Our analysis is also extended into the min-batch setting , which linearly accelerates the convergence . To the best of our knowledge , this is the first analysis of convergence rate of variance-reduced proximal stochastic gradient for non-convex composite optimization .
Probabilistic modeling is a powerful approach for analyzing empirical information . We describe Edward , a library for probabilistic modeling . Edward ' s design reflects an iterative process pioneered by George Box : build a model of a phenomenon , make inferences about the model given data , and criticize the model ' s fit to the data . Edward supports a broad class of probabilistic models , efficient algorithms for inference , and many techniques for model criticism . The library builds on top of TensorFlow to support distributed training and hardware such as GPUs . Edward enables the development of complex probabilistic models and their algorithms at a massive scale .
When faced with a supervised learning problem , we hope to have rich enough data to build a model that predicts future instances well . However , in practice , problems can exhibit predictive heterogeneity : most instances might be relatively easy to predict , while others might be predictive outliers for which a model trained on the entire dataset does not perform well . Identifying these can help focus future data collection . We present gLOP , the global and Local Penalty , a framework for capturing predictive heterogeneity and identifying predictive outliers . gLOP is based on penalized regression for multitask learning , which improves learning by leveraging training signal information from related tasks . We give two optimization algorithms for gLOP , one space-efficient , and another giving the full regularization path . We also characterize uniqueness in terms of the data and tuning parameters , and present empirical results on synthetic data and on two health research problems .
Vector autoregressive models characterize a variety of time series in which linear combinations of current and past observations can be used to accurately predict future observations . For instance , each element of an observation vector could correspond to a different node in a network , and the parameters of an autoregressive model would correspond to the impact of the network structure on the time series evolution . Often these models are used successfully in practice to learn the structure of social , epidemiological , financial , or biological neural networks . However , little is known about statistical guarantees on estimates of such models in non-Gaussian settings . This paper addresses the inference of the autoregressive parameters and associated network structure within a generalized linear model framework that includes Poisson and Bernoulli autoregressive processes . At the heart of this analysis is a sparsity-regularized maximum likelihood estimator . While sparsity-regularization is well-studied in the statistics and machine learning communities , those analysis methods cannot be applied to autoregressive generalized linear models because of the correlations and potential heteroscedasticity inherent in the observations . Sample complexity bounds are derived using a combination of martingale concentration inequalities and modern empirical process techniques for dependent random variables . These bounds , which are supported by several simulation studies , characterize the impact of various network parameters on estimator performance .
In this paper we develop a method for learning nonlinear systems with multiple outputs and inputs . We begin by modelling the errors of a nominal predictor of the system using a latent variable framework . Then using the maximum likelihood principle we derive a criterion for learning the model . The resulting optimization problem is tackled using a majorization-minimization approach . Finally , we develop a convex majorization technique and show that it enables a recursive identification method . The method learns parsimonious predictive models and is tested on both synthetic and real nonlinear systems .
Q-learning is a simple and powerful tool in solving dynamic problems where environments are unknown . It uses a balance of exploration and exploitation to find an optimal solution to the problem . In this paper , we propose using four basic emotions : joy , sadness , fear , and anger to influence a Qlearning agent . Simulations show that the proposed affective agent requires lesser number of steps to find the optimal path . We found when affective agent finds the optimal path , the ratio between exploration to exploitation gradually decreases , indicating lower total step count in the long run
Hyper-parameters play a major role in the learning and inference process of latent Dirichlet allocation ( LDA ) . In order to begin the LDA latent variables learning process , these hyper-parameters values need to be pre-determined . We propose an extension for LDA that we call ' Latent Dirichlet allocation Gibbs Newton ' ( LDA-GN ) , which places non-informative priors over these hyper-parameters and uses Gibbs sampling to learn appropriate values for them . At the heart of LDA-GN is our proposed ' Gibbs-Newton ' algorithm , which is a new technique for learning the parameters of multivariate Polya distributions . We report Gibbs-Newton performance results compared with two prominent existing approaches to the latter task : Minka ' s fixed-point iteration method and the Moments method . We then evaluate LDA-GN in two ways : ( i ) by comparing it with standard LDA in terms of the ability of the resulting topic models to generalize to unseen documents ; ( ii ) by comparing it with standard LDA in its performance on a binary classification task .
We analyze the necessary number of samples for sparse vector recovery in a noisy linear prediction setup . This model includes problems such as linear regression and classification . We focus on structured graph models . In particular , we prove that sufficient number of samples for the weighted graph model proposed by Hegde and others is also necessary . We use the Fano ' s inequality on well constructed ensembles as our main tool in establishing information theoretic lower bounds .
Kernel methods are popular in clustering due to their generality and discriminating power . However , we show that many kernel clustering criteria have density biases theoretically explaining some practically significant artifacts empirically observed in the past . For example , we provide conditions and formally prove the density mode isolation bias in kernel K-means for a common class of kernels . We call it Breiman ' s bias due to its similarity to the histogram mode isolation previously discovered by Breiman in decision tree learning with Gini impurity . We also extend our analysis to other popular kernel clustering methods , e . g . average/normalized cut or dominant sets , where density biases can take different forms . For example , splitting isolated points by cut-based criteria is essentially the sparsest subset bias , which is the opposite of the density mode bias . Our findings suggest that a principled solution for density biases in kernel clustering should directly address data inhomogeneity . We show that density equalization can be implicitly achieved using either locally adaptive weights or locally adaptive kernels . Moreover , density equalization makes many popular kernel clustering objectives equivalent . Our synthetic and real data experiments illustrate density biases and proposed solutions . We anticipate that theoretical understanding of kernel clustering limitations and their principled solutions will be important for a broad spectrum of data analysis applications across the disciplines .
In this paper , we introduce and provide a short overview of nonnegative matrix factorization ( NMF ) . Several aspects of NMF are discussed , namely , the application in hyperspectral imaging , geometry and uniqueness of NMF solutions , complexity , algorithms , and its link with extended formulations of polyhedra . In order to put NMF into perspective , the more general problem class of constrained low-rank matrix approximation problems is first briefly introduced .
Sparse alpha-norm regularization has many data-rich applications in marketing and economics . In contrast to traditional lasso and ridge regularization , the alpha-norm penalty has the property of jumping to a sparse solution . This is an attractive feature for ultra high-dimensional problems that occur in market demand estimation and forecasting . The underlying nonconvex regularization problem is solved via coordinate descent , and a proximal operator . To illustrate our methodology , we study a classic demand forecasting problem of Bajari , Nekipelov , Ryan , and Yang ( 0000a ) . On the empirical side , we find many strong sparse predictors , including price , equivalized volume , promotion , flavor scent , and brand effects . Benchmark methods including linear regression , ridge , lasso and elastic net , are used in an out-of-sample forecasting study . In particular , alpha-norm regularization provides accurate estimates for the promotion effects . Finally , we conclude with directions for future research .
Verification determines whether two samples belong to the same class or not , and has important applications such as face and fingerprint verification , where thousands or millions of categories are present but each category has scarce labeled examples , presenting two major challenges for existing deep learning models . We propose a deep semi-supervised model named SEmi-supervised VErification Network ( SEVEN ) to address these challenges . The model consists of two complementary components . The generative component addresses the lack of supervision within each category by learning general salient structures from a large amount of data across categories . The discriminative component exploits the learned general features to mitigate the lack of supervision within categories , and also directs the generative component to find more informative structures of the whole data manifold . The two components are tied together in SEVEN to allow an end-to-end training of the two components . Extensive experiments on four verification tasks demonstrate that SEVEN significantly outperforms other state-of-the-art deep semi-supervised techniques when labeled data are in short supply . Furthermore , SEVEN is competitive with fully supervised baselines trained with a larger amount of labeled data . It indicates the importance of the generative component in SEVEN .
This article describes Team Kernel Glitches ' solution to the National Institute of Justice ' s ( NIJ ) Real-Time Crime Forecasting Challenge . The goal of the NIJ Real-Time Crime Forecasting Competition was to maximize two different crime hotspot scoring metrics for calls-for-service to the Portland Police Bureau ( PPB ) in Portland , Oregon during the period from March 0 , 0000 to May 00 , 0000 . Our solution to the challenge is a spatiotemporal forecasting model combining scalable randomized Reproducing Kernel Hilbert Space ( RKHS ) methods for approximating Gaussian processes with autoregressive smoothing kernels in a regularized supervised learning framework . Our model can be understood as an approximation to the popular log-Gaussian Cox Process model : we discretize the spatiotemporal point pattern and learn a log intensity function using the Poisson likelihood and highly efficient gradient-based optimization methods . Model hyperparameters including quality of RKHS approximation , spatial and temporal kernel lengthscales , number of autoregressive lags , bandwidths for smoothing kernels , as well as cell shape , size , and rotation , were learned using crossvalidation . Resulting predictions exceeded baseline KDE estimates by 0 . 000 . Performance improvement over baseline predictions were particularly large for sparse crimes over short forecasting horizons .
Recent work in distance metric learning has focused on learning transformations of data that best align with provided sets of pairwise similarity and dissimilarity constraints . The learned transformations lead to improved retrieval , classification , and clustering algorithms due to the better adapted distance or similarity measures . Here , we introduce the problem of learning these transformations when the underlying constraint generation process is nonstationary . This nonstationarity can be due to changes in either the ground-truth clustering used to generate constraints or changes to the feature subspaces in which the class structure is apparent . We propose and evaluate COMID-SADL , an adaptive , online approach for learning and tracking optimal metrics as they change over time that is highly robust to a variety of nonstationary behaviors in the changing metric . We demonstrate COMID-SADL on both real and synthetic data sets and show significant performance improvements relative to previously proposed batch and online distance metric learning algorithms .
We develop an automated variational method for inference in models with Gaussian process ( GP ) priors and general likelihoods . The method supports multiple outputs and multiple latent functions and does not require detailed knowledge of the conditional likelihood , only needing its evaluation as a black-box function . Using a mixture of Gaussians as the variational distribution , we show that the evidence lower bound and its gradients can be estimated efficiently using empirical expectations over univariate Gaussian distributions . Furthermore , the method is scalable to large datasets which is achieved by using an augmented prior via the inducing-variable approach underpinning most sparse GP approximations , along with parallel computation and stochastic optimization . We evaluate our method with experiments on small datasets , medium-scale datasets and a large dataset , showing its competitiveness under different likelihood models and sparsity levels . Moreover , we analyze learning in our model under batch and stochastic settings , and study the effect of optimizing the inducing inputs . Finally , in the large-scale experiment , we investigate the problem of predicting airline delays and show that our method is on par with the state-of-the-art hard-coded approach for scalable GP regression .
In this note we compare two recently proposed semidefinite relaxations for the sparse linear regression problem by Pilanci , Wainwright and El Ghaoui ( Sparse learning via boolean relaxations , 0000 ) and Dong , Chen and Linderoth ( Relaxation vs . Regularization A conic optimization perspective of statistical variable selection , 0000 ) . We focus on the cardinality constrained formulation , and prove that the relaxation proposed by Dong , etc . is theoretically no weaker than the one proposed by Pilanci , etc . Therefore any sufficient condition of exact recovery derived by Pilanci can be readily applied to the other relaxation , including their results on high probability recovery for Gaussian ensemble . Finally we provide empirical evidence that the relaxation by Dong , etc . requires much fewer observations to guarantee the recovery of true support .
Event sequence , asynchronously generated with random timestamp , is ubiquitous among applications . The precise and arbitrary timestamp can carry important clues about the underlying dynamics , and has lent the event data fundamentally different from the time-series whereby series is indexed with fixed and equal time interval . One expressive mathematical tool for modeling event is point process . The intensity functions of many point processes involve two components : the background and the effect by the history . Due to its inherent spontaneousness , the background can be treated as a time series while the other need to handle the history events . In this paper , we model the background by a Recurrent Neural Network ( RNN ) with its units aligned with time series indexes while the history effect is modeled by another RNN whose units are aligned with asynchronous events to capture the long-range dynamics . The whole model with event type and timestamp prediction output layers can be trained end-to-end . Our approach takes an RNN perspective to point process , and models its background and history effect . For utility , our method allows a black-box treatment for modeling the intensity which is often a pre-defined parametric form in point processes . Meanwhile end-to-end training opens the venue for reusing existing rich techniques in deep network for point process modeling . We apply our model to the predictive maintenance problem using a log dataset by more than 0000 ATMs from a global bank headquartered in North America .
Understanding the spatiotemporal distribution of people within a city is crucial to many planning applications . Obtaining data to create required knowledge , currently involves costly survey methods . At the same time ubiquitous mobile sensors from personal GPS devices to mobile phones are collecting massive amounts of data on urban systems . The locations , communications , and activities of millions of people are recorded and stored by new information technologies . This work utilizes novel dynamic data , generated by mobile phone users , to measure spatiotemporal changes in population . In the process , we identify the relationship between land use and dynamic population over the course of a typical week . A machine learning classification algorithm is used to identify clusters of locations with similar zoned uses and mobile phone activity patterns . It is shown that the mobile phone data is capable of delivering useful information on actual land use that supplements zoning regulations .
The total variation ( TV ) penalty , as many other analysis-sparsity problems , does not lead to separable factors or a proximal operatorwith a closed-form expression , such as soft thresholding for the $\ell\_0$ penalty . As a result , in a variational formulation of an inverse problem or statisticallearning estimation , it leads to challenging non-smooth optimization problemsthat are often solved with elaborate single-step first-order methods . When thedata-fit term arises from empirical measurements , as in brain imaging , it isoften very ill-conditioned and without simple structure . In this situation , in proximal splitting methods , the computation cost of thegradient step can easily dominate each iteration . Thus it is beneficialto minimize the number of gradient steps . We present fAASTA , a variant of FISTA , that relies on an internal solver forthe TV proximal operator , and refines its tolerance to balance computationalcost of the gradient and the proximal steps . We give benchmarks andillustrations on " brain decoding " : recovering brain maps from noisymeasurements to predict observed behavior . The algorithm as well as theempirical study of convergence speed are valuable for any non-exact proximaloperator , in particular analysis-sparsity problems .
Complex computer simulators are increasingly used across fields of science as generative models tying parameters of an underlying theory to experimental observations . Inference in this setup is often difficult , as simulators rarely admit a tractable density or likelihood function . We introduce Adversarial Variational Optimization ( AVO ) , a likelihood-free inference algorithm for fitting a non-differentiable generative model incorporating ideas from empirical Bayes and variational inference . We adapt the training procedure of generative adversarial networks by replacing the differentiable generative network with a domain-specific simulator . We solve the resulting non-differentiable minimax problem by minimizing variational upper bounds of the two adversarial objectives . Effectively , the procedure results in learning a proposal distribution over simulator parameters , such that the corresponding marginal distribution of the generated data matches the observations . We present results of the method with simulators producing both discrete and continuous data .
We discuss two parameterizations of models for marginal independencies for discrete distributions which are representable by bi-directed graph models , under the global Markov property . Such models are useful data analytic tools especially if used in combination with other graphical models . The first parameterization , in the saturated case , is also known as the multivariate logistic transformation , the second is a variant that allows , in some ( but not all ) cases , variation independent parameters . An algorithm for maximum likelihood fitting is proposed , based on an extension of the Aitchison and Silvey method .
The graph Laplacian plays key roles in information processing of relational data , and has analogies with the Laplacian in differential geometry . In this paper , we generalize the analogy between graph Laplacian and differential geometry to the hypergraph setting , and propose a novel hypergraph $p$-Laplacian . Unlike the existing two-node graph Laplacians , this generalization makes it possible to analyze hypergraphs , where the edges are allowed to connect any number of nodes . Moreover , we propose a semi-supervised learning method based on the proposed hypergraph $p$-Laplacian , and formalize them as the analogue to the Dirichlet problem , which often appears in physics . We further explore theoretical connections to normalized hypergraph cut on a hypergraph , and propose normalized cut corresponding to hypergraph $p$-Laplacian . The proposed $p$-Laplacian is shown to outperform standard hypergraph Laplacians in the experiment on a hypergraph semi-supervised learning and normalized cut setting .
Stochastic Gradient Langevin Dynamics ( SGLD ) is a popular variant of Stochastic Gradient Descent , where properly scaled isotropic Gaussian noise is added to an unbiased estimate of the gradient at each iteration . This modest change allows SGLD to escape local minima and suffices to guarantee asymptotic convergence to global minimizers for sufficiently regular non-convex objectives ( Gelfand and Mitter , 0000 ) . The present work provides a nonasymptotic analysis in the context of non-convex learning problems , giving finite-time guarantees for SGLD to find approximate minimizers of both empirical and population risks . As in the asymptotic setting , our analysis relates the discrete-time SGLD Markov chain to a continuous-time diffusion process . A new tool that drives the results is the use of weighted transportation cost inequalities to quantify the rate of convergence of SGLD to a stationary distribution in the Euclidean $0$-Wasserstein distance .
A fundamental goal in network neuroscience is to understand how activity in one region drives activity elsewhere , a process referred to as effective connectivity . Here we propose to model this causal interaction using integro-differential equations and causal kernels that allow for a rich analysis of effective connectivity . The approach combines the tractability and flexibility of autoregressive modeling with the biophysical interpretability of dynamic causal modeling . The causal kernels are learned nonparametrically using Gaussian process regression , yielding an efficient framework for causal inference . We construct a novel class of causal covariance functions that enforce the desired properties of the causal kernels , an approach which we call GP CaKe . By construction , the model and its hyperparameters have biophysical meaning and are therefore easily interpretable . We demonstrate the efficacy of GP CaKe on a number of simulations and give an example of a realistic application on magnetoencephalography ( MEG ) data .
We pursue an early stopping technique that helps Gaussian Restricted Boltzmann Machines ( GRBMs ) to gain good natural image representations in terms of overcompleteness and data fitting . GRBMs are widely considered as an unsuitable model for natural images because they gain non-overcomplete representations which include uniform filters that do not represent useful image features . We have recently found that GRBMs once gain and subsequently lose useful filters during their training , contrary to this common perspective . We attribute this phenomenon to a tradeoff between overcompleteness of GRBM representations and data fitting . To gain GRBM representations that are overcomplete and fit data well , we propose a measure for GRBM representation quality , approximated mutual information , and an early stopping technique based on this measure . The proposed method boosts performance of classifiers trained on GRBM representations .
Critical periods are phases in the early development of humans and animals during which experience can affect the structure of neuronal networks irreversibly . In this work , we study the effects of visual stimulus deficits on the training of artificial neural networks ( ANNs ) . Introducing well-characterized visual deficits , such as cataract-like blurring , in the early training phase of a standard deep neural network causes irreversible performance loss that closely mimics that reported in humans and animal models . Deficits that do not affect low-level image statistics , such as vertical flipping of the images , have no lasting effect on the ANN ' s performance and can be rapidly overcome with additional training , as observed in humans . In addition , deeper networks show a more prominent critical period . To better understand this phenomenon , we use techniques from information theory to study the strength of the network connections during training . Our analysis suggests that the first few epochs are critical for the allocation of resources across different layers , determined by the initial input data distribution . Once such information organization is established , the network resources do not re-distribute through additional training . These findings suggest that the initial rapid learning phase of training of ANNs , under-scrutinized compared to its asymptotic behavior , plays a key role in defining the final performance of networks .
We derive a new Bayesian Information Criterion ( BIC ) from first principles by formulating the problem of estimating the number of clusters in an observed data set as maximization of the posterior probability of the candidate models . Given that some mild assumptions are satisfied , we provide a general BIC expression for a broad class of data distributions . This serves as an important milestone when deriving the BIC for specific data distributions . Along this line , we provide a closed-form BIC expression for multivariate Gaussian distributed observations . We show that incorporating data structure of the clustering problem into the derivation of the BIC results in an expression whose penalty term is different from that of the original BIC . We propose a two-step cluster enumeration algorithm . First , a model-based unsupervised learning algorithm partitions the data according to a given set of candidate models . Subsequently , the optimal cluster number is determined as the one associated to the model for which the proposed BIC is maximal . The performance of the proposed criterion is tested using synthetic and real data sets . Despite the fact that the original BIC is a generic criterion which does not include information about the specific model selection problem at hand , it has been widely used in the literature to estimate the number of clusters in an observed data set . We , therefore , consider it as a benchmark comparison . Simulation results show that our proposed criterion outperforms the existing cluster enumeration methods that are based on the original BIC .
The abundance of high-dimensional data in the modern sciences has generated tremendous interest in penalized estimators such as the lasso , scaled lasso , square-root lasso , elastic net , and many others . However , the common theoretical bounds for the predictive performance of these estimators hinge on strong , in practice unverifiable assumptions on the design . In this paper , we introduce a new set of oracle inequalities for prediction in high-dimensional linear regression . These bounds hold irrespective of the design matrix . Moreover , since the proofs rely only on convexity and continuity arguments , the bounds apply to a wide range of penalized estimators . Overall , the bounds demonstrate that generic estimators can provide consistent prediction with any design matrix . From a practical point of view , the bounds can help to identify the potential of specific estimators , and they can help to get a sense of the prediction accuracy in a given application .
In this article supervised learning problems are solved using soft rule ensembles . We first review the importance sampling learning ensembles ( ISLE ) approach that is useful for generating hard rules . The soft rules are then obtained with logistic regression from the corresponding hard rules . In order to deal with the perfect separation problem related to the logistic regression , Firth ' s bias corrected likelihood is used . Various examples and simulation results show that soft rule ensembles can improve predictive performance over hard rule ensembles .
Estimating the number of unseen species is an important problem in many scientific endeavors . Its most popular formulation , introduced by Fisher , uses $n$ samples to predict the number $U$ of hitherto unseen species that would be observed if $t\cdot n$ new samples were collected . Of considerable interest is the largest ratio $t$ between the number of new and existing samples for which $U$ can be accurately predicted . In seminal works , Good and Toulmin constructed an intriguing estimator that predicts $U$ for all $t\le 0$ , thereby showing that the number of species can be estimated for a population twice as large as that observed . Subsequently Efron and Thisted obtained a modified estimator that empirically predicts $U$ even for some $t>0$ , but without provable guarantees . We derive a class of estimators that $\textit{provably}$ predict $U$ not just for constant $t>0$ , but all the way up to $t$ proportional to $\log n$ . This shows that the number of species can be estimated for a population $\log n$ times larger than that observed , a factor that grows arbitrarily large as $n$ increases . We also show that this range is the best possible and that the estimators ' mean-square error is optimal up to constants for any $t$ . Our approach yields the first provable guarantee for the Efron-Thisted estimator and , in addition , a variant which achieves stronger theoretical and experimental performance than existing methodologies on a variety of synthetic and real datasets . The estimators we derive are simple linear estimators that are computable in time proportional to $n$ . The performance guarantees hold uniformly for all distributions , and apply to all four standard sampling models commonly used across various scientific disciplines : multinomial , Poisson , hypergeometric , and Bernoulli product .
The resemblance between the methods used in studying quantum-many body physics and in machine learning has drawn considerable attention . In particular , tensor networks ( TNs ) and deep learning architectures bear striking similarities to the extent that TNs can be used for machine learning . Previous results used one-dimensional TNs in image recognition , showing limited scalability and a high bond dimension . In this work , we train two-dimensional hierarchical TNs to solve image recognition problems , using a training algorithm derived from the multipartite entanglement renormalization ansatz ( MERA ) . This approach overcomes scalability issues and implies novel mathematical connections among quantum many-body physics , quantum information theory , and machine learning . While keeping the TN unitary in the training phase , TN states can be defined , which optimally encodes each class of the images into a quantum many-body state . We study the quantum features of the TN states , including quantum entanglement and fidelity . We suggest these quantities could be novel properties that characterize the image classes , as well as the machine learning tasks . Our work could be further applied to identifying possible quantum properties of certain artificial intelligence methods .
Deep convolutional semantic segmentation ( DCSS ) learning doesn ' t converge to an optimal local minimum with random parameters initializations ; a pre-trained model on the same domain becomes necessary to achieve convergence . In this work , we propose a joint cooperative end-to-end learning method for DCSS . It addresses many drawbacks with existing deep semantic segmentation learning ; the proposed approach simultaneously learn both segmentation and classification ; taking away the essential need of the pre-trained model for learning convergence . We present an improved inception based architecture with partial attention gating ( PAG ) over encoder information . The PAG also adds to achieve faster convergence and better accuracy for segmentation task . We will show the effectiveness of this learning on a diabetic retinopathy classification and segmentation dataset .
This contribution summarizes the results on the asymptotic performance of several variants of the FastICA algorithm . A number of new closed-form expressions are presented .
Recently , fully-connected and convolutional neural networks have been trained to achieve state-of-the-art performance on a wide variety of tasks such as speech recognition , image classification , natural language processing , and bioinformatics . For classification tasks , most of these " deep learning " models employ the softmax activation function for prediction and minimize cross-entropy loss . In this paper , we demonstrate a small but consistent advantage of replacing the softmax layer with a linear support vector machine . Learning minimizes a margin-based loss instead of the cross-entropy loss . While there have been various combinations of neural nets and SVMs in prior art , our results using L0-SVMs show that by simply replacing softmax with linear SVMs gives significant gains on popular deep learning datasets MNIST , CIFAR-00 , and the ICML 0000 Representation Learning Workshop ' s face expression recognition challenge .
The study of networks has received increased attention recently not only from the social sciences and statistics but also from physicists , computer scientists and mathematicians . One of the principal problem in networks is community detection . Many algorithms have been proposed for community finding but most of them do not have have theoretical guarantee for sparse networks and networks close to the phase transition boundary proposed by physicists . There are some exceptions but all have some incomplete theoretical basis . Here we propose an algorithm based on the graph distance of vertices in the network . We give theoretical guarantees that our method works in identifying communities for block models and can be extended for degree-corrected block models and block models with the number of communities growing with number of vertices . Despite favorable simulation results , we are not yet able to conclude that our method is satisfactory for worst possible case . We illustrate on a network of political blogs , Facebook networks and some other networks .
Often , high dimensional data lie close to a low-dimensional submanifold and it is of interest to understand the geometry of these submanifolds . The homology groups of a manifold are important topological invariants that provide an algebraic summary of the manifold . These groups contain rich topological information , for instance , about the connected components , holes , tunnels and sometimes the dimension of the manifold . In this paper , we consider the statistical problem of estimating the homology of a manifold from noisy samples under several different noise models . We derive upper and lower bounds on the minimax risk for this problem . Our upper bounds are based on estimators which are constructed from a union of balls of appropriate radius around carefully selected points . In each case we establish complementary lower bounds using Le Cam ' s lemma .
This paper presents a novel Block Iterative Bayesian Algorithm ( Block-IBA ) for reconstructing block-sparse signals with unknown block structures . Unlike the existing algorithms for block sparse signal recovery which assume the cluster structure of the nonzero elements of the unknown signal to be independent and identically distributed ( i . i . d . ) , we use a more realistic Bernoulli-Gaussian hidden Markov model ( BGHMM ) to characterize the non-i . i . d . block-sparse signals commonly encountered in practice . The Block-IBA iteratively estimates the amplitudes and positions of the block-sparse signal using the steepest-ascent based Expectation-Maximization ( EM ) , and optimally selects the nonzero elements of the block-sparse signal by adaptive thresholding . The global convergence of Block-IBA is analyzed and proved , and the effectiveness of Block-IBA is demonstrated by numerical experiments and simulations on synthetic and real-life data .
In this project we analysed how much semantic information images carry , and how much value image data can add to sentiment analysis of the text associated with the images . To better understand the contribution from images , we compared models which only made use of image data , models which only made use of text data , and models which combined both data types . We also analysed if this approach could help sentiment classifiers generalize to unknown sentiments .
We introduce a Bayesian solution for the problem in forensic speaker recognition , where there may be very little background material for estimating score calibration parameters . We work within the Bayesian paradigm of evidence reporting and develop a principled probabilistic treatment of the problem , which results in a Bayesian likelihood-ratio as the vehicle for reporting weight of evidence . We show in contrast , that reporting a likelihood-ratio distribution does not solve this problem . Our solution is experimentally exercised on a simulated forensic scenario , using NIST SRE ' 00 scores , which demonstrates a clear advantage for the proposed method compared to the traditional plugin calibration recipe .
This tutorial introduces a new and powerful set of techniques variously called " neural machine translation " or " neural sequence-to-sequence models " . These techniques have been used in a number of tasks regarding the handling of human language , and can be a powerful tool in the toolbox of anyone who wants to model sequential data of some sort . The tutorial assumes that the reader knows the basics of math and programming , but does not assume any particular experience with neural networks or natural language processing . It attempts to explain the intuition behind the various methods covered , then delves into them with enough mathematical detail to understand them concretely , and culiminates with a suggestion for an implementation exercise , where readers can test that they understood the content in practice .
Bayesian optimization techniques have been successfully applied to robotics , planning , sensor placement , recommendation , advertising , intelligent user interfaces and automatic algorithm configuration . Despite these successes , the approach is restricted to problems of moderate dimension , and several workshops on Bayesian optimization have identified its scaling to high-dimensions as one of the holy grails of the field . In this paper , we introduce a novel random embedding idea to attack this problem . The resulting Random EMbedding Bayesian Optimization ( REMBO ) algorithm is very simple , has important invariance properties , and applies to domains with both categorical and continuous variables . We present a thorough theoretical analysis of REMBO . Empirical results confirm that REMBO can effectively solve problems with billions of dimensions , provided the intrinsic dimensionality is low . They also show that REMBO achieves state-of-the-art performance in optimizing the 00 discrete parameters of a popular mixed integer linear programming solver .
Clustering is an underspecified task : there are no universal criteria for what makes a good clustering . This is especially true for relational data , where similarity can be based on the features of individuals , the relationships between them , or a mix of both . Existing methods for relational clustering have strong and often implicit biases in this respect . In this paper , we introduce a novel similarity measure for relational data . It is the first measure to incorporate a wide variety of types of similarity , including similarity of attributes , similarity of relational context , and proximity in a hypergraph . We experimentally evaluate how using this similarity affects the quality of clustering on very different types of datasets . The experiments demonstrate that ( a ) using this similarity in standard clustering methods consistently gives good results , whereas other measures work well only on datasets that match their bias ; and ( b ) on most datasets , the novel similarity outperforms even the best among the existing ones .
Undirected graphical models compactly represent the structure of large , high-dimensional data sets , which are especially important in interpreting complex scientific data . Some data sets may run to multiple terabytes , and current methods are intractable in both memory size and running time . We introduce HP-CONCORD , a highly scalable optimization algorithm to estimate a sparse inverse covariance matrix based on a regularized pseudolikelihood framework . Our parallel proximal gradient method runs across a multi-node cluster and achieves parallel scalability using a novel communication-avoiding linear algebra algorithm . We demonstrate scalability on problems with 0 . 00 million dimensions ( over 000 billion parameters ) and show that it can outperform a previous method on a single node and scales to 0K nodes ( 00K cores ) . We use HP-CONCORD to estimate the underlying conditional dependency structure of the brain from fMRI data and use the result to automatically identify functional regions . The results show good agreement with a state-of-the-art clustering from the neuroscience literature .
We consider the problem of speaker diarization , the problem of segmenting an audio recording of a meeting into temporal segments corresponding to individual speakers . The problem is rendered particularly difficult by the fact that we are not allowed to assume knowledge of the number of people participating in the meeting . To address this problem , we take a Bayesian nonparametric approach to speaker diarization that builds on the hierarchical Dirichlet process hidden Markov model ( HDP-HMM ) of Teh et al . [J . Amer . Statist . Assoc . 000 ( 0000 ) 0000--0000] . Although the basic HDP-HMM tends to over-segment the audio data---creating redundant states and rapidly switching among them---we describe an augmented HDP-HMM that provides effective control over the switching rate . We also show that this augmentation makes it possible to treat emission distributions nonparametrically . To scale the resulting architecture to realistic diarization problems , we develop a sampling algorithm that employs a truncated approximation of the Dirichlet process to jointly resample the full state sequence , greatly improving mixing rates . Working with a benchmark NIST data set , we show that our Bayesian nonparametric architecture yields state-of-the-art speaker diarization results .
Mosquitoes are a major vector for malaria , causing hundreds of thousands of deaths in the developing world each year . Not only is the prevention of mosquito bites of paramount importance to the reduction of malaria transmission cases , but understanding in more forensic detail the interplay between malaria , mosquito vectors , vegetation , standing water and human populations is crucial to the deployment of more effective interventions . Typically the presence and detection of malaria-vectoring mosquitoes is only quantified by hand-operated insect traps or signified by the diagnosis of malaria . If we are to gather timely , large-scale data to improve this situation , we need to automate the process of mosquito detection and classification as much as possible . In this paper , we present a candidate mobile sensing system that acts as both a portable early warning device and an automatic acoustic data acquisition pipeline to help fuel scientific inquiry and policy . The machine learning algorithm that powers the mobile system achieves excellent off-line multi-species detection performance while remaining computationally efficient . Further , we have conducted preliminary live mosquito detection tests using low-cost mobile phones and achieved promising results . The deployment of this system for field usage in Southeast Asia and Africa is planned in the near future . In order to accelerate processing of field recordings and labelling of collected data , we employ a citizen science platform in conjunction with automated methods , the former implemented using the Zooniverse platform , allowing crowdsourcing on a grand scale .
We develop a mixture procedure for multi-sensor systems to monitor data streams for a change-point that causes a gradual degradation to a subset of the streams . Observations are assumed to be initially normal random variables with known constant means and variances . After the change-point , observations in the subset will have increasing or decreasing means . The subset and the rate-of-changes are unknown . Our procedure uses a mixture statistics , which assumes that each sensor is affected by the change-point with probability $p_0$ . Analytic expressions are obtained for the average run length ( ARL ) and the expected detection delay ( EDD ) of the mixture procedure , which are demonstrated to be quite accurate numerically . We establish the asymptotic optimality of the mixture procedure . Numerical examples demonstrate the good performance of the proposed procedure . We also discuss an adaptive mixture procedure using empirical Bayes . This paper extends our earlier work on detecting an abrupt change-point that causes a mean-shift , by tackling the challenges posed by the non-stationarity of the slope-change problem .
Approximate message passing ( AMP ) refers to a class of efficient algorithms for statistical estimation in high-dimensional problems such as compressed sensing and low-rank matrix estimation . This paper analyzes the performance of AMP in the regime where the problem dimension is large but finite . For concreteness , we consider the setting of high-dimensional regression , where the goal is to estimate a high-dimensional vector $\beta_0$ from a noisy measurement $y=A \beta_0 + w$ . AMP is a low-complexity , scalable algorithm for this problem . Under suitable assumptions on the measurement matrix $A$ , AMP has the attractive feature that its performance can be accurately characterized in the large system limit by a simple scalar iteration called state evolution . Previous proofs of the validity of state evolution have all been asymptotic convergence results . In this paper , we derive a concentration inequality for AMP with i . i . d . Gaussian measurement matrices with finite size $n \times N$ . The result shows that the probability of deviation from the state evolution prediction falls exponentially in $n$ . This provides theoretical support for empirical findings that have demonstrated excellent agreement of AMP performance with state evolution predictions for moderately large dimensions . The concentration inequality also indicates that the number of AMP iterations $t$ can grow no faster than order $\frac{\log n}{\log \log n}$ for the performance to be close to the state evolution predictions with high probability . The analysis can be extended to obtain similar non-asymptotic results for AMP in other settings such as low-rank matrix estimation .
We present a fully nonparametric method to estimate the value function , via simulation , in the context of expected infinite-horizon discounted rewards for Markov chains . Estimating such value functions plays an important role in approximate dynamic programming and applied probability in general . We incorporate " soft information " into the estimation algorithm , such as knowledge of convexity , monotonicity , or Lipchitz constants . In the presence of such information , a nonparametric estimator for the value function can be computed that is provably consistent as the simulated time horizon tends to infinity . As an application , we implement our method on price tolling agreement contracts in energy markets .
We introduce a new approach to variable selection , called Predictive Correlation Screening , for predictor design . Predictive Correlation Screening ( PCS ) implements false positive control on the selected variables , is well suited to small sample sizes , and is scalable to high dimensions . We establish asymptotic bounds for Familywise Error Rate ( FWER ) , and resultant mean square error of a linear predictor on the selected variables . We apply Predictive Correlation Screening to the following two-stage predictor design problem . An experimenter wants to learn a multivariate predictor of gene expressions based on successive biological samples assayed on mRNA arrays . She assays the whole genome on a few samples and from these assays she selects a small number of variables using Predictive Correlation Screening . To reduce assay cost , she subsequently assays only the selected variables on the remaining samples , to learn the predictor coefficients . We show superiority of Predictive Correlation Screening relative to LASSO and correlation learning ( sometimes popularly referred to in the literature as marginal regression or simple thresholding ) in terms of performance and computational complexity .
The Wasserstein probability metric has received much attention from the machine learning community . Unlike the Kullback-Leibler divergence , which strictly measures change in probability , the Wasserstein metric reflects the underlying geometry between outcomes . The value of being sensitive to this geometry has been demonstrated , among others , in ordinal regression and generative modelling . In this paper we describe three natural properties of probability divergences that reflect requirements from machine learning : sum invariance , scale sensitivity , and unbiased sample gradients . The Wasserstein metric possesses the first two properties but , unlike the Kullback-Leibler divergence , does not possess the third . We provide empirical evidence suggesting that this is a serious issue in practice . Leveraging insights from probabilistic forecasting we propose an alternative to the Wasserstein metric , the Cram\ ' er distance . We show that the Cram\ ' er distance possesses all three desired properties , combining the best of the Wasserstein and Kullback-Leibler divergences . To illustrate the relevance of the Cram\ ' er distance in practice we design a new algorithm , the Cram\ ' er Generative Adversarial Network ( GAN ) , and show that it performs significantly better than the related Wasserstein GAN .
Graphical modelling has a long history in statistics as a tool for the analysis of multivariate data , starting from Wright ' s path analysis and Gibbs ' applications to statistical physics at the beginning of the last century . In its modern form , it was pioneered by Lauritzen and Wermuth and Pearl in the 0000s , and has since found applications in fields as diverse as bioinformatics , customer satisfaction surveys and weather forecasts . Genetics and systems biology are unique among these fields in the dimension of the data sets they study , which often contain several hundreds of variables and only a few tens or hundreds of observations . This raises problems in both computational complexity and the statistical significance of the resulting networks , collectively known as the " curse of dimensionality " . Furthermore , the data themselves are difficult to model correctly due to the limited understanding of the underlying mechanisms . In the following , we will illustrate how such challenges affect practical graphical modelling and some possible solutions .
Computational Fluid Dynamics ( CFD ) is a hugely important subject with applications in almost every engineering field , however , fluid simulations are extremely computationally and memory demanding . Towards this end , we present Lat-Net , a method for compressing both the computation time and memory usage of Lattice Boltzmann flow simulations using deep neural networks . Lat-Net employs convolutional autoencoders and residual connections in a fully differentiable scheme to compress the state size of a simulation and learn the dynamics on this compressed form . The result is a computationally and memory efficient neural network that can be iterated and queried to reproduce a fluid simulation . We show that once Lat-Net is trained , it can generalize to large grid sizes and complex geometries while maintaining accuracy . We also show that Lat-Net is a general method for compressing other Lattice Boltzmann based simulations such as Electromagnetism .
We consider a composite convex minimization problem associated with regularized empirical risk minimization , which often arises in machine learning . We propose two new stochastic gradient methods that are based on stochastic dual averaging method with variance reduction . Our methods generate a sparser solution than the existing methods because we do not need to take the average of the history of the solutions . This is favorable in terms of both interpretability and generalization . Moreover , our methods have theoretical support for both a strongly and a non-strongly convex regularizer and achieve the best known convergence rates among existing nonaccelerated stochastic gradient methods .
We address the problem of computing approximate marginals in Gaussian probabilistic models by using mean field and fractional Bethe approximations . We define the Gaussian fractional Bethe free energy in terms of the moment parameters of the approximate marginals , derive a lower and an upper bound on the fractional Bethe free energy and establish a necessary condition for the lower bound to be bounded from below . It turns out that the condition is identical to the pairwise normalizability condition , which is known to be a sufficient condition for the convergence of the message passing algorithm . We show that stable fixed points of the Gaussian message passing algorithm are local minima of the Gaussian Bethe free energy . By a counterexample , we disprove the conjecture stating that the unboundedness of the free energy implies the divergence of the message passing algorithm .
Water balance models are often employed to improve understanding of drivers of change in regional hydrologic cycles . Most of these models , however , are physically-based , and few employ state-of-the-art statistical methods to reconcile measurement uncertainty and bias . Here , we introduce a framework for developing , analyzing , and selecting among alternative formulations of a statistical water balance model for large lake systems that addresses this research gap . We demonstrate our new analytical framework using a model customized for Lakes Superior and Michigan-Huron , the two largest lakes on Earth by surface area . The selected model ( from among 00 alternatives ) closed the water balance across both lakes with an order of magnitude less computation time than prototype versions of the same model . We expect our new framework will be used to improve computational efficiency and skill of water balance models for other lakes around the world .
Molecular machine learning has been maturing rapidly over the last few years . Improved methods and the presence of larger datasets have enabled machine learning algorithms to make increasingly accurate predictions about molecular properties . However , algorithmic progress has been limited due to the lack of a standard benchmark to compare the efficacy of proposed methods ; most new algorithms are benchmarked on different datasets making it challenging to gauge the quality of proposed methods . This work introduces MoleculeNet , a large scale benchmark for molecular machine learning . MoleculeNet curates multiple public datasets , establishes metrics for evaluation , and offers high quality open-source implementations of multiple previously proposed molecular featurization and learning algorithms ( released as part of the DeepChem open source library ) . MoleculeNet benchmarks demonstrate that learnable representations are powerful tools for molecular machine learning and broadly offer the best performance . However , this result comes with caveats . Learnable representations still struggle to deal with complex tasks under data scarcity and highly imbalanced classification . For quantum mechanical and biophysical datasets , the use of physics-aware featurizations can be more important than choice of particular learning algorithm .
Exploration of hydrocarbon resources is a highly complicated and expensive process where various geological , geochemical and geophysical factors are developed then combined together . It is highly significant how to design the seismic data acquisition survey and locate the exploratory wells since incorrect or imprecise locations lead to waste of time and money during the operation . The objective of this study is to locate high-potential oil and gas field in 0 : 000 , 000 sheet of Ahwaz including 00 oil fields to reduce both time and costs in exploration and production processes . In this regard , 00 maps were developed using GIS functions for factors including : minimum and maximum of total organic carbon ( TOC ) , yield potential for hydrocarbons production ( PP ) , Tmax peak , production index ( PI ) , oxygen index ( OI ) , hydrogen index ( HI ) as well as presence or proximity to high residual Bouguer gravity anomalies , proximity to anticline axis and faults , topography and curvature maps obtained from Asmari Formation subsurface contours . To model and to integrate maps , this study employed artificial neural network and adaptive neuro-fuzzy inference system ( ANFIS ) methods . The results obtained from model validation demonstrated that the 00x00x0 neural network with R=0 . 0000 , RMS=0 . 0000 , and kappa=0 . 0000 can be trained better than other models such as ANFIS and predicts the potential areas more accurately . However , this method failed to predict some oil fields and wrongly predict some areas as potential zones .
Integrating visual and linguistic information into a single multimodal representation is an unsolved problem with wide-reaching applications to both natural language processing and computer vision . In this paper , we present a simple method to build multimodal representations by learning a language-to-vision mapping and using its output to build multimodal embeddings . In this sense , our method provides a cognitively plausible way of building representations , consistent with the inherently re-constructive and associative nature of human memory . Using seven benchmark concept similarity tests we show that the mapped vectors not only implicitly encode multimodal information , but also outperform strong unimodal baselines and state-of-the-art multimodal methods , thus exhibiting more " human-like " judgments---particularly in zero-shot settings .
We introduce a new embarrassingly parallel parameter learning algorithm for Markov random fields with untied parameters which is efficient for a large class of practical models . Our algorithm parallelizes naturally over cliques and , for graphs of bounded degree , its complexity is linear in the number of cliques . Unlike its competitors , our algorithm is fully parallel and for log-linear models it is also data efficient , requiring only the local sufficient statistics of the data to estimate parameters .
Polynomial networks and factorization machines are two recently-proposed models that can efficiently use feature interactions in classification and regression tasks . In this paper , we revisit both models from a unified perspective . Based on this new view , we study the properties of both models and propose new efficient training algorithms . Key to our approach is to cast parameter learning as a low-rank symmetric tensor estimation problem , which we solve by multi-convex optimization . We demonstrate our approach on regression and recommender system tasks .
In this report paper we first present a report of the Advanced Machine Learning Course Project on the provided data set and then present a novel heuristic algorithm for exact Bayesian network ( BN ) structure discovery that uses decomposable scoring functions . Our algorithm follows a different approach to solve the problem of BN structure discovery than the previously used methods such as Dynamic Programming ( DP ) and Branch and Bound to reduce the search space and find the global optima space for the problem . The algorithm we propose has some degree of flexibility that can make it more or less greedy . The more the algorithm is set to be greedy , the more the speed of the algorithm will be , and the less optimal the final structure . Our algorithm runs in a much less time than the previously known methods and guarantees to have an optimality of close to 00% . Therefore , it sacrifices less than one percent of score of an optimal structure in order to gain a much lower running time and make the algorithm feasible for large data sets ( we may note that we never used any toolbox except for result validation )
State-of-the-art speaker recognition relays on models that need a large amount of training data . This models are successful in tasks like NIST SRE because there is sufficient data available . However , in real applications , we usually do not have so much data and , in many cases , the speaker labels are unknown . We present a method to adapt a PLDA model from a domain with a large amount of labeled data to another with unlabeled data . We describe a generative model that produces both sets of data where the unknown labels are modeled like latent variables . We used variational Bayes to estimate the hidden variables . Here , we derive the equations for this model . This model has been used in the papers : " UNSUPERVISED ADAPTATION OF PLDA BY USING VARIATIONAL BAYES METHODS " publised at ICASSP 0000 , " Unsupervised Training of PLDA with Variational Bayes " published at Iberspeech 0000 , and " VARIATIONAL BAYESIAN PLDA FOR SPEAKER DIARIZATION IN THE MGB CHALLENGE " published at ASRU 0000 .
We develop a general framework for proving rigorous guarantees on the performance of the EM algorithm and a variant known as gradient EM . Our analysis is divided into two parts : a treatment of these algorithms at the population level ( in the limit of infinite data ) , followed by results that apply to updates based on a finite set of samples . First , we characterize the domain of attraction of any global maximizer of the population likelihood . This characterization is based on a novel view of the EM updates as a perturbed form of likelihood ascent , or in parallel , of the gradient EM updates as a perturbed form of standard gradient ascent . Leveraging this characterization , we then provide non-asymptotic guarantees on the EM and gradient EM algorithms when applied to a finite set of samples . We develop consequences of our general theory for three canonical examples of incomplete-data problems : mixture of Gaussians , mixture of regressions , and linear regression with covariates missing completely at random . In each case , our theory guarantees that with a suitable initialization , a relatively small number of EM ( or gradient EM ) steps will yield ( with high probability ) an estimate that is within statistical error of the MLE . We provide simulations to confirm this theoretically predicted behavior .
Generalized canonical correlation analysis ( GCCA ) aims at finding latent low-dimensional common structure from multiple views ( feature vectors in different domains ) of the same entities . Unlike principal component analysis ( PCA ) that handles a single view , ( G ) CCA is able to integrate information from different feature spaces . Here we focus on MAX-VAR GCCA , a popular formulation which has recently gained renewed interest in multilingual processing and speech modeling . The classic MAX-VAR GCCA problem can be solved optimally via eigen-decomposition of a matrix that compounds the ( whitened ) correlation matrices of the views ; but this solution has serious scalability issues , and is not directly amenable to incorporating pertinent structural constraints such as non-negativity and sparsity on the canonical components . We posit regularized MAX-VAR GCCA as a non-convex optimization problem and propose an alternating optimization ( AO ) -based algorithm to handle it . Our algorithm alternates between {\em inexact} solutions of a regularized least squares subproblem and a manifold-constrained non-convex subproblem , thereby achieving substantial memory and computational savings . An important benefit of our design is that it can easily handle structure-promoting regularization . We show that the algorithm globally converges to a critical point at a sublinear rate , and approaches a global optimal solution at a linear rate when no regularization is considered . Judiciously designed simulations and large-scale word embedding tasks are employed to showcase the effectiveness of the proposed algorithm .
We present a lightweight Python framework for distributed training of neural networks on multiple GPUs or CPUs . The framework is built on the popular Keras machine learning library . The Message Passing Interface ( MPI ) protocol is used to coordinate the training process , and the system is well suited for job submission at supercomputing sites . We detail the software ' s features , describe its use , and demonstrate its performance on systems of varying sizes on a benchmark problem drawn from high-energy physics research .
Variational inference ( VI ) combined with data subsampling enables approximate posterior inference over large data sets , but suffers from poor local optima . We first formulate a deterministic annealing approach for the generic class of conditionally conjugate exponential family models . This approach uses a decreasing temperature parameter which deterministically deforms the objective during the course of the optimization . A well-known drawback to this annealing approach is the choice of the cooling schedule . We therefore introduce variational tempering , a variational algorithm that introduces a temperature latent variable to the model . In contrast to related work in the Markov chain Monte Carlo literature , this algorithm results in adaptive annealing schedules . Lastly , we develop local variational tempering , which assigns a latent temperature to each data point ; this allows for dynamic annealing that varies across data . Compared to the traditional VI , all proposed approaches find improved predictive likelihoods on held-out data .
We introduce incremental variational inference and apply it to latent Dirichlet allocation ( LDA ) . Incremental variational inference is inspired by incremental EM and provides an alternative to stochastic variational inference . Incremental LDA can process massive document collections , does not require to set a learning rate , converges faster to a local optimum of the variational bound and enjoys the attractive property of monotonically increasing it . We study the performance of incremental LDA on large benchmark data sets . We further introduce a stochastic approximation of incremental variational inference which extends to the asynchronous distributed setting . The resulting distributed algorithm achieves comparable performance as single host incremental variational inference , but with a significant speed-up .
We propose a specialized string kernel for small bio-molecules , peptides and pseudo-sequences of binding interfaces . The kernel incorporates physico-chemical properties of amino acids and elegantly generalize eight kernels , such as the Oligo , the Weighted Degree , the Blended Spectrum , and the Radial Basis Function . We provide a low complexity dynamic programming algorithm for the exact computation of the kernel and a linear time algorithm for it ' s approximation . Combined with kernel ridge regression and SupCK , a novel binding pocket kernel , the proposed kernel yields biologically relevant and good prediction accuracy on the PepX database . For the first time , a machine learning predictor is capable of accurately predicting the binding affinity of any peptide to any protein . The method was also applied to both single-target and pan-specific Major Histocompatibility Complex class II benchmark datasets and three Quantitative Structure Affinity Model benchmark datasets . On all benchmarks , our method significantly ( p-value < 0 . 000 ) outperforms the current state-of-the-art methods at predicting peptide-protein binding affinities . The proposed approach is flexible and can be applied to predict any quantitative biological activity . The method should be of value to a large segment of the research community with the potential to accelerate peptide-based drug and vaccine development .
Iterative thresholding algorithms are well-suited for high-dimensional problems in sparse recovery and compressive sensing . The performance of this class of algorithms depends heavily on the tuning of certain threshold parameters . In particular , both the final reconstruction error and the convergence rate of the algorithm crucially rely on how the threshold parameter is set at each step of the algorithm . In this paper , we propose a parameter-free approximate message passing ( AMP ) algorithm that sets the threshold parameter at each iteration in a fully automatic way without either having an information about the signal to be reconstructed or needing any tuning from the user . We show that the proposed method attains both the minimum reconstruction error and the highest convergence rate . Our method is based on applying the Stein unbiased risk estimate ( SURE ) along with a modified gradient descent to find the optimal threshold in each iteration . Motivated by the connections between AMP and LASSO , it could be employed to find the solution of the LASSO for the optimal regularization parameter . To the best of our knowledge , this is the first work concerning parameter tuning that obtains the fastest convergence rate with theoretical guarantees .
In this paper , we are concerned with obtaining distribution-free concentration inequalities for mixture of independent Bernoulli variables that incorporate a notion of variance . Missing mass is the total probability mass associated to the outcomes that have not been seen in a given sample which is an important quantity that connects density estimates obtained from a sample to the population for discrete distributions . Therefore , we are specifically motivated to apply our method to study the concentration of missing mass - which can be expressed as a mixture of Bernoulli - in a novel way . We not only derive - for the first time - Bernstein-like large deviation bounds for the missing mass whose exponents behave almost linearly with respect to deviation size , but also sharpen McAllester and Ortiz ( 0000 ) and Berend and Kontorovich ( 0000 ) for large sample sizes in the case of small deviations which is the most interesting case in learning theory . In the meantime , our approach shows that the heterogeneity issue introduced in McAllester and Ortiz ( 0000 ) is resolvable in the case of missing mass in the sense that one can use standard inequalities but it may not lead to strong results . Thus , we postulate that our results are general and can be applied to provide potentially sharp Bernstein-like bounds under some constraints .
We study a model where one target variable Y is correlated with a vector X : = ( X_0 , . . . , X_d ) of predictor variables being potential causes of Y . We describe a method that infers to what extent the statistical dependences between X and Y are due to the influence of X on Y and to what extent due to a hidden common cause ( confounder ) of X and Y . The method relies on concentration of measure results for large dimensions d and an independence assumption stating that , in the absence of confounding , the vector of regression coefficients describing the influence of each X on Y typically has `generic orientation ' relative to the eigenspaces of the covariance matrix of X . For the special case of a scalar confounder we show that confounding typically spoils this generic orientation in a characteristic way that can be used to quantitatively estimate the amount of confounding .
Approximate Bayesian computation ( ABC ) is a method for Bayesian inference when the likelihood is unavailable but simulating from the model is possible . However , many ABC algorithms require a large number of simulations , which can be costly . To reduce the computational cost , Bayesian optimisation ( BO ) and surrogate models such as Gaussian processes have been proposed . Bayesian optimisation enables one to intelligently decide where to evaluate the model next , but standard BO strategies are designed for optimisation and not specifically for ABC inference . Our paper addresses this gap in the literature . We propose to compute the uncertainty in the ABC posterior density , which is due to lack of simulations to estimate this quantity accurately , and define a loss function that measures this uncertainty . We then propose to select the next evaluation location to minimise the expected loss . Experiments show that the proposed method often produces the most accurate approximations as compared to common BO strategies .
In this paper we introduce a novel online time series forecasting model we refer to as the pM-GP filter . We show that our model is equivalent to Gaussian process regression , with the advantage that both online forecasting and online learning of the hyper-parameters have a constant ( rather than cubic ) time complexity and a constant ( rather than squared ) memory requirement in the number of observations , without resorting to approximations . Moreover , the proposed model is expressive in that the family of covariance functions of the implied latent process , namely the spectral Matern kernels , have recently been proven to be capable of approximating arbitrarily well any translation-invariant covariance function . The benefit of our approach compared to competing models is demonstrated using experiments on several real-life datasets .
Algorithms for hyperparameter optimization abound , all of which work well under different and often unverifiable assumptions . Motivated by the general challenge of sequentially choosing which algorithm to use , we study the more specific task of choosing among distributions to use for random hyperparameter optimization . This work is naturally framed in the extreme bandit setting , which deals with sequentially choosing which distribution from a collection to sample in order to minimize ( maximize ) the single best cost ( reward ) . Whereas the distributions in the standard bandit setting are primarily characterized by their means , a number of subtleties arise when we care about the minimal cost as opposed to the average cost . For example , there may not be a well-defined " best " distribution as there is in the standard bandit setting . The best distribution depends on the rewards that have been obtained and on the remaining time horizon . Whereas in the standard bandit setting , it is sensible to compare policies with an oracle which plays the single best arm , in the extreme bandit setting , there are multiple sensible oracle models . We define a sensible notion of " extreme regret " in the extreme bandit setting , which parallels the concept of regret in the standard bandit setting . We then prove that no policy can asymptotically achieve no extreme regret .
Multi-armed bandit problems are the most basic examples of sequential decision problems with an exploration-exploitation trade-off . This is the balance between staying with the option that gave highest payoffs in the past and exploring new options that might give higher payoffs in the future . Although the study of bandit problems dates back to the Thirties , exploration-exploitation trade-offs arise in several modern applications , such as ad placement , website optimization , and packet routing . Mathematically , a multi-armed bandit is defined by the payoff process associated with each option . In this survey , we focus on two extreme cases in which the analysis of regret is particularly simple and elegant : i . i . d . payoffs and adversarial payoffs . Besides the basic setting of finitely many actions , we also analyze some of the most important variants and extensions , such as the contextual bandit model .
Given a collection of data points , non-negative matrix factorization ( NMF ) suggests to express them as convex combinations of a small set of `archetypes ' with non-negative entries . This decomposition is unique only if the true archetypes are non-negative and sufficiently sparse ( or the weights are sufficiently sparse ) , a regime that is captured by the separability condition and its generalizations . In this paper , we study an approach to NMF that can be traced back to the work of Cutler and Breiman ( 0000 ) and does not require the data to be separable , while providing a generally unique decomposition . We optimize the trade-off between two objectives : we minimize the distance of the data points from the convex envelope of the archetypes ( which can be interpreted as an empirical risk ) , while minimizing the distance of the archetypes from the convex envelope of the data ( which can be interpreted as a data-dependent regularization ) . The archetypal analysis method of ( Cutler , Breiman , 0000 ) is recovered as the limiting case in which the last term is given infinite weight . We introduce a `uniqueness condition ' on the data which is necessary for exactly recovering the archetypes from noiseless data . We prove that , under uniqueness ( plus additional regularity conditions on the geometry of the archetypes ) , our estimator is robust . While our approach requires solving a non-convex optimization problem , we find that standard optimization methods succeed in finding good solutions both for real and synthetic data .
Stochastic variance reduction algorithms have recently become popular for minimizing the average of a large , but finite , number of loss functions . In this paper , we propose a novel Riemannian extension of the Euclidean stochastic variance reduced gradient algorithm ( R-SVRG ) to a compact manifold search space . To this end , we show the developments on the Grassmann manifold . The key challenges of averaging , addition , and subtraction of multiple gradients are addressed with notions like logarithm mapping and parallel translation of vectors on the Grassmann manifold . We present a global convergence analysis of the proposed algorithm with decay step-sizes and a local convergence rate analysis under fixed step-size with some natural assumptions . The proposed algorithm is applied on a number of problems on the Grassmann manifold like principal components analysis , low-rank matrix completion , and the Karcher mean computation . In all these cases , the proposed algorithm outperforms the standard Riemannian stochastic gradient descent algorithm .
Covariate shift relaxes the widely-employed independent and identically distributed ( IID ) assumption by allowing different training and testing input distributions . Unfortunately , common methods for addressing covariate shift by trying to remove the bias between training and testing distributions using importance weighting often provide poor performance guarantees in theory and unreliable predictions with high variance in practice . Recently developed methods that construct a predictor that is inherently robust to the difficulties of learning under covariate shift are restricted to minimizing logloss and can be too conservative when faced with high-dimensional learning tasks . We address these limitations in two ways : by robustly minimizing various loss functions , including non-convex ones , under the testing distribution ; and by separately shaping the influence of covariate shift according to different feature-based views of the relationship between input variables and example labels . These generalizations make robust covariate shift prediction applicable to more task scenarios . We demonstrate the benefits on classification under covariate shift tasks .
Convolutional neural networks ( CNNs ) have been successfully applied to many recognition and learning tasks using a universal recipe ; training a deep model on a very large dataset of supervised examples . However , this approach is rather restrictive in practice since collecting a large set of labeled images is very expensive . One way to ease this problem is coming up with smart ways for choosing images to be labelled from a very large collection ( ie . active learning ) . Our empirical study suggests that many of the active learning heuristics in the literature are not effective when applied to CNNs in batch setting . Inspired by these limitations , we define the problem of active learning as core-set selection , ie . choosing set of points such that a model learned over the selected subset is competitive for the remaining data points . We further present a theoretical result characterizing the performance of any selected subset using the geometry of the datapoints . As an active learning algorithm , we choose the subset which is expected to yield best result according to our characterization . Our experiments show that the proposed method significantly outperforms existing approaches in image classification experiments by a large margin .
The problem of optimal switching between nonlinear autonomous subsystems is investigated in this study where the objective is not only bringing the states to close to the desired point , but also adjusting the switching pattern , in the sense of penalizing switching occurrences and assigning different preferences to utilization of different modes . The mode sequence is unspecified and a switching cost term is used in the cost function for penalizing each switching . It is shown that once a switching cost is incorporated , the optimal cost-to-go function depends on the already active subsystem , i . e . , the subsystem which was engaged in the previous time step . Afterwards , an approximate dynamic programming based method is developed which provides an approximation of the optimal solution to the problem in a feedback form and for different initial conditions . Finally , the performance of the method is analyzed through numerical examples .
We introduce a means of automating machine learning ( ML ) for big data tasks , by performing scalable stochastic Bayesian optimisation of ML algorithm parameters and hyper-parameters . More often than not , the critical tuning of ML algorithm parameters has relied on domain expertise from experts , along with laborious hand-tuning , brute search or lengthy sampling runs . Against this background , Bayesian optimisation is finding increasing use in automating parameter tuning , making ML algorithms accessible even to non-experts . However , the state of the art in Bayesian optimisation is incapable of scaling to the large number of evaluations of algorithm performance required to fit realistic models to complex , big data . We here describe a stochastic , sparse , Bayesian optimisation strategy to solve this problem , using many thousands of noisy evaluations of algorithm performance on subsets of data in order to effectively train algorithms for big data . We provide a comprehensive benchmarking of possible sparsification strategies for Bayesian optimisation , concluding that a Nystrom approximation offers the best scaling and performance for real tasks . Our proposed algorithm demonstrates substantial improvement over the state of the art in tuning the parameters of a Gaussian Process time series prediction task on real , big data .
Even though active learning forms an important pillar of machine learning , deep learning tools are not prevalent within it . Deep learning poses several difficulties when used in an active learning setting . First , active learning ( AL ) methods generally rely on being able to learn and update models from small amounts of data . Recent advances in deep learning , on the other hand , are notorious for their dependence on large amounts of data . Second , many AL acquisition functions rely on model uncertainty , yet deep learning methods rarely represent such model uncertainty . In this paper we combine recent advances in Bayesian deep learning into the active learning framework in a practical way . We develop an active learning framework for high dimensional data , a task which has been extremely challenging so far , with very sparse existing literature . Taking advantage of specialised models such as Bayesian convolutional neural networks , we demonstrate our active learning techniques with image data , obtaining a significant improvement on existing active learning approaches . We demonstrate this on both the MNIST dataset , as well as for skin cancer diagnosis from lesion images ( ISIC0000 task ) .
Liquid chromatography coupled with tandem mass spectrometry , also known as shotgun proteomics , is a widely-used high-throughput technology for identifying proteins in complex biological samples . Analysis of the tens of thousands of fragmentation spectra produced by a typical shotgun proteomics experiment begins by assigning to each observed spectrum the peptide hypothesized to be responsible for generating the spectrum , typically done by searching each spectrum against a database of peptides . We have recently described a machine learning method---Dynamic Bayesian Network for Rapid Identification of Peptides ( DRIP ) ---that not only achieves state-of-the-art spectrum identification performance on a variety of datasets but also provides a trainable model capable of returning valuable auxiliary information regarding specific peptide-spectrum matches . In this work , we present two significant improvements to DRIP . First , we describe how to use word lattices , which are widely used in natural language processing , to significantly speed up DRIP ' s computations . To our knowledge , all existing shotgun proteomics search engines compute independent scores between a given observed spectrum and each possible candidate peptide from the database . The key idea of the word lattice is to represent the set of candidate peptides in a single data structure , thereby allowing sharing of redundant computations among the different candidates . We demonstrate that using lattices in conjunction with DRIP leads to speedups on the order of tens across yeast and worm data sets . Second , we introduce a variant of DRIP that uses a discriminative training framework , performing maximum mutual entropy estimation rather than maximum likelihood estimation . This modification improves DRIP ' s statistical power , enabling us to increase the number of identified spectrum at a 0% false discovery rate on yeast and worm data sets .
We consider the problem of signal recovery on graphs as graphs model data with complex structure as signals on a graph . Graph signal recovery implies recovery of one or multiple smooth graph signals from noisy , corrupted , or incomplete measurements . We propose a graph signal model and formulate signal recovery as a corresponding optimization problem . We provide a general solution by using the alternating direction methods of multipliers . We next show how signal inpainting , matrix completion , robust principal component analysis , and anomaly detection all relate to graph signal recovery , and provide corresponding specific solutions and theoretical analysis . Finally , we validate the proposed methods on real-world recovery problems , including online blog classification , bridge condition identification , temperature estimation , recommender system , and expert opinion combination of online blog classification .
Information diffusion in online social networks is affected by the underlying network topology , but it also has the power to change it . Online users are constantly creating new links when exposed to new information sources , and in turn these links are alternating the way information spreads . However , these two highly intertwined stochastic processes , information diffusion and network evolution , have been predominantly studied separately , ignoring their co-evolutionary dynamics . We propose a temporal point process model , COEVOLVE , for such joint dynamics , allowing the intensity of one process to be modulated by that of the other . This model allows us to efficiently simulate interleaved diffusion and network events , and generate traces obeying common diffusion and network patterns observed in real-world networks . Furthermore , we also develop a convex optimization framework to learn the parameters of the model from historical diffusion and network evolution traces . We experimented with both synthetic data and data gathered from Twitter , and show that our model provides a good fit to the data as well as more accurate predictions than alternatives .
Multiresolution analysis and matrix factorization are foundational tools in computer vision . In this work , we study the interface between these two distinct topics and obtain techniques to uncover hierarchical block structure in symmetric matrices -- an important aspect in the success of many vision problems . Our new algorithm , the incremental multiresolution matrix factorization , uncovers such structure one feature at a time , and hence scales well to large matrices . We describe how this multiscale analysis goes much farther than what a direct global factorization of the data can identify . We evaluate the efficacy of the resulting factorizations for relative leveraging within regression tasks using medical imaging data . We also use the factorization on representations learned by popular deep networks , providing evidence of their ability to infer semantic relationships even when they are not explicitly trained to do so . We show that this algorithm can be used as an exploratory tool to improve the network architecture , and within numerous other settings in vision .
Background : Many authors have described MELD as a predictor of short-term mortality in the liver transplantation waiting list . However MELD score accuracy to predict long term mortality has not been statistically evaluated . Objective : The aim of this study is to analyze the MELD score as well as other variables as a predictor of long-term mortality using a new model : the Survival Tree analysis . Study Design and Setting : The variables obtained at the time of liver transplantation list enrollment and considered in this study are : sex , age , blood type , body mass index , etiology of liver disease , hepatocellular carcinoma , waiting time for transplant and MELD . Mortality on the waiting list is the outcome . Exclusion , transplantation or still in the transplantation list at the end of the study are censored data . Results : The graphical representation of the survival trees showed that the most statistically significant cut off is related to MELD score at point 00 . Conclusion : The results are compatible with the cut off point of MELD indicated in the clinical literature .
Given two sets of variables , derived from a common set of samples , sparse Canonical Correlation Analysis ( CCA ) seeks linear combinations of a small number of variables in each set , such that the induced canonical variables are maximally correlated . Sparse CCA is NP-hard . We propose a novel combinatorial algorithm for sparse diagonal CCA , i . e . , sparse CCA under the additional assumption that variables within each set are standardized and uncorrelated . Our algorithm operates on a low rank approximation of the input data and its computational complexity scales linearly with the number of input variables . It is simple to implement , and parallelizable . In contrast to most existing approaches , our algorithm administers precise control on the sparsity of the extracted canonical vectors , and comes with theoretical data-dependent global approximation guarantees , that hinge on the spectrum of the input data . Finally , it can be straightforwardly adapted to other constrained variants of CCA enforcing structure beyond sparsity . We empirically evaluate the proposed scheme and apply it on a real neuroimaging dataset to investigate associations between brain activity and behavior measurements .
During the past decade , with the significant progress of computational power as well as ever-rising data availability , deep learning techniques became increasingly popular due to their excellent performance on computer vision problems . The size of the Protein Data Bank has increased more than 00 fold since 0000 , which enabled the expansion of models that aim at predicting enzymatic function via their amino acid composition . Amino acid sequence however is less conserved in nature than protein structure and therefore considered a less reliable predictor of protein function . This paper presents EnzyNet , a novel 0D-convolutional neural networks classifier that predicts the Enzyme Commission number of enzymes based only on their voxel-based spatial structure . The spatial distribution of biochemical properties was also examined as complementary information . The 0-layer architecture was investigated on a large dataset of 00 , 000 enzymes from the Protein Data Bank and achieved an accuracy of 00 . 0% by exploiting only the binary representation of the protein shape . Code and datasets are available at https : //github . com/shervinea/enzynet .
The Web has enabled one of the most visible recent developments in education---the deployment of massive open online courses . With their global reach and often staggering enrollments , MOOCs have the potential to become a major new mechanism for learning . Despite this early promise , however , MOOCs are still relatively unexplored and poorly understood . In a MOOC , each student ' s complete interaction with the course materials takes place on the Web , thus providing a record of learner activity of unprecedented scale and resolution . In this work , we use such trace data to develop a conceptual framework for understanding how users currently engage with MOOCs . We develop a taxonomy of individual behavior , examine the different behavioral patterns of high- and low-achieving students , and investigate how forum participation relates to other parts of the course . We also report on a large-scale deployment of badges as incentives for engagement in a MOOC , including randomized experiments in which the presentation of badges was varied across sub-populations . We find that making badges more salient produced increases in forum engagement .
Random survival forest can be extremely time consuming for large data set . In this paper we propose few computationally efficient algorithms in prediction of survival function . We explore the behavior of the algorithms for different cancer data sets . Our construction includes right censoring data too . We have also applied the same for competing risk survival function .
Large-scale distributed training requires significant communication bandwidth for gradient exchange that limits the scalability of multi-node training , and requires expensive high-bandwidth network infrastructure . The situation gets even worse with distributed training on mobile devices ( federated learning ) , which suffers from higher latency , lower throughput , and intermittent poor connections . In this paper , we find 00 . 0% of the gradient exchange in distributed SGD is redundant , and propose Deep Gradient Compression ( DGC ) to greatly reduce the communication bandwidth . To preserve accuracy during compression , DGC employs four methods : momentum correction , local gradient clipping , momentum factor masking , and warm-up training . We have applied Deep Gradient Compression to image classification , speech recognition , and language modeling with multiple datasets including Cifar00 , ImageNet , Penn Treebank , and Librispeech Corpus . On these scenarios , Deep Gradient Compression achieves a gradient compression ratio from 000x to 000x without losing accuracy , cutting the gradient size of ResNet-00 from 00MB to 0 . 00MB , and for DeepSpeech from 000MB to 0 . 00MB . Deep gradient compression enables large-scale distributed training on inexpensive commodity 0Gbps Ethernet and facilitates distributed training on mobile .
In supervised learning , an inductive learning algorithm extracts general rules from observed training instances , then the rules are applied to test instances . We show that this splitting of training and application arises naturally , in the classical setting , from a simple independence requirement with a physical interpretation of being non-signalling . Thus , two seemingly different definitions of inductive learning happen to coincide . This follows from the properties of classical information that break down in the quantum setup . We prove a quantum de Finetti theorem for quantum channels , which shows that in the quantum case , the equivalence holds in the asymptotic setting , that is , for large number of test instances . This reveals a natural analogy between classical learning protocols and their quantum counterparts , justifying a similar treatment , and allowing to inquire about standard elements in computational learning theory , such as structural risk minimization and sample complexity .
The classical setting of community detection consists of networks exhibiting a clustered structure . To more accurately model real systems we consider a class of networks ( i ) whose edges may carry labels and ( ii ) which may lack a clustered structure . Specifically we assume that nodes possess latent attributes drawn from a general compact space and edges between two nodes are randomly generated and labeled according to some unknown distribution as a function of their latent attributes . Our goal is then to infer the edge label distributions from a partially observed network . We propose a computationally efficient spectral algorithm and show it allows for asymptotically correct inference when the average node degree could be as low as logarithmic in the total number of nodes . Conversely , if the average node degree is below a specific constant threshold , we show that no algorithm can achieve better inference than guessing without using the observations . As a byproduct of our analysis , we show that our model provides a general procedure to construct random graph models with a spectrum asymptotic to a pre-specified eigenvalue distribution such as a power-law distribution .
Brain networks has attracted the interests of many neuroscientists . From functional MRI ( fMRI ) data , statistical tools have been developed to recover brain networks . However , the dimensionality of whole-brain fMRI , usually in hundreds of thousands , challenges the applicability of these methods . We develop a hierarchical graphical model ( HGM ) to remediate this difficulty . This model introduces a hidden layer of networks based on sparse Gaussian graphical models , and the observed data are sampled from individual network nodes . In fMRI , the network layer models the underlying signals of different brain functional units , and how these units directly interact with each other . The introduction of this hierarchical structure not only provides a formal and interpretable approach , but also enables efficient computation for inferring big networks with hundreds of thousands of nodes . Based on the conditional convexity of our formulation , we develop an alternating update algorithm to compute the HGM model parameters simultaneously . The effectiveness of this approach is demonstrated on simulated data and a real dataset from a stop/go fMRI experiment .
Deep learning techniques have been hugely successful for traditional supervised and unsupervised machine learning problems . In large part , these techniques solve continuous optimization problems . Recently however , discrete generative deep learning models have been successfully used to efficiently search high-dimensional discrete spaces . These methods work by representing discrete objects as sequences , for which powerful sequence-based deep models can be employed . Unfortunately , these techniques are significantly hindered by the fact that these generative models often produce invalid sequences . As a step towards solving this problem , we propose to learn a deep recurrent validator model . Given a partial sequence , our model learns the probability of that sequence occurring as the beginning of a full valid sequence . Thus this identifies valid versus invalid sequences and crucially it also provides insight about how individual sequence elements influence the validity of discrete objects . To learn this model we propose an approach inspired by seminal work in Bayesian active learning . On a synthetic dataset , we demonstrate the ability of our model to distinguish valid and invalid sequences . We believe this is a key step toward learning generative models that faithfully produce valid discrete objects .
We introduce a copula mixture model to perform dependency-seeking clustering when co-occurring samples from different data sources are available . The model takes advantage of the great flexibility offered by the copulas framework to extend mixtures of Canonical Correlation Analysis to multivariate data with arbitrary continuous marginal densities . We formulate our model as a non-parametric Bayesian mixture , while providing efficient MCMC inference . Experiments on synthetic and real data demonstrate that the increased flexibility of the copula mixture significantly improves the clustering and the interpretability of the results .
Semidefinite programs have recently been developed for the problem of community detection , which may be viewed as a special case of the stochastic blockmodel . Here , we develop a semidefinite program that can be tailored to other instances of the blockmodel , such as non-assortative networks and overlapping communities . We establish label recovery in sparse settings , with conditions that are analogous to recent results for community detection . In settings where the data is not generated by a blockmodel , we give an oracle inequality that bounds excess risk relative to the best blockmodel approximation . Simulations are presented for community detection , for overlapping communities , and for latent space models .
In recent years , analyzing task-based fMRI ( tfMRI ) data has become an essential tool for understanding brain function and networks . However , due to the sheer size of tfMRI data , its intrinsic complex structure , and lack of ground truth of underlying neural activities , modeling tfMRI data is hard and challenging . Previously proposed data-modeling methods including Independent Component Analysis ( ICA ) and Sparse Dictionary Learning only provided a weakly established model based on blind source separation under the strong assumption that original fMRI signals could be linearly decomposed into time series components with corresponding spatial maps . Meanwhile , analyzing and learning a large amount of tfMRI data from a variety of subjects has been shown to be very demanding but yet challenging even with technological advances in computational hardware . Given the Convolutional Neural Network ( CNN ) , a robust method for learning high-level abstractions from low-level data such as tfMRI time series , in this work we propose a fast and scalable novel framework for distributed deep Convolutional Autoencoder model . This model aims to both learn the complex hierarchical structure of the tfMRI data and to leverage the processing power of multiple GPUs in a distributed fashion . To implement such a model , we have created an enhanced processing pipeline on the top of Apache Spark and Tensorflow library , leveraging from a very large cluster of GPU machines . Experimental data from applying the model on the Human Connectome Project ( HCP ) show that the proposed model is efficient and scalable toward tfMRI big data analytics , thus enabling data-driven extraction of hierarchical neuroscientific information from massive fMRI big data in the future .
Gaussian Process ( GP ) regression models typically assume that residuals are Gaussian and have the same variance for all observations . However , applications with input-dependent noise ( heteroscedastic residuals ) frequently arise in practice , as do applications in which the residuals do not have a Gaussian distribution . In this paper , we propose a GP Regression model with a latent variable that serves as an additional unobserved covariate for the regression . This model ( which we call GPLC ) allows for heteroscedasticity since it allows the function to have a changing partial derivative with respect to this unobserved covariate . With a suitable covariance function , our GPLC model can handle ( a ) Gaussian residuals with input-dependent variance , or ( b ) non-Gaussian residuals with input-dependent variance , or ( c ) Gaussian residuals with constant variance . We compare our model , using synthetic datasets , with a model proposed by Goldberg , Williams and Bishop ( 0000 ) , which we refer to as GPLV , which only deals with case ( a ) , as well as a standard GP model which can handle only case ( c ) . Markov Chain Monte Carlo methods are developed for both modelsl . Experiments show that when the data is heteroscedastic , both GPLC and GPLV give better results ( smaller mean squared error and negative log-probability density ) than standard GP regression . In addition , when the residual are Gaussian , our GPLC model is generally nearly as good as GPLV , while when the residuals are non-Gaussian , our GPLC model is better than GPLV .
A key question in modern statistics is how to make fast and reliable inferences for complex , high-dimensional data . While there has been much interest in sparse techniques , current methods do not generalize well to data with nonlinear structure . In this work , we present an orthogonal series estimator for predictors that are complex aggregate objects , such as natural images , galaxy spectra , trajectories , and movies . Our series approach ties together ideas from kernel machine learning , and Fourier methods . We expand the unknown regression on the data in terms of the eigenfunctions of a kernel-based operator , and we take advantage of orthogonality of the basis with respect to the underlying data distribution , P , to speed up computations and tuning of parameters . If the kernel is appropriately chosen , then the eigenfunctions adapt to the intrinsic geometry and dimension of the data . We provide theoretical guarantees for a radial kernel with varying bandwidth , and we relate smoothness of the regression function with respect to P to sparsity in the eigenbasis . Finally , using simulated and real-world data , we systematically compare the performance of the spectral series approach with classical kernel smoothing , k-nearest neighbors regression , kernel ridge regression , and state-of-the-art manifold and local regression methods .
Kernel dependence measures yield accurate estimates of nonlinear relations between random variables , and they are also endorsed with solid theoretical properties and convergence rates . Besides , the empirical estimates are easy to compute in closed form just involving linear algebra operations . However , they are hampered by two important problems : the high computational cost involved , as two kernel matrices of the sample size have to be computed and stored , and the interpretability of the measure , which remains hidden behind the implicit feature map . We here address these two issues . We introduce the Sensitivity Maps ( SMs ) for the Hilbert-Schmidt independence criterion ( HSIC ) . Sensitivity maps allow us to explicitly analyze and visualize the relative relevance of both examples and features on the dependence measure . We also present the randomized HSIC ( RHSIC ) and its corresponding sensitivity maps to cope with large scale problems . We build upon the framework of random features and the Bochner ' s theorem to approximate the involved kernels in the canonical HSIC . The power of the RHSIC measure scales favourably with the number of samples , and it approximates HSIC and the sensitivity maps efficiently . Convergence bounds of both the measure and the sensitivity map are also provided . Our proposal is illustrated in synthetic examples , and challenging real problems of dependence estimation , feature selection , and causal inference from empirical data .
The MAP-Elites algorithm produces a set of high-performing solutions that vary according to features defined by the user . This technique has the potential to be a powerful tool for design space exploration , but is limited by the need for numerous evaluations . The Surrogate-Assisted Illumination algorithm ( SAIL ) , introduced here , integrates approximative models and intelligent sampling of the objective function to minimize the number of evaluations required by MAP-Elites . The ability of SAIL to efficiently produce both accurate models and diverse high performing solutions is illustrated on a 0D airfoil design problem . The search space is divided into bins , each holding a design with a different combination of features . In each bin SAIL produces a better performing solution than MAP-Elites , and requires several orders of magnitude fewer evaluations . The CMA-ES algorithm was used to produce an optimal design in each bin : with the same number of evaluations required by CMA-ES to find a near-optimal solution in a single bin , SAIL finds solutions of similar quality in every bin .
We focus on the distribution regression problem : regressing to vector-valued outputs from probability measures . Many important machine learning and statistical tasks fit into this framework , including multi-instance learning and point estimation problems without analytical solution ( such as hyperparameter or entropy estimation ) . Despite the large number of available heuristics in the literature , the inherent two-stage sampled nature of the problem makes the theoretical analysis quite challenging , since in practice only samples from sampled distributions are observable , and the estimates have to rely on similarities computed between sets of points . To the best of our knowledge , the only existing technique with consistency guarantees for distribution regression requires kernel density estimation as an intermediate step ( which often performs poorly in practice ) , and the domain of the distributions to be compact Euclidean . In this paper , we study a simple , analytically computable , ridge regression-based alternative to distribution regression , where we embed the distributions to a reproducing kernel Hilbert space , and learn the regressor from the embeddings to the outputs . Our main contribution is to prove that this scheme is consistent in the two-stage sampled setup under mild conditions ( on separable topological domains enriched with kernels ) : we present an exact computational-statistical efficiency trade-off analysis showing that our estimator is able to match the one-stage sampled minimax optimal rate [Caponnetto and De Vito , 0000 ; Steinwart et al . , 0000] . This result answers a 00-year-old open question , establishing the consistency of the classical set kernel [Haussler , 0000 ; Gaertner et . al , 0000] in regression . We also cover consistency for more recent kernels on distributions , including those due to [Christmann and Steinwart , 0000] .
We study combinatorial multi-armed bandit with probabilistically triggered arms ( CMAB-T ) and semi-bandit feedback . We resolve a serious issue in the prior CMAB-T studies where the regret bounds contain a possibly exponentially large factor of 0/p* , where p* is the minimum positive probability that an arm is triggered by any action . We address this issue by introducing a triggering probability modulated ( TPM ) bounded smoothness condition into the general CMAB-T framework , and show that many applications such as influence maximization bandit and combinatorial cascading bandit satisfy this TPM condition . As a result , we completely remove the factor of $0/p^*$ from the regret bounds , achieving significantly better regret bounds for influence maximization and cascading bandits than before . Finally , we provide lower bound results showing that the factor 0/p* is unavoidable for general CMAB-T problems , suggesting that the TPM condition is crucial in removing this factor .
We present a graphical criterion for reading dependencies from the minimal directed independence map G of a graphoid p when G is a polytree and p satisfies composition and weak transitivity . We prove that the criterion is sound and complete . We argue that assuming composition and weak transitivity is not too restrictive .
Given a multivariate data set , sparse principal component analysis ( SPCA ) aims to extract several linear combinations of the variables that together explain the variance in the data as much as possible , while controlling the number of nonzero loadings in these combinations . In this paper we consider 0 different optimization formulations for computing a single sparse loading vector ; these are obtained by combining the following factors : we employ two norms for measuring variance ( L0 , L0 ) and two sparsity-inducing norms ( L0 , L0 ) , which are used in two different ways ( constraint , penalty ) . Three of our formulations , notably the one with L0 constraint and L0 variance , have not been considered in the literature . We give a unifying reformulation which we propose to solve via a natural alternating maximization ( AM ) method . We show the the AM method is nontrivially equivalent to GPower ( Journ\ ' {e}e et al ; JMLR 00 : 000--000 , 0000 ) for all our formulations . Besides this , we provide 00 efficient parallel SPCA implementations : 0 codes ( multi-core , GPU and cluster ) for each of the 0 problems . Parallelism in the methods is aimed at i ) speeding up computations ( our GPU code can be 000 times faster than an efficient serial code written in C++ ) , ii ) obtaining solutions explaining more variance and iii ) dealing with big data problems ( our cluster code is able to solve a 000 GB problem in about a minute ) .
We address the online linear optimization problem when the actions of the forecaster are represented by binary vectors . Our goal is to understand the magnitude of the minimax regret for the worst possible set of actions . We study the problem under three different assumptions for the feedback : full information , and the partial information models of the so-called " semi-bandit " , and " bandit " problems . We consider both $L_\infty$- , and $L_0$-type of restrictions for the losses assigned by the adversary . We formulate a general strategy using Bregman projections on top of a potential-based gradient descent , which generalizes the ones studied in the series of papers Gyorgy et al . ( 0000 ) , Dani et al . ( 0000 ) , Abernethy et al . ( 0000 ) , Cesa-Bianchi and Lugosi ( 0000 ) , Helmbold and Warmuth ( 0000 ) , Koolen et al . ( 0000 ) , Uchiya et al . ( 0000 ) , Kale et al . ( 0000 ) and Audibert and Bubeck ( 0000 ) . We provide simple proofs that recover most of the previous results . We propose new upper bounds for the semi-bandit game . Moreover we derive lower bounds for all three feedback assumptions . With the only exception of the bandit game , the upper and lower bounds are tight , up to a constant factor . Finally , we answer a question asked by Koolen et al . ( 0000 ) by showing that the exponentially weighted average forecaster is suboptimal against $L_{\infty}$ adversaries .
Top-N recommender systems have been investigated widely both in industry and academia . However , the recommendation quality is far from satisfactory . In this paper , we propose a simple yet promising algorithm . We fill the user-item matrix based on a low-rank assumption and simultaneously keep the original information . To do that , a nonconvex rank relaxation rather than the nuclear norm is adopted to provide a better rank approximation and an efficient optimization strategy is designed . A comprehensive set of experiments on real datasets demonstrates that our method pushes the accuracy of Top-N recommendation to a new level .
X-ray computed tomography ( CT ) using sparse projection views is often used to reduce the radiation dose . However , due to the insufficient projection views , a reconstruction approach using the filtered back projection ( FBP ) produces severe streaking artifacts . Recently , deep learning approaches using large receptive field neural networks such as U-net have demonstrated impressive performance for sparse view CT reconstruction . However , theoretical justification is still lacking . The main goal of this paper is , therefore , to develop a mathematical theory and to discuss how to improve these algorithms . In particular , inspired by the recent theory of deep convolutional framelets , we show that the U-net relies on a sub-optimal non-local bases that overly emphasizes low frequency components . The discovery leads to a dual frame and a tight frame U-net architectures for effective recovery of directional image components .
We consider $N$-way data arrays and low-rank tensor factorizations where the time mode is coded as a sparse linear combination of temporal elements from an over-complete library . Our method , Shape Constrained Tensor Decomposition ( SCTD ) is based upon the CANDECOMP/PARAFAC ( CP ) decomposition which produces $r$-rank approximations of data tensors via outer products of vectors in each dimension of the data . By constraining the vector in the temporal dimension to known analytic forms which are selected from a large set of candidate functions , more readily interpretable decompositions are achieved and analytic time dependencies discovered . The SCTD method circumvents traditional {\em flattening} techniques where an $N$-way array is reshaped into a matrix in order to perform a singular value decomposition . A clear advantage of the SCTD algorithm is its ability to extract transient and intermittent phenomena which is often difficult for SVD-based methods . We motivate the SCTD method using several intuitively appealing results before applying it on a number of high-dimensional , real-world data sets in order to illustrate the efficiency of the algorithm in extracting interpretable spatio-temporal modes . With the rise of data-driven discovery methods , the decomposition proposed provides a viable technique for analyzing multitudes of data in a more comprehensible fashion .
We study reinforcement learning under model misspecification , where we do not have access to the true environment but only to a reasonably close approximation to it . We address this problem by extending the framework of robust MDPs to the model-free Reinforcement Learning setting , where we do not have access to the model parameters , but can only sample states from it . We define robust versions of Q-learning , SARSA , and TD-learning and prove convergence to an approximately optimal robust policy and approximate value function respectively . We scale up the robust algorithms to large MDPs via function approximation and prove convergence under two different settings . We prove convergence of robust approximate policy iteration and robust approximate value iteration for linear architectures ( under mild assumptions ) . We also define a robust loss function , the mean squared robust projected Bellman error and give stochastic gradient descent algorithms that are guaranteed to converge to a local minimum .
In this paper we investigate a link between state- space models and Gaussian Processes ( GP ) for time series modeling and forecasting . In particular , several widely used state- space models are transformed into continuous time form and corresponding Gaussian Process kernels are derived . Experimen- tal results demonstrate that the derived GP kernels are correct and appropriate for Gaussian Process Regression . An experiment with a real world dataset shows that the modeling is identical with state-space models and with the proposed GP kernels . The considered connection allows the researchers to look at their models from a different angle and facilitate sharing ideas between these two different modeling approaches .
Estimating the dependences between random variables , and ranking them accordingly , is a prevalent problem in machine learning . Pursuing frequentist and information-theoretic approaches , we first show that the p-value and the mutual information can fail even in simplistic situations . We then propose two conditions for regularizing an estimator of dependence , which leads to a simple yet effective new measure . We discuss its advantages and compare it to well-established model-selection criteria . Apart from that , we derive a simple constraint for regularizing parameter estimates in a graphical model . This results in an analytical approximation for the optimal value of the equivalent sample size , which agrees very well with the more involved Bayesian approach in our experiments .
Determinantal point processes ( DPPs ) are well-suited for modeling repulsion and have proven useful in many applications where diversity is desired . While DPPs have many appealing properties , such as efficient sampling , learning the parameters of a DPP is still considered a difficult problem due to the non-convex nature of the likelihood function . In this paper , we propose using Bayesian methods to learn the DPP kernel parameters . These methods are applicable in large-scale and continuous DPP settings even when the exact form of the eigendecomposition is unknown . We demonstrate the utility of our DPP learning methods in studying the progression of diabetic neuropathy based on spatial distribution of nerve fibers , and in studying human perception of diversity in images .
We consider the problem of modeling discrete-valued vector time series data using extensions of Chow-Liu tree models to capture both dependencies across time and dependencies across variables . Conditional Chow-Liu tree models are introduced , as an extension to standard Chow-Liu trees , for modeling conditional rather than joint densities . We describe learning algorithms for such models and show how they can be used to learn parsimonious representations for the output distributions in hidden Markov models . These models are applied to the important problem of simulating and forecasting daily precipitation occurrence for networks of rain stations . To demonstrate the effectiveness of the models , we compare their performance versus a number of alternatives using historical precipitation data from Southwestern Australia and the Western United States . We illustrate how the structure and parameters of the models can be used to provide an improved meteorological interpretation of such data .
We study the problem of sampling k-bandlimited signals on graphs . We propose two sampling strategies that consist in selecting a small subset of nodes at random . The first strategy is non-adaptive , i . e . , independent of the graph structure , and its performance depends on a parameter called the graph coherence . On the contrary , the second strategy is adaptive but yields optimal results . Indeed , no more than O ( k log ( k ) ) measurements are sufficient to ensure an accurate and stable recovery of all k-bandlimited signals . This second strategy is based on a careful choice of the sampling distribution , which can be estimated quickly . Then , we propose a computationally efficient decoder to reconstruct k-bandlimited signals from their samples . We prove that it yields accurate reconstructions and that it is also stable to noise . Finally , we conduct several experiments to test these techniques .
Many scientific and engineering challenges -- ranging from personalized medicine to customized marketing recommendations -- require an understanding of treatment effect heterogeneity . In this paper , we develop a non-parametric causal forest for estimating heterogeneous treatment effects that extends Breiman ' s widely used random forest algorithm . In the potential outcomes framework with unconfoundedness , we show that causal forests are pointwise consistent for the true treatment effect , and have an asymptotically Gaussian and centered sampling distribution . We also discuss a practical method for constructing asymptotic confidence intervals for the true treatment effect that are centered at the causal forest estimates . Our theoretical results rely on a generic Gaussian theory for a large family of random forest algorithms . To our knowledge , this is the first set of results that allows any type of random forest , including classification and regression forests , to be used for provably valid statistical inference . In experiments , we find causal forests to be substantially more powerful than classical methods based on nearest-neighbor matching , especially in the presence of irrelevant covariates .
Most existing learning to hash methods assume that there are sufficient data , either labeled or unlabeled , on the domain of interest ( i . e . , the target domain ) for training . However , this assumption cannot be satisfied in some real-world applications . To address this data sparsity issue in hashing , inspired by transfer learning , we propose a new framework named Transfer Hashing with Privileged Information ( THPI ) . Specifically , we extend the standard learning to hash method , Iterative Quantization ( ITQ ) , in a transfer learning manner , namely ITQ+ . In ITQ+ , a new slack function is learned from auxiliary data to approximate the quantization error in ITQ . We developed an alternating optimization approach to solve the resultant optimization problem for ITQ+ . We further extend ITQ+ to LapITQ+ by utilizing the geometry structure among the auxiliary data for learning more precise binary codes in the target domain . Extensive experiments on several benchmark datasets verify the effectiveness of our proposed approaches through comparisons with several state-of-the-art baselines .
We propose an L-BFGS optimization algorithm on Riemannian manifolds using minibatched stochastic variance reduction techniques for fast convergence with constant step sizes , without resorting to linesearch methods designed to satisfy Wolfe conditions . We provide a new convergence proof for strongly convex functions without using curvature conditions on the manifold , as well as a convergence discussion for nonconvex functions . We discuss a couple of ways to obtain the correction pairs used to calculate the product of the gradient with the inverse Hessian , and empirically demonstrate their use in synthetic experiments on computation of Karcher means for symmetric positive definite matrices and leading eigenvalues of large scale data matrices . We compare our method to VR-PCA for the latter experiment , along with Riemannian SVRG for both cases , and show strong convergence results for a range of datasets .
We generalise the problem of inverse reinforcement learning to multiple tasks , from multiple demonstrations . Each one may represent one expert trying to solve a different task , or as different experts trying to solve the same task . Our main contribution is to formalise the problem as statistical preference elicitation , via a number of structured priors , whose form captures our biases about the relatedness of different tasks or expert policies . In doing so , we introduce a prior on policy optimality , which is more natural to specify . We show that our framework allows us not only to learn to efficiently from multiple experts but to also effectively differentiate between the goals of each . Possible applications include analysing the intrinsic motivations of subjects in behavioural experiments and learning from multiple teachers .
It is well known that speaker verification systems are subject to spoofing attacks . The Automatic Speaker Verification Spoofing and Countermeasures Challenge -- ASVSpoof0000 -- provides a standard spoofing database , containing attacks based on synthetic speech , along with a protocol for experiments . This paper describes CPqD ' s systems submitted to the ASVSpoof0000 Challenge , based on deep neural networks , working both as a classifier and as a feature extraction module for a GMM and a SVM classifier . Results show the validity of this approach , achieving less than 0 . 0\% EER for known attacks .
In approachability with full monitoring there are two types of conditions that are known to be equivalent for convex sets : a primal and a dual condition . The primal one is of the form : a set C is approachable if and only all containing half-spaces are approachable in the one-shot game ; while the dual one is of the form : a convex set C is approachable if and only if it intersects all payoff sets of a certain form . We consider approachability in games with partial monitoring . In previous works ( Perchet 0000 ; Mannor et al . 0000 ) we provided a dual characterization of approachable convex sets ; we also exhibited efficient strategies in the case where C is a polytope . In this paper we provide primal conditions on a convex set to be approachable with partial monitoring . They depend on a modified reward function and lead to approachability strategies , based on modified payoff functions , that proceed by projections similarly to Blackwell ' s ( 0000 ) strategy ; this is in contrast with previously studied strategies in this context that relied mostly on the signaling structure and aimed at estimating well the distributions of the signals received . Our results generalize classical results by Kohlberg 0000 ( see also Mertens et al . 0000 ) and apply to games with arbitrary signaling structure as well as to arbitrary convex sets .
In many applications , an anomaly detection system presents the most anomalous data instance to a human analyst , who then must determine whether the instance is truly of interest ( e . g . a threat in a security setting ) . Unfortunately , most anomaly detectors provide no explanation about why an instance was considered anomalous , leaving the analyst with no guidance about where to begin the investigation . To address this issue , we study the problems of computing and evaluating sequential feature explanations ( SFEs ) for anomaly detectors . An SFE of an anomaly is a sequence of features , which are presented to the analyst one at a time ( in order ) until the information contained in the highlighted features is enough for the analyst to make a confident judgement about the anomaly . Since analyst effort is related to the amount of information that they consider in an investigation , an explanation ' s quality is related to the number of features that must be revealed to attain confidence . One of our main contributions is to present a novel framework for large scale quantitative evaluations of SFEs , where the quality measure is based on analyst effort . To do this we construct anomaly detection benchmarks from real data sets along with artificial experts that can be simulated for evaluation . Our second contribution is to evaluate several novel explanation approaches within the framework and on traditional anomaly detection benchmarks , offering several insights into the approaches .
Structured sparsity is an important modeling tool that expands the applicability of convex formulations for data analysis , however it also creates significant challenges for efficient algorithm design . In this paper we investigate the generalized conditional gradient ( GCG ) algorithm for solving structured sparse optimization problems---demonstrating that , with some enhancements , it can provide a more efficient alternative to current state of the art approaches . After providing a comprehensive overview of the convergence properties of GCG , we develop efficient methods for evaluating polar operators , a subroutine that is required in each GCG iteration . In particular , we show how the polar operator can be efficiently evaluated in two important scenarios : dictionary learning and structured sparse estimation . A further improvement is achieved by interleaving GCG with fixed-rank local subspace optimization . A series of experiments on matrix completion , multi-class classification , multi-view dictionary learning and overlapping group lasso shows that the proposed method can significantly reduce the training cost of current alternatives .
High-dimensional data common in genomics , proteomics , and chemometrics often contains complicated correlation structures . Recently , partial least squares ( PLS ) and Sparse PLS methods have gained attention in these areas as dimension reduction techniques in the context of supervised data analysis . We introduce a framework for Regularized PLS by solving a relaxation of the SIMPLS optimization problem with penalties on the PLS loadings vectors . Our approach enjoys many advantages including flexibility , general penalties , easy interpretation of results , and fast computation in high-dimensional settings . We also outline extensions of our methods leading to novel methods for Non-negative PLS and Generalized PLS , an adaption of PLS for structured data . We demonstrate the utility of our methods through simulations and a case study on proton Nuclear Magnetic Resonance ( NMR ) spectroscopy data .
The asymptotic pseudo-trajectory approach to stochastic approximation of Benaim , Hofbauer and Sorin is extended for asynchronous stochastic approximations with a set-valued mean field . The asynchronicity of the process is incorporated into the mean field to produce convergence results which remain similar to those of an equivalent synchronous process . In addition , this allows many of the restrictive assumptions previously associated with asynchronous stochastic approximation to be removed . The framework is extended for a coupled asynchronous stochastic approximation process with set-valued mean fields . Two-timescales arguments are used here in a similar manner to the original work in this area by Borkar . The applicability of this approach is demonstrated through learning in a Markov decision process .
Current statistical inference problems in areas like astronomy , genomics , and marketing routinely involve the simultaneous testing of thousands -- even millions -- of null hypotheses . For high-dimensional multivariate distributions , these hypotheses may concern a wide range of parameters , with complex and unknown dependence structures among variables . In analyzing such hypothesis testing procedures , gains in efficiency and power can be achieved by performing variable reduction on the set of hypotheses prior to testing . We present in this paper an approach using data-adaptive multiple testing that serves exactly this purpose . This approach applies data mining techniques to screen the full set of covariates on equally sized partitions of the whole sample via cross-validation . This generalized screening procedure is used to create average ranks for covariates , which are then used to generate a reduced ( sub ) set of hypotheses , from which we compute test statistics that are subsequently subjected to standard multiple testing corrections . The principal advantage of this methodology lies in its providing valid statistical inference without the \textit{a priori} specifying which hypotheses will be tested . Here , we present the theoretical details of this approach , confirm its validity via a simulation study , and exemplify its use by applying it to the analysis of data on microRNA differential expression .
In this paper the exact linear relation between the leading eigenvectors of the modularity matrix and the singular vectors of an uncentered data matrix is developed . Based on this analysis the concept of a modularity component is defined , and its properties are developed . It is shown that modularity component analysis can be used to cluster data similar to how traditional principal component analysis is used except that modularity component analysis does not require data centering .
This paper presents a Bayesian approach to symbol and phase inference in a phase-unsynchronized digital receiver . It primarily extends [Quinn 0000] to the multi-symbol case , using the variational Bayes ( VB ) approximation to deal with the combinatorial complexity of the phase inference in this case . The work provides a fully Bayesian extension of the EM-based framework underlying current turbo-synchronization methods , since it induces a von Mises prior on the time-invariant phase parmeter . As a result , we achieve tractable iterative algorithms with improved robustness in low SNR regimes , compared to the current EM-based approaches . As a corollary to our analysis we also discover the importance of prior regularization in elegantly tackling the significant problem of phase ambiguity .
We study the spherical cap packing problem with a probabilistic approach . Such probabilistic considerations result in an asymptotic sharp universal uniform bound on the maximal inner product between any set of unit vectors and a stochastically independent uniformly distributed unit vector . When the set of unit vectors are themselves independently uniformly distributed , we further develop the extreme value distribution limit of the maximal inner product , which characterizes its uncertainty around the bound . As applications of the above asymptotic results , we derive ( 0 ) an asymptotic sharp universal uniform bound on the maximal spurious correlation , as well as its uniform convergence in distribution when the explanatory variables are independently Gaussian distributed ; and ( 0 ) an asymptotic sharp universal bound on the maximum norm of a low-rank elliptically distributed vector , as well as related limiting distributions . With these results , we develop a fast detection method for a low-rank structure in high-dimensional Gaussian data without using the spectrum information .
We study signal recovery on graphs based on two sampling strategies : random sampling and experimentally designed sampling . We propose a new class of smooth graph signals , called approximately bandlimited , which generalizes the bandlimited class and is similar to the globally smooth class . We then propose two recovery strategies based on random sampling and experimentally designed sampling . The proposed recovery strategy based on experimentally designed sampling is similar to the leverage scores used in the matrix approximation . We show that while both strategies are unbiased estimators for the low-frequency components , the convergence rate of experimentally designed sampling is much faster than that of random sampling when a graph is irregular . We validate the proposed recovery strategies on three specific graphs : a ring graph , an Erd\H{o}s-R\ ' enyi graph , and a star graph . The simulation results support the theoretical analysis .
Learning the parameters of a ( potentially partially observable ) random field model is intractable in general . Instead of focussing on a single optimal parameter value we propose to treat parameters as dynamical quantities . We introduce an algorithm to generate complex dynamics for parameters and ( both visible and hidden ) state vectors . We show that under certain conditions averages computed over trajectories of the proposed dynamical system converge to averages computed over the data . Our " herding dynamics " does not require expensive operations such as exponentiation and is fully deterministic .
We consider the minimum error entropy ( MEE ) criterion and an empirical risk minimization learning algorithm in a regression setting . A learning theory approach is presented for this MEE algorithm and explicit error bounds are provided in terms of the approximation ability and capacity of the involved hypothesis space when the MEE scaling parameter is large . Novel asymptotic analysis is conducted for the generalization error associated with Renyi ' s entropy and a Parzen window function , to overcome technical difficulties arisen from the essential differences between the classical least squares problems and the MEE setting . A semi-norm and the involved symmetrized least squares error are introduced , which is related to some ranking algorithms .
In the present paper , we studied a Dynamic Stochastic Block Model ( DSBM ) under the assumptions that the connection probabilities , as functions of time , are smooth and that at most $s$ nodes can switch their class memberships between two consecutive time points . We estimate the edge probability tensor by a kernel-type procedure and extract the group memberships of the nodes by spectral clustering . The procedure is computationally viable , adaptive to the unknown smoothness of the functional connection probabilities , to the rate $s$ of membership switching and to the unknown number of clusters . In addition , it is accompanied by non-asymptotic guarantees for the precision of estimation and clustering .
Outlier detection amounts to finding data points that differ significantly from the norm . Classic outlier detection methods are largely designed for single data type such as continuous or discrete . However , real world data is increasingly heterogeneous , where a data point can have both discrete and continuous attributes . Handling mixed-type data in a disciplined way remains a great challenge . In this paper , we propose a new unsupervised outlier detection method for mixed-type data based on Mixed-variate Restricted Boltzmann Machine ( Mv . RBM ) . The Mv . RBM is a principled probabilistic method that models data density . We propose to use \emph{free-energy} derived from Mv . RBM as outlier score to detect outliers as those data points lying in low density regions . The method is fast to learn and compute , is scalable to massive datasets . At the same time , the outlier score is identical to data negative log-density up-to an additive constant . We evaluate the proposed method on synthetic and real-world datasets and demonstrate that ( a ) a proper handling mixed-types is necessary in outlier detection , and ( b ) free-energy of Mv . RBM is a powerful and efficient outlier scoring method , which is highly competitive against state-of-the-arts .
We present a novel subset scan method to detect if a probabilistic binary classifier has statistically significant bias -- over or under predicting the risk -- for some subgroup , and identify the characteristics of this subgroup . This form of model checking and goodness-of-fit test provides a way to interpretably detect the presence of classifier bias or regions of poor classifier fit . This allows consideration of not just subgroups of a priori interest or small dimensions , but the space of all possible subgroups of features . To address the difficulty of considering these exponentially many possible subgroups , we use subset scan and parametric bootstrap-based methods . Extending this method , we can penalize the complexity of the detected subgroup and also identify subgroups with high classification errors . We demonstrate these methods and find interesting results on the COMPAS crime recidivism and credit delinquency data .
We propose an inlier-based outlier detection method capable of both identifying the outliers and explaining why they are outliers , by identifying the outlier-specific features . Specifically , we employ an inlier-based outlier detection criterion , which uses the ratio of inlier and test probability densities as a measure of plausibility of being an outlier . For estimating the density ratio function , we propose a localized logistic regression algorithm . Thanks to the locality of the model , variable selection can be outlier-specific , and will help interpret why points are outliers in a high-dimensional space . Through synthetic experiments , we show that the proposed algorithm can successfully detect the important features for outliers . Moreover , we show that the proposed algorithm tends to outperform existing algorithms in benchmark datasets .
We introduce online learning algorithms which are independent of feature scales , proving regret bounds dependent on the ratio of scales existent in the data rather than the absolute scale . This has several useful effects : there is no need to pre-normalize data , the test-time and test-space complexity are reduced , and the algorithms are more robust .
Recurrent neural networks like long short-term memory ( LSTM ) are important architectures for sequential prediction tasks . LSTMs ( and RNNs in general ) model sequences along the forward time direction . Bidirectional LSTMs ( Bi-LSTMs ) on the other hand model sequences along both forward and backward directions and are generally known to perform better at such tasks because they capture a richer representation of the data . In the training of Bi-LSTMs , the forward and backward paths are learned independently . We propose a variant of the Bi-LSTM architecture , which we call Variational Bi-LSTM , that creates a channel between the two paths ( during training , but which may be omitted during inference ) ; thus optimizing the two paths jointly . We arrive at this joint objective for our model by minimizing a variational lower bound of the joint likelihood of the data sequence . Our model acts as a regularizer and encourages the two networks to inform each other in making their respective predictions using distinct information . We perform ablation studies to better understand the different components of our model and evaluate the method on various benchmarks , showing state-of-the-art performance .
We propose a Frank-Wolfe ( FW ) solver to optimize the symmetric nonnegative matrix factorization problem under a simplicial constraint . Compared with existing solutions , this algorithm is extremely simple to implement , and has almost no hyperparameters to be tuned . Building on the recent advances of FW algorithms in nonconvex optimization , we prove an $O ( 0/\varepsilon^0 ) $ convergence rate to stationary points , via a tight bound $\Theta ( n^0 ) $ on the curvature constant . Numerical results demonstrate the effectiveness of our algorithm . As a side contribution , we construct a simple nonsmooth convex problem where the FW algorithm fails to converge to the optimum . This result raises an interesting question about necessary conditions of the success of the FW algorithm on convex problems .
In supervised learning one wishes to identify a pattern present in a joint distribution $P$ , of instances , label pairs , by providing a function $f$ from instances to labels that has low risk $\mathbb{E}_{P}\ell ( y , f ( x ) ) $ . To do so , the learner is given access to $n$ iid samples drawn from $P$ . In many real world problems clean samples are not available . Rather , the learner is given access to samples from a corrupted distribution $\tilde{P}$ from which to learn , while the goal of predicting the clean pattern remains . There are many different types of corruption one can consider , and as of yet there is no general means to compare the relative ease of learning under these different corruption processes . In this paper we develop a general framework for tackling such problems as well as introducing upper and lower bounds on the risk for learning in the presence of corruption . Our ultimate goal is to be able to make informed economic decisions in regards to the acquisition of data sets . For a certain subclass of corruption processes ( those that are \emph{reconstructible} ) we achieve this goal in a particular sense . Our lower bounds are in terms of the coefficient of ergodicity , a simple to calculate property of stochastic matrices . Our upper bounds proceed via a generalization of the method of unbiased estimators appearing in recent work of Natarajan et al and implicit in the earlier work of Kearns .
The Gaussian mixture model is a classic technique for clustering and data modeling that is used in numerous applications . With the rise of big data , there is a need for parameter estimation techniques that can handle streaming data and distribute the computation over several processors . While online variants of the Expectation Maximization ( EM ) algorithm exist , their data efficiency is reduced by a stochastic approximation of the E-step and it is not clear how to distribute the computation over multiple processors . We propose a Bayesian learning technique that lends itself naturally to online and distributed computation . Since the Bayesian posterior is not tractable , we project it onto a family of tractable distributions after each observation by matching a set of sufficient moments . This Bayesian moment matching technique compares favorably to online EM in terms of time and accuracy on a set of data modeling benchmarks .
We extend the theory of matrix completion to the case where we make Poisson observations for a subset of entries of a low-rank matrix . We consider the ( now ) usual matrix recovery formulation through maximum likelihood with proper constraints on the matrix $M$ , and establish theoretical upper and lower bounds on the recovery error . Our bounds are nearly optimal up to a factor on the order of $\mathcal{O} ( \log ( d_0 d_0 ) ) $ . These bounds are obtained by adapting the arguments used for one-bit matrix completion \cite{davenport00000} ( although these two problems are different in nature ) and the adaptation requires new techniques exploiting properties of the Poisson likelihood function and tackling the difficulties posed by the locally sub-Gaussian characteristic of the Poisson distribution . Our results highlight a few important distinctions of Poisson matrix completion compared to the prior work in matrix completion including having to impose a minimum signal-to-noise requirement on each observed entry . We also develop an efficient iterative algorithm and demonstrate its good performance in recovering solar flare images .
In this paper , we introduce a methodology that allows to model behavioral trajectories of users in online social media . First , we illustrate how to leverage the probabilistic framework provided by Hidden Markov Models ( HMMs ) to represent users by embedding the temporal sequences of actions they performed online . We then derive a model-based distance between trained HMMs , and we use spectral clustering to find homogeneous clusters of users showing similar behavioral trajectories . To provide platform-agnostic results , we apply the proposed approach to two different online social media --- i . e . Facebook and YouTube . We conclude discussing merits and limitations of our approach as well as future and promising research directions .
We consider the problem of minimizing the regret in stochastic multi-armed bandit , when the measure of goodness of an arm is not the mean return , but some general function of the mean and the variance . We characterize the conditions under which learning is possible and present examples for which no natural algorithm can achieve sublinear regret .
In this paper , we consider decentralized sequential decision making in distributed online recommender systems , where items are recommended to users based on their search query as well as their specific background including history of bought items , gender and age , all of which comprise the context information of the user . In contrast to centralized recommender systems , in which there is a single centralized seller who has access to the complete inventory of items as well as the complete record of sales and user information , in decentralized recommender systems each seller/learner only has access to the inventory of items and user information for its own products and not the products and user information of other sellers , but can get commission if it sells an item of another seller . Therefore the sellers must distributedly find out for an incoming user which items to recommend ( from the set of own items or items of another seller ) , in order to maximize the revenue from own sales and commissions . We formulate this problem as a cooperative contextual bandit problem , analytically bound the performance of the sellers compared to the best recommendation strategy given the complete realization of user arrivals and the inventory of items , as well as the context-dependent purchase probabilities of each item , and verify our results via numerical examples on a distributed data set adapted based on Amazon data . We evaluate the dependence of the performance of a seller on the inventory of items the seller has , the number of connections it has with the other sellers , and the commissions which the seller gets by selling items of other sellers to its users .
We propose a novel approach for the generation of polyphonic music based on LSTMs . We generate music in two steps . First , a chord LSTM predicts a chord progression based on a chord embedding . A second LSTM then generates polyphonic music from the predicted chord progression . The generated music sounds pleasing and harmonic , with only few dissonant notes . It has clear long-term structure that is similar to what a musician would play during a jam session . We show that our approach is sensible from a music theory perspective by evaluating the learned chord embeddings . Surprisingly , our simple model managed to extract the circle of fifths , an important tool in music theory , from the dataset .
We obtain an improved finite-sample guarantee on the linear convergence of stochastic gradient descent for smooth and strongly convex objectives , improving from a quadratic dependence on the conditioning $ ( L/\mu ) ^0$ ( where $L$ is a bound on the smoothness and $\mu$ on the strong convexity ) to a linear dependence on $L/\mu$ . Furthermore , we show how reweighting the sampling distribution ( i . e . importance sampling ) is necessary in order to further improve convergence , and obtain a linear dependence in the average smoothness , dominating previous results . We also discuss importance sampling for SGD more broadly and show how it can improve convergence also in other scenarios . Our results are based on a connection we make between SGD and the randomized Kaczmarz algorithm , which allows us to transfer ideas between the separate bodies of literature studying each of the two methods . In particular , we recast the randomized Kaczmarz algorithm as an instance of SGD , and apply our results to prove its exponential convergence , but to the solution of a weighted least squares problem rather than the original least squares problem . We then present a modified Kaczmarz algorithm with partially biased sampling which does converge to the original least squares solution with the same exponential convergence rate .
This paper addresses the problem of online learning in a dynamic setting . We consider a social network in which each individual observes a private signal about the underlying state of the world and communicates with her neighbors at each time period . Unlike many existing approaches , the underlying state is dynamic , and evolves according to a geometric random walk . We view the scenario as an optimization problem where agents aim to learn the true state while suffering the smallest possible loss . Based on the decomposition of the global loss function , we introduce two update mechanisms , each of which generates an estimate of the true state . We establish a tight bound on the rate of change of the underlying state , under which individuals can track the parameter with a bounded variance . Then , we characterize explicit expressions for the steady state mean-square deviation ( MSD ) of the estimates from the truth , per individual . We observe that only one of the estimators recovers the optimal MSD , which underscores the impact of the objective function decomposition on the learning quality . Finally , we provide an upper bound on the regret of the proposed methods , measured as an average of errors in estimating the parameter in a finite time .
Last year , at least 00 , 000 scientific papers used the Kohn-Sham scheme of density functional theory to solve electronic structure problems in a wide variety of scientific fields , ranging from materials science to biochemistry to astrophysics . Machine learning holds the promise of learning the kinetic energy functional via examples , by-passing the need to solve the Kohn-Sham equations . This should yield substantial savings in computer time , allowing either larger systems or longer time-scales to be tackled , but attempts to machine-learn this functional have been limited by the need to find its derivative . The present work overcomes this difficulty by directly learning the density-potential and energy-density maps for test systems and various molecules . Both improved accuracy and lower computational cost with this method are demonstrated by reproducing DFT energies for a range of molecular geometries generated during molecular dynamics simulations . Moreover , the methodology could be applied directly to quantum chemical calculations , allowing construction of density functionals of quantum-chemical accuracy .
Experiments in particle physics produce enormous quantities of data that must be analyzed and interpreted by teams of physicists . This analysis is often exploratory , where scientists are unable to enumerate the possible types of signal prior to performing the experiment . Thus , tools for summarizing , clustering , visualizing and classifying high-dimensional data are essential . In this work , we show that meaningful physical content can be revealed by transforming the raw data into a learned high-level representation using deep neural networks , with measurements taken at the Daya Bay Neutrino Experiment as a case study . We further show how convolutional deep neural networks can provide an effective classification filter with greater than 00% accuracy across different classes of physics events , significantly better than other machine learning approaches .
We define a generalized likelihood function based on uncertainty measures and show that maximizing such a likelihood function for different measures induces different types of classifiers . In the probabilistic framework , we obtain classifiers that optimize the cross-entropy function . In the possibilistic framework , we obtain classifiers that maximize the interclass margin . Furthermore , we show that the support vector machine is a sub-class of these maximum-margin classifiers .
To answer the existence of optimal swimmer learning/teaching strategies , this work introduces a two-level clustering in order to analyze temporal dynamics of motor learning in breaststroke swimming . Each level have been performed through Sparse Fisher-EM , a unsupervised framework which can be applied efficiently on large and correlated datasets . The induced sparsity selects key points of the coordination phase without any prior knowledge .
Finding efficient and provable methods to solve non-convex optimization problems is an outstanding challenge in machine learning and optimization theory . A popular approach used to tackle non-convex problems is to use convex relaxation techniques to find a convex surrogate for the problem . Unfortunately , convex relaxations typically must be found on a problem-by-problem basis . Thus , providing a general-purpose strategy to estimate a convex relaxation would have a wide reaching impact . Here , we introduce Convex Relaxation Regression ( CoRR ) , an approach for learning convex relaxations for a class of smooth functions . The main idea behind our approach is to estimate the convex envelope of a function $f$ by evaluating $f$ at a set of $T$ random points and then fitting a convex function to these function evaluations . We prove that with probability greater than $0-\delta$ , the solution of our algorithm converges to the global optimizer of $f$ with error $\mathcal{O} \Big ( \big ( \frac{\log ( 0/\delta ) }{T} \big ) ^{\alpha} \Big ) $ for some $\alpha> 0$ . Our approach enables the use of convex optimization tools to solve a class of non-convex optimization problems .
One-bit measurements widely exist in the real world , and they can be used to recover sparse signals . This task is known as the problem of learning halfspaces in learning theory and one-bit compressive sensing ( 0bit-CS ) in signal processing . In this paper , we propose novel algorithms based on both convex and nonconvex sparsity-inducing penalties for robust 0bit-CS . We provide a sufficient condition to verify whether a solution is globally optimal or not . Then we show that the globally optimal solution for positive homogeneous penalties can be obtained in two steps : a proximal operator and a normalization step . For several nonconvex penalties , including minimax concave penalty ( MCP ) , $\ell_0$ norm , and sorted $\ell_0$ penalty , we provide fast algorithms for finding the analytical solutions by solving the dual problem . Specifically , our algorithm is more than $000$ times faster than the existing algorithm for MCP . Its efficiency is comparable to the algorithm for the $\ell_0$ penalty in time , while its performance is much better . Among these penalties , the sorted $\ell_0$ penalty is most robust to noise in different settings .
We present online prediction methods for univariate and multivariate time series that allow us to handle nonstationary artifacts present in most real time series . Specifically , we show that applying appropriate transformations to such time series can lead to improved theoretical and empirical prediction performance . Moreover , since these transformations are usually unknown , we employ the learning with experts setting to develop a fully online method ( NonSTOP ) for predicting nonstationary time series . This framework allows for seasonality and/or other trends in univariate time series and cointegration in multivariate time series . Our algorithms and regret analysis subsumes recent related work while significantly expanding the applicability of such methods . For all the methods , we provide sub-linear regret bounds using relaxed assumptions . We note that the theoretical guarantees do not fully capture the benefits of the nonstationary transformations , thus we provide a data-dependent analysis of the follow-the-leader algorithm for least squares loss that provides insight into the success of using nonstationary transformations . We support all of our results with experiments on simulated and real data .
User engagement in social networks depends critically on the number of online actions their users take in the network . Can we design an algorithm that finds when to incentivize users to take actions to maximize the overall activity in a social network ? In this paper , we model the number of online actions over time using multidimensional Hawkes processes , derive an alternate representation of these processes based on stochastic differential equations ( SDEs ) with jumps and , exploiting this alternate representation , address the above question from the perspective of stochastic optimal control of SDEs with jumps . We find that the optimal level of incentivized actions depends linearly on the current level of overall actions . Moreover , the coefficients of this linear relationship can be found by solving a matrix Riccati differential equation , which can be solved efficiently , and a first order differential equation , which has a closed form solution . As a result , we are able to design an efficient online algorithm , Cheshire , to sample the optimal times of the users ' incentivized actions . Experiments on both synthetic and real data gathered from Twitter show that our algorithm is able to consistently maximize the number of online actions more effectively than the state of the art .
We revisit the stochastic limited-memory BFGS ( L-BFGS ) algorithm . By proposing a new framework for the convergence analysis , we prove improved convergence rates and computational complexities of the stochastic L-BFGS algorithms compared to previous works . In addition , we propose several practical acceleration strategies to speed up the empirical performance of such algorithms . We also provide theoretical analyses for most of the strategies . Experiments on large-scale logistic and ridge regression problems demonstrate that our proposed strategies yield significant improvements vis-\`a-vis competing state-of-the-art algorithms .
In this paper I present an extended implementation of the Random ferns algorithm contained in the R package rFerns . It differs from the original by the ability of consuming categorical and numerical attributes instead of only binary ones . Also , instead of using simple attribute subspace ensemble it employs bagging and thus produce error approximation and variable importance measure modelled after Random forest algorithm . I also present benchmarks ' results which show that although Random ferns ' accuracy is mostly smaller than achieved by Random forest , its speed and good quality of importance measure it provides make rFerns a reasonable choice for a specific applications .
For classification problems with significant class imbalance , subsampling can reduce computational costs at the price of inflated variance in estimating model parameters . We propose a method for subsampling efficiently for logistic regression by adjusting the class balance locally in feature space via an accept-reject scheme . Our method generalizes standard case-control sampling , using a pilot estimate to preferentially select examples whose responses are conditionally rare given their features . The biased subsampling is corrected by a post-hoc analytic adjustment to the parameters . The method is simple and requires one parallelizable scan over the full data set . Standard case-control sampling is inconsistent under model misspecification for the population risk-minimizing coefficients $\theta^*$ . By contrast , our estimator is consistent for $\theta^*$ provided that the pilot estimate is . Moreover , under correct specification and with a consistent , independent pilot estimate , our estimator has exactly twice the asymptotic variance of the full-sample MLE - even if the selected subsample comprises a miniscule fraction of the full data set , as happens when the original data are severely imbalanced . The factor of two improves to $0+\frac{0}{c}$ if we multiply the baseline acceptance probabilities by $c>0$ ( and weight points with acceptance probability greater than 0 ) , taking roughly $\frac{0+c}{0}$ times as many data points into the subsample . Experiments on simulated and real data show that our method can substantially outperform standard case-control subsampling .
A new family of penalty functions , adaptive to likelihood , is introduced for model selection in general regression models . It arises naturally through assuming certain types of prior distribution on the regression parameters . To study stability properties of the penalized maximum likelihood estimator , two types of asymptotic stability are defined . Theoretical properties , including the parameter estimation consistency , model selection consistency , and asymptotic stability , are established under suitable regularity conditions . An efficient coordinate-descent algorithm is proposed . Simulation results and real data analysis show that the proposed method has competitive performance in comparison with existing ones .
The idea of computer vision as the Bayesian inverse problem to computer graphics has a long history and an appealing elegance , but it has proved difficult to directly implement . Instead , most vision tasks are approached via complex bottom-up processing pipelines . Here we show that it is possible to write short , simple probabilistic graphics programs that define flexible generative models and to automatically invert them to interpret real-world images . Generative probabilistic graphics programs consist of a stochastic scene generator , a renderer based on graphics software , a stochastic likelihood model linking the renderer ' s output and the data , and latent variables that adjust the fidelity of the renderer and the tolerance of the likelihood model . Representations and algorithms from computer graphics , originally designed to produce high-quality images , are instead used as the deterministic backbone for highly approximate and stochastic generative models . This formulation combines probabilistic programming , computer graphics , and approximate Bayesian computation , and depends only on general-purpose , automatic inference techniques . We describe two applications : reading sequences of degraded and adversarially obscured alphanumeric characters , and inferring 0D road models from vehicle-mounted camera images . Each of the probabilistic graphics programs we present relies on under 00 lines of probabilistic code , and supports accurate , approximately Bayesian inferences about ambiguous real-world images .
Many statistical learning problems can be posed as minimization of a sum of two convex functions , one typically a composition of non-smooth and linear functions . Examples include regression under structured sparsity assumptions . Popular algorithms for solving such problems , e . g . , ADMM , often involve non-trivial optimization subproblems or smoothing approximation . We consider two classes of primal-dual algorithms that do not incur these difficulties , and unify them from a perspective of monotone operator theory . From this unification we propose a continuum of preconditioned forward-backward operator splitting algorithms amenable to parallel and distributed computing . For the entire region of convergence of the whole continuum of algorithms , we establish its rates of convergence . For some known instances of this continuum , our analysis closes the gap in theory . We further exploit the unification to propose a continuum of accelerated algorithms . We show that the whole continuum attains the theoretically optimal rate of convergence . The scalability of the proposed algorithms , as well as their convergence behavior , is demonstrated up to 0 . 0 million variables with a distributed implementation .
Online reviews provided by consumers are a valuable asset for e-Commerce platforms , influencing potential consumers in making purchasing decisions . However , these reviews are of varying quality , with the useful ones buried deep within a heap of non-informative reviews . In this work , we attempt to automatically identify review quality in terms of its helpfulness to the end consumers . In contrast to previous works in this domain exploiting a variety of syntactic and community-level features , we delve deep into the semantics of reviews as to what makes them useful , providing interpretable explanation for the same . We identify a set of consistency and semantic factors , all from the text , ratings , and timestamps of user-generated reviews , making our approach generalizable across all communities and domains . We explore review semantics in terms of several latent factors like the expertise of its author , his judgment about the fine-grained facets of the underlying product , and his writing style . These are cast into a Hidden Markov Model -- Latent Dirichlet Allocation ( HMM-LDA ) based model to jointly infer : ( i ) reviewer expertise , ( ii ) item facets , and ( iii ) review helpfulness . Large-scale experiments on five real-world datasets from Amazon show significant improvement over state-of-the-art baselines in predicting and ranking useful reviews .
Network embeddings have become very popular in learning effective feature representations of networks . Motivated by the recent successes of embeddings in natural language processing , researchers have tried to find network embeddings in order to exploit machine learning algorithms for mining tasks like node classification and edge prediction . However , most of the work focuses on finding distributed representations of nodes , which are inherently ill-suited to tasks such as community detection which are intuitively dependent on subgraphs . Here , we propose sub0vec , an unsupervised scalable algorithm to learn feature representations of arbitrary subgraphs . We provide means to characterize similarties between subgraphs and provide theoretical analysis of sub0vec and demonstrate that it preserves the so-called local proximity . We also highlight the usability of sub0vec by leveraging it for network mining tasks , like community detection . We show that sub0vec gets significant gains over state-of-the-art methods and node-embedding methods . In particular , sub0vec offers an approach to generate a richer vocabulary of features of subgraphs to support representation and reasoning .
It has often been taken as a working assumption that directed links in information networks are frequently formed by " short-cutting " a two-step path between the source and the destination -- a kind of implicit " link copying " analogous to the process of triadic closure in social networks . Despite the role of this assumption in theoretical models such as preferential attachment , it has received very little direct empirical investigation . Here we develop a formalization and methodology for studying this type of directed closure process , and we provide evidence for its important role in the formation of links on Twitter . We then analyze a sequence of models designed to capture the structural phenomena related to directed closure that we observe in the Twitter data .
A major drawback of backpropagation through time ( BPTT ) is the difficulty of learning long-term dependencies , coming from having to propagate credit information backwards through every single step of the forward computation . This makes BPTT both computationally impractical and biologically implausible . For this reason , full backpropagation through time is rarely used on long sequences , and truncated backpropagation through time is used as a heuristic . However , this usually leads to biased estimates of the gradient in which longer term dependencies are ignored . Addressing this issue , we propose an alternative algorithm , Sparse Attentive Backtracking , which might also be related to principles used by brains to learn long-term dependencies . Sparse Attentive Backtracking learns an attention mechanism over the hidden states of the past and selectively backpropagates through paths with high attention weights . This allows the model to learn long term dependencies while only backtracking for a small number of time steps , not just from the recent past but also from attended relevant past states .
We develop a Bayesian nonparametric approach to a general family of latent class problems in which individuals can belong simultaneously to multiple classes and where each class can be exhibited multiple times by an individual . We introduce a combinatorial stochastic process known as the negative binomial process ( NBP ) as an infinite-dimensional prior appropriate for such problems . We show that the NBP is conjugate to the beta process , and we characterize the posterior distribution under the beta-negative binomial process ( BNBP ) and hierarchical models based on the BNBP ( the HBNBP ) . We study the asymptotic properties of the BNBP and develop a three-parameter extension of the BNBP that exhibits power-law behavior . We derive MCMC algorithms for posterior inference under the HBNBP , and we present experiments using these algorithms in the domains of image segmentation , object recognition , and document analysis .
Decentralized optimization algorithms have received much attention due to the recent advances in network information processing . However , conventional decentralized algorithms based on projected gradient descent are incapable of handling high dimensional constrained problems , as the projection step becomes computationally prohibitive to compute . To address this problem , this paper adopts a projection-free optimization approach , a . k . a . ~the Frank-Wolfe ( FW ) or conditional gradient algorithm . We first develop a decentralized FW ( DeFW ) algorithm from the classical FW algorithm . The convergence of the proposed algorithm is studied by viewing the decentralized algorithm as an inexact FW algorithm . Using a diminishing step size rule and letting $t$ be the iteration number , we show that the DeFW algorithm ' s convergence rate is ${\cal O} ( 0/t ) $ for convex objectives ; is ${\cal O} ( 0/t^0 ) $ for strongly convex objectives with the optimal solution in the interior of the constraint set ; and is ${\cal O} ( 0/\sqrt{t} ) $ towards a stationary point for smooth but non-convex objectives . We then show that a consensus-based DeFW algorithm meets the above guarantees with two communication rounds per iteration . Furthermore , we demonstrate the advantages of the proposed DeFW algorithm on low-complexity robust matrix completion and communication efficient sparse learning . Numerical results on synthetic and real data are presented to support our findings .
We investigate in this paper the architecture of deep convolutional networks . Building on existing state of the art models , we propose a reconfiguration of the model parameters into several parallel branches at the global network level , with each branch being a standalone CNN . We show that this arrangement is an efficient way to significantly reduce the number of parameters without losing performance or to significantly improve the performance with the same level of performance . The use of branches brings an additional form of regularization . In addition to the split into parallel branches , we propose a tighter coupling of these branches by placing the " fuse ( averaging ) layer " before the Log-Likelihood and SoftMax layers during training . This gives another significant performance improvement , the tighter coupling favouring the learning of better representations , even at the level of the individual branches . We refer to this branched architecture as " coupled ensembles " . The approach is very generic and can be applied with almost any DCNN architecture . With coupled ensembles of DenseNet-BC and parameter budget of 00M , we obtain error rates of 0 . 00% , 00 . 00% and 0 . 00% respectively on CIFAR-00 , CIFAR-000 and SVHN tasks . For the same budget , DenseNet-BC has error rate of 0 . 00% , 00 . 00% , and 0 . 0% respectively . With ensembles of coupled ensembles , of DenseNet-BC networks , with 00M total parameters , we obtain error rates of 0 . 00% , 00 . 00% and 0 . 00% respectively on these tasks .
We consider the problem of recommending relevant labels ( items ) for a given data point ( user ) . In particular , we are interested in the practically important setting where the evaluation is with respect to non-decomposable ( over labels ) performance metrics like the $F_0$ measure , and the training data has missing labels . To this end , we propose a generic framework that given a performance metric $\Psi$ , can devise a regularized objective function and a threshold such that all the values in the predicted score vector above and only above the threshold are selected to be positive . We show that the regret or generalization error in the given metric $\Psi$ is bounded ultimately by estimation error of certain underlying parameters . In particular , we derive regret bounds under three popular settings : a ) collaborative filtering , b ) multilabel classification , and c ) PU ( positive-unlabeled ) learning . For each of the above problems , we can obtain precise non-asymptotic regret bound which is small even when a large fraction of labels is missing . Our empirical results on synthetic and benchmark datasets demonstrate that by explicitly modeling for missing labels and optimizing the desired performance metric , our algorithm indeed achieves significantly better performance ( like $F_0$ score ) when compared to methods that do not model missing label information carefully .
Recently , deep residual networks have been successfully applied in many computer vision and natural language processing tasks , pushing the state-of-the-art performance with deeper and wider architectures . In this work , we interpret deep residual networks as ordinary differential equations ( ODEs ) , which have long been studied in mathematics and physics with rich theoretical and empirical success . From this interpretation , we develop a theoretical framework on stability and reversibility of deep neural networks , and derive three reversible neural network architectures that can go arbitrarily deep in theory . The reversibility property allows a memory-efficient implementation , which does not need to store the activations for most hidden layers . Together with the stability of our architectures , this enables training deeper networks using only modest computational resources . We provide both theoretical analyses and empirical results . Experimental results demonstrate the efficacy of our architectures against several strong baselines on CIFAR-00 , CIFAR-000 and STL-00 with superior or on-par state-of-the-art performance . Furthermore , we show our architectures yield superior results when trained using fewer training data .
Most learning algorithms are not invariant to the scale of the function that is being approximated . We propose to adaptively normalize the targets used in learning . This is useful in value-based reinforcement learning , where the magnitude of appropriate value approximations can change over time when we update the policy of behavior . Our main motivation is prior work on learning to play Atari games , where the rewards were all clipped to a predetermined range . This clipping facilitates learning across many different games with a single learning algorithm , but a clipped reward function can result in qualitatively different behavior . Using the adaptive normalization we can remove this domain-specific heuristic without diminishing overall performance .
The Fisher information matrix ( FIM ) is a foundational concept in statistical signal processing . The FIM depends on the probability distribution , assumed to belong to a smooth parametric family . Traditional approaches to estimating the FIM require estimating the probability distribution function ( PDF ) , or its parameters , along with its gradient or Hessian . However , in many practical situations the PDF of the data is not known but the statistician has access to an observation sample for any parameter value . Here we propose a method of estimating the FIM directly from sampled data that does not require knowledge of the underlying PDF . The method is based on non-parametric estimation of an $f$-divergence over a local neighborhood of the parameter space and a relation between curvature of the $f$-divergence and the FIM . Thus we obtain an empirical estimator of the FIM that does not require density estimation and is asymptotically consistent . We empirically evaluate the validity of our approach using two experiments .
While modern day web applications aim to create impact at the civilization level , they have become vulnerable to adversarial activity , where the next cyber-attack can take any shape and can originate from anywhere . The increasing scale and sophistication of attacks , has prompted the need for a data driven solution , with machine learning forming the core of many cybersecurity systems . Machine learning was not designed with security in mind , and the essential assumption of stationarity , requiring that the training and testing data follow similar distributions , is violated in an adversarial domain . In this paper , an adversary ' s view point of a classification based system , is presented . Based on a formal adversarial model , the Seed-Explore-Exploit framework is presented , for simulating the generation of data driven and reverse engineering attacks on classifiers . Experimental evaluation , on 00 real world datasets and using the Google Cloud Prediction Platform , demonstrates the innate vulnerability of classifiers and the ease with which evasion can be carried out , without any explicit information about the classifier type , the training data or the application domain . The proposed framework , algorithms and empirical evaluation , serve as a white hat analysis of the vulnerabilities , and aim to foster the development of secure machine learning frameworks .
Deep learning models require extensive architecture design exploration and hyperparameter optimization to perform well on a given task . The exploration of the model design space is often made by a human expert , and optimized using a combination of grid search and search heuristics over a large space of possible choices . Neural Architecture Search ( NAS ) is a Reinforcement Learning approach that has been proposed to automate architecture design . NAS has been successfully applied to generate Neural Networks that rival the best human-designed architectures . However , NAS requires sampling , constructing , and training hundreds to thousands of models to achieve well-performing architectures . This procedure needs to be executed from scratch for each new task . The application of NAS to a wide set of tasks currently lacks a way to transfer generalizable knowledge across tasks . In this paper , we present the Multitask Neural Model Search ( MNMS ) controller . Our goal is to learn a generalizable framework that can condition model construction on successful model searches for previously seen tasks , thus significantly speeding up the search for new tasks . We demonstrate that MNMS can conduct an automated architecture search for multiple tasks simultaneously while still learning well-performing , specialized models for each task . We then show that pre-trained MNMS controllers can transfer learning to new tasks . By leveraging knowledge from previous searches , we find that pre-trained MNMS models start from a better location in the search space and reduce search time on unseen tasks , while still discovering models that outperform published human-designed models .
Latent variable models can be used to probabilistically " fill-in " missing data entries . The variational autoencoder architecture ( Kingma and Welling , 0000 ; Rezende et al . , 0000 ) includes a " recognition " or " encoder " network that infers the latent variables given the data variables . However , it is not clear how to handle missing data variables in this network . We show how to calculate exactly the latent posterior distribution for the factor analysis ( FA ) model in the presence of missing data , and note that this solution exhibits a non-trivial dependence on the pattern of missingness . Experiments compare the effectiveness of various approaches to filling in the missing data .
We propose a simple but strong baseline for time series classification from scratch with deep neural networks . Our proposed baseline models are pure end-to-end without any heavy preprocessing on the raw data or feature crafting . The proposed Fully Convolutional Network ( FCN ) achieves premium performance to other state-of-the-art approaches and our exploration of the very deep neural networks with the ResNet structure is also competitive . The global average pooling in our convolutional model enables the exploitation of the Class Activation Map ( CAM ) to find out the contributing region in the raw data for the specific labels . Our models provides a simple choice for the real world application and a good starting point for the future research . An overall analysis is provided to discuss the generalization capability of our models , learned features , network structures and the classification semantics .
Many learning tasks , such as cross-validation , parameter search , or leave-one-out analysis , involve multiple instances of similar problems , each instance sharing a large part of learning data with the others . We introduce a robust framework for solving multiple square-root LASSO problems , based on a sketch of the learning data that uses low-rank approximations . Our approach allows a dramatic reduction in computational effort , in effect reducing the number of observations from $m$ ( the number of observations to start with ) to $k$ ( the number of singular values retained in the low-rank model ) , while not sacrificing---sometimes even improving---the statistical performance . Theoretical analysis , as well as numerical experiments on both synthetic and real data , illustrate the efficiency of the method in large scale applications .
The group membership prediction ( GMP ) problem involves predicting whether or not a collection of instances share a certain semantic property . For instance , in kinship verification given a collection of images , the goal is to predict whether or not they share a {\it familial} relationship . In this context we propose a novel probability model and introduce latent {\em view-specific} and {\em view-shared} random variables to jointly account for the view-specific appearance and cross-view similarities among data instances . Our model posits that data from each view is independent conditioned on the shared variables . This postulate leads to a parametric probability model that decomposes group membership likelihood into a tensor product of data-independent parameters and data-dependent factors . We propose learning the data-independent parameters in a discriminative way with bilinear classifiers , and test our prediction algorithm on challenging visual recognition tasks such as multi-camera person re-identification and kinship verification . On most benchmark datasets , our method can significantly outperform the current state-of-the-art .
This paper presents an acceleration framework for packing linear programming problems where the amount of data available is limited , i . e . , where the number of constraints m is small compared to the variable dimension n . The framework can be used as a black box to speed up linear programming solvers dramatically , by two orders of magnitude in our experiments . We present worst-case guarantees on the quality of the solution and the speedup provided by the algorithm , showing that the framework provides an approximately optimal solution while running the original solver on a much smaller problem . The framework can be used to accelerate exact solvers , approximate solvers , and parallel/distributed solvers . Further , it can be used for both linear programs and integer linear programs .
Bipartite data is common in data engineering and brings unique challenges , particularly when it comes to clustering tasks that impose on strong structural assumptions . This work presents an unsupervised method for assessing similarity in bipartite data . Similar to some co-clustering methods , the method is based on regular equivalence in graphs . The algorithm uses spectral properties of a bipartite adjacency matrix to estimate similarity in both dimensions . The method is reflexive in that similarity in one dimension is used to inform similarity in the other . Reflexive regular equivalence can also use the structure of transitivities -- in a network sense -- the contribution of which is controlled by the algorithm ' s only free-parameter , $\alpha$ . The method is completely unsupervised and can be used to validate assumptions of co-similarity , which are required but often untested , in co-clustering analyses . Three variants of the method with different normalizations are tested on synthetic data . The method is found to be robust to noise and well-suited to asymmetric co-similar structure , making it particularly informative for cluster analysis and recommendation in bipartite data of unknown structure . In experiments , the convergence and speed of the algorithm are found to be stable for different levels of noise . Real-world data from a network of malaria genes are analyzed , where the similarity produced by the reflexive method is shown to out-perform other measures ' ability to correctly classify genes .
Assessing the performance of a learned model is a crucial part of machine learning . However , in some domains only positive and unlabeled examples are available , which prohibits the use of most standard evaluation metrics . We propose an approach to estimate any metric based on contingency tables , including ROC and PR curves , using only positive and unlabeled data . Estimating these performance metrics is essentially reduced to estimating the fraction of ( latent ) positives in the unlabeled set , assuming known positives are a random sample of all positives . We provide theoretical bounds on the quality of our estimates , illustrate the importance of estimating the fraction of positives in the unlabeled set and demonstrate empirically that we are able to reliably estimate ROC and PR curves on real data .
A nonparametric family of conditional distributions is introduced , which generalizes conditional exponential families using functional parameters in a suitable RKHS . An algorithm is provided for learning the generalized natural parameter , and consistency of the estimator is established in the well specified case . In experiments , the new method generally outperforms a competing approach with consistency guarantees , and is competitive with a deep conditional density model on datasets that exhibit abrupt transitions and heteroscedasticity .
In this paper , we deal with two challenges for measuring the similarity of the subject identities in practical video-based face recognition - the variation of the head pose in uncontrolled environments and the computational expense of processing videos . Since the frame-wise feature mean is unable to characterize the pose diversity among frames , we define and preserve the overall pose diversity and closeness in a video . Then , identity will be the only source of variation across videos since the pose varies even within a single video . Instead of simply using all the frames , we select those faces whose pose point is closest to the centroid of the K-means cluster containing that pose point . Then , we represent a video as a bag of frame-wise deep face features while the number of features has been reduced from hundreds to K . Since the video representation can well represent the identity , now we measure the subject similarity between two videos as the max correlation among all possible pairs in the two bags of features . On the official 0 , 000 video-pairs of the YouTube Face dataset for face verification , our algorithm achieves a comparable performance with VGG-face that averages over deep features of all frames . Other vision tasks can also benefit from the generic idea of employing geometric cues to improve the descriptiveness of deep features .
In this paper we are going to introduce a new nearest neighbours based approach to clustering , and compare it with previous solutions ; the resulting algorithm , which takes inspiration from both DBscan and minimum spanning tree approaches , is deterministic but proves simpler , faster and doesnt require to set in advance a value for k , the number of clusters .
In this paper we develop an Expectation Maximization ( EM ) algorithm to estimate the parameter of a Yule-Simon distribution . The Yule-Simon distribution exhibits the " rich get richer " effect whereby an 00-00 type of rule tends to dominate . These distributions are ubiquitous in industrial settings . The EM algorithm presented provides both frequentist and Bayesian estimates of the $\lambda$ parameter . By placing the estimation method within the EM framework we are able to derive Standard errors of the resulting estimate . Additionally , we prove convergence of the Yule-Simon EM algorithm and study the rate of convergence . An explicit , closed form solution for the rate of convergence of the algorithm is given .
Community detection , which aims to cluster $N$ nodes in a given graph into $r$ distinct groups based on the observed undirected edges , is an important problem in network data analysis . In this paper , the popular stochastic block model ( SBM ) is extended to the generalized stochastic block model ( GSBM ) that allows for adversarial outlier nodes , which are connected with the other nodes in the graph in an arbitrary way . Under this model , we introduce a procedure using convex optimization followed by $k$-means algorithm with $k=r$ . Both theoretical and numerical properties of the method are analyzed . A theoretical guarantee is given for the procedure to accurately detect the communities with small misclassification rate under the setting where the number of clusters can grow with $N$ . This theoretical result admits to the best-known result in the literature of computationally feasible community detection in SBM without outliers . Numerical results show that our method is both computationally fast and robust to different kinds of outliers , while some popular computationally fast community detection algorithms , such as spectral clustering applied to adjacency matrices or graph Laplacians , may fail to retrieve the major clusters due to a small portion of outliers . We apply a slight modification of our method to a political blogs data set , showing that our method is competent in practice and comparable to existing computationally feasible methods in the literature . To the best of the authors ' knowledge , our result is the first in the literature in terms of clustering communities with fast growing numbers under the GSBM where a portion of arbitrary outlier nodes exist .
We consider parametric exponential families of dimension $K$ on the real line . We study a variant of \textit{boundary crossing probabilities} coming from the multi-armed bandit literature , in the case when the real-valued distributions form an exponential family of dimension $K$ . Formally , our result is a concentration inequality that bounds the probability that $\mathcal{B}^\psi ( \hat \theta_n , \theta^\star ) \geq f ( t/n ) /n$ , where $\theta^\star$ is the parameter of an unknown target distribution , $\hat \theta_n$ is the empirical parameter estimate built from $n$ observations , $\psi$ is the log-partition function of the exponential family and $\mathcal{B}^\psi$ is the corresponding Bregman divergence . From the perspective of stochastic multi-armed bandits , we pay special attention to the case when the boundary function $f$ is logarithmic , as it is enables to analyze the regret of the state-of-the-art \KLUCB\ and \KLUCBp\ strategies , whose analysis was left open in such generality . Indeed , previous results only hold for the case when $K=0$ , while we provide results for arbitrary finite dimension $K$ , thus considerably extending the existing results . Perhaps surprisingly , we highlight that the proof techniques to achieve these strong results already existed three decades ago in the work of T . L . Lai , and were apparently forgotten in the bandit community . We provide a modern rewriting of these beautiful techniques that we believe are useful beyond the application to stochastic multi-armed bandits .
Multilayer networks are a useful data structure for simultaneously capturing multiple types of relationships between a set of nodes . In such networks , each relational definition gives rise to a layer . While each layer provides its own set of information , community structure across layers can be collectively utilized to discover and quantify underlying relational patterns between nodes . To concisely extract information from a multilayer network , we propose to identify and combine sets of layers with meaningful similarities in community structure . In this paper , we describe the " strata multilayer stochastic block model ' ' ( sMLSBM ) , a probabilistic model for multilayer community structure . The central extension of the model is that there exist groups of layers , called " strata ' ' , which are defined such that all layers in a given stratum have community structure described by a common stochastic block model ( SBM ) . That is , layers in a stratum exhibit similar node-to-community assignments and SBM probability parameters . Fitting the sMLSBM to a multilayer network provides a joint clustering that yields node-to-community and layer-to-stratum assignments , which cooperatively aid one another during inference . We describe an algorithm for separating layers into their appropriate strata and an inference technique for estimating the SBM parameters for each stratum . We demonstrate our method using synthetic networks and a multilayer network inferred from data collected in the Human Microbiome Project .
In the mixture models problem it is assumed that there are $K$ distributions $\theta_{0} , \ldots , \theta_{K}$ and one gets to observe a sample from a mixture of these distributions with unknown coefficients . The goal is to associate instances with their generating distributions , or to identify the parameters of the hidden distributions . In this work we make the assumption that we have access to several samples drawn from the same $K$ underlying distributions , but with different mixing weights . As with topic modeling , having multiple samples is often a reasonable assumption . Instead of pooling the data into one sample , we prove that it is possible to use the differences between the samples to better recover the underlying structure . We present algorithms that recover the underlying structure under milder assumptions than the current state of art when either the dimensionality or the separation is high . The methods , when applied to topic modeling , allow generalization to words not present in the training data .
Cluster analysis and outlier detection are strongly coupled tasks in data mining area . Cluster structure can be easily destroyed by few outliers ; on the contrary , the outliers are defined by the concept of cluster , which are recognized as the points belonging to none of the clusters . However , most existing studies handle them separately . In light of this , we consider the joint cluster analysis and outlier detection problem , and propose the Clustering with Outlier Removal ( COR ) algorithm . Generally speaking , the original space is transformed into the binary space via generating basic partitions in order to define clusters . Then an objective function based Holoentropy is designed to enhance the compactness of each cluster with a few outliers removed . With further analyses on the objective function , only partial of the problem can be handled by K-means optimization . To provide an integrated solution , an auxiliary binary matrix is nontrivally introduced so that COR completely and efficiently solves the challenging problem via a unified K-means- - with theoretical supports . Extensive experimental results on numerous data sets in various domains demonstrate the effectiveness and efficiency of COR significantly over the rivals including K-means- - and other state-of-the-art outlier detection methods in terms of cluster validity and outlier detection . Some key factors in COR are further analyzed for practical use . Finally , an application on flight trajectory is provided to demonstrate the effectiveness of COR in the real-world scenario .
The method of " random Fourier features ( RFF ) " has become a popular tool for approximating the " radial basis function ( RBF ) " kernel . The variance of RFF is actually large . Interestingly , the variance can be substantially reduced by a simple normalization step as we theoretically demonstrate . We name the improved scheme as the " normalized RFF ( NRFF ) " . We also propose the " generalized min-max ( GMM ) " kernel as a measure of data similarity . GMM is positive definite as there is an associated hashing method named " generalized consistent weighted sampling ( GCWS ) " which linearizes this nonlinear kernel . We provide an extensive empirical evaluation of the RBF kernel and the GMM kernel on more than 00 publicly available datasets . For a majority of the datasets , the ( tuning-free ) GMM kernel outperforms the best-tuned RBF kernel . We conduct extensive experiments for comparing the linearized RBF kernel using NRFF with the linearized GMM kernel using GCWS . We observe that , to reach a comparable classification accuracy , GCWS typically requires substantially fewer samples than NRFF , even on datasets where the original RBF kernel outperforms the original GMM kernel . The empirical success of GCWS ( compared to NRFF ) can also be explained from a theoretical perspective . Firstly , the relative variance ( normalized by the squared expectation ) of GCWS is substantially smaller than that of NRFF , except for the very high similarity region ( where the variances of both methods are close to zero ) . Secondly , if we make a model assumption on the data , we can show analytically that GCWS exhibits much smaller variance than NRFF for estimating the same object ( e . g . , the RBF kernel ) , except for the very high similarity region .
We present the first differentially private algorithms for reinforcement learning , which apply to the task of evaluating a fixed policy . We establish two approaches for achieving differential privacy , provide a theoretical analysis of the privacy and utility of the two algorithms , and show promising results on simple empirical examples .
Outlier detection plays an essential role in many data-driven applications to identify isolated instances that are different from the majority . While many statistical learning and data mining techniques have been used for developing more effective outlier detection algorithms , the interpretation of detected outliers does not receive much attention . Interpretation is becoming increasingly important to help people trust and evaluate the developed models through providing intrinsic reasons why the certain outliers are chosen . It is difficult , if not impossible , to simply apply feature selection for explaining outliers due to the distinct characteristics of various detection models , complicated structures of data in certain applications , and imbalanced distribution of outliers and normal instances . In addition , the role of contrastive contexts where outliers locate , as well as the relation between outliers and contexts , are usually overlooked in interpretation . To tackle the issues above , in this paper , we propose a novel Contextual Outlier INterpretation ( COIN ) method to explain the abnormality of existing outliers spotted by detectors . The interpretability for an outlier is achieved from three aspects : outlierness score , attributes that contribute to the abnormality , and contextual description of its neighborhoods . Experimental results on various types of datasets demonstrate the flexibility and effectiveness of the proposed framework compared with existing interpretation approaches .
Vector autoregression ( VAR ) is a fundamental tool for modeling the joint dynamics of multivariate time series . However , as the number of component series is increased , the VAR model quickly becomes overparameterized , making reliable estimation difficult and impeding its adoption as a forecasting tool in high dimensional settings . A number of authors have sought to address this issue by incorporating regularized approaches , such as the lasso , that impose sparse or low-rank structures on the estimated coefficient parameters of the VAR . More traditional approaches attempt to address overparameterization by selecting a low lag order , based on the assumption that dynamic dependence among components is short-range . However , these methods typically assume a single , universal lag order that applies across all components , unnecessarily constraining the dynamic relationship between the components and impeding forecast performance . The lasso-based approaches are more flexible but do not incorporate the notion of lag order selection . We propose a new class of regularized VAR models , called hierarchical vector autoregression ( HVAR ) , that embed the notion of lag selection into a convex regularizer . The key convex modeling tool is a group lasso with nested groups which ensure the sparsity pattern of autoregressive lag coefficients honors the ordered structure inherent to VAR . We provide computationally efficient algorithms for solving HVAR problems that can be parallelized across the components . A simulation study shows the improved performance in forecasting and lag order selection over previous approaches , and a macroeconomic application further highlights forecasting improvements as well as the convenient , interpretable output of a HVAR model .
In an end-to-end dialog system , the aim of dialog state tracking is to accurately estimate a compact representation of the current dialog status from a sequence of noisy observations produced by the speech recognition and the natural language understanding modules . This paper introduces a novel method of dialog state tracking based on the general paradigm of machine reading and proposes to solve it using an End-to-End Memory Network , MemN0N , a memory-enhanced neural network architecture . We evaluate the proposed approach on the second Dialog State Tracking Challenge ( DSTC-0 ) dataset . The corpus has been converted for the occasion in order to frame the hidden state variable inference as a question-answering task based on a sequence of utterances extracted from a dialog . We show that the proposed tracker gives encouraging results . Then , we propose to extend the DSTC-0 dataset with specific reasoning capabilities requirement like counting , list maintenance , yes-no question answering and indefinite knowledge management . Finally , we present encouraging results using our proposed MemN0N based tracking model .
Performing statistical inference in high-dimension is an outstanding challenge . A major source of difficulty is the absence of precise information on the distribution of high-dimensional estimators . Here , we consider linear regression in the high-dimensional regime $p\gg n$ . In this context , we would like to perform inference on a high-dimensional parameters vector $\theta^*\in{\mathbb R}^p$ . Important progress has been achieved in computing confidence intervals for single coordinates $\theta^*_i$ . A key role in these new methods is played by a certain debiased estimator $\hat{\theta}^{\rm d}$ that is constructed from the Lasso . Earlier work establishes that , under suitable assumptions on the design matrix , the coordinates of $\hat{\theta}^{\rm d}$ are asymptotically Gaussian provided $\theta^*$ is $s_0$-sparse with $s_0 = o ( \sqrt{n}/\log p ) $ . The condition $s_0 = o ( \sqrt{n}/ \log p ) $ is stronger than the one for consistent estimation , namely $s_0 = o ( n/ \log p ) $ . We study Gaussian designs with known or unknown population covariance . When the covariance is known , we prove that the debiased estimator is asymptotically Gaussian under the nearly optimal condition $s_0 = o ( n/ ( \log p ) ^0 ) $ . Note that earlier work was limited to $s_0 = o ( \sqrt{n}/\log p ) $ even for perfectly known covariance . The same conclusion holds if the population covariance is unknown but can be estimated sufficiently well , e . g . under the same sparsity conditions on the inverse covariance as assumed by earlier work . For intermediate regimes , we describe the trade-off between sparsity in the coefficients and in the inverse covariance of the design . We further discuss several applications of our results to high-dimensional inference . In particular , we propose a new estimator that is minimax optimal up to a factor $0+o_n ( 0 ) $ for i . i . d . Gaussian designs .
Limbo is an open-source C++00 library for Bayesian optimization which is designed to be both highly flexible and very fast . It can be used to optimize functions for which the gradient is unknown , evaluations are expensive , and runtime cost matters ( e . g . , on embedded systems or robots ) . Benchmarks on standard functions show that Limbo is about 0 times faster than BayesOpt ( another C++ library ) for a similar accuracy .
Gaussian Processes ( GPs ) are widely used tools in statistics , machine learning , robotics , computer vision , and scientific computation . However , despite their popularity , they can be difficult to apply ; all but the simplest classification or regression applications require specification and inference over complex covariance functions that do not admit simple analytical posteriors . This paper shows how to embed Gaussian processes in any higher-order probabilistic programming language , using an idiom based on memoization , and demonstrates its utility by implementing and extending classic and state-of-the-art GP applications . The interface to Gaussian processes , called gpmem , takes an arbitrary real-valued computational process as input and returns a statistical emulator that automatically improve as the original process is invoked and its input-output behavior is recorded . The flexibility of gpmem is illustrated via three applications : ( i ) robust GP regression with hierarchical hyper-parameter learning , ( ii ) discovering symbolic expressions from time-series data by fully Bayesian structure learning over kernels generated by a stochastic grammar , and ( iii ) a bandit formulation of Bayesian optimization with automatic inference and action selection . All applications share a single 00-line Python library and require fewer than 00 lines of probabilistic code each .
Information Cascades Model captures dynamical properties of user activity in a social network . In this work , we develop a novel framework for activity shaping under the Continuous-Time Information Cascades Model which allows the administrator for local control actions by allocating targeted resources that can alter the spread of the process . Our framework employs the optimization of the spectral radius of the Hazard matrix , a quantity that has been shown to drive the maximum influence in a network , while enjoying a simple convex relaxation when used to minimize the influence of the cascade . In addition , use-cases such as quarantine and node immunization are discussed to highlight the generality of the proposed activity shaping framework . Finally , we present the NetShape influence minimization method which is compared favorably to baseline and state-of-the-art approaches through simulations on real social networks .
Motivated by vision tasks such as robust face and object recognition , we consider the following general problem : given a collection of low-dimensional linear subspaces in a high-dimensional ambient ( image ) space and a query point ( image ) , efficiently determine the nearest subspace to the query in $\ell^0$ distance . We show in theory that Cauchy random embedding of the objects into significantly-lower-dimensional spaces helps preserve the identity of the nearest subspace with constant probability . This offers the possibility of efficiently selecting several candidates for accurate search . We sketch preliminary experiments on robust face and digit recognition to corroborate our theory .
Despite the prevalence of collaborative filtering in recommendation systems , there has been little theoretical development on why and how well it works , especially in the " online " setting , where items are recommended to users over time . We address this theoretical gap by introducing a model for online recommendation systems , cast item recommendation under the model as a learning problem , and analyze the performance of a cosine-similarity collaborative filtering method . In our model , each of $n$ users either likes or dislikes each of $m$ items . We assume there to be $k$ types of users , and all the users of a given type share a common string of probabilities determining the chance of liking each item . At each time step , we recommend an item to each user , where a key distinction from related bandit literature is that once a user consumes an item ( e . g . , watches a movie ) , then that item cannot be recommended to the same user again . The goal is to maximize the number of likable items recommended to users over time . Our main result establishes that after nearly $\log ( km ) $ initial learning time steps , a simple collaborative filtering algorithm achieves essentially optimal performance without knowing $k$ . The algorithm has an exploitation step that uses cosine similarity and two types of exploration steps , one to explore the space of items ( standard in the literature ) and the other to explore similarity between users ( novel to this work ) .
The problem of multiple hypothesis testing arises when there are more than one hypothesis to be tested simultaneously for statistical significance . This is a very common situation in many data mining applications . For instance , assessing simultaneously the significance of all frequent itemsets of a single dataset entails a host of hypothesis , one for each itemset . A multiple hypothesis testing method is needed to control the number of false positives ( Type I error ) . Our contribution in this paper is to extend the multiple hypothesis framework to be used with a generic data mining algorithm . We provide a method that provably controls the family-wise error rate ( FWER , the probability of at least one false positive ) in the strong sense . We evaluate the performance of our solution on both real and generated data . The results show that our method controls the FWER while maintaining the power of the test .
Motivated by the reconstruction and the prediction of electricity consumption , we extend Nonnegative Matrix Factorization~ ( NMF ) to take into account side information ( column or row features ) . We consider general linear measurement settings , and propose a framework which models non-linear relationships between features and the response variables . We extend previous theoretical results to obtain a sufficient condition on the identifiability of the NMF in this setting . Based the classical Hierarchical Alternating Least Squares~ ( HALS ) algorithm , we propose a new algorithm ( HALSX , or Hierarchical Alternating Least Squares with eXogeneous variables ) which estimates the factorization model . The algorithm is validated on both simulated and real electricity consumption datasets as well as a recommendation dataset , to show its performance in matrix recovery and prediction for new rows and columns .
Multitask learning can be effective when features useful in one task are also useful for other tasks , and the group lasso is a standard method for selecting a common subset of features . In this paper , we are interested in a less restrictive form of multitask learning , wherein ( 0 ) the available features can be organized into subsets according to a notion of similarity and ( 0 ) features useful in one task are similar , but not necessarily identical , to the features best suited for other tasks . The main contribution of this paper is a new procedure called Sparse Overlapping Sets ( SOS ) lasso , a convex optimization that automatically selects similar features for related learning tasks . Error bounds are derived for SOSlasso and its consistency is established for squared error loss . In particular , SOSlasso is motivated by multi- subject fMRI studies in which functional activity is classified using brain voxels as features . Experiments with real and synthetic data demonstrate the advantages of SOSlasso compared to the lasso and group lasso .
The main aim of this paper is to provide an analysis of gradient descent ( GD ) algorithms with gradient errors that do not necessarily vanish , asymptotically . In particular , sufficient conditions are presented for both stability ( almost sure boundedness of the iterates ) and convergence of GD with bounded , ( possibly ) non-diminishing gradient errors . In addition to ensuring stability , such an algorithm is shown to converge to a small neighborhood of the minimum set , which depends on the gradient errors . It is worth noting that the main result of this paper can be used to show that GD with asymptotically vanishing errors indeed converges to the minimum set . The results presented herein are not only more general when compared to previous results , but our analysis of GD with errors is new to the literature to the best of our knowledge . Our work extends the contributions of Mangasarian & Solodov , Bertsekas & Tsitsiklis and Tadic & Doucet . Using our framework , a simple yet effective implementation of GD using simultaneous perturbation stochastic approximations ( SP SA ) , with constant sensitivity parameters , is presented . Another important improvement over many previous results is that there are no `additional ' restrictions imposed on the step-sizes . In machine learning applications where step-sizes are related to learning rates , our assumptions , unlike those of other papers , do not affect these learning rates . Finally , we present experimental results to validate our theory .
We consider the fundamental problem in non-convex optimization of efficiently reaching a stationary point . In contrast to the convex case , in the long history of this basic problem , the only known theoretical results on first-order non-convex optimization remain to be full gradient descent that converges in $O ( 0/\varepsilon ) $ iterations for smooth objectives , and stochastic gradient descent that converges in $O ( 0/\varepsilon^0 ) $ iterations for objectives that are sum of smooth functions . We provide the first improvement in this line of research . Our result is based on the variance reduction trick recently introduced to convex optimization , as well as a brand new analysis of variance reduction that is suitable for non-convex optimization . For objectives that are sum of smooth functions , our first-order minibatch stochastic method converges with an $O ( 0/\varepsilon ) $ rate , and is faster than full gradient descent by $\Omega ( n^{0/0} ) $ . We demonstrate the effectiveness of our methods on empirical risk minimizations with non-convex loss functions and training neural nets .
We present a system and a set of techniques for learning linear predictors with convex losses on terascale datasets , with trillions of features , {The number of features here refers to the number of non-zero entries in the data matrix . } billions of training examples and millions of parameters in an hour using a cluster of 0000 machines . Individually none of the component techniques are new , but the careful synthesis required to obtain an efficient implementation is . The result is , up to our knowledge , the most scalable and efficient linear learning system reported in the literature ( as of 0000 when our experiments were conducted ) . We describe and thoroughly evaluate the components of the system , showing the importance of the various design choices .
Representation learning has become an invaluable approach for learning from symbolic data such as text and graphs . However , while complex symbolic datasets often exhibit a latent hierarchical structure , state-of-the-art methods typically learn embeddings in Euclidean vector spaces , which do not account for this property . For this purpose , we introduce a new approach for learning hierarchical representations of symbolic data by embedding them into hyperbolic space -- or more precisely into an n-dimensional Poincar\ ' e ball . Due to the underlying hyperbolic geometry , this allows us to learn parsimonious representations of symbolic data by simultaneously capturing hierarchy and similarity . We introduce an efficient algorithm to learn the embeddings based on Riemannian optimization and show experimentally that Poincar\ ' e embeddings outperform Euclidean embeddings significantly on data with latent hierarchies , both in terms of representation capacity and in terms of generalization ability .
We introduce Dimple , a fully open-source API for probabilistic modeling . Dimple allows the user to specify probabilistic models in the form of graphical models , Bayesian networks , or factor graphs , and performs inference ( by automatically deriving an inference engine from a variety of algorithms ) on the model . Dimple also serves as a compiler for GP0 , a hardware accelerator for inference .
In this work , we present the Grounded Recurrent Neural Network ( GRNN ) , a recurrent neural network architecture for multi-label prediction which explicitly ties labels to specific dimensions of the recurrent hidden state ( we call this process " grounding " ) . The approach is particularly well-suited for extracting large numbers of concepts from text . We apply the new model to address an important problem in healthcare of understanding what medical concepts are discussed in clinical text . Using a publicly available dataset derived from Intensive Care Units , we learn to label a patient ' s diagnoses and procedures from their discharge summary . Our evaluation shows a clear advantage to using our proposed architecture over a variety of strong baselines .
We introduce a learning framework called learning using privileged information ( LUPI ) to the computer vision field . We focus on the prototypical computer vision problem of teaching computers to recognize objects in images . We want the computers to be able to learn faster at the expense of providing extra information during training time . As additional information about the image data , we look at several scenarios that have been studied in computer vision before : attributes , bounding boxes and image tags . The information is privileged as it is available at training time but not at test time . We explore two maximum-margin techniques that are able to make use of this additional source of information , for binary and multiclass object classification . We interpret these methods as learning easiness and hardness of the objects in the privileged space and then transferring this knowledge to train a better classifier in the original space . We provide a thorough analysis and comparison of information transfer from privileged to the original data spaces for both LUPI methods . Our experiments show that incorporating privileged information can improve the classification accuracy . Finally , we conduct user studies to understand which samples are easy and which are hard for human learning , and explore how this information is related to easy and hard samples when learning a classifier .
Since their invention , generative adversarial networks ( GANs ) have become a popular approach for learning to model a distribution of real ( unlabeled ) data . Convergence problems during training are overcome by Wasserstein GANs which minimize the distance between the model and the empirical distribution in terms of a different metric , but thereby introduce a Lipschitz constraint into the optimization problem . A simple way to enforce the Lipschitz constraint on the class of functions , which can be modeled by the neural network , is weight clipping . It was proposed that training can be improved by instead augmenting the loss by a regularization term that penalizes the deviation of the gradient of the critic ( as a function of the network ' s input ) from one . We present theoretical arguments why using a weaker regularization term enforcing the Lipschitz constraint is preferable . These arguments are supported by experimental results on toy data sets .
Sparse principal component analysis ( sparse PCA ) aims at finding a sparse basis to improve the interpretability over the dense basis of PCA , meanwhile the sparse basis should cover the data subspace as much as possible . In contrast to most of existing work which deal with the problem by adding some sparsity penalties on various objectives of PCA , in this paper , we propose a new method SPCArt , whose motivation is to find a rotation matrix and a sparse basis such that the sparse basis approximates the basis of PCA after the rotation . The algorithm of SPCArt consists of three alternating steps : rotate PCA basis , truncate small entries , and update the rotation matrix . Its performance bounds are also given . SPCArt is efficient , with each iteration scaling linearly with the data dimension . It is easy to choose parameters in SPCArt , due to its explicit physical explanations . Besides , we give a unified view to several existing sparse PCA methods and discuss the connection with SPCArt . Some ideas in SPCArt are extended to GPower , a popular sparse PCA algorithm , to overcome its drawback . Experimental results demonstrate that SPCArt achieves the state-of-the-art performance . It also achieves a good tradeoff among various criteria , including sparsity , explained variance , orthogonality , balance of sparsity among loadings , and computational speed .
A central question in statistical learning is to design algorithms that not only perform well on training data , but also generalize to new and unseen data . In this paper , we tackle this question by formulating a distributionally robust stochastic optimization ( DRSO ) problem , which seeks a solution that minimizes the worst-case expected loss over a family of distributions that are close to the empirical distribution in Wasserstein distances . We establish a connection between such Wasserstein DRSO and regularization . More precisely , we identify a broad class of loss functions , for which the Wasserstein DRSO is asymptotically equivalent to a regularization problem with a gradient-norm penalty . Such relation provides new interpretations for problems involving regularization , including a great number of statistical learning problems and discrete choice models ( e . g . multinomial logit ) . The connection suggests a principled way to regularize high-dimensional , non-convex problems . This is demonstrated through the training of Wasserstein generative adversarial networks in deep learning .
The development of molecular signatures for the prediction of time-to-event outcomes is a methodologically challenging task in bioinformatics and biostatistics . Although there are numerous approaches for the derivation of marker combinations and their evaluation , the underlying methodology often suffers from the problem that different optimization criteria are mixed during the feature selection , estimation and evaluation steps . This might result in marker combinations that are only suboptimal regarding the evaluation criterion of interest . To address this issue , we propose a unified framework to derive and evaluate biomarker combinations . Our approach is based on the concordance index for time-to-event data , which is a non-parametric measure to quantify the discrimatory power of a prediction rule . Specifically , we propose a component-wise boosting algorithm that results in linear biomarker combinations that are optimal with respect to a smoothed version of the concordance index . We investigate the performance of our algorithm in a large-scale simulation study and in two molecular data sets for the prediction of survival in breast cancer patients . Our numerical results show that the new approach is not only methodologically sound but can also lead to a higher discriminatory power than traditional approaches for the derivation of gene signatures .
We study the scenario of graph-based clustering algorithms such as spectral clustering . Given a set of data points , one first has to construct a graph on the data points and then apply a graph clustering algorithm to find a suitable partition of the graph . Our main question is if and how the construction of the graph ( choice of the graph , choice of parameters , choice of weights ) influences the outcome of the final clustering result . To this end we study the convergence of cluster quality measures such as the normalized cut or the Cheeger cut on various kinds of random geometric graphs as the sample size tends to infinity . It turns out that the limit values of the same objective function are systematically different on different types of graphs . This implies that clustering results systematically depend on the graph and can be very different for different types of graph . We provide examples to illustrate the implications on spectral clustering .
We study the statistical limits of both detecting and estimating a rank-one deformation of a symmetric random Gaussian tensor . We establish upper and lower bounds on the critical signal-to-noise ratio , under a variety of priors for the planted vector : ( i ) a uniformly sampled unit vector , ( ii ) i . i . d . $\pm 0$ entries , and ( iii ) a sparse vector where a constant fraction $\rho$ of entries are i . i . d . $\pm 0$ and the rest are zero . For each of these cases , our upper and lower bounds match up to a $0+o ( 0 ) $ factor as the order $d$ of the tensor becomes large . For sparse signals ( iii ) , our bounds are also asymptotically tight in the sparse limit $\rho \to 0$ for any fixed $d$ ( including the $d=0$ case of sparse PCA ) . Our upper bounds for ( i ) demonstrate a phenomenon reminiscent of the work of Baik , Ben Arous and P\ ' ech\ ' e : an `eigenvalue ' of a perturbed tensor emerges from the bulk at a strictly lower signal-to-noise ratio than when the perturbation itself exceeds the bulk ; we quantify the size of this effect . We also provide some general results for larger classes of priors . In particular , the large $d$ asymptotics of the threshold location differs between problems with discrete priors versus continuous priors . Finally , for priors ( i ) and ( ii ) we carry out the replica prediction from statistical physics , which is conjectured to give the exact information-theoretic threshold for any fixed $d$ . Of independent interest , we introduce a new improvement to the second moment method for contiguity , on which our lower bounds are based . Our technique conditions away from rare `bad ' events that depend on interactions between the signal and noise . This enables us to close $\sqrt{0}$-factor gaps present in several previous works .
One of the most fundamental problems in causal inference is the estimation of a causal effect when variables are confounded . This is difficult in an observational study , because one has no direct evidence that all confounders have been adjusted for . We introduce a novel approach for estimating causal effects that exploits observational conditional independencies to suggest " weak " paths in a unknown causal graph . The widely used faithfulness condition of Spirtes et al . is relaxed to allow for varying degrees of " path cancellations " that imply conditional independencies but do not rule out the existence of confounding causal paths . The outcome is a posterior distribution over bounds on the average causal effect via a linear programming approach and Bayesian inference . We claim this approach should be used in regular practice along with other default tools in observational studies .
Engineering problems often involve data sources of variable fidelity with different costs of obtaining an observation . In particular , one can use both a cheap low fidelity function ( e . g . a computational experiment with a CFD code ) and an expensive high fidelity function ( e . g . a wind tunnel experiment ) to generate a data sample in order to construct a regression model of a high fidelity function . The key question in this setting is how the sizes of the high and low fidelity data samples should be selected in order to stay within a given computational budget and maximize accuracy of the regression model prior to committing resources on data acquisition . In this paper we obtain minimax interpolation errors for single and variable fidelity scenarios for a multivariate Gaussian process regression . Evaluation of the minimax errors allows us to identify cases when the variable fidelity data provides better interpolation accuracy than the exclusively high fidelity data for the same computational budget . These results allow us to calculate the optimal shares of variable fidelity data samples under the given computational budget constraint . Real and synthetic data experiments suggest that using the obtained optimal shares often outperforms natural heuristics in terms of the regression accuracy .
The maximal information coefficient ( MIC ) is a tool for finding the strongest pairwise relationships in a data set with many variables ( Reshef et al . , 0000 ) . MIC is useful because it gives similar scores to equally noisy relationships of different types . This property , called {\em equitability} , is important for analyzing high-dimensional data sets . Here we formalize the theory behind both equitability and MIC in the language of estimation theory . This formalization has a number of advantages . First , it allows us to show that equitability is a generalization of power against statistical independence . Second , it allows us to compute and discuss the population value of MIC , which we call MIC_* . In doing so we generalize and strengthen the mathematical results proven in Reshef et al . ( 0000 ) and clarify the relationship between MIC and mutual information . Introducing MIC_* also enables us to reason about the properties of MIC more abstractly : for instance , we show that MIC_* is continuous and that there is a sense in which it is a canonical " smoothing " of mutual information . We also prove an alternate , equivalent characterization of MIC_* that we use to state new estimators of it as well as an algorithm for explicitly computing it when the joint probability density function of a pair of random variables is known . Our hope is that this paper provides a richer theoretical foundation for MIC and equitability going forward . This paper will be accompanied by a forthcoming companion paper that performs extensive empirical analysis and comparison to other methods and discusses the practical aspects of both equitability and the use of MIC and its related statistics .
Artificial neural networks are most commonly trained with the back-propagation algorithm , where the gradient for learning is provided by back-propagating the error , layer by layer , from the output layer to the hidden layers . A recently discovered method called feedback-alignment shows that the weights used for propagating the error backward don ' t have to be symmetric with the weights used for propagation the activation forward . In fact , random feedback weights work evenly well , because the network learns how to make the feedback useful . In this work , the feedback alignment principle is used for training hidden layers more independently from the rest of the network , and from a zero initial condition . The error is propagated through fixed random feedback connections directly from the output layer to each hidden layer . This simple method is able to achieve zero training error even in convolutional networks and very deep networks , completely without error back-propagation . The method is a step towards biologically plausible machine learning because the error signal is almost local , and no symmetric or reciprocal weights are required . Experiments show that the test performance on MNIST and CIFAR is almost as good as those obtained with back-propagation for fully connected networks . If combined with dropout , the method achieves 0 . 00% error on the permutation invariant MNIST task .
Natural disasters can have catastrophic impacts on the functionality of infrastructure systems and cause severe physical and socio-economic losses . Given budget constraints , it is crucial to optimize decisions regarding mitigation , preparedness , response , and recovery practices for these systems . This requires accurate and efficient means to evaluate the infrastructure system reliability . While numerous research efforts have addressed and quantified the impact of natural disasters on infrastructure systems , typically using the Monte Carlo approach , they still suffer from high computational cost and , thus , are of limited applicability to large systems . This paper presents a deep learning framework for accelerating infrastructure system reliability analysis . In particular , two distinct deep neural network surrogates are constructed and studied : ( 0 ) A classifier surrogate which speeds up the connectivity determination of networks , and ( 0 ) An end-to-end surrogate that replaces a number of components such as roadway status realization , connectivity determination , and connectivity averaging . The proposed approach is applied to a simulation-based study of the two-terminal connectivity of a California transportation network subject to extreme probabilistic earthquake events . Numerical results highlight the effectiveness of the proposed approach in accelerating the transportation system two-terminal reliability analysis with extremely high prediction accuracy .
In this paper we propose a novel application of Gaussian processes ( GPs ) to financial asset allocation . Our approach is deeply rooted in Stochastic Portfolio Theory ( SPT ) , a stochastic analysis framework introduced by Robert Fernholz that aims at flexibly analysing the performance of certain investment strategies in stock markets relative to benchmark indices . In particular , SPT has exhibited some investment strategies based on company sizes that , under realistic assumptions , outperform benchmark indices with probability 0 over certain time horizons . Galvanised by this result , we consider the inverse problem that consists of learning ( from historical data ) an optimal investment strategy based on any given set of trading characteristics , and using a user-specified optimality criterion that may go beyond outperforming a benchmark index . Although this inverse problem is of the utmost interest to investment management practitioners , it can hardly be tackled using the SPT framework . We show that our machine learning approach learns investment strategies that considerably outperform existing SPT strategies in the US stock market .
The bootstrap provides a simple and powerful means of assessing the quality of estimators . However , in settings involving large datasets , the computation of bootstrap-based quantities can be prohibitively demanding . As an alternative , we present the Bag of Little Bootstraps ( BLB ) , a new procedure which incorporates features of both the bootstrap and subsampling to obtain a robust , computationally efficient means of assessing estimator quality . BLB is well suited to modern parallel and distributed computing architectures and retains the generic applicability , statistical efficiency , and favorable theoretical properties of the bootstrap . We provide the results of an extensive empirical and theoretical investigation of BLB ' s behavior , including a study of its statistical correctness , its large-scale implementation and performance , selection of hyperparameters , and performance on real data .
Non-negative matrix factorization ( NMF ) is a technique for finding latent representations of data . The method has been applied to corpora to construct topic models . However , NMF has likelihood assumptions which are often violated by real document corpora . We present a double parametric bootstrap test for evaluating the fit of an NMF-based topic model based on the duality of the KL divergence and Poisson maximum likelihood estimation . The test correctly identifies whether a topic model based on an NMF approach yields reliable results in simulated and real data .
The bipartite record linkage task consists of merging two disparate datafiles containing information on two overlapping sets of entities . This is non-trivial in the absence of unique identifiers and it is important for a wide variety of applications given that it needs to be solved whenever we have to combine information from different sources . Most statistical techniques currently used for record linkage are derived from a seminal paper by Fellegi and Sunter ( 0000 ) . These techniques usually assume independence in the matching statuses of record pairs to derive estimation procedures and optimal point estimators . We argue that this independence assumption is unreasonable and instead target a bipartite matching between the two datafiles as our parameter of interest . Bayesian implementations allow us to quantify uncertainty on the matching decisions and derive a variety of point estimators using different loss functions . We propose partial Bayes estimates that allow uncertain parts of the bipartite matching to be left unresolved . We evaluate our approach to record linkage using a variety of challenging scenarios and show that it outperforms the traditional methodology . We illustrate the advantages of our methods merging two datafiles on casualties from the civil war of El Salvador .
Both the human brain and artificial learning agents operating in real-world or comparably complex environments are faced with the challenge of online model selection . In principle this challenge can be overcome : hierarchical Bayesian inference provides a principled method for model selection and it converges on the same posterior for both off-line ( i . e . batch ) and online learning . However , maintaining a parameter posterior for each model in parallel has in general an even higher memory cost than storing the entire data set and is consequently clearly unfeasible . Alternatively , maintaining only a limited set of models in memory could limit memory requirements . However , sufficient statistics for one model will usually be insufficient for fitting a different kind of model , meaning that the agent loses information with each model change . We propose that episodic memory can circumvent the challenge of limited memory-capacity online model selection by retaining a selected subset of data points . We design a method to compute the quantities necessary for model selection even when the data is discarded and only statistics of one ( or few ) learnt models are available . We demonstrate on a simple model that a limited-sized episodic memory buffer , when the content is optimised to retain data with statistics not matching the current representation , can resolve the fundamental challenge of online model selection .
We introduce a class of learning problems where the agent is presented with a series of tasks . Intuitively , if there is relation among those tasks , then the information gained during execution of one task has value for the execution of another task . Consequently , the agent is intrinsically motivated to explore its environment beyond the degree necessary to solve the current task it has at hand . We develop a decision theoretic setting that generalises standard reinforcement learning tasks and captures this intuition . More precisely , we consider a multi-stage stochastic game between a learning agent and an opponent . We posit that the setting is a good model for the problem of life-long learning in uncertain environments , where while resources must be spent learning about currently important tasks , there is also the need to allocate effort towards learning about aspects of the world which are not relevant at the moment . This is due to the fact that unpredictable future events may lead to a change of priorities for the decision maker . Thus , in some sense , the model " explains " the necessity of curiosity . Apart from introducing the general formalism , the paper provides algorithms . These are evaluated experimentally in some exemplary domains . In addition , performance bounds are proven for some cases of this problem .
Researchers often summarize their work in the form of posters . Posters provide a coherent and efficient way to convey core ideas from scientific papers . Generating a good scientific poster , however , is a complex and time consuming cognitive task , since such posters need to be readable , informative , and visually aesthetic . In this paper , for the first time , we study the challenging problem of learning to generate posters from scientific papers . To this end , a data-driven framework , that utilizes graphical models , is proposed . Specifically , given content to display , the key elements of a good poster , including panel layout and attributes of each panel , are learned and inferred from data . Then , given inferred layout and attributes , composition of graphical elements within each panel is synthesized . To learn and validate our model , we collect and make public a Poster-Paper dataset , which consists of scientific papers and corresponding posters with exhaustively labelled panels and attributes . Qualitative and quantitative results indicate the effectiveness of our approach .
We study the performance of stochastically trained deep neural networks ( DNNs ) whose synaptic weights are implemented using emerging memristive devices that exhibit limited dynamic range , resolution , and variability in their programming characteristics . We show that a key device parameter to optimize the learning efficiency of DNNs is the variability in its programming characteristics . DNNs with such memristive synapses , even with dynamic range as low as $00$ and only $00$ discrete levels , when trained based on stochastic updates suffer less than $0\%$ loss in accuracy compared to floating point software baseline . We also study the performance of stochastic memristive DNNs when used as inference engines with noise corrupted data and find that if the device variability can be minimized , the relative degradation in performance for the Stochastic DNN is better than that of the software baseline . Hence , our study presents a new optimization corner for memristive devices for building large noise-immune deep learning systems .
The Efficient Global Optimization ( EGO ) algorithm uses a conditional Gaus-sian Process ( GP ) to approximate an objective function known at a finite number of observation points and sequentially adds new points which maximize the Expected Improvement criterion according to the GP . The important factor that controls the efficiency of EGO is the GP covariance function ( or kernel ) which should be chosen according to the objective function . Traditionally , a pa-rameterized family of covariance functions is considered whose parameters are learned through statistical procedures such as maximum likelihood or cross-validation . However , it may be questioned whether statistical procedures for learning covariance functions are the most efficient for optimization as they target a global agreement between the GP and the observations which is not the ultimate goal of optimization . Furthermore , statistical learning procedures are computationally expensive . The main alternative to the statistical learning of the GP is self-adaptation , where the algorithm tunes the kernel parameters based on their contribution to objective function improvement . After questioning the possibility of self-adaptation for kriging based optimizers , this paper proposes a novel approach for tuning the length-scale of the GP in EGO : At each iteration , a small ensemble of kriging models structured by their length-scales is created . All of the models contribute to an iterate in an EGO-like fashion . Then , the set of models is densified around the model whose length-scale yielded the best iterate and further points are produced . Numerical experiments are provided which motivate the use of many length-scales . The tested implementation does not perform better than the classical EGO algorithm in a sequential context but show the potential of the approach for parallel implementations .
The standard Kernel Quadrature method for numerical integration with random point sets ( also called Bayesian Monte Carlo ) is known to converge in root mean square error at a rate determined by the ratio $s/d$ , where $s$ and $d$ encode the smoothness and dimension of the integrand . However , an empirical investigation reveals that the rate constant $C$ is highly sensitive to the distribution of the random points . In contrast to standard Monte Carlo integration , for which optimal importance sampling is well-understood , the sampling distribution that minimises $C$ for Kernel Quadrature does not admit a closed form . This paper argues that the practical choice of sampling distribution is an important open problem . One solution is considered ; a novel automatic approach based on adaptive tempering and sequential Monte Carlo . Empirical results demonstrate a dramatic reduction in integration error of up to 0 orders of magnitude can be achieved with the proposed method .
The aim of this short note is to draw attention to a method by which the partition function and marginal probabilities for a certain class of random fields on complete graphs can be computed in polynomial time . This class includes Ising models with homogeneous pairwise potentials but arbitrary ( inhomogeneous ) unary potentials . Similarly , the partition function and marginal probabilities can be computed in polynomial time for random fields on complete bipartite graphs , provided they have homogeneous pairwise potentials . We expect that these tractable classes of large scale random fields can be very useful for the evaluation of approximation algorithms by providing exact error estimates .
Under a Bayesian framework , we formulate the fully sequential sampling and selection decision in statistical ranking and selection as a stochastic control problem , and derive the associated Bellman equation . Using value function approximation , we derive an approximately optimal allocation policy . We show that this policy is not only computationally efficient but also possesses both one-step-ahead and asymptotic optimality for independent normal sampling distributions . Moreover , the proposed allocation policy is easily generalizable in the approximate dynamic programming paradigm .
We propose a novel method for maximum likelihood-based parameter inference in nonlinear and/or non-Gaussian state space models . The method is an iterative procedure with three steps . At each iteration a particle filter is used to estimate the value of the log-likelihood function at the current parameter iterate . Using these log-likelihood estimates , a surrogate objective function is created by utilizing a Gaussian process model . Finally , we use a heuristic procedure to obtain a revised parameter iterate , providing an automatic trade-off between exploration and exploitation of the surrogate model . The method is profiled on two state space models with good performance both considering accuracy and computational cost .
Finding " densely connected clusters " in a graph is in general an important and well studied problem in the literature \cite{Schaeffer} . It has various applications in pattern recognition , social networking and data mining \cite{Duda , Mishra} . Recently , Ames and Vavasis have suggested a novel method for finding cliques in a graph by using convex optimization over the adjacency matrix of the graph \cite{Ames , Ames0} . Also , there has been recent advances in decomposing a given matrix into its " low rank " and " sparse " components \cite{Candes , Chandra} . In this paper , inspired by these results , we view " densely connected clusters " as imperfect cliques , where imperfections correspond missing edges , which are relatively sparse . We analyze the problem in a probabilistic setting and aim to detect disjointly planted clusters . Our main result basically suggests that , one can find \emph{dense} clusters in a graph , as long as the clusters are sufficiently large . We conclude by discussing possible extensions and future research directions .
Dynamical systems with large state-spaces are often expensive to thoroughly explore experimentally . Coarse-graining methods aim to define simpler systems which are more amenable to analysis and exploration ; most current methods , however , focus on a priori state aggregation based on similarities in transition rates , which is not necessarily reflected in similar behaviours at the level of trajectories . We propose a way to coarsen the state-space of a system which optimally preserves the satisfaction of a set of logical specifications about the system ' s trajectories . Our approach is based on Gaussian Process emulation and Multi-Dimensional Scaling , a dimensionality reduction technique which optimally preserves distances in non-Euclidean spaces . We show how to obtain low-dimensional visualisations of the system ' s state-space from the perspective of properties ' satisfaction , and how to define macro-states which behave coherently with respect to the specifications . Our approach is illustrated on a non-trivial running example , showing promising performance and high computational efficiency .
Driving styles have a great influence on vehicle fuel economy , active safety , and drivability . To recognize driving styles of path-tracking behaviors for different divers , a statistical pattern-recognition method is developed to deal with the uncertainty of driving styles or characteristics based on probability density estimation . First , to describe driver path-tracking styles , vehicle speed and throttle opening are selected as the discriminative parameters , and a conditional kernel density function of vehicle speed and throttle opening is built , respectively , to describe the uncertainty and probability of two representative driving styles , e . g . , aggressive and normal . Meanwhile , a posterior probability of each element in feature vector is obtained using full Bayesian theory . Second , a Euclidean distance method is involved to decide to which class the driver should be subject instead of calculating the complex covariance between every two elements of feature vectors . By comparing the Euclidean distance between every elements in feature vector , driving styles are classified into seven levels ranging from low normal to high aggressive . Subsequently , to show benefits of the proposed pattern-recognition method , a cross-validated method is used , compared with a fuzzy logic-based pattern-recognition method . The experiment results show that the proposed statistical pattern-recognition method for driving styles based on kernel density estimation is more efficient and stable than the fuzzy logic-based method .
Path queries on a knowledge graph can be used to answer compositional questions such as " What languages are spoken by people living in Lisbon ? " . However , knowledge graphs often have missing facts ( edges ) which disrupts path queries . Recent models for knowledge base completion impute missing facts by embedding knowledge graphs in vector spaces . We show that these models can be recursively applied to answer path queries , but that they suffer from cascading errors . This motivates a new " compositional " training objective , which dramatically improves all models ' ability to answer path queries , in some cases more than doubling accuracy . On a standard knowledge base completion task , we also demonstrate that compositional training acts as a novel form of structural regularization , reliably improving performance across all base models ( reducing errors by up to 00% ) and achieving new state-of-the-art results .
We study the problem of nonparametric dependence detection . Many existing methods suffer severe power loss due to non-uniform consistency , which we illustrate with a paradox . To avoid such power loss , we approach the nonparametric test of independence through the new framework of binary expansion statistics ( BEStat ) and binary expansion testing ( BET ) , which examine dependence through a novel binary expansion filtration approximation of the copula . Through a Hadamard-Walsh transform , we find that the cross interactions of binary variables in the filtration are complete sufficient statistics for dependence . These interactions are also uncorrelated under the null . By utilizing these interactions , the BET avoids the problem of non-uniform consistency and improves upon a wide class of commonly used methods ( a ) by achieving the minimax rate in sample size requirement for specified power and ( b ) by providing clear interpretations of global and local relationships upon rejection of independence . The binary expansion approach also connects the test statistics with the current computing system to facilitate efficient bitwise implementation . We illustrate the BET by a study of the distribution of stars in the night sky and by an exploratory data analysis of the TCGA breast cancer data .
In an era where accumulating data is easy and storing it inexpensive , feature selection plays a central role in helping to reduce the high-dimensionality of huge amounts of otherwise meaningless data . In this paper , we propose a graph-based method for feature selection that ranks features by identifying the most important ones into arbitrary set of cues . Mapping the problem on an affinity graph-where features are the nodes-the solution is given by assessing the importance of nodes through some indicators of centrality , in particular , the Eigen-vector Centrality ( EC ) . The gist of EC is to estimate the importance of a feature as a function of the importance of its neighbors . Ranking central nodes individuates candidate features , which turn out to be effective from a classification point of view , as proved by a thoroughly experimental section . Our approach has been tested on 0 diverse datasets from recent literature ( e . g . , biological data and object recognition , among others ) , and compared against filter , embedded and wrappers methods . The results are remarkable in terms of accuracy , stability and low execution time .
We provide new results concerning label efficient , polynomial time , passive and active learning of linear separators . We prove that active learning provides an exponential improvement over PAC ( passive ) learning of homogeneous linear separators under nearly log-concave distributions . Building on this , we provide a computationally efficient PAC algorithm with optimal ( up to a constant factor ) sample complexity for such problems . This resolves an open question concerning the sample complexity of efficient PAC algorithms under the uniform distribution in the unit ball . Moreover , it provides the first bound for a polynomial-time PAC algorithm that is tight for an interesting infinite class of hypothesis functions under a general and natural class of data-distributions , providing significant progress towards a longstanding open question . We also provide new bounds for active and passive learning in the case that the data might not be linearly separable , both in the agnostic case and and under the Tsybakov low-noise condition . To derive our results , we provide new structural results for ( nearly ) log-concave distributions , which might be of independent interest as well .
Estimation in generalized linear models ( GLM ) is complicated by the presence of constraints . One can handle constraints by maximizing a penalized log-likelihood . Penalties such as the lasso are effective in high dimensions , but often lead to unwanted shrinkage . This paper explores instead penalizing the squared distance to constraint sets . Distance penalties are more flexible than algebraic and regularization penalties , and avoid the drawback of shrinkage . To optimize distance penalized objectives , we make use of the majorization-minimization principle . Resulting algorithms constructed within this framework are amenable to acceleration and come with global convergence guarantees . Applications to shape constraints , sparse regression , and rank-restricted matrix regression on synthetic and real data showcase strong empirical performance , even under non-convex constraints .
Machine learning algorithms are optimized to model statistical properties of the training data . If the input data reflects stereotypes and biases of the broader society , then the output of the learning algorithm also captures these stereotypes . In this paper , we initiate the study of gender stereotypes in {\em word embedding} , a popular framework to represent text data . As their use becomes increasingly common , applications can inadvertently amplify unwanted stereotypes . We show across multiple datasets that the embeddings contain significant gender stereotypes , especially with regard to professions . We created a novel gender analogy task and combined it with crowdsourcing to systematically quantify the gender bias in a given embedding . We developed an efficient algorithm that reduces gender stereotype using just a handful of training examples while preserving the useful geometric properties of the embedding . We evaluated our algorithm on several metrics . While we focus on male/female stereotypes , our framework may be applicable to other types of embedding biases .
Sparsity inducing regularization is an important part for learning over-complete visual representations . Despite the popularity of $\ell_0$ regularization , in this paper , we investigate the usage of non-convex regularizations in this problem . Our contribution consists of three parts . First , we propose the leaky capped norm regularization ( LCNR ) , which allows model weights below a certain threshold to be regularized more strongly as opposed to those above , therefore imposes strong sparsity and only introduces controllable estimation bias . We propose a majorization-minimization algorithm to optimize the joint objective function . Second , our study over monocular 0D shape recovery and neural networks with LCNR outperforms $\ell_0$ and other non-convex regularizations , achieving state-of-the-art performance and faster convergence . Third , we prove a theoretical global convergence speed on the 0D recovery problem . To the best of our knowledge , this is the first convergence analysis of the 0D recovery problem .
We consider learning the possible causal direction of two observed variables in the presence of latent confounding variables . Several existing methods have been shown to consistently estimate causal direction assuming linear or some type of nonlinear relationship and no latent confounders . However , the estimation results could be distorted if either assumption is actually violated . In this paper , we first propose a new linear non-Gaussian acyclic structural equation model with individual-specific effects that allows latent confounders to be considered . We then propose an empirical Bayesian approach for estimating possible causal direction using the new model . We demonstrate the effectiveness of our method using artificial and real-world data .
Estimating statistical models within sensor networks requires distributed algorithms , in which both data and computation are distributed across the nodes of the network . We propose a general approach for distributed learning based on combining local estimators defined by pseudo-likelihood components , encompassing a number of combination methods , and provide both theoretical and experimental analysis . We show that simple linear combination or max-voting methods , when combined with second-order information , are statistically competitive with more advanced and costly joint optimization . Our algorithms have many attractive properties including low communication and computational cost and " any-time " behavior .
For mass spectra acquired from cancer patients by MALDI or SELDI techniques , automated discrimination between cancer types or stages has often been implemented by machine learnings . These techniques typically generate " black-box " classifiers , which are difficult to interpret biologically . We develop new and efficient signature discovery algorithms leading to interpretable signatures combining the discriminating power of explicitly selected small groups of biomarkers , identified by their m/z ratios . Our approach is based on rigorous stochastic modeling of " homogeneous " datasets of mass spectra by a versatile class of parameterized Markov Random Fields . We present detailed algorithms validated by precise theoretical results . We also outline the successful tests of our approach to generate efficient explicit signatures for six benchmark discrimination tasks , based on mass spectra acquired from colorectal cancer patients , as well as from ovarian cancer patients .
In regression problems , the use of TSK fuzzy systems is widely extended due to the precision of the obtained models . Moreover , the use of simple linear TSK models is a good choice in many real problems due to the easy understanding of the relationship between the output and input variables . In this paper we present FRULER , a new genetic fuzzy system for automatically learning accurate and simple linguistic TSK fuzzy rule bases for regression problems . In order to reduce the complexity of the learned models while keeping a high accuracy , the algorithm consists of three stages : instance selection , multi-granularity fuzzy discretization of the input variables , and the evolutionary learning of the rule base that uses the Elastic Net regularization to obtain the consequents of the rules . Each stage was validated using 00 real-world datasets and FRULER was compared with three state of the art enetic fuzzy systems . Experimental results show that FRULER achieves the most accurate and simple models compared even with approximative approaches .
Yes , they do . This paper provides the first empirical demonstration that deep convolutional models really need to be both deep and convolutional , even when trained with methods such as distillation that allow small or shallow models of high accuracy to be trained . Although previous research showed that shallow feed-forward nets sometimes can learn the complex functions previously learned by deep nets while using the same number of parameters as the deep models they mimic , in this paper we demonstrate that the same methods cannot be used to train accurate models on CIFAR-00 unless the student models contain multiple layers of convolution . Although the student models do not have to be as deep as the teacher model they mimic , the students need multiple convolutional layers to learn functions of comparable accuracy as the deep convolutional teacher .
Although RNNs have been shown to be powerful tools for processing sequential data , finding architectures or optimization strategies that allow them to model very long term dependencies is still an active area of research . In this work , we carefully analyze two synthetic datasets originally outlined in ( Hochreiter and Schmidhuber , 0000 ) which are used to evaluate the ability of RNNs to store information over many time steps . We explicitly construct RNN solutions to these problems , and using these constructions , illuminate both the problems themselves and the way in which RNNs store different types of information in their hidden states . These constructions furthermore explain the success of recent methods that specify unitary initializations or constraints on the transition matrices .
Hybrid continuous-discrete models naturally represent many real-world applications in robotics , finance , and environmental engineering . Inference with large-scale models is challenging because relational structures deteriorate rapidly during inference with observations . The main contribution of this paper is an efficient relational variational inference algorithm that factors largescale probability models into simpler variational models , composed of mixtures of iid ( Bernoulli ) random variables . The algorithm takes probability relational models of largescale hybrid systems and converts them to a close-to-optimal variational models . Then , it efficiently calculates marginal probabilities on the variational models by using a latent ( or lifted ) variable elimination or a lifted stochastic sampling . This inference is unique because it maintains the relational structure upon individual observations and during inference steps .
We discuss theoretical aspects of the product rule for classification problems in supervised machine learning for the case of combining classifiers . We show that ( 0 ) the product rule arises from the MAP classifier supposing equivalent priors and conditional independence given a class ; ( 0 ) under some conditions , the product rule is equivalent to minimizing the sum of the squared distances to the respective centers of the classes related with different features , such distances being weighted by the spread of the classes ; ( 0 ) observing some hypothesis , the product rule is equivalent to concatenating the vectors of features .
Spectral clustering is amongst the most popular methods for community detection in graphs . A key step in spectral clustering algorithms is the eigen-decomposition of the $n{\times}n$ graph Laplacian matrix to extract its $k$ leading eigenvectors , where $k$ is the desired number of clusters among $n$ objects . This is prohibitively complex to implement for very large datasets . However , it has recently been shown that it is possible to bypass the eigen-decomposition by computing an approximate spectral embedding through graph filtering of random signals . In this paper , we prove that spectral clustering performed via graph filtering can still recover the planted clusters consistently , under mild conditions . We analyse the effects of sparsity , dimensionality and filter approximation error on the consistency of the algorithm .
This work addresses the issue of large covariance matrix estimation in high-dimensional statistical analysis . Recently , improved iterative algorithms with positive-definite guarantee have been developed . However , these algorithms cannot be directly extended to use a nonconvex penalty for sparsity inducing . Generally , a nonconvex penalty has the capability of ameliorating the bias problem of the popular convex lasso penalty , and thus is more advantageous . In this work , we propose a class of positive-definite covariance estimators using generalized nonconvex penalties . We develop a first-order algorithm based on the alternating direction method framework to solve the nonconvex optimization problem efficiently . The convergence of this algorithm has been proved . Further , the statistical properties of the new estimators have been analyzed for generalized nonconvex penalties . Moreover , extension of this algorithm to covariance estimation from sketched measurements has been considered . The performances of the new estimators have been demonstrated by both a simulation study and a gene clustering example for tumor tissues . Code for the proposed estimators is available at https : //github . com/FWen/Nonconvex-PDLCE . git .
Dictionary learning is a cutting-edge area in imaging processing , that has recently led to state-of-the-art results in many signal processing tasks . The idea is to conduct a linear decomposition of a signal using a few atoms of a learned and usually over-completed dictionary instead of a pre-defined basis . Determining a proper size of the to-be-learned dictionary is crucial for both precision and efficiency of the process , while most of the existing dictionary learning algorithms choose the size quite arbitrarily . In this paper , a novel regularization method called the Grouped Smoothly Clipped Absolute Deviation ( GSCAD ) is employed for learning the dictionary . The proposed method can simultaneously learn a sparse dictionary and select the appropriate dictionary size . Efficient algorithm is designed based on the alternative direction method of multipliers ( ADMM ) which decomposes the joint non-convex problem with the non-convex penalty into two convex optimization problems . Several examples are presented for image denoising and the experimental results are compared with other state-of-the-art approaches .
We consider the analysis of high dimensional data given in the form of a matrix with columns consisting of observations and rows consisting of features . Often the data is such that the observations do not reside on a regular grid , and the given order of the features is arbitrary and does not convey a notion of locality . Therefore , traditional transforms and metrics cannot be used for data organization and analysis . In this paper , our goal is to organize the data by defining an appropriate representation and metric such that they respect the smoothness and structure underlying the data . We also aim to generalize the joint clustering of observations and features in the case the data does not fall into clear disjoint groups . For this purpose , we propose multiscale data-driven transforms and metrics based on trees . Their construction is implemented in an iterative refinement procedure that exploits the co-dependencies between features and observations . Beyond the organization of a single dataset , our approach enables us to transfer the organization learned from one dataset to another and to integrate several datasets together . We present an application to breast cancer gene expression analysis : learning metrics on the genes to cluster the tumor samples into cancer sub-types and validating the joint organization of both the genes and the samples . We demonstrate that using our approach to combine information from multiple gene expression cohorts , acquired by different profiling technologies , improves the clustering of tumor samples .
We present a general framework for classification of sparse and irregularly-sampled time series . The properties of such time series can result in substantial uncertainty about the values of the underlying temporal processes , while making the data difficult to deal with using standard classification methods that assume fixed-dimensional feature spaces . To address these challenges , we propose an uncertainty-aware classification framework based on a special computational layer we refer to as the Gaussian process adapter that can connect irregularly sampled time series data to any black-box classifier learnable using gradient descent . We show how to scale up the required computations based on combining the structured kernel interpolation framework and the Lanczos approximation method , and how to discriminatively train the Gaussian process adapter in combination with a number of classifiers end-to-end using backpropagation .
0D Convolutional Neural Networks ( 0D-CNN ) have been used for object recognition based on the voxelized shape of an object . However , interpreting the decision making process of these 0D-CNNs is still an infeasible task . In this paper , we present a unique 0D-CNN based Gradient-weighted Class Activation Mapping method ( 0D-GradCAM ) for visual explanations of the distinct local geometric features of interest within an object . To enable efficient learning of 0D geometries , we augment the voxel data with surface normals of the object boundary . We then train a 0D-CNN with this augmented data and identify the local features critical for decision-making using 0D GradCAM . An application of this feature identification framework is to recognize difficult-to-manufacture drilled hole features in a complex CAD geometry . The framework can be extended to identify difficult-to-manufacture features at multiple spatial scales leading to a real-time design for manufacturability decision support system .
Recent work has demonstrated that problems-- particularly imitation learning and structured prediction-- where a learner ' s predictions influence the input-distribution it is tested on can be naturally addressed by an interactive approach and analyzed using no-regret online learning . These approaches to imitation learning , however , neither require nor benefit from information about the cost of actions . We extend existing results in two directions : first , we develop an interactive imitation learning approach that leverages cost information ; second , we extend the technique to address reinforcement learning . The results provide theoretical support to the commonly observed successes of online approximate policy iteration . Our approach suggests a broad new family of algorithms and provides a unifying view of existing techniques for imitation and reinforcement learning .
Entropy rate of sequential data-streams naturally quantifies the complexity of the generative process . Thus entropy rate fluctuations could be used as a tool to recognize dynamical perturbations in signal sources , and could potentially be carried out without explicit background noise characterization . However , state of the art algorithms to estimate the entropy rate have markedly slow convergence ; making such entropic approaches non-viable in practice . We present here a fundamentally new approach to estimate entropy rates , which is demonstrated to converge significantly faster in terms of input data lengths , and is shown to be effective in diverse applications ranging from the estimation of the entropy rate of English texts to the estimation of complexity of chaotic dynamical systems . Additionally , the convergence rate of entropy estimates do not follow from any standard limit theorem , and reported algorithms fail to provide any confidence bounds on the computed values . Exploiting a connection to the theory of probabilistic automata , we establish a convergence rate of $O ( \log \vert s \vert/\sqrt[0]{\vert s \vert} ) $ as a function of the input length $\vert s \vert$ , which then yields explicit uncertainty estimates , as well as required data lengths to satisfy pre-specified confidence bounds .
We study consistency properties of surrogate loss functions for general multiclass learning problems , defined by a general multiclass loss matrix . We extend the notion of classification calibration , which has been studied for binary and multiclass 0-0 classification problems ( and for certain other specific learning problems ) , to the general multiclass setting , and derive necessary and sufficient conditions for a surrogate loss to be calibrated with respect to a loss matrix in this setting . We then introduce the notion of convex calibration dimension of a multiclass loss matrix , which measures the smallest `size ' of a prediction space in which it is possible to design a convex surrogate that is calibrated with respect to the loss matrix . We derive both upper and lower bounds on this quantity , and use these results to analyze various loss matrices . In particular , we apply our framework to study various subset ranking losses , and use the convex calibration dimension as a tool to show both the existence and non-existence of various types of convex calibrated surrogates for these losses . Our results strengthen recent results of Duchi et al . ( 0000 ) and Calauzenes et al . ( 0000 ) on the non-existence of certain types of convex calibrated surrogates in subset ranking . We anticipate the convex calibration dimension may prove to be a useful tool in the study and design of surrogate losses for general multiclass learning problems .
We address the problem of maximizing an unknown submodular function that can only be accessed via noisy evaluations . Our work is motivated by the task of summarizing content , e . g . , image collections , by leveraging users ' feedback in form of clicks or ratings . For summarization tasks with the goal of maximizing coverage and diversity , submodular set functions are a natural choice . When the underlying submodular function is unknown , users ' feedback can provide noisy evaluations of the function that we seek to maximize . We provide a generic algorithm -- \submM{} -- for maximizing an unknown submodular function under cardinality constraints . This algorithm makes use of a novel exploration module -- \blbox{} -- that proposes good elements based on adaptively sampling noisy function evaluations . \blbox{} is able to accommodate different kinds of observation models such as value queries and pairwise comparisons . We provide PAC-style guarantees on the quality and sampling cost of the solution obtained by \submM{} . We demonstrate the effectiveness of our approach in an interactive , crowdsourced image collection summarization application .
Generative Adversarial Networks ( GAN ) have become one of the most successful frameworks for unsupervised generative modeling . As GANs are difficult to train much research has focused on this . However , very little of this research has directly exploited game-theoretic techniques . We introduce Generative Adversarial Network Games ( GANGs ) , which explicitly model a finite zero-sum game between a generator ( $G$ ) and classifier ( $C$ ) that use mixed strategies . The size of these games precludes exact solution methods , therefore we define resource-bounded best responses ( RBBRs ) , and a resource-bounded Nash Equilibrium ( RB-NE ) as a pair of mixed strategies such that neither $G$ or $C$ can find a better RBBR . The RB-NE solution concept is richer than the notion of `local Nash equilibria ' in that it captures not only failures of escaping local optima of gradient descent , but applies to any approximate best response computations , including methods with random restarts . To validate our approach , we solve GANGs with the Parallel Nash Memory algorithm , which provably monotonically converges to an RB-NE . We compare our results to standard GAN setups , and demonstrate that our method deals well with typical GAN problems such as mode collapse , partial mode coverage and forgetting .
Gaussian process regression generally does not scale to beyond a few thousands data points without applying some sort of kernel approximation method . Most approximations focus on the high eigenvalue part of the spectrum of the kernel matrix , $K$ , which leads to bad performance when the length scale of the kernel is small . In this paper we introduce Multiresolution Kernel Approximation ( MKA ) , the first true broad bandwidth kernel approximation algorithm . Important points about MKA are that it is memory efficient , and it is a direct method , which means that it also makes it easy to approximate $K^{-0}$ and $\mathop{\textrm{det}} ( K ) $ .
In this paper , we propose a coordinate descent approach to low-rank structured semidefinite programming . The approach , which we call the Mixing method , is extremely simple to implement , has no free parameters , and typically attains an order of magnitude or better improvement in optimization performance over the current state of the art . We show that for certain problems , the method is strictly decreasing and guaranteed to converge to a critical point . We then apply the algorithm to three separate domains : solving the maximum cut semidefinite relaxation , solving a ( novel ) maximum satisfiability relaxation , and solving the GloVe word embedding optimization problem . In all settings , we demonstrate improvement over the existing state of the art along various dimensions . In total , this work substantially expands the scope and scale of problems that can be solved using semidefinite programming methods .
The technique of Formal Concept Analysis is applied to a dataset describing the traits of rodents , with the goal of identifying zoonotic disease carriers , or those species carrying infections that can spillover to cause human disease . The concepts identified among these species together provide rules-of-thumb about the intrinsic biological features of rodents that carry zoonotic diseases , and offer utility for better targeting field surveillance efforts in the search for novel disease carriers in the wild .
We consider a stochastic bandit problem with infinitely many arms . In this setting , the learner has no chance of trying all the arms even once and has to dedicate its limited number of samples only to a certain number of arms . All previous algorithms for this setting were designed for minimizing the cumulative regret of the learner . In this paper , we propose an algorithm aiming at minimizing the simple regret . As in the cumulative regret setting of infinitely many armed bandits , the rate of the simple regret will depend on a parameter $\beta$ characterizing the distribution of the near-optimal arms . We prove that depending on $\beta$ , our algorithm is minimax optimal either up to a multiplicative constant or up to a $\log ( n ) $ factor . We also provide extensions to several important cases : when $\beta$ is unknown , in a natural setting where the near-optimal arms have a small variance , and in the case of unknown time horizon .
We theoretically and experimentally investigate tensor-based regression and classification . Our focus is regularization with various tensor norms , including the overlapped trace norm , the latent trace norm , and the scaled latent trace norm . We first give dual optimization methods using the alternating direction method of multipliers , which is computationally efficient when the number of training samples is moderate . We then theoretically derive an excess risk bound for each tensor norm and clarify their behavior . Finally , we perform extensive experiments using simulated and real data and demonstrate the superiority of tensor-based learning methods over vector- and matrix-based learning methods .
We study the estimation of $\beta$ for the nonlinear model $y = f ( X\sp{\top}\beta ) + \epsilon$ when $f$ is a nonlinear transformation that is known , $\beta$ has sparse nonzero coordinates , and the number of observations can be much smaller than that of parameters ( $n\ll p$ ) . We show that in order to bound the $L_0$ error of the $L_0$ regularized estimator $\hat\beta$ , i . e . , $\|\hat\beta - \beta\|_0$ , it is sufficient to establish two conditions . Based on this , we obtain bounds of the $L_0$ error for ( 0 ) $L_0$ regularized maximum likelihood estimation ( MLE ) for exponential linear models and ( 0 ) $L_0$ regularized least square ( LS ) regression for the more general case where $f$ is analytic . For the analytic case , we rely on power series expansion of $f$ , which requires taking into account the singularities of $f$ .
The paper studies the problem of recovering a spectrally sparse object from a small number of time domain samples . Specifically , the object of interest with ambient dimension $n$ is assumed to be a mixture of $r$ complex multi-dimensional sinusoids , while the underlying frequencies can assume any value in the unit disk . Conventional compressed sensing paradigms suffer from the {\em basis mismatch} issue when imposing a discrete dictionary on the Fourier representation . To address this problem , we develop a novel nonparametric algorithm , called enhanced matrix completion ( EMaC ) , based on structured matrix completion . The algorithm starts by arranging the data into a low-rank enhanced form with multi-fold Hankel structure , then attempts recovery via nuclear norm minimization . Under mild incoherence conditions , EMaC allows perfect recovery as soon as the number of samples exceeds the order of $\mathcal{O} ( r\log^{0} n ) $ . We also show that , in many instances , accurate completion of a low-rank multi-fold Hankel matrix is possible when the number of observed entries is proportional to the information theoretical limits ( except for a logarithmic gap ) . The robustness of EMaC against bounded noise and its applicability to super resolution are further demonstrated by numerical experiments .
Information mapping is a popular application of Multivoxel Pattern Analysis ( MVPA ) to fMRI . Information maps are constructed using the so called searchlight method , where the spherical multivoxel neighborhood of every voxel ( i . e . , a searchlight ) in the brain is evaluated for the presence of task-relevant response patterns . Despite their widespread use , information maps present several challenges for interpretation . One such challenge has to do with inferring the size and shape of a multivoxel pattern from its signature on the information map . To address this issue , we formally examined the geometric basis of this mapping relationship . Based on geometric considerations , we show how and why small patterns ( i . e . , having smaller spatial extents ) can produce a larger signature on the information map as compared to large patterns , independent of the size of the searchlight radius . Furthermore , we show that the number of informative searchlights over the brain increase as a function of searchlight radius , even in the complete absence of any multivariate response patterns . These properties are unrelated to the statistical capabilities of the pattern-analysis algorithms used but are obligatory geometric properties arising from using the searchlight procedure .
Group discussions are essential for organizing every aspect of modern life , from faculty meetings to senate debates , from grant review panels to papal conclaves . While costly in terms of time and organization effort , group discussions are commonly seen as a way of reaching better decisions compared to solutions that do not require coordination between the individuals ( e . g . voting ) ---through discussion , the sum becomes greater than the parts . However , this assumption is not irrefutable : anecdotal evidence of wasteful discussions abounds , and in our own experiments we find that over 00% of discussions are unproductive . We propose a framework for analyzing conversational dynamics in order to determine whether a given task-oriented discussion is worth having or not . We exploit conversational patterns reflecting the flow of ideas and the balance between the participants , as well as their linguistic choices . We apply this framework to conversations naturally occurring in an online collaborative world exploration game developed and deployed to support this research . Using this setting , we show that linguistic cues and conversational patterns extracted from the first 00 seconds of a team discussion are predictive of whether it will be a wasteful or a productive one .
MicroRNAs ( miRNAs ) are small RNA molecules composed of 00-00 nt , which play important regulatory roles in post-transcriptional gene regulation by inhibiting the translation of the mRNA into proteins or otherwise cleaving the target mRNA . Inferring miRNA targets provides useful information for understanding the roles of miRNA in biological processes that are potentially involved in complex diseases . Statistical methodologies for point estimation , such as the Least Absolute Shrinkage and Selection Operator ( LASSO ) algorithm , have been proposed to identify the interactions of miRNA and mRNA based on sequence and expression data . In this paper , we propose using the Bayesian LASSO ( BLASSO ) and the non-negative Bayesian LASSO ( nBLASSO ) to analyse the interactions between miRNA and mRNA using expression data . The proposed Bayesian methods explore the posterior distributions for those parameters required to model the miRNA-mRNA interactions . These approaches can be used to observe the inferred effects of the miRNAs on the targets by plotting the posterior distributions of those parameters . For comparison purposes , the Least Squares Regression ( LSR ) , Ridge Regression ( RR ) , LASSO , non-negative LASSO ( nLASSO ) , and the proposed Bayesian approaches were applied to four public datasets . We concluded that nLASSO and nBLASSO perform best in terms of sensitivity and specificity . Compared to the point estimate algorithms , which only provide single estimates for those parameters , the Bayesian methods are more meaningful and provide credible intervals , which take into account the uncertainty of the inferred interactions of the miRNA and mRNA . Furthermore , Bayesian methods naturally provide statistical significance to select convincing inferred interactions , while point estimate algorithms require a manually chosen threshold , which is less meaningful , to choose the possible interactions .
In this paper we bring to bear some new tools from statistical learning on the analysis of roll call data . We present a new data-driven model for roll call voting that is geometric in nature . We construct the model by adapting the " Partition Decoupling Method , " an unsupervised learning technique originally developed for the analysis of families of time series , to produce a multiscale geometric description of a weighted network associated to a set of roll call votes . Central to this approach is the quantitative notion of a " motivation , " a cluster-based and learned basis element that serves as a building block in the representation of roll call data . Motivations enable the formulation of a quantitative description of ideology and their data-dependent nature makes possible a quantitative analysis of the evolution of ideological factors . This approach is generally applicable to roll call data and we apply it in particular to the historical roll call voting of the U . S . House and Senate . This methodology provides a mechanism for estimating the dimension of the underlying action space . We determine that the dominant factors form a low- ( one- or two- ) dimensional representation with secondary factors adding higher-dimensional features . In this way our work supports and extends the findings of both Poole-Rosenthal and Heckman-Snyder concerning the dimensionality of the action space . We give a detailed analysis of several individual Senates and use the AdaBoost technique from statistical learning to determine those votes with the most powerful discriminatory value . When used as a predictive model , this geometric view significantly outperforms spatial models such as the Poole-Rosenthal DW-NOMINATE model and the Heckman-Snyder 0-factor model , both in raw accuracy as well as Aggregate Proportional Reduced Error ( APRE ) .
We consider the problem of estimating a function defined over $n$ locations on a $d$-dimensional grid ( having all side lengths equal to $n^{0/d}$ ) . When the function is constrained to have discrete total variation bounded by $C_n$ , we derive the minimax optimal ( squared ) $\ell_0$ estimation error rate , parametrized by $n$ and $C_n$ . Total variation denoising , also known as the fused lasso , is seen to be rate optimal . Several simpler estimators exist , such as Laplacian smoothing and Laplacian eigenmaps . A natural question is : can these simpler estimators perform just as well ? We prove that these estimators , and more broadly all estimators given by linear transformations of the input data , are suboptimal over the class of functions with bounded variation . This extends fundamental findings of Donoho and Johnstone [0000] on 0-dimensional total variation spaces to higher dimensions . The implication is that the computationally simpler methods cannot be used for such sophisticated denoising tasks , without sacrificing statistical accuracy . We also derive minimax rates for discrete Sobolev spaces over $d$-dimensional grids , which are , in some sense , smaller than the total variation function spaces . Indeed , these are small enough spaces that linear estimators can be optimal---and a few well-known ones are , such as Laplacian smoothing and Laplacian eigenmaps , as we show . Lastly , we investigate the problem of adaptivity of the total variation denoiser to these smaller Sobolev function spaces .
We develop a worst-case analysis of aggregation of classifier ensembles for binary classification . The task of predicting to minimize error is formulated as a game played over a given set of unlabeled data ( a transductive setting ) , where prior label information is encoded as constraints on the game . The minimax solution of this game identifies cases where a weighted combination of the classifiers can perform significantly better than any single classifier .
This paper is a follow up to the previous author ' s paper on convex optimization . In that paper we began the process of adjusting greedy-type algorithms from nonlinear approximation for finding sparse solutions of convex optimization problems . We modified there three the most popular in nonlinear approximation in Banach spaces greedy algorithms -- Weak Chebyshev Greedy Algorithm , Weak Greedy Algorithm with Free Relaxation and Weak Relaxed Greedy Algorithm -- for solving convex optimization problems . We continue to study sparse approximate solutions to convex optimization problems . It is known that in many engineering applications researchers are interested in an approximate solution of an optimization problem as a linear combination of elements from a given system of elements . There is an increasing interest in building such sparse approximate solutions using different greedy-type algorithms . In this paper we concentrate on greedy algorithms that provide expansions , which means that the approximant at the $m$th iteration is equal to the sum of the approximant from the previous iteration ( $ ( m-0 ) $th iteration ) and one element from the dictionary with an appropriate coefficient . The problem of greedy expansions of elements of a Banach space is well studied in nonlinear approximation theory . At a first glance the setting of a problem of expansion of a given element and the setting of the problem of expansion in an optimization problem are very different . However , it turns out that the same technique can be used for solving both problems . We show how the technique developed in nonlinear approximation theory , in particular , the greedy expansions technique can be adjusted for finding a sparse solution of an optimization problem given by an expansion with respect to a given dictionary .
A mixture of Gaussians fit to a single curved or heavy-tailed cluster will report that the data contains many clusters . To produce more appropriate clusterings , we introduce a model which warps a latent mixture of Gaussians to produce nonparametric cluster shapes . The possibly low-dimensional latent mixture model allows us to summarize the properties of the high-dimensional clusters ( or density manifolds ) describing the data . The number of manifolds , as well as the shape and dimension of each manifold is automatically inferred . We derive a simple inference scheme for this model which analytically integrates out both the mixture parameters and the warping function . We show that our model is effective for density estimation , performs better than infinite Gaussian mixture models at recovering the true number of clusters , and produces interpretable summaries of high-dimensional datasets .
This paper presents a general vector-valued reproducing kernel Hilbert spaces ( RKHS ) framework for the problem of learning an unknown functional dependency between a structured input space and a structured output space . Our formulation encompasses both Vector-valued Manifold Regularization and Co-regularized Multi-view Learning , providing in particular a unifying framework linking these two important learning approaches . In the case of the least square loss function , we provide a closed form solution , which is obtained by solving a system of linear equations . In the case of Support Vector Machine ( SVM ) classification , our formulation generalizes in particular both the binary Laplacian SVM to the multi-class , multi-view settings and the multi-class Simplex Cone SVM to the semi-supervised , multi-view settings . The solution is obtained by solving a single quadratic optimization problem , as in standard SVM , via the Sequential Minimal Optimization ( SMO ) approach . Empirical results obtained on the task of object recognition , using several challenging datasets , demonstrate the competitiveness of our algorithms compared with other state-of-the-art methods .
Sparse support vector machine ( SVM ) is a popular classification technique that can simultaneously learn a small set of the most interpretable features and identify the support vectors . It has achieved great successes in many real-world applications . However , for large-scale problems involving a huge number of samples and extremely high-dimensional features , solving sparse SVMs remains challenging . By noting that sparse SVMs induce sparsities in both feature and sample spaces , we propose a novel approach , which is based on accurate estimations of the primal and dual optima of sparse SVMs , to simultaneously identify the features and samples that are guaranteed to be irrelevant to the outputs . Thus , we can remove the identified inactive samples and features from the training phase , leading to substantial savings in both the memory usage and computational cost without sacrificing accuracy . To the best of our knowledge , the proposed method is the \emph{first} \emph{static} feature and sample reduction method for sparse SVM . Experiments on both synthetic and real datasets ( e . g . , the kddb dataset with about 00 million samples and 00 million features ) demonstrate that our approach significantly outperforms state-of-the-art methods and the speedup gained by our approach can be orders of magnitude .
The condensed nearest neighbor ( CNN ) algorithm is a heuristic for reducing the number of prototypical points stored by a nearest neighbor classifier , while keeping the classification rule given by the reduced prototypical set consistent with the full set . I present an upper bound on the number of prototypical points accumulated by CNN . The bound originates in a bound on the number of times the decision rule is updated during training in the multiclass perceptron algorithm , and thus is independent of training set size .
Personalized predictive medicine necessitates the modeling of patient illness and care processes , which inherently have long-term temporal dependencies . Healthcare observations , recorded in electronic medical records , are episodic and irregular in time . We introduce DeepCare , an end-to-end deep dynamic neural network that reads medical records , stores previous illness history , infers current illness states and predicts future medical outcomes . At the data level , DeepCare represents care episodes as vectors in space , models patient health state trajectories through explicit memory of historical records . Built on Long Short-Term Memory ( LSTM ) , DeepCare introduces time parameterizations to handle irregular timed events by moderating the forgetting and consolidation of memory cells . DeepCare also incorporates medical interventions that change the course of illness and shape future medical risk . Moving up to the health state level , historical and present health states are then aggregated through multiscale temporal pooling , before passing through a neural network that estimates future outcomes . We demonstrate the efficacy of DeepCare for disease progression modeling , intervention recommendation , and future risk prediction . On two important cohorts with heavy social and economic burden -- diabetes and mental health -- the results show improved modeling and risk prediction accuracy .
In many signal processing problems , it may be fruitful to represent the signal under study in a frame . If a probabilistic approach is adopted , it becomes then necessary to estimate the hyper-parameters characterizing the probability distribution of the frame coefficients . This problem is difficult since in general the frame synthesis operator is not bijective . Consequently , the frame coefficients are not directly observable . This paper introduces a hierarchical Bayesian model for frame representation . The posterior distribution of the frame coefficients and model hyper-parameters is derived . Hybrid Markov Chain Monte Carlo algorithms are subsequently proposed to sample from this posterior distribution . The generated samples are then exploited to estimate the hyper-parameters and the frame coefficients of the target signal . Validation experiments show that the proposed algorithms provide an accurate estimation of the frame coefficients and hyper-parameters . Application to practical problems of image denoising show the impact of the resulting Bayesian estimation on the recovered signal quality .
We consider in this paper a class of composite optimization problems whose objective function is given by the summation of a general smooth and nonsmooth component , together with a relatively simple nonsmooth term . We present a new class of first-order methods , namely the gradient sliding algorithms , which can skip the computation of the gradient for the smooth component from time to time . As a consequence , these algorithms require only ${\cal O} ( 0/\sqrt{\epsilon} ) $ gradient evaluations for the smooth component in order to find an $\epsilon$-solution for the composite problem , while still maintaining the optimal ${\cal O} ( 0/\epsilon^0 ) $ bound on the total number of subgradient evaluations for the nonsmooth component . We then present a stochastic counterpart for these algorithms and establish similar complexity bounds for solving an important class of stochastic composite optimization problems . Moreover , if the smooth component in the composite function is strongly convex , the developed gradient sliding algorithms can significantly reduce the number of graduate and subgradient evaluations for the smooth and nonsmooth component to ${\cal O} ( \log ( 0/\epsilon ) ) $ and ${\cal O} ( 0/\epsilon ) $ , respectively . Finally , we generalize these algorithms to the case when the smooth component is replaced by a nonsmooth one possessing a certain bi-linear saddle point structure .
As increasing amounts of sensitive personal information is aggregated into data repositories , it has become important to develop mechanisms for processing the data without revealing information about individual data instances . The differential privacy model provides a framework for the development and theoretical analysis of such mechanisms . In this paper , we propose an algorithm for learning a discriminatively trained multi-class Gaussian classifier that satisfies differential privacy using a large margin loss function with a perturbed regularization term . We present a theoretical upper bound on the excess risk of the classifier introduced by the perturbation .
We propose a novel adaptive importance sampling algorithm which incorporates Stein variational gradient decent algorithm ( SVGD ) with importance sampling ( IS ) . Our algorithm leverages the nonparametric transforms in SVGD to iteratively decrease the KL divergence between our importance proposal and the target distribution . The advantages of this algorithm are twofold : first , our algorithm turns SVGD into a standard IS algorithm , allowing us to use standard diagnostic and analytic tools of IS to evaluate and interpret the results ; second , we do not restrict the choice of our importance proposal to predefined distribution families like traditional ( adaptive ) IS methods . Empirical experiments demonstrate that our algorithm performs well on evaluating partition functions of restricted Boltzmann machines and testing likelihood of variational auto-encoders .
In this paper , we deal with the problem of curves clustering . We propose a nonparametric method which partitions the curves into clusters and discretizes the dimensions of the curve points into intervals . The cross-product of these partitions forms a data-grid which is obtained using a Bayesian model selection approach while making no assumptions regarding the curves . Finally , a post-processing technique , aiming at reducing the number of clusters in order to improve the interpretability of the clustering , is proposed . It consists in optimally merging the clusters step by step , which corresponds to an agglomerative hierarchical classification whose dissimilarity measure is the variation of the criterion . Interestingly this measure is none other than the sum of the Kullback-Leibler divergences between clusters distributions before and after the merges . The practical interest of the approach for functional data exploratory analysis is presented and compared with an alternative approach on an artificial and a real world data set .
This paper demonstrates the use of genetic algorithms for evolving a grandmaster-level evaluation function for a chess program . This is achieved by combining supervised and unsupervised learning . In the supervised learning phase the organisms are evolved to mimic the behavior of human grandmasters , and in the unsupervised learning phase these evolved organisms are further improved upon by means of coevolution . While past attempts succeeded in creating a grandmaster-level program by mimicking the behavior of existing computer chess programs , this paper presents the first successful attempt at evolving a state-of-the-art evaluation function by learning only from databases of games played by humans . Our results demonstrate that the evolved program outperforms a two-time World Computer Chess Champion .
Reinforcement Learning AI commonly uses reward/penalty signals that are objective and explicit in an environment -- e . g . game score , completion time , etc . -- in order to learn the optimal strategy for task performance . However , Human-AI interaction for such AI agents should include additional reinforcement that is implicit and subjective -- e . g . human preferences for certain AI behavior -- in order to adapt the AI behavior to idiosyncratic human preferences . Such adaptations would mirror naturally occurring processes that increase trust and comfort during social interactions . Here , we show how a hybrid brain-computer-interface ( hBCI ) , which detects an individual ' s level of interest in objects/events in a virtual environment , can be used to adapt the behavior of a Deep Reinforcement Learning AI agent that is controlling a virtual autonomous vehicle . Specifically , we show that the AI learns a driving strategy that maintains a safe distance from a lead vehicle , and most novelly , preferentially slows the vehicle when the human passengers of the vehicle encounter objects of interest . This adaptation affords an additional 00\% viewing time for subjectively interesting objects . This is the first demonstration of how an hBCI can be used to provide implicit reinforcement to an AI agent in a way that incorporates user preferences into the control system .
Fault detection in industrial plants is a hot research area as more and more sensor data are being collected throughout the industrial process . Automatic data-driven approaches are widely needed and seen as a promising area of investment . This paper proposes an effective machine learning algorithm to predict industrial plant faults based on classification methods such as penalized logistic regression , random forest and gradient boosted tree . A fault ' s start time and end time are predicted sequentially in two steps by formulating the original prediction problems as classification problems . The algorithms described in this paper won first place in the Prognostics and Health Management Society 0000 Data Challenge .
We present DUAL-LOCO , a communication-efficient algorithm for distributed statistical estimation . DUAL-LOCO assumes that the data is distributed according to the features rather than the samples . It requires only a single round of communication where low-dimensional random projections are used to approximate the dependences between features available to different workers . We show that DUAL-LOCO has bounded approximation error which only depends weakly on the number of workers . We compare DUAL-LOCO against a state-of-the-art distributed optimization method on a variety of real world datasets and show that it obtains better speedups while retaining good accuracy .
In this paper , we introduce a package for semi-supervised learning research in the R programming language called RSSL . We cover the purpose of the package , the methods it includes and comment on their use and implementation . We then show , using several code examples , how the package can be used to replicate well-known results from the semi-supervised learning literature .
We examine overlapping clustering schemes with functorial constraints , in the spirit of Carlsson--Memoli . This avoids issues arising from the chaining required by partition-based methods . Our principal result shows that any clustering functor is naturally constrained to refine single-linkage clusters and be refined by maximal-linkage clusters . We work in the context of metric spaces with non-expansive maps , which is appropriate for modeling data processing which does not increase information content .
We propose a version of least-mean-square ( LMS ) algorithm for sparse system identification . Our algorithm called online linearized Bregman iteration ( OLBI ) is derived from minimizing the cumulative prediction error squared along with an l0-l0 norm regularizer . By systematically treating the non-differentiable regularizer we arrive at a simple two-step iteration . We demonstrate that OLBI is bias free and compare its operation with existing sparse LMS algorithms by rederiving them in the online convex optimization framework . We perform convergence analysis of OLBI for white input signals and derive theoretical expressions for both the steady state and instantaneous mean square deviations ( MSD ) . We demonstrate numerically that OLBI improves the performance of LMS type algorithms for signals generated from sparse tap weights .
Wisdom of the crowd , the collective intelligence derived from responses of multiple human or machine individuals to the same questions , can be more accurate than each individual , and improve social decision-making and prediction accuracy . This can also integrate multiple programs or datasets , each as an individual , for the same predictive questions . Crowd wisdom estimates each individual ' s independent error level arising from their limited knowledge , and finds the crowd consensus that minimizes the overall error . However , previous studies have merely built isolated , problem-specific models with limited generalizability , and mainly for binary ( yes/no ) responses . Here we show with simulation and real-world data that the crowd wisdom problem is analogous to one-dimensional unsupervised dimension reduction in machine learning . This provides a natural class of crowd wisdom solutions , such as principal component analysis and Isomap , which can handle binary and also continuous responses , like confidence levels , and consequently can be more accurate than existing solutions . They can even outperform supervised-learning-based collective intelligence that is calibrated on historical performance of individuals , e . g . penalized linear regression and random forest . This study unifies crowd wisdom and unsupervised dimension reduction , and thereupon introduces a broad range of highly-performing and widely-applicable crowd wisdom methods . As the costs for data acquisition and processing rapidly decrease , this study will promote and guide crowd wisdom applications in the social and natural sciences , including data fusion , meta-analysis , crowd-sourcing , and committee decision making .
We present a new Markov chain Monte Carlo method for estimating posterior probabilities of structural features in Bayesian networks . The method draws samples from the posterior distribution of partial orders on the nodes ; for each sampled partial order , the conditional probabilities of interest are computed exactly . We give both analytical and empirical results that suggest the superiority of the new method compared to previous methods , which sample either directed acyclic graphs or linear orders on the nodes .
Interesting data often concentrate on low dimensional smooth manifolds inside a high dimensional ambient space . Random projections are a simple , powerful tool for dimensionality reduction of such data . Previous works have studied bounds on how many projections are needed to accurately preserve the geometry of these manifolds , given their intrinsic dimensionality , volume and curvature . However , such works employ definitions of volume and curvature that are inherently difficult to compute . Therefore such theory cannot be easily tested against numerical simulations to understand the tightness of the proven bounds . We instead study typical distortions arising in random projections of an ensemble of smooth Gaussian random manifolds . We find explicitly computable , approximate theoretical bounds on the number of projections required to accurately preserve the geometry of these manifolds . Our bounds , while approximate , can only be violated with a probability that is exponentially small in the ambient dimension , and therefore they hold with high probability in cases of practical interest . Moreover , unlike previous work , we test our theoretical bounds against numerical experiments on the actual geometric distortions that typically occur for random projections of random smooth manifolds . We find our bounds are tighter than previous results by several orders of magnitude .
Massively multitask neural architectures provide a learning framework for drug discovery that synthesizes information from many distinct biological sources . To train these architectures at scale , we gather large amounts of data from public sources to create a dataset of nearly 00 million measurements across more than 000 biological targets . We investigate several aspects of the multitask framework by performing a series of empirical studies and obtain some interesting results : ( 0 ) massively multitask networks obtain predictive accuracies significantly better than single-task methods , ( 0 ) the predictive power of multitask networks improves as additional tasks and data are added , ( 0 ) the total amount of data and the total number of tasks both contribute significantly to multitask improvement , and ( 0 ) multitask networks afford limited transferability to tasks not in the training set . Our results underscore the need for greater data sharing and further algorithmic innovation to accelerate the drug discovery process .
We study the total least squares ( TLS ) problem that generalizes least squares regression by allowing measurement errors in both dependent and independent variables . TLS is widely used in applied fields including computer vision , system identification and econometrics . The special case when all dependent and independent variables have the same level of uncorrelated Gaussian noise , known as ordinary TLS , can be solved by singular value decomposition ( SVD ) . However , SVD cannot solve many important practical TLS problems with realistic noise structure , such as having varying measurement noise , known structure on the errors , or large outliers requiring robust error-norms . To solve such problems , we develop convex relaxation approaches for a general class of structured TLS ( STLS ) . We show both theoretically and experimentally , that while the plain nuclear norm relaxation incurs large approximation errors for STLS , the re-weighted nuclear norm approach is very effective , and achieves better accuracy on challenging STLS problems than popular non-convex solvers . We describe a fast solution based on augmented Lagrangian formulation , and apply our approach to an important class of biological problems that use population average measurements to infer cell-type and physiological-state specific expression levels that are very hard to measure directly .
This paper studies the problem of estimating the covariance of a collection of vectors using only extremely compressed measurements of each vector . An estimator based on back-projections of these compressive samples is proposed and analyzed . A distribution-free analysis shows that by observing just a single compressive measurement of each vector , one can consistently estimate the covariance matrix , in both infinity and spectral norm , and this same analysis leads to precise rates of convergence in both norms . Via information-theoretic techniques , lower bounds showing that this estimator is minimax-optimal for both infinity and spectral norm estimation problems are established . These results are also specialized to give matching upper and lower bounds for estimating the population covariance of a collection of Gaussian vectors , again in the compressive measurement model . The analysis conducted in this paper shows that the effective sample complexity for this problem is scaled by a factor of $m^0/d^0$ where $m$ is the compression dimension and $d$ is the ambient dimension . Applications to subspace learning ( Principal Components Analysis ) and learning over distributed sensor networks are also discussed .
Some real-world problems revolve to solve the optimization problem \max_{x\in\mathcal{X}}f\left ( x\right ) where f\left ( . \right ) is a black-box function and X might be the set of non-vectorial objects ( e . g . , distributions ) where we can only define a symmetric and non-negative similarity score on it . This setting requires a novel view for the standard framework of Bayesian Optimization that generalizes the core insightful spirit of this framework . With this spirit , in this paper , we propose Analogical-based Bayesian Optimization that can maximize black-box function over a domain where only a similarity score can be defined . Our pathway is as follows : we first base on the geometric view of Gaussian Processes ( GP ) to define the concept of influence level that allows us to analytically represent predictive means and variances of GP posteriors and base on that view to enable replacing kernel similarity by a more genetic similarity score . Furthermore , we also propose two strategies to find a batch of query points that can efficiently handle high dimensional data .
This paper introduces a model of environmental acoustic scenes which adopts a morphological approach by ab-stracting temporal structures of acoustic scenes . To demonstrate its potential , this model is employed to evaluate the performance of a large set of acoustic events detection systems . This model allows us to explicitly control key morphological aspects of the acoustic scene and isolate their impact on the performance of the system under evaluation . Thus , more information can be gained on the behavior of evaluated systems , providing guidance for further improvements . The proposed model is validated using submitted systems from the IEEE DCASE Challenge ; results indicate that the proposed scheme is able to successfully build datasets useful for evaluating some aspects the performance of event detection systems , more particularly their robustness to new listening conditions and the increasing level of background sounds .
The profusion of online news articles makes it difficult to find interesting articles , a problem that can be assuaged by using a recommender system to bring the most relevant news stories to readers . However , news recommendation is challenging because the most relevant articles are often new content seen by few users . In addition , they are subject to trends and preference changes over time , and in many cases we do not have sufficient information to profile the reader . In this paper , we introduce a class of news recommendation systems based on context trees . They can provide high-quality news recommendation to anonymous visitors based on present browsing behaviour . We show that context-tree recommender systems provide good prediction accuracy and recommendation novelty , and they are sufficiently flexible to capture the unique properties of news articles .
We show that the disagreement coefficient of certain smooth hypothesis classes is $O ( m ) $ , where $m$ is the dimension of the hypothesis space , thereby answering a question posed in \cite{friedman00} .
This works extends the Random Embedding Bayesian Optimization approach by integrating a warping of the high dimensional subspace within the covariance kernel . The proposed warping , that relies on elementary geometric considerations , allows mitigating the drawbacks of the high extrinsic dimensionality while avoiding the algorithm to evaluate points giving redundant information . It also alleviates constraints on bound selection for the embedded domain , thus improving the robustness , as illustrated with a test case with 00 variables and intrinsic dimension 0 .
When using reinforcement learning ( RL ) algorithms to evaluate a policy it is common , given a large state space , to introduce some form of approximation architecture for the value function ( VF ) . The exact form of this architecture can have a significant effect on the accuracy of the VF estimate , however , and determining a suitable approximation architecture can often be a highly complex task . Consequently there is a large amount of interest in the potential for allowing RL algorithms to adaptively generate approximation architectures . We investigate a method of adapting approximation architectures which uses feedback regarding the frequency with which an agent has visited certain states to guide which areas of the state space to approximate with greater detail . This method is " unsupervised " in the sense that it makes no direct reference to reward or the VF estimate . We introduce an algorithm based upon this idea which adapts a state aggregation approximation architecture on-line . A common method of scoring a VF estimate is to weight the squared Bellman error of each state-action by the probability of that state-action occurring . Adopting this scoring method , and assuming $S$ states , we demonstrate theoretically that - provided ( 0 ) the number of cells $X$ in the state aggregation architecture is of order $\sqrt{S}\log_0{S}\ln{S}$ or greater , ( 0 ) the policy and transition function are close to deterministic , and ( 0 ) the prior for the transition function is uniformly distributed - our algorithm , used in conjunction with a suitable RL algorithm , can guarantee a score which is arbitrarily close to zero as $S$ becomes large . It is able to do this despite having only $O ( X \log_0S ) $ space complexity and negligible time complexity . The results take advantage of certain properties of the stationary distributions of Markov chains .
Optimization problems with rank constraints arise in many applications , including matrix regression , structured PCA , matrix completion and matrix decomposition problems . An attractive heuristic for solving such problems is to factorize the low-rank matrix , and to run projected gradient descent on the nonconvex factorized optimization problem . The goal of this problem is to provide a general theoretical framework for understanding when such methods work well , and to characterize the nature of the resulting fixed point . We provide a simple set of conditions under which projected gradient descent , when given a suitable initialization , converges geometrically to a statistically useful solution . Our results are applicable even when the initial solution is outside any region of local convexity , and even when the problem is globally concave . Working in a non-asymptotic framework , we show that our conditions are satisfied for a wide range of concrete models , including matrix regression , structured PCA , matrix completion with real and quantized observations , matrix decomposition , and graph clustering problems . Simulation results show excellent agreement with the theoretical predictions .
Inspired by the importance of diversity in biological system , we built an heterogeneous system that could achieve this goal . Our architecture could be summarized in two basic steps . First , we generate a diverse set of classification hypothesis using both Convolutional Neural Networks , currently the state-of-the-art technique for this task , among with other traditional and innovative machine learning techniques . Then , we optimally combine them through Meta-Nets , a family of recently developed and performing ensemble methods .
We consider a sparse high dimensional regression model where the goal is to recover a k-sparse unknown vector \beta^* from n noisy linear observations of the form Y=X\beta^*+W \in R^n where X \in R^{n \times p} has iid N ( 0 , 0 ) entries and W \in R^n has iid N ( 0 , \sigma^0 ) entries . Under certain assumptions on the parameters , an intriguing assymptotic gap appears between the minimum value of n , call it n^* , for which the recovery is information theoretically possible , and the minimum value of n , call it n_{alg} , for which an efficient algorithm is known to provably recover \beta^* . In a recent paper it was conjectured that the gap is not artificial , in the sense that for sample sizes n \in [n^* , n_{alg}] the problem is algorithmically hard . We support this conjecture in two ways . Firstly , we show that a well known recovery mechanism called Basis Pursuit Denoising Scheme provably fails to \ell_0-stably recover the vector when n \in [n^* , c n_{alg}] , for some sufficiently small constant c>0 . Secondly , we establish that n_{alg} , up to a multiplicative constant factor , is a phase transition point for the appearance of a certain Overlap Gap Property ( OGP ) over the space of k-sparse vectors . The presence of such an Overlap Gap Property phase transition , which originates in statistical physics , is known to provide evidence of an algorithmic hardness . Finally we show that if n>C n_{alg} for some large enough constant C>0 , a very simple algorithm based on a local search improvement is able to infer correctly the support of the unknown vector \beta^* , adding it to the list of provably successful algorithms for the high dimensional linear regression problem .
A nonparametric Bayesian extension of Factor Analysis ( FA ) is proposed where observed data $\mathbf{Y}$ is modeled as a linear superposition , $\mathbf{G}$ , of a potentially infinite number of hidden factors , $\mathbf{X}$ . The Indian Buffet Process ( IBP ) is used as a prior on $\mathbf{G}$ to incorporate sparsity and to allow the number of latent features to be inferred . The model ' s utility for modeling gene expression data is investigated using randomly generated data sets based on a known sparse connectivity matrix for E . Coli , and on three biological data sets of increasing complexity .
We present a new notion of probabilistic duality for random variables involving mixture distributions . Using this notion , we show how to implement a highly-parallelizable Gibbs sampler for weakly coupled discrete pairwise graphical models with strictly positive factors that requires almost no preprocessing and is easy to implement . Moreover , we show how our method can be combined with blocking to improve mixing . Even though our method leads to inferior mixing times compared to a sequential Gibbs sampler , we argue that our method is still very useful for large dynamic networks , where factors are added and removed on a continuous basis , as it is hard to maintain a graph coloring in this setup . Similarly , our method is useful for parallelizing Gibbs sampling in graphical models that do not allow for graph colorings with a small number of colors such as densely connected graphs .
As one of the most important types of ( weaker ) supervised information in machine learning and pattern recognition , pairwise constraint , which specifies whether a pair of data points occur together , has recently received significant attention , especially the problem of pairwise constraint propagation . At least two reasons account for this trend : the first is that compared to the data label , pairwise constraints are more general and easily to collect , and the second is that since the available pairwise constraints are usually limited , the constraint propagation problem is thus important . This paper provides an up-to-date critical survey of pairwise constraint propagation research . There are two underlying motivations for us to write this survey paper : the first is to provide an up-to-date review of the existing literature , and the second is to offer some insights into the studies of pairwise constraint propagation . To provide a comprehensive survey , we not only categorize existing propagation techniques but also present detailed descriptions of representative methods within each category .
This work proposes a new algorithm for training a re-weighted L0 Support Vector Machine ( SVM ) , inspired on the re-weighted Lasso algorithm of Cand\`es et al . and on the equivalence between Lasso and SVM shown recently by Jaggi . In particular , the margin required for each training vector is set independently , defining a new weighted SVM model . These weights are selected to be binary , and they are automatically adapted during the training of the model , resulting in a variation of the Frank-Wolfe optimization algorithm with essentially the same computational complexity as the original algorithm . As shown experimentally , this algorithm is computationally cheaper to apply since it requires less iterations to converge , and it produces models with a sparser representation in terms of support vectors and which are more stable with respect to the selection of the regularization hyper-parameter .
Generative Adversarial Networks ( GANs ) have become a popular method to learn a probability model from data . Many GAN architectures with different optimization metrics have been introduced recently . Instead of proposing yet another architecture , this paper aims to provide an understanding of some of the basic issues surrounding GANs . First , we propose a natural way of specifying the loss function for GANs by drawing a connection with supervised learning . Second , we shed light on the generalization peformance of GANs through the analysis of a simple LQG setting : the generator is Linear , the loss function is Quadratic and the data is drawn from a Gaussian distribution . We show that in this setting : 0 ) the optimal GAN solution converges to population Principal Component Analysis ( PCA ) as the number of training samples increases ; 0 ) the number of samples required scales exponentially with the dimension of the data ; 0 ) the number of samples scales almost linearly if the discriminator is constrained to be quadratic . Thus , linear generators and quadratic discriminators provide a good balance for fast learning .
The derivation of statistical properties for Partial Least Squares regression can be a challenging task . The reason is that the construction of latent components from the predictor variables also depends on the response variable . While this typically leads to good performance and interpretable models in practice , it makes the statistical analysis more involved . In this work , we study the intrinsic complexity of Partial Least Squares Regression . Our contribution is an unbiased estimate of its Degrees of Freedom . It is defined as the trace of the first derivative of the fitted values , seen as a function of the response . We establish two equivalent representations that rely on the close connection of Partial Least Squares to matrix decompositions and Krylov subspace techniques . We show that the Degrees of Freedom depend on the collinearity of the predictor variables : The lower the collinearity is , the higher the Degrees of Freedom are . In particular , they are typically higher than the naive approach that defines the Degrees of Freedom as the number of components . Further , we illustrate how the Degrees of Freedom approach can be used for the comparison of different regression methods . In the experimental section , we show that our Degrees of Freedom estimate in combination with information criteria is useful for model selection .
In many healthcare settings , intuitive decision rules for risk stratification can help effective hospital resource allocation . This paper introduces a novel variant of decision tree algorithms that produces a chain of decisions , not a general tree . Our algorithm , $\alpha$-Carving Decision Chain ( ACDC ) , sequentially carves out " pure " subsets of the majority class examples . The resulting chain of decision rules yields a pure subset of the minority class examples . Our approach is particularly effective in exploring large and class-imbalanced health datasets . Moreover , ACDC provides an interactive interpretation in conjunction with visual performance metrics such as Receiver Operating Characteristics curve and Lift chart .
Neural networks require a careful design in order to perform properly on a given task . In particular , selecting a good activation function ( possibly in a data-dependent fashion ) is a crucial step , which remains an open problem in the research community . Despite a large amount of investigations , most current implementations simply select one fixed function from a small set of candidates , which is not adapted during training , and is shared among all neurons throughout the different layers . However , neither two of these assumptions can be supposed optimal in practice . In this paper , we present a principled way to have data-dependent adaptation of the activation functions , which is performed independently for each neuron . This is achieved by leveraging over past and present advances on cubic spline interpolation , allowing for local adaptation of the functions around their regions of use . The resulting algorithm is relatively cheap to implement , and overfitting is counterbalanced by the inclusion of a novel damping criterion , which penalizes unwanted oscillations from a predefined shape . Experimental results validate the proposal over two well-known benchmarks .
Sparse coding is a common approach to learning local features for object recognition . Recently , there has been an increasing interest in learning features from spatio-temporal , binocular , or other multi-observation data , where the goal is to encode the relationship between images rather than the content of a single image . We provide an analysis of multi-view feature learning , which shows that hidden variables encode transformations by detecting rotation angles in the eigenspaces shared among multiple image warps . Our analysis helps explain recent experimental results showing that transformation-specific features emerge when training complex cell models on videos . Our analysis also shows that transformation-invariant features can emerge as a by-product of learning representations of transformations .
Discrimination-aware classification is receiving an increasing attention in the data mining and machine learning fields . The data preprocessing methods for constructing a discrimination-free classifier remove discrimination from the training data , and learn the classifier from the cleaned data . However , there lacks of a theoretical guarantee for the performance of these methods . In this paper , we fill this theoretical gap by mathematically bounding the probability that the discrimination in predictions is within a given interval in terms of the given training data and classifier . In our analysis , we adopt the causal model for modeling the mechanisms in data generation , and formally defining discrimination in the population , in a dataset , and in the prediction . The theoretical results show that the fundamental assumption made by the data preprocessing methods is not correct . Finally , we develop a framework for constructing a discrimination-free classifier with a theoretical guarantee .
In recent years there has been a flurry of works on learning Bayesian networks from data . One of the hard problems in this area is how to effectively learn the structure of a belief network from incomplete data- that is , in the presence of missing values or hidden variables . In a recent paper , I introduced an algorithm called Structural EM that combines the standard Expectation Maximization ( EM ) algorithm , which optimizes parameters , with structure search for model selection . That algorithm learns networks based on penalized likelihood scores , which include the BIC/MDL score and various approximations to the Bayesian score . In this paper , I extend Structural EM to deal directly with Bayesian model selection . I prove the convergence of the resulting algorithm and show how to apply it for learning a large class of probabilistic models , including Bayesian networks and some variants thereof .
How can we recognise social roles of people , given a completely unlabelled social network ? We present a transfer learning approach to network role classification based on feature transformations from each network ' s local feature distribution to a global feature space . Experiments are carried out on real-world datasets . ( See manuscript for the full abstract . )
The amount of data available in the world is growing faster than our ability to deal with it . However , if we take advantage of the internal \emph{structure} , data may become much smaller for machine learning purposes . In this paper we focus on one of the fundamental machine learning tasks , empirical risk minimization ( ERM ) , and provide faster algorithms with the help from the clustering structure of the data . We introduce a simple notion of raw clustering that can be efficiently computed from the data , and propose two algorithms based on clustering information . Our accelerated algorithm ClusterACDM is built on a novel Haar transformation applied to the dual space of the ERM problem , and our variance-reduction based algorithm ClusterSVRG introduces a new gradient estimator using clustering . Our algorithms outperform their classical counterparts ACDM and SVRG respectively .
We propose a new active learning by query synthesis approach using Generative Adversarial Networks ( GAN ) . Different from regular active learning , the resulting algorithm adaptively synthesizes training instances for querying to increase learning speed . We generate queries according to the uncertainty principle , but our idea can work with other active learning principles . We report results from various numerical experiments to demonstrate the effectiveness the proposed approach . In some settings , the proposed algorithm outperforms traditional pool-based approaches . To the best our knowledge , this is the first active learning work using GAN .
In the wake of recent advances in experimental methods in neuroscience , the ability to record in-vivo neuronal activity from awake animals has become feasible . The availability of such rich and detailed physiological measurements calls for the development of advanced data analysis tools , as commonly used techniques do not suffice to capture the spatio-temporal network complexity . In this paper , we propose a new hierarchical coupled geometry analysis , which exploits the hidden connectivity structures between neurons and the dynamic patterns at multiple time-scales . Our approach gives rise to the joint organization of neurons and dynamic patterns in data-driven hierarchical data structures . These structures provide local to global data representations , from local partitioning of the data in flexible trees through a new multiscale metric to a global manifold embedding . The application of our techniques to in-vivo neuronal recordings demonstrate the capability of extracting neuronal activity patterns and identifying temporal trends , associated with particular behavioral events and manipulations introduced in the experiments .
Generalized cross validation ( GCV ) is one of the most important approaches used to estimate parameters in the context of inverse problems and regularization techniques . A notable example is the determination of the smoothness parameter in splines . When the data are generated by a state space model , like in the spline case , efficient algorithms are available to evaluate the GCV score with complexity that scales linearly in the data set size . However , these methods are not amenable to on-line applications since they rely on forward and backward recursions . Hence , if the objective has been evaluated at time $t-0$ and new data arrive at time t , then O ( t ) operations are needed to update the GCV score . In this paper we instead show that the update cost is $O ( 0 ) $ , thus paving the way to the on-line use of GCV . This result is obtained by deriving the novel GCV filter which extends the classical Kalman filter equations to efficiently propagate the GCV score over time . We also illustrate applications of the new filter in the context of state estimation and on-line regularized linear system identification .
We consider the problem of predicting as well as the best linear combination of d given functions in least squares regression , and variants of this problem including constraints on the parameters of the linear combination . When the input distribution is known , there already exists an algorithm having an expected excess risk of order d/n , where n is the size of the training data . Without this strong assumption , standard results often contain a multiplicative log n factor , and require some additional assumptions like uniform boundedness of the d-dimensional input representation and exponential moments of the output . This work provides new risk bounds for the ridge estimator and the ordinary least squares estimator , and their variants . It also provides shrinkage procedures with convergence rate d/n ( i . e . , without the logarithmic factor ) in expectation and in deviations , under various assumptions . The key common surprising factor of these results is the absence of exponential moment condition on the output distribution while achieving exponential deviations . All risk bounds are obtained through a PAC-Bayesian analysis on truncated differences of losses . Finally , we show that some of these results are not particular to the least squares loss , but can be generalized to similar strongly convex loss functions .
The subdifferential of convex functions of the singular spectrum of real matrices has been widely studied in matrix analysis , optimization and automatic control theory . Convex analysis and optimization over spaces of tensors is now gaining much interest due to its potential applications to signal processing , statistics and engineering . The goal of this paper is to present an applications to the problem of low rank tensor recovery based on linear random measurement by extending the results of Tropp to the tensors setting .
It is known that evolution strategies in continuous domains might not converge in the presence of noise . It is also known that , under mild assumptions , and using an increasing number of resamplings , one can mitigate the effect of additive noise and recover convergence . We show new sufficient conditions for the convergence of an evolutionary algorithm with constant number of resamplings ; in particular , we get fast rates ( log-linear convergence ) provided that the variance decreases around the optimum slightly faster than in the so-called multiplicative noise model . Keywords : Noisy optimization , evolutionary algorithm , theory .
Continuous time Bayesian networks ( CTBNs ) describe structured stochastic processes with finitely many states that evolve over continuous time . A CTBN is a directed ( possibly cyclic ) dependency graph over a set of variables , each of which represents a finite state continuous time Markov process whose transition model is a function of its parents . We address the problem of learning parameters and structure of a CTBN from fully observed data . We define a conjugate prior for CTBNs , and show how it can be used both for Bayesian parameter estimation and as the basis of a Bayesian score for structure learning . Because acyclicity is not a constraint in CTBNs , we can show that the structure learning problem is significantly easier , both in theory and in practice , than structure learning for dynamic Bayesian networks ( DBNs ) . Furthermore , as CTBNs can tailor the parameters and dependency structure to the different time granularities of the evolution of different variables , they can provide a better fit to continuous-time processes than DBNs with a fixed time granularity .
We describe a Groebner basis of relations among conditional probabilities in a discrete probability space , with any set of conditioned-upon events . They may be specialized to the partially-observed random variable case , the purely conditional case , and other special cases . We also investigate the connection to generalized permutohedra and describe a conditional probability simplex .
Complex systems can be modelled at various levels of detail . Ideally , causal models of the same system should be consistent with one another in the sense that they agree in their predictions of the effects of interventions . We formalise this notion of consistency in the case of Structural Equation Models ( SEMs ) by introducing exact transformations between SEMs . This provides a general language to consider , for instance , the different levels of description in the following three scenarios : ( a ) models with large numbers of variables versus models in which the `irrelevant ' or unobservable variables have been marginalised out ; ( b ) micro-level models versus macro-level models in which the macro-variables are aggregate features of the micro-variables ; ( c ) dynamical time series models versus models of their stationary behaviour . Our analysis stresses the importance of well specified interventions in the causal modelling process and sheds light on the interpretation of cyclic SEMs .
Recent studies have highlighted the vulnerability of deep neural networks ( DNNs ) to adversarial examples - a visually indistinguishable adversarial image can easily be crafted to cause a well-trained model to misclassify . Existing methods for crafting adversarial examples are based on $L_0$ and $L_\infty$ distortion metrics . However , despite the fact that $L_0$ distortion accounts for the total variation and encourages sparsity in the perturbation , little has been developed for crafting $L_0$-based adversarial examples . In this paper , we formulate the process of attacking DNNs via adversarial examples as an elastic-net regularized optimization problem . Our elastic-net attacks to DNNs ( EAD ) feature $L_0$-oriented adversarial examples and include the state-of-the-art $L_0$ attack as a special case . Experimental results on MNIST , CIFAR00 and ImageNet show that EAD can yield a distinct set of adversarial examples with small $L_0$ distortion and attains similar attack performance to the state-of-the-art methods in different attack scenarios . More importantly , EAD leads to improved attack transferability and complements adversarial training for DNNs , suggesting novel insights on leveraging $L_0$ distortion in adversarial machine learning and security implications of DNNs .
This work falls within the context of predicting the value of a real function at some input locations given a limited number of observations of this function . The Kriging interpolation technique ( or Gaussian process regression ) is often considered to tackle such a problem but the method suffers from its computational burden when the number of observation points is large . We introduce in this article nested Kriging predictors which are constructed by aggregating sub-models based on subsets of observation points . This approach is proven to have better theoretical properties than other aggregation methods that can be found in the literature . Contrarily to some other methods it can be shown that the proposed aggregation method is consistent . Finally , the practical interest of the proposed method is illustrated on simulated datasets and on an industrial test case with $00^0$ observations in a 0-dimensional space .
We give tight concentration bounds for mixtures of martingales that are simultaneously uniform over ( a ) mixture distributions , in a PAC-Bayes sense ; and ( b ) all finite times . These bounds are proved in terms of the martingale variance , extending classical Bernstein inequalities , and sharpening and simplifying prior work .
We propose mS0GD : a method incorporating a mini-batching scheme for improving the theoretical complexity and practical performance of semi-stochastic gradient descent ( S0GD ) . We consider the problem of minimizing a strongly convex function represented as the sum of an average of a large number of smooth convex functions , and a simple nonsmooth convex regularizer . Our method first performs a deterministic step ( computation of the gradient of the objective function at the starting point ) , followed by a large number of stochastic steps . The process is repeated a few times with the last iterate becoming the new starting point . The novelty of our method is in introduction of mini-batching into the computation of stochastic steps . In each step , instead of choosing a single function , we sample $b$ functions , compute their gradients , and compute the direction based on this . We analyze the complexity of the method and show that it benefits from two speedup effects . First , we prove that as long as $b$ is below a certain threshold , we can reach any predefined accuracy with less overall work than without mini-batching . Second , our mini-batching scheme admits a simple parallel implementation , and hence is suitable for further acceleration by parallelization .
In sparse recovery we are given a matrix $A$ ( the dictionary ) and a vector of the form $A X$ where $X$ is sparse , and the goal is to recover $X$ . This is a central notion in signal processing , statistics and machine learning . But in applications such as sparse coding , edge detection , compression and super resolution , the dictionary $A$ is unknown and has to be learned from random examples of the form $Y = AX$ where $X$ is drawn from an appropriate distribution --- this is the dictionary learning problem . In most settings , $A$ is overcomplete : it has more columns than rows . This paper presents a polynomial-time algorithm for learning overcomplete dictionaries ; the only previously known algorithm with provable guarantees is the recent work of Spielman , Wang and Wright who gave an algorithm for the full-rank case , which is rarely the case in applications . Our algorithm applies to incoherent dictionaries which have been a central object of study since they were introduced in seminal work of Donoho and Huo . In particular , a dictionary is $\mu$-incoherent if each pair of columns has inner product at most $\mu / \sqrt{n}$ . The algorithm makes natural stochastic assumptions about the unknown sparse vector $X$ , which can contain $k \leq c \min ( \sqrt{n}/\mu \log n , m^{0/0 -\eta} ) $ non-zero entries ( for any $\eta > 0$ ) . This is close to the best $k$ allowable by the best sparse recovery algorithms even if one knows the dictionary $A$ exactly . Moreover , both the running time and sample complexity depend on $\log 0/\epsilon$ , where $\epsilon$ is the target accuracy , and so our algorithms converge very quickly to the true dictionary . Our algorithm can also tolerate substantial amounts of noise provided it is incoherent with respect to the dictionary ( e . g . , Gaussian ) . In the noisy setting , our running time and sample complexity depend polynomially on $0/\epsilon$ , and this is necessary .
Environmental acoustic sensing involves the retrieval and processing of audio signals to better understand our surroundings . While large-scale acoustic data make manual analysis infeasible , they provide a suitable playground for machine learning approaches . Most existing machine learning techniques developed for environmental acoustic sensing do not provide flexible control of the trade-off between the false positive rate and the false negative rate . This paper presents a cost-sensitive classification paradigm , in which the hyper-parameters of classifiers and the structure of variational autoencoders are selected in a principled Neyman-Pearson framework . We examine the performance of the proposed approach using a dataset from the HumBug project which aims to detect the presence of mosquitoes using sound collected by simple embedded devices .
In this note we provide detailed derivations of two versions of small-variance asymptotics for hierarchical Dirichlet process ( HDP ) mixture models and the HDP hidden Markov model ( HDP-HMM , a . k . a . the infinite HMM ) . We include derivations for the probabilities of certain CRP and CRF partitions , which are of more general interest .
In this paper , we tackle the problem of online semi-supervised learning ( SSL ) . When data arrive in a stream , the dual problems of computation and data storage arise for any SSL method . We propose a fast approximate online SSL algorithm that solves for the harmonic solution on an approximate graph . We show , both empirically and theoretically , that good behavior can be achieved by collapsing nearby points into a set of local " representative points " that minimize distortion . Moreover , we regularize the harmonic solution to achieve better stability properties . We apply our algorithm to face recognition and optical character recognition applications to show that we can take advantage of the manifold structure to outperform the previous methods . Unlike previous heuristic approaches , we show that our method yields provable performance bounds .
MAP inference for general energy functions remains a challenging problem . While most efforts are channeled towards improving the linear programming ( LP ) based relaxation , this work is motivated by the quadratic programming ( QP ) relaxation . We propose a novel MAP relaxation that penalizes the Kullback-Leibler divergence between the LP pairwise auxiliary variables , and QP equivalent terms given by the product of the unaries . We develop two efficient algorithms based on variants of this relaxation . The algorithms minimize the non-convex objective using belief propagation and dual decomposition as building blocks . Experiments on synthetic and real-world data show that the solutions returned by our algorithms substantially improve over the LP relaxation .
In many statistical problems , a more coarse-grained model may be suitable for population-level behaviour , whereas a more detailed model is appropriate for accurate modelling of individual behaviour . This raises the question of how to integrate both types of models . Methods such as posterior regularization follow the idea of generalized moment matching , in that they allow matching expectations between two models , but sometimes both models are most conveniently expressed as latent variable models . We propose latent Bayesian melding , which is motivated by averaging the distributions over populations statistics of both the individual-level and the population-level models under a logarithmic opinion pool framework . In a case study on electricity disaggregation , which is a type of single-channel blind source separation problem , we show that latent Bayesian melding leads to significantly more accurate predictions than an approach based solely on generalized moment matching .
It is needed to ensure the integrity of systems that process sensitive information and control many aspects of everyday life . We examine the use of machine learning algorithms to detect malware using the system calls generated by executables-alleviating attempts at obfuscation as the behavior is monitored rather than the bytes of an executable . We examine several machine learning techniques for detecting malware including random forests , deep learning techniques , and liquid state machines . The experiments examine the effects of concept drift on each algorithm to understand how well the algorithms generalize to novel malware samples by testing them on data that was collected after the training data . The results suggest that each of the examined machine learning algorithms is a viable solution to detect malware-achieving between 00% and 00% class-averaged accuracy ( CAA ) . In real-world scenarios , the performance evaluation on an operational network may not match the performance achieved in training . Namely , the CAA may be about the same , but the values for precision and recall over the malware can change significantly . We structure experiments to highlight these caveats and offer insights into expected performance in operational environments . In addition , we use the induced models to gain a better understanding about what differentiates the malware samples from the goodware , which can further be used as a forensics tool to understand what the malware ( or goodware ) was doing to provide directions for investigation and remediation .
Transactional network data can be thought of as a list of one-to-many communications ( e . g . , email ) between nodes in a social network . Most social network models convert this type of data into binary relations between pairs of nodes . We develop a latent mixed membership model capable of modeling richer forms of transactional network data , including relations between more than two nodes . The model can cluster nodes and predict transactions . The block-model nature of the model implies that groups can be characterized in very general ways . This flexible notion of group structure enables discovery of rich structure in transactional networks . Estimation and inference are accomplished via a variational EM algorithm . Simulations indicate that the learning algorithm can recover the correct generative model . Interesting structure is discovered in the Enron email dataset and another dataset extracted from the Reddit website . Analysis of the Reddit data is facilitated by a novel performance measure for comparing two soft clusterings . The new model is superior at discovering mixed membership in groups and in predicting transactions .
Choosing the best-performing optimizer ( s ) out of a portfolio of optimization algorithms is usually a difficult and complex task . It gets even worse , if the underlying functions are unknown , i . e . , so-called Black-Box problems , and function evaluations are considered to be expensive . In the case of continuous single-objective optimization problems , Exploratory Landscape Analysis ( ELA ) - a sophisticated and effective approach for characterizing the landscapes of such problems by means of numerical values before actually performing the optimization task itself - is advantageous . Unfortunately , until now it has been quite complicated to compute multiple ELA features simultaneously , as the corresponding code has been - if at all - spread across multiple platforms or at least across several packages within these platforms . This article presents a broad summary of existing ELA approaches and introduces flacco , an R-package for feature-based landscape analysis of continuous and constrained optimization problems . Although its functions neither solve the optimization problem itself nor the related " Algorithm Selection Problem ( ASP ) " , it offers easy access to an essential ingredient of the ASP by providing a wide collection of ELA features on a single platform - even within a single package . In addition , flacco provides multiple visualization techniques , which enhance the understanding of some of these numerical features , and thereby make certain landscape properties more comprehensible . On top of that , we will introduce the package ' s build-in , as well as web-hosted and hence platform-independent , graphical user interface ( GUI ) , which facilitates the usage of the package - especially for people who are not familiar with R - making it a very convenient toolbox when working towards algorithm selection of continuous single-objective optimization problems .
A central problem in ranking is to design a ranking measure for evaluation of ranking functions . In this paper we study , from a theoretical perspective , the widely used Normalized Discounted Cumulative Gain ( NDCG ) -type ranking measures . Although there are extensive empirical studies of NDCG , little is known about its theoretical properties . We first show that , whatever the ranking function is , the standard NDCG which adopts a logarithmic discount , converges to 0 as the number of items to rank goes to infinity . On the first sight , this result is very surprising . It seems to imply that NDCG cannot differentiate good and bad ranking functions , contradicting to the empirical success of NDCG in many applications . In order to have a deeper understanding of ranking measures in general , we propose a notion referred to as consistent distinguishability . This notion captures the intuition that a ranking measure should have such a property : For every pair of substantially different ranking functions , the ranking measure can decide which one is better in a consistent manner on almost all datasets . We show that NDCG with logarithmic discount has consistent distinguishability although it converges to the same limit for all ranking functions . We next characterize the set of all feasible discount functions for NDCG according to the concept of consistent distinguishability . Specifically we show that whether NDCG has consistent distinguishability depends on how fast the discount decays , and 0/r is a critical point . We then turn to the cut-off version of NDCG , i . e . , NDCG@k . We analyze the distinguishability of NDCG@k for various choices of k and the discount functions . Experimental results on real Web search datasets agree well with the theory .
Much of human knowledge sits in large databases of unstructured text . Leveraging this knowledge requires algorithms that extract and record metadata on unstructured text documents . Assigning topics to documents will enable intelligent search , statistical characterization , and meaningful classification . Latent Dirichlet allocation ( LDA ) is the state-of-the-art in topic classification . Here , we perform a systematic theoretical and numerical analysis that demonstrates that current optimization techniques for LDA often yield results which are not accurate in inferring the most suitable model parameters . Adapting approaches for community detection in networks , we propose a new algorithm which displays high-reproducibility and high-accuracy , and also has high computational efficiency . We apply it to a large set of documents in the English Wikipedia and reveal its hierarchical structure . Our algorithm promises to make " big data " text analysis systems more reliable .
Resolving a conjecture of Abbe , Bandeira and Hall , the authors have recently shown that the semidefinite programming ( SDP ) relaxation of the maximum likelihood estimator achieves the sharp threshold for exactly recovering the community structure under the binary stochastic block model of two equal-sized clusters . The same was shown for the case of a single cluster and outliers . Extending the proof techniques , in this paper it is shown that SDP relaxations also achieve the sharp recovery threshold in the following cases : ( 0 ) Binary stochastic block model with two clusters of sizes proportional to network size but not necessarily equal ; ( 0 ) Stochastic block model with a fixed number of equal-sized clusters ; ( 0 ) Binary censored block model with the background graph being Erd\H{o}s-R\ ' enyi . Furthermore , a sufficient condition is given for an SDP procedure to achieve exact recovery for the general case of a fixed number of clusters plus outliers . These results demonstrate the versatility of SDP relaxation as a simple , general purpose , computationally feasible methodology for community detection .
Monte Carlo ( MC ) sampling algorithms are an extremely widely-used technique to estimate expectations of functions f ( x ) , especially in high dimensions . Control variates are a very powerful technique to reduce the error of such estimates , but in their conventional form rely on having an accurate approximation of f , a priori . Stacked Monte Carlo ( StackMC ) is a recently introduced technique designed to overcome this limitation by fitting a control variate to the data samples themselves . Done naively , forming a control variate to the data would result in overfitting , typically worsening the MC algorithm ' s performance . StackMC uses in-sample / out-sample techniques to remove this overfitting . Crucially , it is a post-processing technique , requiring no additional samples , and can be applied to data generated by any MC estimator . Our preliminary experiments demonstrated that StackMC improved the estimates of expectations when it was used to post-process samples produces by a " simple sampling " MC estimator . Here we substantially extend this earlier work . We provide an in-depth analysis of the StackMC algorithm , which we use to construct an improved version of the original algorithm , with lower estimation error . We then perform experiments of StackMC on several additional kinds of MC estimators , demonstrating improved performance when the samples are generated via importance sampling , Latin-hypercube sampling and quasi-Monte Carlo sampling . We also show how to extend StackMC to combine multiple fitting functions , and how to apply it to discrete input spaces x .
Distillation ( Hinton et al . , 0000 ) and privileged information ( Vapnik & Izmailov , 0000 ) are two techniques that enable machines to learn from other machines . This paper unifies these two techniques into generalized distillation , a framework to learn from multiple machines and data representations . We provide theoretical and causal insight about the inner workings of generalized distillation , extend it to unsupervised , semisupervised and multitask learning scenarios , and illustrate its efficacy on a variety of numerical simulations on both synthetic and real-world data .
Tensor rank and low-rank tensor decompositions have many applications in learning and complexity theory . Most known algorithms use unfoldings of tensors and can only handle rank up to $n^{\lfloor p/0 \rfloor}$ for a $p$-th order tensor in $\mathbb{R}^{n^p}$ . Previously no efficient algorithm can decompose 0rd order tensors when the rank is super-linear in the dimension . Using ideas from sum-of-squares hierarchy , we give the first quasi-polynomial time algorithm that can decompose a random 0rd order tensor decomposition when the rank is as large as $n^{0/0}/\textrm{polylog} n$ . We also give a polynomial time algorithm for certifying the injective norm of random low rank tensors . Our tensor decomposition algorithm exploits the relationship between injective norm and the tensor components . The proof relies on interesting tools for decoupling random variables to prove better matrix concentration bounds , which can be useful in other settings .
The majority of medical documents and electronic health records ( EHRs ) are in text format that poses a challenge for data processing and finding relevant documents . Looking for ways to automatically retrieve the enormous amount of health and medical knowledge has always been an intriguing topic . Powerful methods have been developed in recent years to make the text processing automatic . One of the popular approaches to retrieve information based on discovering the themes in health & medical corpora is topic modeling , however , this approach still needs new perspectives . In this research we describe fuzzy latent semantic analysis ( FLSA ) , a novel approach in topic modeling using fuzzy perspective . FLSA can handle health & medical corpora redundancy issue and provides a new method to estimate the number of topics . The quantitative evaluations show that FLSA produces superior performance and features to latent Dirichlet allocation ( LDA ) , the most popular topic model .
In this paper , we face the problem of simulating discrete random variables with general and varying distributions in a scalable framework , where fully parallelizable operations should be preferred . The new paradigm is inspired by the context of discrete choice models . Compared to classical algorithms , we add parallelized randomness , and we leave the final simulation of the random variable to a single associative operation . We characterize the set of algorithms that work in this way , and those algorithms that may have an additive or multiplicative local noise . As a consequence , we could define a natural way to solve some popular simulation problems .
When modeling a probability distribution with a Bayesian network , we are faced with the problem of how to handle continuous variables . Most previous work has either solved the problem by discretizing , or assumed that the data are generated by a single Gaussian . In this paper we abandon the normality assumption and instead use statistical methods for nonparametric density estimation . For a naive Bayesian classifier , we present experimental results on a variety of natural and artificial domains , comparing two methods of density estimation : assuming normality and modeling each conditional distribution with a single Gaussian ; and using nonparametric kernel density estimation . We observe large reductions in error on several natural and artificial data sets , which suggests that kernel estimation is a useful tool for learning Bayesian models .
Big data sets must be carefully partitioned into statistically similar data subsets that can be used as representative samples for big data analysis tasks . In this paper , we propose the random sample partition ( RSP ) to represent a big data set as a set of non-overlapping data subsets , i . e . RSP data blocks , where each RSP data block has the same probability distribution with the whole big data set . Then , the block-based sampling is used to directly select representative samples for a variety of data analysis tasks . We show how RSP data blocks can be employed to estimate statistics and build models which are equivalent ( or approximate ) to those from the whole big data set .
A substantial progress in development of new and efficient tensor factorization techniques has led to an extensive research of their applicability in recommender systems field . Tensor-based recommender models push the boundaries of traditional collaborative filtering techniques by taking into account a multifaceted nature of real environments , which allows to produce more accurate , situational ( e . g . context-aware , criteria-driven ) recommendations . Despite the promising results , tensor-based methods are poorly covered in existing recommender systems surveys . This survey aims to complement previous works and provide a comprehensive overview on the subject . To the best of our knowledge , this is the first attempt to consolidate studies from various application domains in an easily readable , digestible format , which helps to get a notion of the current state of the field . We also provide a high level discussion of the future perspectives and directions for further improvement of tensor-based recommendation systems .
Most existing approaches address multi-view subspace clustering problem by constructing the affinity matrix on each view separately and afterwards propose how to extend spectral clustering algorithm to handle multi-view data . This paper presents an approach to multi-view subspace clustering that learns a joint subspace representation by constructing affinity matrix shared among all views . Relying on the importance of both low-rank and sparsity constraints in the construction of the affinity matrix , we introduce the objective that balances between the agreement across different views , while at the same time encourages sparsity and low-rankness of the solution . Related low-rank and sparsity constrained optimization problem is for each view solved using the alternating direction method of multipliers . Furthermore , we extend our approach to cluster data drawn from nonlinear subspaces by solving the corresponding problem in a reproducing kernel Hilbert space . The proposed algorithm outperforms state-of-the-art multi-view subspace clustering algorithms on one synthetic and four real-world datasets .
Discovering causal relations is fundamental to reasoning and intelligence . In particular , observational causal discovery algorithms estimate the cause-effect relation between two random entities $X$ and $Y$ , given $n$ samples from $P ( X , Y ) $ . In this paper , we develop a framework to estimate the cause-effect relation between two static entities $x$ and $y$ : for instance , an art masterpiece $x$ and its fraudulent copy $y$ . To this end , we introduce the notion of proxy variables , which allow the construction of a pair of random entities $ ( A , B ) $ from the pair of static entities $ ( x , y ) $ . Then , estimating the cause-effect relation between $A$ and $B$ using an observational causal discovery algorithm leads to an estimation of the cause-effect relation between $x$ and $y$ . For example , our framework detects the causal relation between unprocessed photographs and their modifications , and orders in time a set of shuffled frames from a video . As our main case study , we introduce a human-elicited dataset of 00 , 000 pairs of casually-linked pairs of words from natural language . Our methods discover 00% of these causal relations . Finally , we discuss the role of proxy variables in machine learning , as a general tool to incorporate static knowledge into prediction tasks .
Autism Spectrum Disorders ( ASDs ) are often associated with specific atypical postural or motor behaviors , of which Stereotypical Motor Movements ( SMMs ) have a specific visibility . While the identification and the quantification of SMM patterns remain complex , its automation would provide support to accurate tuning of the intervention in the therapy of autism . Therefore , it is essential to develop automatic SMM detection systems in a real world setting , taking care of strong inter-subject and intra-subject variability . Wireless accelerometer sensing technology can provide a valid infrastructure for real-time SMM detection , however such variability remains a problem also for machine learning methods , in particular whenever handcrafted features extracted from accelerometer signal are considered . Here , we propose to employ the deep learning paradigm in order to learn discriminating features from multi-sensor accelerometer signals . Our results provide preliminary evidence that feature learning and transfer learning embedded in the deep architecture achieve higher accurate SMM detectors in longitudinal scenarios .
In this communication , we describe some interrelations between generalized $q$-entropies and a generalized version of Fisher information . In information theory , the de Bruijn identity links the Fisher information and the derivative of the entropy . We show that this identity can be extended to generalized versions of entropy and Fisher information . More precisely , a generalized Fisher information naturally pops up in the expression of the derivative of the Tsallis entropy . This generalized Fisher information also appears as a special case of a generalized Fisher information for estimation problems . Indeed , we derive here a new Cram\ ' er-Rao inequality for the estimation of a parameter , which involves a generalized form of Fisher information . This generalized Fisher information reduces to the standard Fisher information as a particular case . In the case of a translation parameter , the general Cram\ ' er-Rao inequality leads to an inequality for distributions which is saturated by generalized $q$-Gaussian distributions . These generalized $q$-Gaussians are important in several areas of physics and mathematics . They are known to maximize the $q$-entropies subject to a moment constraint . The Cram\ ' er-Rao inequality shows that the generalized $q$-Gaussians also minimize the generalized Fisher information among distributions with a fixed moment . Similarly , the generalized $q$-Gaussians also minimize the generalized Fisher information among distributions with a given $q$-entropy .
We propose a paradigm to deep-learn the ever-expanding databases which have emerged in mathematical physics and particle phenomenology , as diverse as the statistics of string vacua or combinatorial and algebraic geometry . As concrete examples , we establish multi-layer neural networks as both classifiers and predictors and train them with a host of available data ranging from Calabi-Yau manifolds and vector bundles , to quiver representations for gauge theories . We find that even a relatively simple neural network can learn many significant quantities to astounding accuracy in a matter of minutes and can also predict hithertofore unencountered results . This paradigm should prove a valuable tool in various investigations in landscapes in physics as well as pure mathematics .
A new procedure , called DDa-procedure , is developed to solve the problem of classifying d-dimensional objects into q >= 0 classes . The procedure is completely nonparametric ; it uses q-dimensional depth plots and a very efficient algorithm for discrimination analysis in the depth space [0 , 0]^q . Specifically , the depth is the zonoid depth , and the algorithm is the alpha-procedure . In case of more than two classes several binary classifications are performed and a majority rule is applied . Special treatments are discussed for ' outsiders ' , that is , data having zero depth vector . The DDa-classifier is applied to simulated as well as real data , and the results are compared with those of similar procedures that have been recently proposed . In most cases the new procedure has comparable error rates , but is much faster than other classification approaches , including the SVM .
Many statistical methods have been proposed to estimate causal models in classical situations with fewer variables than observations ( p<n , p : the number of variables and n : the number of observations ) . However , modern datasets including gene expression data need high-dimensional causal modeling in challenging situations with orders of magnitude more variables than observations ( p>>n ) . In this paper , we propose a method to find exogenous variables in a linear non-Gaussian causal model , which requires much smaller sample sizes than conventional methods and works even when p>>n . The key idea is to identify which variables are exogenous based on non-Gaussianity instead of estimating the entire structure of the model . Exogenous variables work as triggers that activate a causal chain in the model , and their identification leads to more efficient experimental designs and better understanding of the causal mechanism . We present experiments with artificial data and real-world gene expression data to evaluate the method .
Recently proposed models which learn to write computer programs from data use either input/output examples or rich execution traces . Instead , we argue that a novel alternative is to use a glass-box loss function , given as a program itself that can be directly inspected . Glass-box optimization covers a wide range of problems , from computing the greatest common divisor of two integers , to learning-to-learn problems . In this paper , we present an intelligent search system which learns , given the partial program and the glass-box problem , the probabilities over the space of programs . We empirically demonstrate that our informed search procedure leads to significant improvements compared to brute-force program search , both in terms of accuracy and time . For our experiments we use rich context free grammars inspired by number theory , text processing , and algebra . Our results show that ( i ) performing 0 rounds of our framework typically solves about 00% of the target problems , ( ii ) our framework can improve itself even in domain agnostic scenarios , and ( iii ) it can solve problems that would be otherwise too slow to solve with brute-force search .
We propose a framework for feature selection that employs kernel-based measures of independence to find a subset of covariates that is maximally predictive of the response . Building on past work in kernel dimension reduction , we formulate our approach as a constrained optimization problem involving the trace of the conditional covariance operator , and additionally provide some consistency results . We then demonstrate on a variety of synthetic and real data sets that our method compares favorably with other state-of-the-art algorithms .
Unsupervised clustering is one of the most fundamental challenges in machine learning . A popular hypothesis is that data are generated from a union of low-dimensional nonlinear manifolds ; thus an approach to clustering is identifying and separating these manifolds . In this paper , we present a novel approach to solve this problem by using a mixture of autoencoders . Our model consists of two parts : 0 ) a collection of autoencoders where each autoencoder learns the underlying manifold of a group of similar objects , and 0 ) a mixture assignment neural network , which takes the concatenated latent vectors from the autoencoders as input and infers the distribution over clusters . By jointly optimizing the two parts , we simultaneously assign data to clusters and learn the underlying manifolds of each cluster .
We present efficient algorithms for the problem of contextual bandits with i . i . d . covariates , an arbitrary sequence of rewards , and an arbitrary class of policies . Our algorithm BISTRO requires d calls to the empirical risk minimization ( ERM ) oracle per round , where d is the number of actions . The method uses unlabeled data to make the problem computationally simple . When the ERM problem itself is computationally hard , we extend the approach by employing multiplicative approximation algorithms for the ERM . The integrality gap of the relaxation only enters in the regret bound rather than the benchmark . Finally , we show that the adversarial version of the contextual bandit problem is learnable ( and efficient ) whenever the full-information supervised online learning problem has a non-trivial regret guarantee ( and efficient ) .
The paper presents a novel , principled approach to train recurrent neural networks from the Reservoir Computing family that are robust to missing part of the input features at prediction time . By building on the ensembling properties of Dropout regularization , we propose a methodology , named DropIn , which efficiently trains a neural model as a committee machine of subnetworks , each capable of predicting with a subset of the original input features . We discuss the application of the DropIn methodology in the context of Reservoir Computing models and targeting applications characterized by input sources that are unreliable or prone to be disconnected , such as in pervasive wireless sensor networks and ambient intelligence . We provide an experimental assessment using real-world data from such application domains , showing how the Dropin methodology allows to maintain predictive performances comparable to those of a model without missing features , even when 00\%-00\% of the inputs are not available .
Low-rank representation~ ( LRR ) has been a significant method for segmenting data that are generated from a union of subspaces . It is , however , known that solving the LRR program is challenging in terms of time complexity and memory footprint , in that the size of the nuclear norm regularized matrix is $n$-by-$n$ ( where $n$ is the number of samples ) . In this paper , we thereby develop a fast online implementation of LRR that reduces the memory cost from $O ( n^0 ) $ to $O ( pd ) $ , with $p$ being the ambient dimension and $d$ being some estimated rank~ ( $d < p \ll n$ ) . The crux for this end is a non-convex reformulation of the LRR program , which pursues the basis dictionary that generates the ( uncorrupted ) observations . We build the theoretical guarantee that the sequence of the solutions produced by our algorithm converges to a stationary point of the empirical and the expected loss function asymptotically . Extensive experiments on synthetic and realistic datasets further substantiate that our algorithm is fast , robust and memory efficient .
Much information available on the web is copied , reused or rephrased . The phenomenon that multiple web sources pick up certain information is often called trend . A central problem in the context of web data mining is to detect those web sources that are first to publish information which will give rise to a trend . We present a simple and efficient method for finding trends dominating a pool of web sources and identifying those web sources that publish the information relevant to a trend before others . We validate our approach on real data collected from influential technology news feeds .
Conventional SVM-based image coding methods are founded on independently restricting the distortion in every image coefficient at some particular image representation . Geometrically , this implies allowing arbitrary signal distortions in an $n$-dimensional rectangle defined by the $\varepsilon$-insensitivity zone in each dimension of the selected image representation domain . Unfortunately , not every image representation domain is well-suited for such a simple , scalar-wise , approach because statistical and/or perceptual interactions between the coefficients may exist . These interactions imply that scalar approaches may induce distortions that do not follow the image statistics and/or are perceptually annoying . Taking into account these relations would imply using non-rectangular $\varepsilon$-insensitivity regions ( allowing coupled distortions in different coefficients ) , which is beyond the conventional SVM formulation . In this paper , we report a condition on the suitable domain for developing efficient SVM image coding schemes . We analytically demonstrate that no linear domain fulfills this condition because of the statistical and perceptual inter-coefficient relations that exist in these domains . This theoretical result is experimentally confirmed by comparing SVM learning in previously reported linear domains and in a recently proposed non-linear perceptual domain that simultaneously reduces the statistical and perceptual relations ( so it is closer to fulfilling the proposed condition ) . These results highlight the relevance of an appropriate choice of the image representation before SVM learning .
The optimization problem behind neural networks is highly non-convex . Training with stochastic gradient descent and variants requires careful parameter tuning and provides no guarantee to achieve the global optimum . In contrast we show under quite weak assumptions on the data that a particular class of feedforward neural networks can be trained globally optimal with a linear convergence rate with our nonlinear spectral method . Up to our knowledge this is the first practically feasible method which achieves such a guarantee . While the method can in principle be applied to deep networks , we restrict ourselves for simplicity in this paper to one and two hidden layer networks . Our experiments confirm that these models are rich enough to achieve good performance on a series of real-world datasets .
Convolutional neural networks ( CNNs ) have recently emerged as a popular building block for natural language processing ( NLP ) . Despite their success , most existing CNN models employed in NLP are not expressive enough , in the sense that all input sentences share the same learned ( and static ) set of filters . Motivated by this problem , we propose an adaptive convolutional filter generation framework for natural language understanding , by leveraging a meta network to generate input-aware filters . We further generalize our framework to model question-answer sentence pairs and propose an adaptive question answering ( AdaQA ) model ; a novel two-way feature abstraction mechanism is introduced to encapsulate co-dependent sentence representations . We investigate the effectiveness of our framework on document categorization and answer sentence-selection tasks , achieving state-of-the-art performance on several benchmark datasets .
How can we perform efficient inference and learning in directed probabilistic models , in the presence of continuous latent variables with intractable posterior distributions , and large datasets ? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and , under some mild differentiability conditions , even works in the intractable case . Our contributions is two-fold . First , we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods . Second , we show that for i . i . d . datasets with continuous latent variables per datapoint , posterior inference can be made especially efficient by fitting an approximate inference model ( also called a recognition model ) to the intractable posterior using the proposed lower bound estimator . Theoretical advantages are reflected in experimental results .
Given a weighted graph with $N$ vertices , consider a real-valued regression problem in a semi-supervised setting , where one observes $n$ labeled vertices , and the task is to label the remaining ones . We present a theoretical study of $\ell_p$-based Laplacian regularization under a $d$-dimensional geometric random graph model . We provide a variational characterization of the performance of this regularized learner as $N$ grows to infinity while $n$ stays constant , the associated optimality conditions lead to a partial differential equation that must be satisfied by the associated function estimate $\hat{f}$ . From this formulation we derive several predictions on the limiting behavior the $d$-dimensional function $\hat{f}$ , including ( a ) a phase transition in its smoothness at the threshold $p = d + 0$ , and ( b ) a tradeoff between smoothness and sensitivity to the underlying unlabeled data distribution $P$ . Thus , over the range $p \leq d$ , the function estimate $\hat{f}$ is degenerate and " spiky , " whereas for $p\geq d+0$ , the function estimate $\hat{f}$ is smooth . We show that the effect of the underlying density vanishes monotonically with $p$ , such that in the limit $p = \infty$ , corresponding to the so-called Absolutely Minimal Lipschitz Extension , the estimate $\hat{f}$ is independent of the distribution $P$ . Under the assumption of semi-supervised smoothness , ignoring $P$ can lead to poor statistical performance , in particular , we construct a specific example for $d=0$ to demonstrate that $p=0$ has lower risk than $p=\infty$ due to the former penalty adapting to $P$ and the latter ignoring it . We also provide simulations that verify the accuracy of our predictions for finite sample sizes . Together , these properties show that $p = d+0$ is an optimal choice , yielding a function estimate $\hat{f}$ that is both smooth and non-degenerate , while remaining maximally sensitive to $P$ .
Class imbalance presents a major hurdle in the application of data mining methods . A common practice to deal with it is to create ensembles of classifiers that learn from resampled balanced data . For example , bagged decision trees combined with random undersampling ( RUS ) or the synthetic minority oversampling technique ( SMOTE ) . However , most of the resampling methods entail asymmetric changes to the examples of different classes , which in turn can introduce its own biases in the model . Furthermore , those methods require a performance measure to be specified a priori before learning . An alternative is to use a so-called threshold-moving method that a posteriori changes the decision threshold of a model to counteract the imbalance , thus has a potential to adapt to the performance measure of interest . Surprisingly , little attention has been paid to the potential of combining bagging ensemble with threshold-moving . In this paper , we present probability thresholding bagging ( PT-bagging ) , a versatile plug-in method that fills this gap . Contrary to usual rebalancing practice , our method preserves the natural class distribution of the data resulting in well calibrated posterior probabilities . We also extend the proposed method to handle multiclass data . The method is validated on binary and multiclass benchmark data sets . We perform analyses that provide insights into the proposed method .
Distance metric learning is an important component for many tasks , such as statistical classification and content-based image retrieval . Existing approaches for learning distance metrics from pairwise constraints typically suffer from two major problems . First , most algorithms only offer point estimation of the distance metric and can therefore be unreliable when the number of training examples is small . Second , since these algorithms generally select their training examples at random , they can be inefficient if labeling effort is limited . This paper presents a Bayesian framework for distance metric learning that estimates a posterior distribution for the distance metric from labeled pairwise constraints . We describe an efficient algorithm based on the variational method for the proposed Bayesian approach . Furthermore , we apply the proposed Bayesian framework to active distance metric learning by selecting those unlabeled example pairs with the greatest uncertainty in relative distance . Experiments in classification demonstrate that the proposed framework achieves higher classification accuracy and identifies more informative training examples than the non-Bayesian approach and state-of-the-art distance metric learning algorithms .
We introduce contextual explanation networks ( CENs ) ---a class of models that learn to predict by generating and leveraging intermediate explanations . CENs combine deep networks with context-specific probabilistic models and construct explanations in the form of locally-correct hypotheses . Contrary to the existing post-hoc model-explanation tools , CENs learn to predict and to explain jointly . Our approach offers two major advantages : ( i ) for each prediction , valid instance-specific explanations are generated with no computational overhead and ( ii ) prediction via explanation acts as a regularization and boosts performance in low-resource settings . We prove that local approximations to the decision boundary of our networks are consistent with the generated explanations . Our results on image and text classification and survival analysis tasks demonstrate that CENs can easily match or outperform the state-of-the-art while offering additional insights behind each prediction , valuable for decision support .
The law of total probability may be deployed in binary classification exercises to estimate the unconditional class probabilities if the class proportions in the training set are not representative of the population class proportions . We argue that this is not a conceptually sound approach and suggest an alternative based on the new law of total odds . We quantify the bias of the total probability estimator of the unconditional class probabilities and show that the total odds estimator is unbiased . The sample version of the total odds estimator is shown to coincide with a maximum-likelihood estimator known from the literature . The law of total odds can also be used for transforming the conditional class probabilities if independent estimates of the unconditional class probabilities of the population are available . Keywords : Total probability , likelihood ratio , Bayes ' formula , binary classification , relative odds , unbiased estimator , supervised learning , dataset shift .
Exploiting the wealth of imaging and non-imaging information for disease prediction tasks requires models capable of representing , at the same time , individual features as well as data associations between subjects from potentially large populations . Graphs provide a natural framework for such tasks , yet previous graph-based approaches focus on pairwise similarities without modelling the subjects ' individual characteristics and features . On the other hand , relying solely on subject-specific imaging feature vectors fails to model the interaction and similarity between subjects , which can reduce performance . In this paper , we introduce the novel concept of Graph Convolutional Networks ( GCN ) for brain analysis in populations , combining imaging and non-imaging data . We represent populations as a sparse graph where its vertices are associated with image-based feature vectors and the edges encode phenotypic information . This structure was used to train a GCN model on partially labelled graphs , aiming to infer the classes of unlabelled nodes from the node features and pairwise associations between subjects . We demonstrate the potential of the method on the challenging ADNI and ABIDE databases , as a proof of concept of the benefit from integrating contextual information in classification tasks . This has a clear impact on the quality of the predictions , leading to 00 . 0% accuracy for ABIDE ( outperforming the current state of the art of 00 . 0% ) and 00% for ADNI for prediction of MCI conversion , significantly outperforming standard linear classifiers where only individual features are considered .
It is generally believed that ensemble approaches , which combine multiple algorithms or models , can outperform any single algorithm at machine learning tasks , such as prediction . In this paper , we propose Bayesian convex and linear aggregation approaches motivated by regression applications . We show that the proposed approach is minimax optimal when the true data-generating model is a convex or linear combination of models in the list . Moreover , the method can adapt to sparsity structure in which certain models should receive zero weights , and the method is tuning parameter free unlike competitors . More generally , under an M-open view when the truth falls outside the space of all convex/linear combinations , our theory suggests that the posterior measure tends to concentrate on the best approximation of the truth at the minimax rate . We illustrate the method through simulation studies and several applications .
We study the problem of maximizing a monotone submodular function subject to a cardinality constraint $k$ , with the added twist that a number of items $\tau$ from the returned set may be removed . We focus on the worst-case setting considered in ( Orlin et al . , 0000 ) , in which a constant-factor approximation guarantee was given for $\tau = o ( \sqrt{k} ) $ . In this paper , we solve a key open problem raised therein , presenting a new Partitioned Robust ( PRo ) submodular maximization algorithm that achieves the same guarantee for more general $\tau = o ( k ) $ . Our algorithm constructs partitions consisting of buckets with exponentially increasing sizes , and applies standard submodular optimization subroutines on the buckets in order to construct the robust solution . We numerically demonstrate the performance of PRo in data summarization and influence maximization , demonstrating gains over both the greedy algorithm and the algorithm of ( Orlin et al . , 0000 ) .
Active learning is a powerful approach to analyzing data effectively . We show that the feasibility of active learning depends crucially on the choice of measure with respect to which the query is being optimized . The standard information gain , for example , does not permit an accurate evaluation with a small committee , a representative subset of the model space . We propose a surrogate measure requiring only a small committee and discuss the properties of this new measure . We devise , in addition , a bootstrap approach for committee selection . The advantages of this approach are illustrated in the context of recovering ( regulatory ) network models .
This article establishes the performance of stochastic blockmodels in addressing the co-clustering problem of partitioning a binary array into subsets , assuming only that the data are generated by a nonparametric process satisfying the condition of separate exchangeability . We provide oracle inequalities with rate of convergence $\mathcal{O}_P ( n^{-0/0} ) $ corresponding to profile likelihood maximization and mean-square error minimization , and show that the blockmodel can be interpreted in this setting as an optimal piecewise-constant approximation to the generative nonparametric model . We also show for large sample sizes that the detection of co-clusters in such data indicates with high probability the existence of co-clusters of equal size and asymptotically equivalent connectivity in the underlying generative process .
Independent component analysis ( ICA ) has been widely used for blind source separation in many fields such as brain imaging analysis , signal processing and telecommunication . Many statistical techniques based on M-estimates have been proposed for estimating the mixing matrix . Recently , several nonparametric methods have been developed , but in-depth analysis of asymptotic efficiency has not been available . We analyze ICA using semiparametric theories and propose a straightforward estimate based on the efficient score function by using B-spline approximations . The estimate is asymptotically efficient under moderate conditions and exhibits better performance than standard ICA methods in a variety of simulations .
We study the problem of multivariate regression where the data are naturally grouped , and a regression matrix is to be estimated for each group . We propose an approach in which a dictionary of low rank parameter matrices is estimated across groups , and a sparse linear combination of the dictionary elements is estimated to form a model within each group . We refer to the method as conditional sparse coding since it is a coding procedure for the response vectors Y conditioned on the covariate vectors X . This approach captures the shared information across the groups while adapting to the structure within each group . It exploits the same intuition behind sparse coding that has been successfully developed in computer vision and computational neuroscience . We propose an algorithm for conditional sparse coding , analyze its theoretical properties in terms of predictive accuracy , and present the results of simulation and brain imaging experiments that compare the new technique to reduced rank regression .
We develop a new method called Discriminated Hub Graphical Lasso ( DHGL ) based on Hub Graphical Lasso ( HGL ) by providing prior information of hubs . We apply this new method in two situations : with known hubs and without known hubs . Then we compare DHGL with HGL using several measures of performance . When some hubs are known , we can always estimate the precision matrix better via DHGL than HGL . When no hubs are known , we use Graphical Lasso ( GL ) to provide information of hubs and find that the performance of DHGL will always be better than HGL if correct prior information is given and will seldom degenerate when the prior information is wrong .
A nonlinear channel estimator using complex Least Square Support Vector Machines ( LS-SVM ) is proposed for pilot-aided OFDM system and applied to Long Term Evolution ( LTE ) downlink under high mobility conditions . The estimation algorithm makes use of the reference signals to estimate the total frequency response of the highly selective multipath channel in the presence of non-Gaussian impulse noise interfering with pilot signals . Thus , the algorithm maps trained data into a high dimensional feature space and uses the structural risk minimization ( SRM ) principle to carry out the regression estimation for the frequency response function of the highly selective channel . The simulations show the effectiveness of the proposed method which has good performance and high precision to track the variations of the fading channels compared to the conventional LS method and it is robust at high speed mobility .
We develop an iterative subsampling approach to improve the computational efficiency of our previous work on solution path clustering ( SPC ) . The SPC method achieves clustering by concave regularization on the pairwise distances between cluster centers . This clustering method has the important capability to recognize noise and to provide a short path of clustering solutions ; however , it is not sufficiently fast for big datasets . Thus , we propose a method that iterates between clustering a small subsample of the full data and sequentially assigning the other data points to attain orders of magnitude of computational savings . The new method preserves the ability to isolate noise , includes a solution selection mechanism that ultimately provides one clustering solution with an estimated number of clusters , and is shown to be able to extract small tight clusters from noisy data . The method ' s relatively minor losses in accuracy are demonstrated through simulation studies , and its ability to handle large datasets is illustrated through applications to gene expression datasets . An R package , SPClustering , for the SPC method with iterative subsampling is available at http : //www . stat . ucla . edu/~zhou/Software . html .
Empirical risk minimization frequently employs convex surrogates to underlying discrete loss functions in order to achieve computational tractability during optimization . However , classical convex surrogates can only tightly bound modular loss functions , sub-modular functions or supermodular functions separately while maintaining polynomial time computation . In this work , a novel generic convex surrogate for general non-modular loss functions is introduced , which provides for the first time a tractable solution for loss functions that are neither super-modular nor submodular . This convex surro-gate is based on a submodular-supermodular decomposition for which the existence and uniqueness is proven in this paper . It takes the sum of two convex surrogates that separately bound the supermodular component and the submodular component using slack-rescaling and the Lov{\ ' a}sz hinge , respectively . It is further proven that this surrogate is convex , piecewise linear , an extension of the loss function , and for which subgradient computation is polynomial time . Empirical results are reported on a non-submodular loss based on the S{{\o}}rensen-Dice difference function , and a real-world face track dataset with tens of thousands of frames , demonstrating the improved performance , efficiency , and scalabil-ity of the novel convex surrogate .
Tomal et al . ( 0000 ) introduced the notion of " phalanxes " in the context of rare-class detection in two-class classification problems . A phalanx is a subset of features that work well for classification tasks . In this paper , we propose a different class of phalanxes for application in regression settings . We define a " Regression Phalanx " - a subset of features that work well together for prediction . We propose a novel algorithm which automatically chooses Regression Phalanxes from high-dimensional data sets using hierarchical clustering and builds a prediction model for each phalanx for further ensembling . Through extensive simulation studies and several real-life applications in various areas ( including drug discovery , chemical analysis of spectra data , microarray analysis and climate projections ) we show that an ensemble of Regression Phalanxes improves prediction accuracy when combined with effective prediction methods like Lasso or Random Forests .
Most high-dimensional estimation and prediction methods propose to minimize a cost function ( empirical risk ) that is written as a sum of losses associated to each data point . In this paper we focus on the case of non-convex losses , which is practically important but still poorly understood . Classical empirical process theory implies uniform convergence of the empirical risk to the population risk . While uniform convergence implies consistency of the resulting M-estimator , it does not ensure that the latter can be computed efficiently . In order to capture the complexity of computing M-estimators , we propose to study the landscape of the empirical risk , namely its stationary points and their properties . We establish uniform convergence of the gradient and Hessian of the empirical risk to their population counterparts , as soon as the number of samples becomes larger than the number of unknown parameters ( modulo logarithmic factors ) . Consequently , good properties of the population risk can be carried to the empirical risk , and we can establish one-to-one correspondence of their stationary points . We demonstrate that in several problems such as non-convex binary classification , robust regression , and Gaussian mixture model , this result implies a complete characterization of the landscape of the empirical risk , and of the convergence properties of descent algorithms . We extend our analysis to the very high-dimensional setting in which the number of parameters exceeds the number of samples , and provide a characterization of the empirical risk landscape under a nearly information-theoretically minimal condition . Namely , if the number of samples exceeds the sparsity of the unknown parameters vector ( modulo logarithmic factors ) , then a suitable uniform convergence result takes place . We apply this result to non-convex binary classification and robust regression in very high-dimension .
We propose a reinforcement learning solution to the \emph{soccer dribbling task} , a scenario in which a soccer agent has to go from the beginning to the end of a region keeping possession of the ball , as an adversary attempts to gain possession . While the adversary uses a stationary policy , the dribbler learns the best action to take at each decision point . After defining meaningful variables to represent the state space , and high-level macro-actions to incorporate domain knowledge , we describe our application of the reinforcement learning algorithm \emph{Sarsa} with CMAC for function approximation . Our experiments show that , after the training period , the dribbler is able to accomplish its task against a strong adversary around 00% of the time .
We consider the problem of function estimation in the case where the data distribution may shift between training and test time , and additional information about it may be available at test time . This relates to popular scenarios such as covariate shift , concept drift , transfer learning and semi-supervised learning . This working paper discusses how these tasks could be tackled depending on the kind of changes of the distributions . It argues that knowledge of an underlying causal direction can facilitate several of these tasks .
Understanding the flow of information in Deep Neural Networks is a challenging problem that has gain increasing attention over the last few years . While several methods have been proposed to explain network predictions , only few attempts to analyze them from a theoretical perspective have been made in the past . In this work we analyze various state-of-the-art attribution methods and prove unexplored connections between them . We also show how some methods can be reformulated and more conveniently implemented . Finally , we perform an empirical evaluation with six attribution methods on a variety of tasks and architectures and discuss their strengths and limitations .
We present an algorithm to identify sparse dependence structure in continuous and non-Gaussian probability distributions , given a corresponding set of data . The conditional independence structure of an arbitrary distribution can be represented as an undirected graph ( or Markov random field ) , but most algorithms for learning this structure are restricted to the discrete or Gaussian cases . Our new approach allows for more realistic and accurate descriptions of the distribution in question , and in turn better estimates of its sparse Markov structure . Sparsity in the graph is of interest as it can accelerate inference , improve sampling methods , and reveal important dependencies between variables . The algorithm relies on exploiting the connection between the sparsity of the graph and the sparsity of transport maps , which deterministically couple one probability measure to another .
We propose a Bayesian methodology for one-mode projecting a bipartite network that is being observed across a series of discrete time steps . The resulting one mode network captures the uncertainty over the presence/absence of each link and provides a probability distribution over its possible weight values . Additionally , the incorporation of prior knowledge over previous states makes the resulting network less sensitive to noise and missing observations that usually take place during the data collection process . The methodology consists of computationally inexpensive update rules and is scalable to large problems , via an appropriate distributed implementation .
This work provides simple algorithms for multi-class ( and multi-label ) prediction in settings where both the number of examples n and the data dimension d are relatively large . These robust and parameter free algorithms are essentially iterative least-squares updates and very versatile both in theory and in practice . On the theoretical front , we present several variants with convergence guarantees . Owing to their effective use of second-order structure , these algorithms are substantially better than first-order methods in many practical scenarios . On the empirical side , we present a scalable stagewise variant of our approach , which achieves dramatic computational speedups over popular optimization packages such as Liblinear and Vowpal Wabbit on standard datasets ( MNIST and CIFAR-00 ) , while attaining state-of-the-art accuracies .
We introduce a convex approach for mixed linear regression over $d$ features . This approach is a second-order cone program , based on L0 minimization , which assigns an estimate regression coefficient in $\mathbb{R}^{d}$ for each data point . These estimates can then be clustered using , for example , $k$-means . For problems with two or more mixture classes , we prove that the convex program exactly recovers all of the mixture components in the noiseless setting under technical conditions that include a well-separation assumption on the data . Under these assumptions , recovery is possible if each class has at least $d$ independent measurements . We also explore an iteratively reweighted least squares implementation of this method on real and synthetic data .
Most multi-class classifiers make their prediction for a test sample by scoring the classes and selecting the one with the highest score . Analyzing these prediction scores is useful to understand the classifier behavior and to assess its reliability . We present an interactive visualization that facilitates per-class analysis of these scores . Our system , called Classilist , enables relating these scores to the classification correctness and to the underlying samples and their features . We illustrate how such analysis reveals varying behavior of different classifiers . Classilist is available for use online , along with source code , video tutorials , and plugins for R , RapidMiner , and KNIME at https : //katehara . github . io/classilist-site/ .
Given the observation of a high-dimensional Ornstein-Uhlenbeck ( OU ) process in continuous time , we proceed to the inference of the drift parameter under a row-sparsity assumption . Towards that aim , we consider the negative log-likelihood of the process , penalized by an $\ell^0$-penalization ( Lasso and Adaptive Lasso ) . We provide both non-asymptotic and asymptotic results for this procedure , by means of a sharp oracle inequality , and a limit theorem in the long-time asymptotics , including asymptotic consistency for variable selection . As a by-product , we point out the fact that for the Ornstein-Uhlenbeck process , one does not need an assumption of restricted eigenvalue type in order to derive fast rates for the Lasso , while it is well-known to be mandatory for linear regression for instance . Numerical results illustrate the benefits of this penalized procedure compared to standard maximum likelihood approaches both on simulations and real-world financial data .
The trade-off between the cost of acquiring and processing data , and uncertainty due to a lack of data is fundamental in machine learning . A basic instance of this trade-off is the problem of deciding when to make noisy and costly observations of a discrete-time Gaussian random walk , so as to minimise the posterior variance plus observation costs . We present the first proof that a simple policy , which observes when the posterior variance exceeds a threshold , is optimal for this problem . The proof generalises to a wide range of cost functions other than the posterior variance . This result implies that optimal policies for linear-quadratic-Gaussian control with costly observations have a threshold structure . It also implies that the restless bandit problem of observing multiple such time series , has a well-defined Whittle index . We discuss computation of that index , give closed-form formulae for it , and compare the performance of the associated index policy with heuristic policies . The proof is based on a new verification theorem that demonstrates threshold structure for Markov decision processes , and on the relation between binary sequences known as mechanical words and the dynamics of discontinuous nonlinear maps , which frequently arise in physics , control and biology .
Outlier detection is a crucial part of robust evaluation for crowdsourceable assessment of Quality of Experience ( QoE ) and has attracted much attention in recent years . In this paper , we propose some simple and fast algorithms for outlier detection and robust QoE evaluation based on the nonconvex optimization principle . Several iterative procedures are designed with or without knowing the number of outliers in samples . Theoretical analysis is given to show that such procedures can reach statistically good estimates under mild conditions . Finally , experimental results with simulated and real-world crowdsourcing datasets show that the proposed algorithms could produce similar performance to Huber-LASSO approach in robust ranking , yet with nearly 0 or 00 times speed-up , without or with a prior knowledge on the sparsity size of outliers , respectively . Therefore the proposed methodology provides us a set of helpful tools for robust QoE evaluation with crowdsourcing data .
During the course of human language evolution , the semantic meanings of words keep evolving with time . The understanding of evolving semantics enables us to capture the true meaning of the words in different usage contexts , and thus is critical for various applications , such as machine translation . While it is naturally promising to study word semantics in a time-aware manner , traditional methods to learn word vector representation do not adequately capture the change over time . To this end , in this paper , we aim at learning time-aware vector representation of words through dynamic word embedding modeling . Specifically , we first propose a method that captures time-specific semantics and across-time alignment simultaneously in a way that is robust to data sparsity . Then , we solve the resulting optimization problem using a scalable coordinate descent method . Finally , we perform the empirical study on New York Times data to learn the temporal embeddings and develop multiple evaluations that illustrate the semantic evolution of words , discovered from news media . Moreover , our qualitative and quantitative tests indicate that the our method not only reliably captures the semantic evolution over time , but also onsistently outperforms state-of-the-art temporal embedding approaches on both semantic accuracy and alignment quality .
We propose an extension of the concept of Expected Improvement criterion commonly used in Kriging based optimization . We extend it for more complex Kriging models , e . g . models using derivatives . The target field of application are CFD problems , where objective function are extremely expensive to evaluate , but the theory can be also used in other fields .
This article proposes a performance analysis of kernel least squares support vector machines ( LS-SVMs ) based on a random matrix approach , in the regime where both the dimension of data $p$ and their number $n$ grow large at the same rate . Under a two-class Gaussian mixture model for the input data , we prove that the LS-SVM decision function is asymptotically normal with means and covariances shown to depend explicitly on the derivatives of the kernel function . This provides improved understanding along with new insights into the internal workings of SVM-type methods for large datasets .
Functional connectivity refers to the temporal statistical relationship between spatially distinct brain regions and is usually inferred from the time series coherence/correlation in brain activity between regions of interest . In human functional brain networks , the network structure is often inferred from functional magnetic resonance imaging ( fMRI ) blood oxygen level dependent ( BOLD ) signal . Since the BOLD signal is a proxy for neuronal activity , it is of interest to learn the latent functional network structure . Additionally , despite a core set of observations about functional networks such as small-worldness , modularity , exponentially truncated degree distributions , and presence of various types of hubs , very little is known about the computational principles which can give rise to these observations . This paper introduces a Hidden Markov Random Field framework for the purpose of representing , estimating , and evaluating latent neuronal functional relationships between different brain regions using fMRI data .
Although there has been substantial research in software analytics for effort estimation in traditional software projects , little work has been done for estimation in agile projects , especially estimating user stories or issues . Story points are the most common unit of measure used for estimating the effort involved in implementing a user story or resolving an issue . In this paper , we offer for the \emph{first} time a comprehensive dataset for story points-based estimation that contains 00 , 000 issues from 00 open source projects . We also propose a prediction model for estimating story points based on a novel combination of two powerful deep learning architectures : long short-term memory and recurrent highway network . Our prediction system is \emph{end-to-end} trainable from raw input data to prediction outcomes without any manual feature engineering . An empirical evaluation demonstrates that our approach consistently outperforms three common effort estimation baselines and two alternatives in both Mean Absolute Error and the Standardized Accuracy .
In this paper , we will investigate the efficacy of IMAT ( Iterative Method of Adaptive Thresholding ) in recovering the sparse signal ( parameters ) for linear models with missing data . Sparse recovery rises in compressed sensing and machine learning problems and has various applications necessitating viable reconstruction methods specifically when we work with big data . This paper will focus on comparing the power of IMAT in reconstruction of the desired sparse signal with LASSO . Additionally , we will assume the model has random missing information . Missing data has been recently of interest in big data and machine learning problems since they appear in many cases including but not limited to medical imaging datasets , hospital datasets , and massive MIMO . The dominance of IMAT over the well-known LASSO will be taken into account in different scenarios . Simulations and numerical results are also provided to verify the arguments .
The time to converge to the steady state of a finite Markov chain can be greatly reduced by a lifting operation , which creates a new Markov chain on an expanded state space . For a class of quadratic objectives , we show an analogous behavior where a distributed ADMM algorithm can be seen as a lifting of Gradient Descent algorithm . This provides a deep insight for its faster convergence rate under optimal parameter tuning . We conjecture that this gain is always present , as opposed to the lifting of a Markov chain which sometimes only provides a marginal speedup .
Classical collaborative filtering , and content-based filtering methods try to learn a static recommendation model given training data . These approaches are far from ideal in highly dynamic recommendation domains such as news recommendation and computational advertisement , where the set of items and users is very fluid . In this work , we investigate an adaptive clustering technique for content recommendation based on exploration-exploitation strategies in contextual multi-armed bandit settings . Our algorithm takes into account the collaborative effects that arise due to the interaction of the users with the items , by dynamically grouping users based on the items under consideration and , at the same time , grouping items based on the similarity of the clusterings induced over the users . The resulting algorithm thus takes advantage of preference patterns in the data in a way akin to collaborative filtering methods . We provide an empirical analysis on medium-size real-world datasets , showing scalability and increased prediction performance ( as measured by click-through rate ) over state-of-the-art methods for clustering bandits . We also provide a regret analysis within a standard linear stochastic noise setting .
In this paper , we predict the likelihood of a player making a shot in basketball from multiagent trajectories . Previous approaches to similar problems center on hand-crafting features to capture domain specific knowledge . Although intuitive , recent work in deep learning has shown this approach is prone to missing important predictive features . To circumvent this issue , we present a convolutional neural network ( CNN ) approach where we initially represent the multiagent behavior as an image . To encode the adversarial nature of basketball , we use a multi-channel image which we then feed into a CNN . Additionally , to capture the temporal aspect of the trajectories we " fade " the player trajectories . We find that this approach is superior to a traditional FFN model . By using gradient ascent to create images using an already trained CNN , we discover what features the CNN filters learn . Last , we find that a combined CNN+FFN is the best performing network with an error rate of 00% .
Deep learning models ( aka Deep Neural Networks ) have revolutionized many fields including computer vision , natural language processing , speech recognition , and is being increasingly used in clinical healthcare applications . However , few works exist which have benchmarked the performance of the deep learning models with respect to the state-of-the-art machine learning models and prognostic scoring systems on publicly available healthcare datasets . In this paper , we present the benchmarking results for several clinical prediction tasks such as mortality prediction , length of stay prediction , and ICD-0 code group prediction using Deep Learning models , ensemble of machine learning models ( Super Learner algorithm ) , SAPS II and SOFA scores . We used the Medical Information Mart for Intensive Care III ( MIMIC-III ) ( v0 . 0 ) publicly available dataset , which includes all patients admitted to an ICU at the Beth Israel Deaconess Medical Center from 0000 to 0000 , for the benchmarking tasks . Our results show that deep learning models consistently outperform all the other approaches especially when the `raw ' clinical time series data is used as input features to the models .
We consider the problem of inferring the interactions between a set of N binary variables from the knowledge of their frequencies and pairwise correlations . The inference framework is based on the Hopfield model , a special case of the Ising model where the interaction matrix is defined through a set of patterns in the variable space , and is of rank much smaller than N . We show that Maximum Lik elihood inference is deeply related to Principal Component Analysis when the amp litude of the pattern components , xi , is negligible compared to N^0/0 . Using techniques from statistical mechanics , we calculate the corrections to the patterns to the first order in xi/N^0/0 . We stress that it is important to generalize the Hopfield model and include both attractive and repulsive patterns , to correctly infer networks with sparse and strong interactions . We present a simple geometrical criterion to decide how many attractive and repulsive patterns should be considered as a function of the sampling noise . We moreover discuss how many sampled configurations are required for a good inference , as a function of the system size , N and of the amplitude , xi . The inference approach is illustrated on synthetic and biological data .
Sparse coding has shown its power as an effective data representation method . However , up to now , all the sparse coding approaches are limited within the single domain learning problem . In this paper , we extend the sparse coding to cross domain learning problem , which tries to learn from a source domain to a target domain with significant different distribution . We impose the Maximum Mean Discrepancy ( MMD ) criterion to reduce the cross-domain distribution difference of sparse codes , and also regularize the sparse codes by the class labels of the samples from both domains to increase the discriminative ability . The encouraging experiment results of the proposed cross-domain sparse coding algorithm on two challenging tasks --- image classification of photograph and oil painting domains , and multiple user spam detection --- show the advantage of the proposed method over other cross-domain data representation methods .
The number of possible methods of generalizing binary classification to multi-class classification increases exponentially with the number of class labels . Often , the best method of doing so will be highly problem dependent . Here we present classification software in which the partitioning of multi-class classification problems into binary classification problems is specified using a recursive control language .
Images have become one of the most popular types of media through which users convey their emotions within online social networks . Although vast amount of research is devoted to sentiment analysis of textual data , there has been very limited work that focuses on analyzing sentiment of image data . In this work , we propose a novel visual sentiment prediction framework that performs image understanding with Deep Convolutional Neural Networks ( CNN ) . Specifically , the proposed sentiment prediction framework performs transfer learning from a CNN with millions of parameters , which is pre-trained on large-scale data for object recognition . Experiments conducted on two real-world datasets from Twitter and Tumblr demonstrate the effectiveness of the proposed visual sentiment analysis framework .
In this paper , we methodologically address the problem of cumulative reward overestimation in deep reinforcement learning . We generalise notions from information-theoretic bounded rationality to handle high-dimensional state spaces efficiently . The resultant algorithm encompasses a wide range of learning outcomes that can be demonstrated by tuning a Lagrange multiplier that intrinsically penalises rewards . We show that deep Q-networks arise as a special case of our proposed approach . We introduce a novel scheduling scheme for bounded-rational behaviour that ensures sample efficiency and robustness . In experiments on Atari games , we show that our algorithm outperforms other deep reinforcement learning algorithms ( e . g . , deep and double deep Q-networks ) in terms of both game-play performance and sample complexity .
The past decade has seen substantial work on the use of non-negative matrix factorization and its probabilistic counterparts for audio source separation . Although able to capture audio spectral structure well , these models neglect the non-stationarity and temporal dynamics that are important properties of audio . The recently proposed non-negative factorial hidden Markov model ( N-FHMM ) introduces a temporal dimension and improves source separation performance . However , the factorial nature of this model makes the complexity of inference exponential in the number of sound sources . Here , we present a Bayesian variant of the N-FHMM suited to an efficient variational inference algorithm , whose complexity is linear in the number of sound sources . Our algorithm performs comparably to exact inference in the original N-FHMM but is significantly faster . In typical configurations of the N-FHMM , our method achieves around a 00x increase in speed .
We generalize stochastic subgradient descent methods to situations in which we do not receive independent samples from the distribution over which we optimize , but instead receive samples that are coupled over time . We show that as long as the source of randomness is suitably ergodic---it converges quickly enough to a stationary distribution---the method enjoys strong convergence guarantees , both in expectation and with high probability . This result has implications for stochastic optimization in high-dimensional spaces , peer-to-peer distributed optimization schemes , decision problems with dependent data , and stochastic optimization problems over combinatorial spaces .
The outlying property detection problem is the problem of discovering the properties distinguishing a given object , known in advance to be an outlier in a database , from the other database objects . In this paper , we analyze the problem within a context where numerical attributes are taken into account , which represents a relevant case left open in the literature . We introduce a measure to quantify the degree the outlierness of an object , which is associated with the relative likelihood of the value , compared to the to the relative likelihood of other objects in the database . As a major contribution , we present an efficient algorithm to compute the outlierness relative to significant subsets of the data . The latter subsets are characterized in a " rule-based " fashion , and hence the basis for the underlying explanation of the outlierness .
Bell ' s Theorem shows that quantum mechanical correlations can violate the constraints that the causal structure of certain experiments impose on any classical explanation . It is thus natural to ask to which degree the causal assumptions -- e . g . locality or measurement independence -- have to be relaxed in order to allow for a classical description of such experiments . Here , we develop a conceptual and computational framework for treating this problem . We employ the language of Bayesian networks to systematically construct alternative causal structures and bound the degree of relaxation using quantitative measures that originate from the mathematical theory of causality . The main technical insight is that the resulting problems can often be expressed as computationally tractable linear programs . We demonstrate the versatility of the framework by applying it to a variety of scenarios , ranging from relaxations of the measurement independence , locality and bilocality assumptions , to a novel causal interpretation of CHSH inequality violations .
While convergence of the Alternating Direction Method of Multipliers ( ADMM ) on convex problems is well studied , convergence on nonconvex problems is only partially understood . In this paper , we consider the Gaussian phase retrieval problem , formulated as a linear constrained optimization problem with a biconvex objective . The particular structure allows for a novel application of the ADMM . It can be shown that the dual variable is zero at the global minimizer . This motivates the analysis of a block coordinate descent algorithm , which is equivalent to the ADMM with the dual variable fixed to be zero . We show that the block coordinate descent algorithm converges to the global minimizer at a linear rate , when starting from a deterministically achievable initialization point .
This paper proposes a novel type of random forests called a denoising random forests that are robust against noises contained in test samples . Such noise-corrupted samples cause serious damage to the estimation performances of random forests , since unexpected child nodes are often selected and the leaf nodes that the input sample reaches are sometimes far from those for a clean sample . Our main idea for tackling this problem originates from a binary indicator vector that encodes a traversal path of a sample in the forest . Our proposed method effectively employs this vector by introducing denoising autoencoders into random forests . A denoising autoencoder can be trained with indicator vectors produced from clean and noisy input samples , and non-leaf nodes where incorrect decisions are made can be identified by comparing the input and output of the trained denoising autoencoder . Multiple traversal paths with respect to the nodes with incorrect decisions caused by the noises can then be considered for the estimation .
The ubiquitous presence of sequence data across fields such as the web , healthcare , bioinformatics , and text mining has made sequence mining a vital research area . However , sequence mining is particularly challenging because of difficulty in finding ( dis ) similarity/distance between sequences . This is because a distance measure between sequences is not obvious due to their unstructuredness---arbitrary strings of arbitrary length . Feature representations , such as n-grams , are often used but they either compromise on extracting both short- and long-term sequence patterns or have a high computation . We propose a new function , Sequence Graph Transform ( SGT ) , that extracts the short- and long-term sequence features and embeds them in a finite-dimensional feature space . Importantly , SGT has low computation and can extract any amount of short- to long-term patterns without any increase in the computation , also proved theoretically in this paper . Due to this , SGT yields superior result with significantly higher accuracy and lower computation compared to the existing methods . We show it via several experimentation and SGT ' s real world application for clustering , classification , search and visualization as examples .
How can we find patterns and anomalies in a tensor , or multi-dimensional array , in an efficient and directly interpretable way ? How can we do this in an online environment , where a new tensor arrives each time step ? Finding patterns and anomalies in a tensor is a crucial problem with many applications , including building safety monitoring , patient health monitoring , cyber security , terrorist detection , and fake user detection in social networks . Standard PARAFAC and Tucker decomposition results are not directly interpretable . Although a few sampling-based methods have previously been proposed towards better interpretability , they need to be made faster , more memory efficient , and more accurate . In this paper , we propose CTD , a fast , accurate , and directly interpretable tensor decomposition method based on sampling . CTD-S , the static version of CTD , provably guarantees a high accuracy that is 00 ~ 00x more accurate than that of the state-of-the-art method . Also , CTD-S is made 0 ~ 00x faster , and 0 ~ 00x more memory-efficient than the state-of-the-art method by removing redundancy . CTD-D , the dynamic version of CTD , is the first interpretable dynamic tensor decomposition method ever proposed . Also , it is made 0 ~ 0x faster than already fast CTD-S by exploiting factors at previous time step and by reordering operations . With CTD , we demonstrate how the results can be effectively interpreted in the online distributed denial of service ( DDoS ) attack detection .
We define a Hidden Markov Model ( HMM ) in which each hidden state has time-dependent $\textit{activity levels}$ that drive transitions and emissions , and show how to estimate its parameters . Our construction is motivated by the problem of inferring human mobility on sub-daily time scales from , for example , mobile phone records .
Similar to convolution neural networks , recurrent neural networks ( RNNs ) typically suffer from over-parameterization . Quantizing bit-widths of weights and activations results in runtime efficiency on hardware , yet it often comes at the cost of reduced accuracy . This paper proposes a quantization approach that increases model size with bit-width reduction . This approach will allow networks to perform at their baseline accuracy while still maintaining the benefits of reduced precision and overall model size reduction .
In statistical inference problems , we wish to obtain lower bounds on the minimax risk , that is to bound the performance of any possible estimator . A standard technique to obtain risk lower bounds involves the use of Fano ' s inequality . In an information-theoretic setting , it is known that Fano ' s inequality typically does not give a sharp converse result ( error lower bound ) for channel coding problems . Moreover , recent work has shown that an argument based on binary hypothesis testing gives tighter results . We adapt this technique to the statistical setting , and argue that Fano ' s inequality can always be replaced by this approach to obtain tighter lower bounds that can be easily computed and are asymptotically sharp . We illustrate our technique in three applications : density estimation , active learning of a binary classifier , and compressed sensing , obtaining tighter risk lower bounds in each case .
The matrix-completion problem has attracted a lot of attention , largely as a result of the celebrated Netflix competition . Two popular approaches for solving the problem are nuclear-norm-regularized matrix approximation ( Candes and Tao , 0000 , Mazumder , Hastie and Tibshirani , 0000 ) , and maximum-margin matrix factorization ( Srebro , Rennie and Jaakkola , 0000 ) . These two procedures are in some cases solving equivalent problems , but with quite different algorithms . In this article we bring the two approaches together , leading to an efficient algorithm for large matrix factorization and completion that outperforms both of these . We develop a software package " softImpute " in R for implementing our approaches , and a distributed version for very large matrices using the " Spark " cluster programming environment .
Topic models such as Latent Dirichlet Allocation ( LDA ) have been widely used in information retrieval for tasks ranging from smoothing and feedback methods to tools for exploratory search and discovery . However , classical methods for inferring topic models do not scale up to the massive size of today ' s publicly available Web-scale data sets . The state-of-the-art approaches rely on custom strategies , implementations and hardware to facilitate their asynchronous , communication-intensive workloads . We present APS-LDA , which integrates state-of-the-art topic modeling with cluster computing frameworks such as Spark using a novel asynchronous parameter server . Advantages of this integration include convenient usage of existing data processing pipelines and eliminating the need for disk writes as data can be kept in memory from start to finish . Our goal is not to outperform highly customized implementations , but to propose a general high-performance topic modeling framework that can easily be used in today ' s data processing pipelines . We compare APS-LDA to the existing Spark LDA implementations and show that our system can , on a 000-core cluster , process up to 000 times more data and 00 times more topics without sacrificing model quality .
A research frontier has emerged in scientific computation , wherein numerical error is regarded as a source of epistemic uncertainty that can be modelled . This raises several statistical challenges , including the design of statistical methods that enable the coherent propagation of probabilities through a ( possibly deterministic ) computational work-flow . This paper examines the case for probabilistic numerical methods in routine statistical computation . Our focus is on numerical integration , where a probabilistic integrator is equipped with a full distribution over its output that reflects the presence of an unknown numerical error . Our main technical contribution is to establish , for the first time , rates of posterior contraction for these methods . These show that probabilistic integrators can in principle enjoy the " best of both worlds " , leveraging the sampling efficiency of Monte Carlo methods whilst providing a principled route to assess the impact of numerical error on scientific conclusions . Several substantial applications are provided for illustration and critical evaluation , including examples from statistical modelling , computer graphics and a computer model for an oil reservoir .
In this paper , we provide a novel construction of the linear-sized spectral sparsifiers of Batson , Spielman and Srivastava [BSS00] . While previous constructions required $\Omega ( n^0 ) $ running time [BSS00 , Zou00] , our sparsification routine can be implemented in almost-quadratic running time $O ( n^{0+\varepsilon} ) $ . The fundamental conceptual novelty of our work is the leveraging of a strong connection between sparsification and a regret minimization problem over density matrices . This connection was known to provide an interpretation of the randomized sparsifiers of Spielman and Srivastava [SS00] via the application of matrix multiplicative weight updates ( MWU ) [CHS00 , Vis00] . In this paper , we explain how matrix MWU naturally arises as an instance of the Follow-the-Regularized-Leader framework and generalize this approach to yield a larger class of updates . This new class allows us to accelerate the construction of linear-sized spectral sparsifiers , and give novel insights on the motivation behind Batson , Spielman and Srivastava [BSS00] .
We obtain an index of the complexity of a random sequence by allowing the role of the measure in classical probability theory to be played by a function we call the generating mechanism . Typically , this generating mechanism will be a finite automata . We generate a set of biased sequences by applying a finite state automata with a specified number , $m$ , of states to the set of all binary sequences . Thus we can index the complexity of our random sequence by the number of states of the automata . We detail optimal algorithms to predict sequences generated in this way .
The goal of unsupervised representation learning is to extract a new representation of data , such that solving many different tasks becomes easier . Existing methods typically focus on vectorized data and offer little support for relational data , which additionally describe relationships among instances . In this work we introduce an approach for relational unsupervised representation learning . Viewing a relational dataset as a hypergraph , new features are obtained by clustering vertices and hyperedges . To find a representation suited for many relational learning tasks , a wide range of similarities between relational objects is considered , e . g . feature and structural similarities . We experimentally evaluate the proposed approach and show that models learned on such latent representations perform better , have lower complexity , and outperform the existing approaches on classification tasks .
With access to large datasets , deep neural networks ( DNN ) have achieved human-level accuracy in image and speech recognition tasks . However , in chemistry , availability of large standardized and labelled datasets is scarce , and many chemical properties of research interest , chemical data is inherently small and fragmented . In this work , we explore transfer learning techniques in conjunction with the existing Chemception CNN model , to create a transferable and generalizable deep neural network for small-molecule property prediction . Our latest model , ChemNet learns in a semi-supervised manner from inexpensive labels computed from the ChEMBL database . When fine-tuned to the Tox00 , HIV and FreeSolv dataset , which are 0 separate chemical properties that ChemNet was not originally trained on , we demonstrate that ChemNet exceeds the performance of existing Chemception models and other contemporary DNN models . Furthermore , as ChemNet has been pre-trained on a large diverse chemical database , it can be used as a general-purpose plug-and-play deep neural network for the prediction of novel small-molecule chemical properties .
In distributed machine learning , data is dispatched to multiple machines for processing . Motivated by the fact that similar data points often belong to the same or similar classes , and more generally , classification rules of high accuracy tend to be " locally simple but globally complex " ( Vapnik & Bottou 0000 ) , we propose data dependent dispatching that takes advantage of such structure . We present an in-depth analysis of this model , providing new algorithms with provable worst-case guarantees , analysis proving existing scalable heuristics perform well in natural non worst-case conditions , and techniques for extending a dispatching rule from a small sample to the entire distribution . We overcome novel technical challenges to satisfy important conditions for accurate distributed learning , including fault tolerance and balancedness . We empirically compare our approach with baselines based on random partitioning , balanced partition trees , and locality sensitive hashing , showing that we achieve significantly higher accuracy on both synthetic and real world image and advertising datasets . We also demonstrate that our technique strongly scales with the available computing power .
Structure learning of Bayesian networks is an important problem that arises in numerous machine learning applications . In this work , we present a novel approach for learning the structure of Bayesian networks using the solution of an appropriately constructed traveling salesman problem . In our approach , one computes an optimal ordering ( partially ordered set ) of random variables using methods for the traveling salesman problem . This ordering significantly reduces the search space for the subsequent greedy optimization that computes the final structure of the Bayesian network . We demonstrate our approach of learning Bayesian networks on real world census and weather datasets . In both cases , we demonstrate that the approach very accurately captures dependencies between random variables . We check the accuracy of the predictions based on independent studies in both application domains .
Modes and ridges of the probability density function behind observed data are useful geometric features . Mode-seeking clustering assigns cluster labels by associating data samples with the nearest modes , and estimation of density ridges enables us to find lower-dimensional structures hidden in data . A key technical challenge both in mode-seeking clustering and density ridge estimation is accurate estimation of the ratios of the first- and second-order density derivatives to the density . A naive approach takes a three-step approach of first estimating the data density , then computing its derivatives , and finally taking their ratios . However , this three-step approach can be unreliable because a good density estimator does not necessarily mean a good density derivative estimator , and division by the estimated density could significantly magnify the estimation error . To cope with these problems , we propose a novel estimator for the \emph{density-derivative-ratios} . The proposed estimator does not involve density estimation , but rather \emph{directly} approximates the ratios of density derivatives of any order . Moreover , we establish a convergence rate of the proposed estimator . Based on the proposed estimator , new methods both for mode-seeking clustering and density ridge estimation are developed , and corresponding convergence rates to the mode and ridge of the underlying density are also established . Finally , we experimentally demonstrate that the developed methods significantly outperform existing methods , particularly for relatively high-dimensional data .
We propose a novel " tree-averaging " model that utilizes the ensemble of classification and regression trees ( CART ) . Each constituent tree is estimated with a subset of similar data . We treat this grouping of subsets as Bayesian ensemble trees ( BET ) and model them as an infinite mixture Dirichlet process . We show that BET adapts to data heterogeneity and accurately estimates each component . Compared with the bootstrap-aggregating approach , BET shows improved prediction performance with fewer trees . We develop an efficient estimating procedure with improved sampling strategies in both CART and mixture models . We demonstrate these advantages of BET with simulations , classification of breast cancer and regression of lung function measurement of cystic fibrosis patients . Keywords : Bayesian CART ; Dirichlet Process ; Ensemble Approach ; Heterogeneity ; Mixture of Trees .
Many modern big data applications feature large scale in both numbers of responses and predictors . Better statistical efficiency and scientific insights can be enabled by understanding the large-scale response-predictor association network structures via layers of sparse latent factors ranked by importance . Yet sparsity and orthogonality have been two largely incompatible goals . To accommodate both features , in this paper we suggest the method of sparse orthogonal factor regression ( SOFAR ) via the sparse singular value decomposition with orthogonality constrained optimization to learn the underlying association networks , with broad applications to both unsupervised and supervised learning tasks such as biclustering with sparse singular value decomposition , sparse principal component analysis , sparse factor analysis , and spare vector autoregression analysis . Exploiting the framework of convexity-assisted nonconvex optimization , we derive nonasymptotic error bounds for the suggested procedure characterizing the theoretical advantages . The statistical guarantees are powered by an efficient SOFAR algorithm with convergence property . Both computational and theoretical advantages of our procedure are demonstrated with several simulation and real data examples .
Performing signal processing tasks on compressive measurements of data has received great attention in recent years . In this paper , we extend previous work on compressive dictionary learning by showing that more general random projections may be used , including sparse ones . More precisely , we examine compressive K-means clustering as a special case of compressive dictionary learning and give theoretical guarantees for its performance for a very general class of random projections . We then propose a memory and computation efficient dictionary learning algorithm , specifically designed for analyzing large volumes of high-dimensional data , which learns the dictionary from very sparse random projections . Experimental results demonstrate that our approach allows for reduction of computational complexity and memory/data access , with controllable loss in accuracy .
The key limiting factor in graphical model inference and learning is the complexity of the partition function . We thus ask the question : what are general conditions under which the partition function is tractable ? The answer leads to a new kind of deep architecture , which we call sum-product networks ( SPNs ) . SPNs are directed acyclic graphs with variables as leaves , sums and products as internal nodes , and weighted edges . We show that if an SPN is complete and consistent it represents the partition function and all marginals of some graphical model , and give semantics to its nodes . Essentially all tractable graphical models can be cast as SPNs , but SPNs are also strictly more general . We then propose learning algorithms for SPNs , based on backpropagation and EM . Experiments show that inference and learning with SPNs can be both faster and more accurate than with standard deep networks . For example , SPNs perform image completion better than state-of-the-art deep networks for this task . SPNs also have intriguing potential connections to the architecture of the cortex .
One iteration of $k$-means or EM for Gaussian mixture models ( GMMs ) scales linearly with the number of data points $N$ , the number of clusters $C$ , and the data dimensionality $D$ . In this study , we explore whether one iteration of $k$-means or EM for GMMs can scale sublinearly with $C$ at run-time , while the increase of the clustering objective remains effective . The tool we apply for complexity reduction is variational EM , which is typically applied to make training of generative models with exponentially many hidden states tractable . Here , we apply novel theoretical results on truncated variational EM to make tractable clustering algorithms more efficient . The basic idea is the use of a partial variational E-step which reduces the linear complexity of $\mathcal{O} ( NCD ) $ required for a full E-step to a sublinear complexity . Our main observation is that the linear dependency on $C$ can be reduced to a dependency on a much smaller parameter $G$ , related to the cluster neighborhood relationship . We focus on two versions of partial variational EM for clustering : variational GMM , scaling with $\mathcal{O} ( NG^0D ) $ , and variational $k$-means , scaling with $\mathcal{O} ( NGD ) $ per iteration . Empirical results then show that these algorithms still require comparable numbers of iterations to increase the clustering objective to the same values as $k$-means . For data with many clusters , we consequently observe reductions of the net computational demands between two and three orders of magnitude . More generally , our results provide substantial empirical evidence in favor of clustering to scale sublinearly with $C$ .
We propose a novel denoising framework for task functional Magnetic Resonance Imaging ( tfMRI ) data to delineate the high-resolution spatial pattern of the brain functional connectivity via dictionary learning and sparse coding ( DLSC ) . In order to address the limitations of the unsupervised DLSC-based fMRI studies , we utilize the prior knowledge of task paradigm in the learning step to train a data-driven dictionary and to model the sparse representation . We apply the proposed DLSC-based method to Human Connectome Project ( HCP ) motor tfMRI dataset . Studies on the functional connectivity of cerebrocerebellar circuits in somatomotor networks show that the DLSC-based denoising framework can significantly improve the prominent connectivity patterns , in comparison to the temporal non-local means ( tNLM ) -based denoising method as well as the case without denoising , which is consistent and neuroscientifically meaningful within motor area . The promising results show that the proposed method can provide an important foundation for the high-resolution functional connectivity analysis , and provide a better approach for fMRI preprocessing .
Obtaining enough labeled data to robustly train complex discriminative models is a major bottleneck in the machine learning pipeline . A popular solution is combining multiple sources of weak supervision using generative models . The structure of these models affects training label quality , but is difficult to learn without any ground truth labels . We instead rely on these weak supervision sources having some structure by virtue of being encoded programmatically . We present Coral , a paradigm that infers generative model structure by statically analyzing the code for these heuristics , thus reducing the data required to learn structure significantly . We prove that Coral ' s sample complexity scales quasilinearly with the number of heuristics and number of relations found , improving over the standard sample complexity , which is exponential in $n$ for identifying $n^{\textrm{th}}$ degree relations . Experimentally , Coral matches or outperforms traditional structure learning approaches by up to 0 . 00 F0 points . Using Coral to model dependencies instead of assuming independence results in better performance than a fully supervised model by 0 . 00 accuracy points when heuristics are used to label radiology data without ground truth labels .
Networks capture pairwise interactions between entities and are frequently used in applications such as social networks , food networks , and protein interaction networks , to name a few . Communities , cohesive groups of nodes , often form in these applications , and identifying them gives insight into the overall organization of the network . One common quality function used to identify community structure is modularity . In Hu et al . [SIAM J . App . Math . , 00 ( 0 ) , 0000] , it was shown that modularity optimization is equivalent to minimizing a particular nonconvex total variation ( TV ) based functional over a discrete domain . They solve this problem---assuming the number of communities is known---using a Merriman , Bence , Osher ( MBO ) scheme . We show that modularity optimization is equivalent to minimizing a convex TV-based functional over a discrete domain---again , assuming the number of communities is known . Furthermore , we show that modularity has no convex relaxation satisfying certain natural conditions . Despite this , we partially relax the discrete constraint using a Ginzburg Landau functional , yielding an optimization problem that is more nearly convex . We then derive an MBO algorithm with fewer parameters than in Hu et al . and which is 0 times faster at solving the associated diffusion equation due to the fact that the underlying discretization is unconditionally stable . Our numerical tests include a hyperspectral video whose associated graph has 00 million edges , which is roughly 00 times larger than was handled in the paper of Hu et al .
In data sets with many more features than observations , independent screening based on all univariate regression models leads to a computationally convenient variable selection method . Recent efforts have shown that in the case of generalized linear models , independent screening may suffice to capture all relevant features with high probability , even in ultra-high dimension . It is unclear whether this formal sure screening property is attainable when the response is a right-censored survival time . We propose a computationally very efficient independent screening method for survival data which can be viewed as the natural survival equivalent of correlation screening . We state conditions under which the method admits the sure screening property within a general class of single-index hazard rate models with ultra-high dimensional features . An iterative variant is also described which combines screening with penalized regression in order to handle more complex feature covariance structures . The methods are evaluated through simulation studies and through application to a real gene expression dataset .
We present an exploration of the rich theoretical connections between several classes of regularized models , network flows , and recent results in submodular function theory . This work unifies key aspects of these problems under a common theory , leading to novel methods for working with several important models of interest in statistics , machine learning and computer vision . In Part 0 , we review the concepts of network flows and submodular function optimization theory foundational to our results . We then examine the connections between network flows and the minimum-norm algorithm from submodular optimization , extending and improving several current results . This leads to a concise representation of the structure of a large class of pairwise regularized models important in machine learning , statistics and computer vision . In Part 0 , we describe the full regularization path of a class of penalized regression problems with dependent variables that includes the graph-guided LASSO and total variation constrained models . This description also motivates a practical algorithm . This allows us to efficiently find the regularization path of the discretized version of TV penalized models . Ultimately , our new algorithms scale up to high-dimensional problems with millions of variables .
In various approaches to learning , notably in domain adaptation , active learning , learning under covariate shift , semi-supervised learning , learning with concept drift , and the like , one often wants to compare a baseline classifier to one or more advanced ( or at least different ) strategies . In this chapter , we basically argue that if such classifiers , in their respective training phases , optimize a so-called surrogate loss that it may also be valuable to compare the behavior of this loss on the test set , next to the regular classification error rate . It can provide us with an additional view on the classifiers ' relative performances that error rates cannot capture . As an example , limited but convincing empirical results demonstrates that we may be able to find semi-supervised learning strategies that can guarantee performance improvements with increasing numbers of unlabeled data in terms of log-likelihood . In contrast , the latter may be impossible to guarantee for the classification error rate .
Recurrent sequence generators conditioned on input data through an attention mechanism have recently shown very good performance on a range of tasks in- cluding machine translation , handwriting synthesis and image caption gen- eration . We extend the attention-mechanism with features needed for speech recognition . We show that while an adaptation of the model used for machine translation in reaches a competitive 00 . 0% phoneme error rate ( PER ) on the TIMIT phoneme recognition task , it can only be applied to utterances which are roughly as long as the ones it was trained on . We offer a qualitative explanation of this failure and propose a novel and generic method of adding location-awareness to the attention mechanism to alleviate this issue . The new method yields a model that is robust to long inputs and achieves 00% PER in single utterances and 00% in 00-times longer ( repeated ) utterances . Finally , we propose a change to the at- tention mechanism that prevents it from concentrating too much on single frames , which further reduces PER to 00 . 0% level .
Multi-step ahead forecasting is still an open challenge in time series forecasting . Several approaches that deal with this complex problem have been proposed in the literature but an extensive comparison on a large number of tasks is still missing . This paper aims to fill this gap by reviewing existing strategies for multi-step ahead forecasting and comparing them in theoretical and practical terms . To attain such an objective , we performed a large scale comparison of these different strategies using a large experimental benchmark ( namely the 000 series from the NN0 forecasting competition ) . In addition , we considered the effects of deseasonalization , input variable selection , and forecast combination on these strategies and on multi-step ahead forecasting at large . The following three findings appear to be consistently supported by the experimental results : Multiple-Output strategies are the best performing approaches , deseasonalization leads to uniformly improved forecast accuracy , and input selection is more effective when performed in conjunction with deseasonalization .
This paper reports on our analysis of the 0000 CAMRa Challenge dataset ( Track 0 ) for context-aware movie recommendation systems . The train dataset comprises 0 , 000 , 000 ratings provided by 000 , 000 users on 00 , 000$ movies , as well as the household groupings of a subset of the users . The test dataset comprises 0 , 000 ratings for which the user label is missing , but the household label is provided . The challenge required to identify the user labels for the ratings in the test set . Our main finding is that temporal information ( time labels of the ratings ) is significantly more useful for achieving this objective than the user preferences ( the actual ratings ) . Using a model that leverages on this fact , we are able to identify users within a known household with an accuracy of approximately 00% ( i . e . misclassification rate around 0% ) .
Bayesian hierarchical models are increasing popular in economics . When using hierarchical models , it is useful not only to calculate posterior expectations , but also to measure the robustness of these expectations to reasonable alternative prior choices . We use variational Bayes and linear response methods to provide fast , accurate posterior means and robustness measures with an application to measuring the effectiveness of microcredit in the developing world .
The relation between performance and stress is described by the Yerkes-Dodson Law but varies significantly between individuals . This paper describes a method for determining the individual optimal performance as a function of physiological signals . The method is based on attention and reasoning tests of increasing complexity under monitoring of three physiological signals : Galvanic Skin Response ( GSR ) , Heart Rate ( HR ) , and Electromyogram ( EMG ) . Based on the test results with 00 different individuals , we first show that two of the signals , GSR and HR , have enough discriminative power to distinguish between relax and stress periods . We then show a positive correlation between the complexity level of the tests and the GSR and HR signals , and we finally determine the optimal performance point as the signal level just before a performance decrease . We also discuss the differences among signals depending on the type of test .
Sparse learning has recently received increasing attention in many areas including machine learning , statistics , and applied mathematics . The mixed-norm regularization based on the l0q norm with q>0 is attractive in many applications of regression and classification in that it facilitates group sparsity in the model . The resulting optimization problem is , however , challenging to solve due to the inherent structure of the mixed-norm regularization . Existing work deals with special cases with q=0 , 0 , infinity , and they cannot be easily extended to the general case . In this paper , we propose an efficient algorithm based on the accelerated gradient method for solving the general l0q-regularized problem . One key building block of the proposed algorithm is the l0q-regularized Euclidean projection ( EP_0q ) . Our theoretical analysis reveals the key properties of EP_0q and illustrates why EP_0q for the general q is significantly more challenging to solve than the special cases . Based on our theoretical analysis , we develop an efficient algorithm for EP_0q by solving two zero finding problems . To further improve the efficiency of solving large dimensional mixed-norm regularized problems , we propose a screening method which is able to quickly identify the inactive groups , i . e . , groups that have 0 components in the solution . This may lead to substantial reduction in the number of groups to be entered to the optimization . An appealing feature of our screening method is that the data set needs to be scanned only once to run the screening . Compared to that of solving the mixed-norm regularized problems , the computational cost of our screening test is negligible . The key of the proposed screening method is an accurate sensitivity analysis of the dual optimal solution when the regularization parameter varies . Experimental results demonstrate the efficiency of the proposed algorithm .
Systems based on artificial neural networks ( ANNs ) have achieved state-of-the-art results in many natural language processing tasks . Although ANNs do not require manually engineered features , ANNs have many hyperparameters to be optimized . The choice of hyperparameters significantly impacts models ' performances . However , the ANN hyperparameters are typically chosen by manual , grid , or random search , which either requires expert experiences or is computationally expensive . Recent approaches based on Bayesian optimization using Gaussian processes ( GPs ) is a more systematic way to automatically pinpoint optimal or near-optimal machine learning hyperparameters . Using a previously published ANN model yielding state-of-the-art results for dialog act classification , we demonstrate that optimizing hyperparameters using GP further improves the results , and reduces the computational time by a factor of 0 compared to a random search . Therefore it is a useful technique for tuning ANN models to yield the best performances for natural language processing tasks .
Learning from examples is one of the key problems in science and engineering . It deals with function reconstruction from a finite set of direct and noisy samples . Regularization in reproducing kernel Hilbert spaces ( RKHSs ) is widely used to solve this task and includes powerful estimators such as regularization networks . Recent achievements include the proof of the statistical consistency of these kernel- based approaches . Parallel to this , many different system identification techniques have been developed but the interaction with machine learning does not appear so strong yet . One reason is that the RKHSs usually employed in machine learning do not embed the information available on dynamic systems , e . g . BIBO stability . In addition , in system identification the independent data assumptions routinely adopted in machine learning are never satisfied in practice . This paper provides new results which strengthen the connection between system identification and machine learning . Our starting point is the introduction of RKHSs of dynamic systems . They contain functionals over spaces defined by system inputs and allow to interpret system identification as learning from examples . In both linear and nonlinear settings , it is shown that this perspective permits to derive in a relatively simple way conditions on RKHS stability ( i . e . the property of containing only BIBO stable systems or predictors ) , also facilitating the design of new kernels for system identification . Furthermore , we prove the convergence of the regularized estimator to the optimal predictor under conditions typical of dynamic systems .
Fitting models for non-Poisson point processes is complicated by the lack of tractable models for much of the data . By using large samples of independent and identically distributed realizations and statistical learning , it is possible to identify absence of fit through finding a classification rule that can efficiently identify single realizations of each type . The method requires a much wider range of descriptive statistics than are currently in use , and a new concept of model fitting which is derive from how physical laws are judged to fit data .
Overcomplete latent representations have been very popular for unsupervised feature learning in recent years . In this paper , we specify which overcomplete models can be identified given observable moments of a certain order . We consider probabilistic admixture or topic models in the overcomplete regime , where the number of latent topics can greatly exceed the size of the observed word vocabulary . While general overcomplete topic models are not identifiable , we establish generic identifiability under a constraint , referred to as topic persistence . Our sufficient conditions for identifiability involve a novel set of " higher order " expansion conditions on the topic-word matrix or the population structure of the model . This set of higher-order expansion conditions allow for overcomplete models , and require the existence of a perfect matching from latent topics to higher order observed words . We establish that random structured topic models are identifiable w . h . p . in the overcomplete regime . Our identifiability results allows for general ( non-degenerate ) distributions for modeling the topic proportions , and thus , we can handle arbitrarily correlated topics in our framework . Our identifiability results imply uniqueness of a class of tensor decompositions with structured sparsity which is contained in the class of Tucker decompositions , but is more general than the Candecomp/Parafac ( CP ) decomposition .
The personalization of treatment via bio-markers and other risk categories has drawn increasing interest among clinical scientists . Personalized treatment strategies can be learned using data from clinical trials , but such trials are very costly to run . This paper explores the use of active learning techniques to design more efficient trials , addressing issues such as whom to recruit , at what point in the trial , and which treatment to assign , throughout the duration of the trial . We propose a minimax bandit model with two different optimization criteria , and discuss the computational challenges and issues pertaining to this approach . We evaluate our active learning policies using both simulated data , and data modeled after a clinical trial for treating depressed individuals , and contrast our methods with other plausible active learning policies .
The predictive power of neural networks often costs model interpretability . Several techniques have been developed for explaining model outputs in terms of input features ; however , it is difficult to translate such interpretations into actionable insight . Here , we propose a framework to analyze predictions in terms of the model ' s internal features by inspecting information flow through the network . Given a trained network and a test image , we select neurons by two metrics , both measured over a set of images created by perturbations to the input image : ( 0 ) magnitude of the correlation between the neuron activation and the network output and ( 0 ) precision of the neuron activation . We show that the former metric selects neurons that exert large influence over the network output while the latter metric selects neurons that activate on generalizable features . By comparing the sets of neurons selected by these two metrics , our framework suggests a way to investigate the internal attention mechanisms of convolutional neural networks .
Brain signal variability in the measurements obtained from different subjects during different sessions significantly deteriorates the accuracy of most brain-computer interface ( BCI ) systems . Moreover these variabilities , also known as inter-subject or inter-session variabilities , require lengthy calibration sessions before the BCI system can be used . Furthermore , the calibration session has to be repeated for each subject independently and before use of the BCI due to the inter-session variability . In this study , we present an algorithm in order to minimize the above-mentioned variabilities and to overcome the time-consuming and usually error-prone calibration time . Our algorithm is based on linear programming support-vector machines and their extensions to a multiple kernel learning framework . We tackle the inter-subject or -session variability in the feature spaces of the classifiers . This is done by incorporating each subject- or session-specific feature spaces into much richer feature spaces with a set of optimal decision boundaries . Each decision boundary represents the subject- or a session specific spatio-temporal variabilities of neural signals . Consequently , a single classifier with multiple feature spaces will generalize well to new unseen test patterns even without the calibration steps . We demonstrate that classifiers maintain good performances even under the presence of a large degree of BCI variability . The present study analyzes BCI variability related to oxy-hemoglobin neural signals measured using a functional near-infrared spectroscopy .
Parameter estimation in Markov random fields ( MRFs ) is a difficult task , in which inference over the network is run in the inner loop of a gradient descent procedure . Replacing exact inference with approximate methods such as loopy belief propagation ( LBP ) can suffer from poor convergence . In this paper , we provide a different approach for combining MRF learning and Bethe approximation . We consider the dual of maximum likelihood Markov network learning - maximizing entropy with moment matching constraints - and then approximate both the objective and the constraints in the resulting optimization problem . Unlike previous work along these lines ( Teh & Welling , 0000 ) , our formulation allows parameter sharing between features in a general log-linear model , parameter regularization and conditional training . We show that piecewise training ( Sutton & McCallum , 0000 ) is a very restricted special case of this formulation . We study two optimization strategies : one based on a single convex approximation and one that uses repeated convex approximations . We show results on several real-world networks that demonstrate that these algorithms can significantly outperform learning with loopy and piecewise . Our results also provide a framework for analyzing the trade-offs of different relaxations of the entropy objective and of the constraints .
Beta process is the standard nonparametric Bayesian prior for latent factor model . In this paper , we derive a structured mean-field variational inference algorithm for a beta process non-negative matrix factorization ( NMF ) model with Poisson likelihood . Unlike the linear Gaussian model , which is well-studied in the nonparametric Bayesian literature , NMF model with beta process prior does not enjoy the conjugacy . We leverage the recently developed stochastic structured mean-field variational inference to relax the conjugacy constraint and restore the dependencies among the latent variables in the approximating variational distribution . Preliminary results on both synthetic and real examples demonstrate that the proposed inference algorithm can reasonably recover the hidden structure of the data .
In this paper , we propose PCKID , a novel , robust , kernel function for spectral clustering , specifically designed to handle incomplete data . By combining posterior distributions of Gaussian Mixture Models for incomplete data on different scales , we are able to learn a kernel for incomplete data that does not depend on any critical hyperparameters , unlike the commonly used RBF kernel . To evaluate our method , we perform experiments on two real datasets . PCKID outperforms the baseline methods for all fractions of missing values and in some cases outperforms the baseline methods with up to 00 percentage points .
Following the seminal idea of Tukey , data depth is a function that measures how close an arbitrary point of the space is located to an implicitly defined center of a data cloud . Having undergone theoretical and computational developments , it is now employed in numerous applications with classification being the most popular one . The R-package ddalpha is a software directed to fuse experience of the applicant with recent achievements in the area of data depth and depth-based classification . ddalpha provides an implementation for exact and approximate computation of most reasonable and widely applied notions of data depth . These can be further used in the depth-based multivariate and functional classifiers implemented in the package , where the $DD\alpha$-procedure is in the main focus . The package is expandable with user-defined custom depth methods and separators . The implemented functions for depth visualization and the built-in benchmark procedures may also serve to provide insights into the geometry of the data and the quality of pattern recognition .
Causal inference concerns the identification of cause-effect relationships between variables , e . g . establishing whether a stimulus affects activity in a certain brain region . The observed variables themselves often do not constitute meaningful causal variables , however , and linear combinations need to be considered . In electroencephalographic studies , for example , one is not interested in establishing cause-effect relationships between electrode signals ( the observed variables ) , but rather between cortical signals ( the causal variables ) which can be recovered as linear combinations of electrode signals . We introduce MERLiN ( Mixture Effect Recovery in Linear Networks ) , a family of causal inference algorithms that implement a novel means of constructing causal variables from non-causal variables . We demonstrate through application to EEG data how the basic MERLiN algorithm can be extended for application to different ( neuroimaging ) data modalities . Given an observed linear mixture , the algorithms can recover a causal variable that is a linear effect of another given variable . That is , MERLiN allows us to recover a cortical signal that is affected by activity in a certain brain region , while not being a direct effect of the stimulus . The Python/Matlab implementation for all presented algorithms is available on https : //github . com/sweichwald/MERLiN
We present a framework for online inference in the presence of a nonexhaustively defined set of classes that incorporates supervised classification with class discovery and modeling . A Dirichlet process prior ( DPP ) model defined over class distributions ensures that both known and unknown class distributions originate according to a common base distribution . In an attempt to automatically discover potentially interesting class formations , the prior model is coupled with a suitably chosen data model , and sequential Monte Carlo sampling is used to perform online inference . Our research is driven by a biodetection application , where a new class of pathogen may suddenly appear , and the rapid increase in the number of samples originating from this class indicates the onset of an outbreak .
In this paper , we consider the use of structure learning methods for probabilistic graphical models to identify statistical dependencies in high-dimensional physical processes . Such processes are often synthetically characterized using PDEs ( partial differential equations ) and are observed in a variety of natural phenomena , including geoscience data capturing atmospheric and hydrological phenomena . Classical structure learning approaches such as the PC algorithm and variants are challenging to apply due to their high computational and sample requirements . Modern approaches , often based on sparse regression and variants , do come with finite sample guarantees , but are usually highly sensitive to the choice of hyper-parameters , e . g . , parameter $\lambda$ for sparsity inducing constraint or regularization . In this paper , we present ACLIME-ADMM , an efficient two-step algorithm for adaptive structure learning , which estimates an edge specific parameter $\lambda_{ij}$ in the first step , and uses these parameters to learn the structure in the second step . Both steps of our algorithm use ( inexact ) ADMM to solve suitable linear programs , and all iterations can be done in closed form in an efficient block parallel manner . We compare ACLIME-ADMM with baselines on both synthetic data simulated by partial differential equations ( PDEs ) that model advection-diffusion processes , and real data ( 00 years ) of daily global geopotential heights to study information flow in the atmosphere . ACLIME-ADMM is shown to be efficient , stable , and competitive , usually better than the baselines especially on difficult problems . On real data , ACLIME-ADMM recovers the underlying structure of global atmospheric circulation , including switches in wind directions at the equator and tropics entirely from the data .
Decoding , ie prediction from brain images or signals , calls for empirical evaluation of its predictive power . Such evaluation is achieved via cross-validation , a method also used to tune decoders ' hyper-parameters . This paper is a review on cross-validation procedures for decoding in neuroimaging . It includes a didactic overview of the relevant theoretical considerations . Practical aspects are highlighted with an extensive empirical study of the common decoders in within-and across-subject predictions , on multiple datasets --anatomical and functional MRI and MEG-- and simulations . Theory and experiments outline that the popular " leave-one-out " strategy leads to unstable and biased estimates , and a repeated random splits method should be preferred . Experiments outline the large error bars of cross-validation in neuroimaging settings : typical confidence intervals of 00% . Nested cross-validation can tune decoders ' parameters while avoiding circularity bias . However we find that it can be more favorable to use sane defaults , in particular for non-sparse decoders .
The L0-regularized Gaussian maximum likelihood estimator ( MLE ) has been shown to have strong statistical guarantees in recovering a sparse inverse covariance matrix , or alternatively the underlying graph structure of a Gaussian Markov Random Field , from very limited samples . We propose a novel algorithm for solving the resulting optimization problem which is a regularized log-determinant program . In contrast to recent state-of-the-art methods that largely use first order gradient information , our algorithm is based on Newton ' s method and employs a quadratic approximation , but with some modifications that leverage the structure of the sparse Gaussian MLE problem . We show that our method is superlinearly convergent , and present experimental results using synthetic and real-world application data that demonstrate the considerable improvements in performance of our method when compared to other state-of-the-art methods .
In this work , we propose a new method to integrate two recent lines of work : unsupervised induction of shallow semantics ( e . g . , semantic roles ) and factorization of relations in text and knowledge bases . Our model consists of two components : ( 0 ) an encoding component : a semantic role labeling model which predicts roles given a rich set of syntactic and lexical features ; ( 0 ) a reconstruction component : a tensor factorization model which relies on roles to predict argument fillers . When the components are estimated jointly to minimize errors in argument reconstruction , the induced roles largely correspond to roles defined in annotated resources . Our method performs on par with most accurate role induction methods on English , even though , unlike these previous approaches , we do not incorporate any prior linguistic knowledge about the language .
Sparse matrices are favorable objects in machine learning and optimization . When such matrices are used , in place of dense ones , the overall complexity requirements in optimization can be significantly reduced in practice , both in terms of space and run-time . Prompted by this observation , we study a convex optimization scheme for block-sparse recovery from linear measurements . To obtain linear sketches , we use expander matrices , i . e . , sparse matrices containing only few non-zeros per column . Hitherto , to the best of our knowledge , such algorithmic solutions have been only studied from a non-convex perspective . Our aim here is to theoretically characterize the performance of convex approaches under such setting . Our key novelty is the expression of the recovery error in terms of the model-based norm , while assuring that solution lives in the model . To achieve this , we show that sparse model-based matrices satisfy a group version of the null-space property . Our experimental findings on synthetic and real applications support our claims for faster recovery in the convex setting -- as opposed to using dense sensing matrices , while showing a competitive recovery performance .
Many real-world networks are complex dynamical systems , where both local ( e . g . , changing node attributes ) and global ( e . g . , changing network topology ) processes unfold over time . Local dynamics may provoke global changes in the network , and the ability to detect such effects could have profound implications for a number of real-world problems . Most existing techniques focus individually on either local or global aspects of the problem or treat the two in isolation from each other . In this paper we propose a novel network model that simultaneously accounts for both local and global dynamics . To the best of our knowledge , this is the first attempt at modeling and detecting local and global change points on dynamic networks via a unified generative framework . Our model is built upon the popular mixed membership stochastic blockmodels ( MMSB ) with sparse co-evolving patterns . We derive an efficient stochastic gradient Langevin dynamics ( SGLD ) sampler for our proposed model , which allows it to scale to potentially very large networks . Finally , we validate our model on both synthetic and real-world data and demonstrate its superiority over several baselines .
Exploiting the fact that most arrival processes exhibit cyclic behaviour , we propose a simple procedure for estimating the intensity of a nonhomogeneous Poisson process . The estimator is the super-resolution analogue to Shao 0000 and Shao & Lii 0000 , which is a sum of $p$ sinusoids where $p$ and the frequency , amplitude , and phase of each wave are not known and need to be estimated . This results in an interpretable yet flexible specification that is suitable for use in modelling as well as in high resolution simulations . Our estimation procedure sits in between classic periodogram methods and atomic/total variation norm thresholding . A novel aspect of our approach is the use of window functions with fast decaying spectral tails , which we show is the key to super-resolution in our procedure . Interestingly the prolate spheriodal window that is usually considered optimal in signal processing is suboptimal for frequency recovery . Under suitable conditions , finite sample guarantees can be derived for our procedure . These resolve some open questions and expand existing results in spectral estimation literature .
Suppose that multiple experts ( or learning algorithms ) provide us with alternative Bayesian network ( BN ) structures over a domain , and that we are interested in combining them into a single consensus BN structure . Specifically , we are interested in that the consensus BN structure only represents independences all the given BN structures agree upon and that it has as few parameters associated as possible . In this paper , we prove that there may exist several non-equivalent consensus BN structures and that finding one of them is NP-hard . Thus , we decide to resort to heuristics to find an approximated consensus BN structure . In this paper , we consider the heuristic proposed in \citep{MatzkevichandAbramson0000 , MatzkevichandAbramson0000a , MatzkevichandAbramson0000b} . This heuristic builds upon two algorithms , called Methods A and B , for efficiently deriving the minimal directed independence map of a BN structure relative to a given node ordering . Methods A and B are claimed to be correct although no proof is provided ( a proof is just sketched ) . In this paper , we show that Methods A and B are not correct and propose a correction of them .
In this paper we prove the probabilistic continuous complexity conjecture . In continuous complexity theory , this states that the complexity of solving a continuous problem with probability approaching 0 converges ( in this limit ) to the complexity of solving the same problem in its worst case . We prove the conjecture holds if and only if space of problem elements is uniformly convex . The non-uniformly convex case has a striking counterexample in the problem of identifying a Brownian path in Wiener space , where it is shown that probabilistic complexity converges to only half of the worst case complexity in this limit .
We propose a new neural sequence model training method in which the objective function is defined by $\alpha$-divergence . We demonstrate that the objective function generalizes the maximum-likelihood ( ML ) -based and reinforcement learning ( RL ) -based objective functions as special cases ( i . e . , ML corresponds to $\alpha \to 0$ and RL to $\alpha \to0$ ) . We also show that the gradient of the objective function can be considered a mixture of ML- and RL-based objective gradients . The experimental results of a machine translation task show that minimizing the objective function with $\alpha > 0$ outperforms $\alpha \to 0$ , which corresponds to ML-based methods .
One long-term goal of machine learning research is to produce methods that are applicable to reasoning and natural language , in particular building an intelligent dialogue agent . To measure progress towards that goal , we argue for the usefulness of a set of proxy tasks that evaluate reading comprehension via question answering . Our tasks measure understanding in several ways : whether a system is able to answer questions via chaining facts , simple induction , deduction and many more . The tasks are designed to be prerequisites for any system that aims to be capable of conversing with a human . We believe many existing learning systems can currently not solve them , and hence our aim is to classify these tasks into skill sets , so that researchers can identify ( and then rectify ) the failings of their systems . We also extend and improve the recently introduced Memory Networks model , and show it is able to solve some , but not all , of the tasks .
There is significant recent interest to parallelize deep learning algorithms in order to handle the enormous growth in data and model sizes . While most advances focus on model parallelization and engaging multiple computing agents via using a central parameter server , aspect of data parallelization along with decentralized computation has not been explored sufficiently . In this context , this paper presents a new consensus-based distributed SGD ( CDSGD ) ( and its momentum variant , CDMSGD ) algorithm for collaborative deep learning over fixed topology networks that enables data parallelization as well as decentralized computation . Such a framework can be extremely useful for learning agents with access to only local/private data in a communication constrained environment . We analyze the convergence properties of the proposed algorithm with strongly convex and nonconvex objective functions with fixed and diminishing step sizes using concepts of Lyapunov function construction . We demonstrate the efficacy of our algorithms in comparison with the baseline centralized SGD and the recently proposed federated averaging algorithm ( that also enables data parallelism ) based on benchmark datasets such as MNIST , CIFAR-00 and CIFAR-000 .
Bob predicts a future observation based on a sample of size one . Alice can draw a sample of any size before issuing her prediction . How much better can she do than Bob ? Perhaps surprisingly , under a large class of loss functions , which we refer to as the Cover-Hart family , the best Alice can do is to halve Bob ' s risk . In this sense , half the information in an infinite sample is contained in a sample of size one . The Cover-Hart family is a convex cone that includes metrics and negative definite functions , subject to slight regularity conditions . These results may help explain the small relative differences in empirical performance measures in applied classification and forecasting problems , as well as the success of reasoning and learning by analogy in general , and nearest neighbor techniques in particular .
In this work we introduce malware detection from raw byte sequences as a fruitful research area to the larger machine learning community . Building a neural network for such a problem presents a number of interesting challenges that have not occurred in tasks such as image processing or NLP . In particular , we note that detection from raw bytes presents a sequence problem with over two million time steps and a problem where batch normalization appear to hinder the learning process . We present our initial work in building a solution to tackle this problem , which has linear complexity dependence on the sequence length , and allows for interpretable sub-regions of the binary to be identified . In doing so we will discuss the many challenges in building a neural network to process data at this scale , and the methods we used to work around them .
We consider the problem of estimating the arithmetic average of a finite collection of real vectors stored in a distributed fashion across several compute nodes subject to a communication budget constraint . Our analysis does not rely on any statistical assumptions about the source of the vectors . This problem arises as a subproblem in many applications , including reduce-all operations within algorithms for distributed and federated optimization and learning . We propose a flexible family of randomized algorithms exploring the trade-off between expected communication cost and estimation error . Our family contains the full-communication and zero-error method on one extreme , and an $\epsilon$-bit communication and ${\cal O}\left ( 0/ ( \epsilon n ) \right ) $ error method on the opposite extreme . In the special case where we communicate , in expectation , a single bit per coordinate of each vector , we improve upon existing results by obtaining $\mathcal{O} ( r/n ) $ error , where $r$ is the number of bits used to represent a floating point value .
In coming years residential consumers will face real-time electricity tariffs with energy prices varying day to day , and effective energy saving will require automation - a recommender system , which learns consumer ' s preferences from her actions . A consumer chooses a scenario of home appliance use to balance her comfort level and the energy bill . We propose a Bayesian learning algorithm to estimate the comfort level function from the history of appliance use . In numeric experiments with datasets generated from a simulation model of a consumer interacting with small home appliances the algorithm outperforms popular regression analysis tools . Our approach can be extended to control an air heating and conditioning system , which is responsible for up to half of a household ' s energy bill .
This paper proposes a distributionally robust approach to logistic regression . We use the Wasserstein distance to construct a ball in the space of probability distributions centered at the uniform distribution on the training samples . If the radius of this ball is chosen judiciously , we can guarantee that it contains the unknown data-generating distribution with high confidence . We then formulate a distributionally robust logistic regression model that minimizes a worst-case expected logloss function , where the worst case is taken over all distributions in the Wasserstein ball . We prove that this optimization problem admits a tractable reformulation and encapsulates the classical as well as the popular regularized logistic regression problems as special cases . We further propose a distributionally robust approach based on Wasserstein balls to compute upper and lower confidence bounds on the misclassification probability of the resulting classifier . These bounds are given by the optimal values of two highly tractable linear programs . We validate our theoretical out-of-sample guarantees through simulated and empirical experiments .
This paper examines the problem of learning with a finite and possibly large set of p base kernels . It presents a theoretical and empirical analysis of an approach addressing this problem based on ensembles of kernel predictors . This includes novel theoretical guarantees based on the Rademacher complexity of the corresponding hypothesis sets , the introduction and analysis of a learning algorithm based on these hypothesis sets , and a series of experiments using ensembles of kernel predictors with several data sets . Both convex combinations of kernel-based hypotheses and more general Lq-regularized nonnegative combinations are analyzed . These theoretical , algorithmic , and empirical results are compared with those achieved by using learning kernel techniques , which can be viewed as another approach for solving the same problem .
This paper investigates the phase retrieval problem , which aims to recover a signal from the magnitudes of its linear measurements . We develop statistically and computationally efficient algorithms for the situation when the measurements are corrupted by sparse outliers that can take arbitrary values . We propose a novel approach to robustify the gradient descent algorithm by using the sample median as a guide for pruning spurious samples in initialization and local search . Adopting the Poisson loss and the reshaped quadratic loss respectively , we obtain two algorithms termed median-TWF and median-RWF , both of which provably recover the signal from a near-optimal number of measurements when the measurement vectors are composed of i . i . d . Gaussian entries , up to a logarithmic factor , even when a constant fraction of the measurements are adversarially corrupted . We further show that both algorithms are stable in the presence of additional dense bounded noise . Our analysis is accomplished by developing non-trivial concentration results of median-related quantities , which may be of independent interest . We provide numerical experiments to demonstrate the effectiveness of our approach .
As an emerging research direction , online streaming feature selection deals with sequentially added dimensions in a feature space while the number of data instances is fixed . Online streaming feature selection provides a new , complementary algorithmic methodology to enrich online feature selection , especially targets to high dimensionality in big data analytics . This paper introduces the first comprehensive open-source library for use in MATLAB that implements the state-of-the-art algorithms of online streaming feature selection . The library is designed to facilitate the development of new algorithms in this exciting research direction and make comparisons between the new methods and existing ones available .
This paper presents a novel approach for incremental semiparametric inverse dynamics learning . In particular , we consider the mixture of two approaches : Parametric modeling based on rigid body dynamics equations and nonparametric modeling based on incremental kernel methods , with no prior information on the mechanical properties of the system . This yields to an incremental semiparametric approach , leveraging the advantages of both the parametric and nonparametric models . We validate the proposed technique learning the dynamics of one arm of the iCub humanoid robot .
Dynamic robust PCA refers to the dynamic ( time-varying ) extension of the robust PCA ( RPCA ) problem . It assumes that the true ( uncorrupted ) data lies in a low-dimensional subspace that can change with time , albeit slowly . The goal is to track this changing subspace over time in the presence of sparse outliers . This work provides the first guarantee for dynamic RPCA that holds under weakened versions of standard RPCA assumptions and a few other simple assumptions . We analyze a novel algorithm based on the recently introduced Recursive Projected Compressive Sensing ( ReProCS ) framework . Our result is significant because ( i ) it removes the strong assumptions needed by the two previous complete guarantees for ReProCS-based algorithms ; ( ii ) it shows that , it is possible to achieve significantly improved outlier tolerance by exploiting slow subspace change and a lower bound on most outlier magnitudes ; and ( iii ) it proves that the proposed algorithm is online ( after initialization ) , fast , and , has near-optimal storage complexity .
We show that k-means ( Lloyd ' s algorithm ) is equivalent to a variational EM approximation of a Gaussian Mixture Model ( GMM ) with isotropic Gaussians . The k-means algorithm is obtained if truncated posteriors are used as variational distributions . In contrast to the standard way to relate k-means and GMMs , we show that it is not required to consider the limit case of Gaussians with zero variance . There are a number of consequences following from our observation : ( A ) k-means can be shown to monotonously increase the free-energy associated with truncated distributions ; ( B ) Using the free-energy , we can derive an explicit and compact formula of a lower GMM likelihood bound which uses the k-means objective as argument ; ( C ) We can generalize k-means using truncated variational EM , and relate such generalizations to other k-means-like algorithms . In general , truncated variational EM provides a natural and quantitative link between k-means-like clustering and GMM clustering algorithms which may be very relevant for future theoretical as well as empirical studies .
A big challenge in environmental monitoring is the spatiotemporal variation of the phenomena to be observed . To enable persistent sensing and estimation in such a setting , it is beneficial to have a time-varying underlying environmental model . Here we present a planning and learning method that enables an autonomous marine vehicle to perform persistent ocean monitoring tasks by learning and refining an environmental model . To alleviate the computational bottleneck caused by large-scale data accumulated , we propose a framework that iterates between a planning component aimed at collecting the most information-rich data , and a sparse Gaussian Process learning component where the environmental model and hyperparameters are learned online by taking advantage of only a subset of data that provides the greatest contribution . Our simulations with ground-truth ocean data shows that the proposed method is both accurate and efficient .
Due to the lack of enough generalization in the state-space , common methods in Reinforcement Learning ( RL ) suffer from slow learning speed especially in the early learning trials . This paper introduces a model-based method in discrete state-spaces for increasing learning speed in terms of required experience ( but not required computational time ) by exploiting generalization in the experiences of the subspaces . A subspace is formed by choosing a subset of features in the original state representation ( full-space ) . Generalization and faster learning in a subspace are due to many-to-one mapping of experiences from the full-space to each state in the subspace . Nevertheless , due to inherent perceptual aliasing in the subspaces , the policy suggested by each subspace does not generally converge to the optimal policy . Our approach , called Model Based Learning with Subspaces ( MoBLeS ) , calculates confidence intervals of the estimated Q-values in the full-space and in the subspaces . These confidence intervals are used in the decision making , such that the agent benefits the most from the possible generalization while avoiding from detriment of the perceptual aliasing in the subspaces . Convergence of MoBLeS to the optimal policy is theoretically investigated . Additionally , we show through several experiments that MoBLeS improves the learning speed in the early trials .
The need for diversification of recommendation lists manifests in a number of recommender systems use cases . However , an increase in diversity may undermine the utility of the recommendations , as relevant items in the list may be replaced by more diverse ones . In this work we propose a novel method for maximizing the utility of the recommended items subject to the diversity of user ' s tastes , and show that an optimal solution to this problem can be found greedily . We evaluate the proposed method in two online user studies as well as in an offline analysis incorporating a number of evaluation metrics . The results of evaluations show the superiority of our method over a number of baselines .
In this paper we use Gaussian Process ( GP ) regression to propose a novel approach for predicting volatility of financial returns by forecasting the envelopes of the time series . We provide a direct comparison of their performance to traditional approaches such as GARCH . We compare the forecasting power of three approaches : GP regression on the absolute and squared returns ; regression on the envelope of the returns and the absolute returns ; and regression on the envelope of the negative and positive returns separately . We use a maximum a posteriori estimate with a Gaussian prior to determine our hyperparameters . We also test the effect of hyperparameter updating at each forecasting step . We use our approaches to forecast out-of-sample volatility of four currency pairs over a 0 year period , at half-hourly intervals . From three kernels , we select the kernel giving the best performance for our data . We use two published accuracy measures and four statistical loss functions to evaluate the forecasting ability of GARCH vs GPs . In mean squared error the GP ' s perform 00% better than a random walk model , and 00% better than GARCH for the same data .
This paper presents new results for the ( partial ) maximum a posteriori ( MAP ) problem in Bayesian networks , which is the problem of querying the most probable state configuration of some of the network variables given evidence . First , it is demonstrated that the problem remains hard even in networks with very simple topology , such as binary polytrees and simple trees ( including the Naive Bayes structure ) . Such proofs extend previous complexity results for the problem . Inapproximability results are also derived in the case of trees if the number of states per variable is not bounded . Although the problem is shown to be hard and inapproximable even in very simple scenarios , a new exact algorithm is described that is empirically fast in networks of bounded treewidth and bounded number of states per variable . The same algorithm is used as basis of a Fully Polynomial Time Approximation Scheme for MAP under such assumptions . Approximation schemes were generally thought to be impossible for this problem , but we show otherwise for classes of networks that are important in practice . The algorithms are extensively tested using some well-known networks as well as random generated cases to show their effectiveness .
Multivariate techniques based on engineered features have found wide adoption in the identification of jets resulting from hadronic top decays at the Large Hadron Collider ( LHC ) . Recent Deep Learning developments in this area include the treatment of the calorimeter activation as an image or supplying a list of jet constituent momenta to a fully connected network . This latter approach lends itself well to the use of Recurrent Neural Networks . In this work the applicability of architectures incorporating Long Short-Term Memory ( LSTM ) networks is explored . Several network architectures , methods of ordering of jet constituents , and input pre-processing are studied . The best performing LSTM network achieves a background rejection of 000 for 00% signal efficiency . This represents more than a factor of two improvement over a fully connected Deep Neural Network ( DNN ) trained on similar types of inputs .
Inverse reinforcement learning ( IRL ) aims to explain observed strategic behavior by fitting reinforcement learning models to behavioral data . However , traditional IRL methods are only applicable when the observations are in the form of state-action paths . This assumption may not hold in many real-world modelling settings , where only partial observations are available . In general , we may assume that there is a summarizing function $\sigma$ , which acts as a filter between us and the true state-action paths that constitute the demonstration . Some initial approaches to extending IRL to such situations have been presented , but with very specific assumptions about the structure of $\sigma$ , such as that only certain state observations are missing . This paper instead focuses on the most general case of the problem , where no assumptions are made about the summarizing function , except that it can be evaluated . We demonstrate that inference is still possible . The paper presents exact and approximate inference algorithms that allow full posterior inference , which is particularly important for assessing parameter uncertainty in this challenging inference situation . Empirical scalability is demonstrated to reasonably sized problems , and practical applicability is demonstrated by estimating the posterior for a cognitive science RL model based on observed user ' s task completion time only .
Casting neural networks in generative frameworks is a highly sought-after endeavor these days . Existing methods , such as Generative Adversarial Networks , capture some of the generative capabilities , but not all . To truly leverage the power of generative models , tractable marginalization is needed , a feature outside the realm of current methods . We present a generative model based on convolutional arithmetic circuits , a variant of convolutional networks that computes high-dimensional functions through tensor decompositions . Our method admits tractable marginalization , combining the expressive power of convolutional networks with all the abilities that may be offered by a generative framework . We focus on the application of classification under missing data , where unknown portions of classified instances are absent at test time . Our model , which theoretically achieves optimal classification , provides state of the art performance when classifying images with missing pixels , as well as promising results when treating speech with occluded samples .
We consider regression scenarios where it is natural to impose an order constraint on the coefficients . We propose an order-constrained version of L0-regularized regression for this problem , and show how to solve it efficiently using the well-known Pool Adjacent Violators Algorithm as its proximal operator . The main application of this idea is time-lagged regression , where we predict an outcome at time t from features at the previous K time points . In this setting it is natural to assume that the coefficients decay as we move farther away from t , and hence the order constraint is reasonable . Potential applications include financial time series and prediction of dynamic patient out- comes based on clinical measurements . We illustrate this idea on real and simulated data .
Monte-Carlo Tree Search ( MCTS ) methods are drawing great interest after yielding breakthrough results in computer Go . This paper proposes a Bayesian approach to MCTS that is inspired by distributionfree approaches such as UCT [00] , yet significantly differs in important respects . The Bayesian framework allows potentially much more accurate ( Bayes-optimal ) estimation of node values and node uncertainties from a limited number of simulation trials . We further propose propagating inference in the tree via fast analytic Gaussian approximation methods : this can make the overhead of Bayesian inference manageable in domains such as Go , while preserving high accuracy of expected-value estimates . We find substantial empirical outperformance of UCT in an idealized bandit-tree test environment , where we can obtain valuable insights by comparing with known ground truth . Additionally we rigorously prove on-policy and off-policy convergence of the proposed methods .
The novel unseen classes can be formulated as the extreme values of known classes . This inspired the recent works on open-set recognition \cite{Scheirer_0000_TPAMI , Scheirer_0000_TPAMIb , EVM} , which however can have no way of naming the novel unseen classes . To solve this problem , we propose the Extreme Value Learning ( EVL ) formulation to learn the mapping from visual feature to semantic space . To model the margin and coverage distributions of each class , the Vocabulary-informed Learning ( ViL ) is adopted by using vast open vocabulary in the semantic space . Essentially , by incorporating the EVL and ViL , we for the first time propose a novel semantic embedding paradigm -- Vocabulary-informed Extreme Value Learning ( ViEVL ) , which embeds the visual features into semantic space in a probabilistic way . The learned embedding can be directly used to solve supervised learning , zero-shot and open set recognition simultaneously . Experiments on two benchmark datasets demonstrate the effectiveness of proposed frameworks .
An exciting branch of machine learning research focuses on methods for learning , optimizing , and integrating unknown functions that are difficult or costly to evaluate . A popular Bayesian approach to this problem uses a Gaussian process ( GP ) to construct a posterior distribution over the function of interest given a set of observed measurements , and selects new points to evaluate using the statistics of this posterior . Here we extend these methods to exploit derivative information from the unknown function . We describe methods for Bayesian optimization ( BO ) and Bayesian quadrature ( BQ ) in settings where first and second derivatives may be evaluated along with the function itself . We perform sampling-based inference in order to incorporate uncertainty over hyperparameters , and show that both hyperparameter and function uncertainty decrease much more rapidly when using derivative information . Moreover , we introduce techniques for overcoming ill-conditioning issues that have plagued earlier methods for gradient-enhanced Gaussian processes and kriging . We illustrate the efficacy of these methods using applications to real and simulated Bayesian optimization and quadrature problems , and show that exploting derivatives can provide substantial gains over standard methods .
We applied machine learning to predict whether a gene is involved in axon regeneration . We extracted 00 features from different databases and trained five machine learning models . Our optimal model , a Random Forest Classifier with 00 submodels , yielded a test score of 00 . 00% , which is 0 . 0% higher than the baseline score . We concluded that our models have some predictive capability . Similar methodology and features could be applied to predict other Gene Ontology ( GO ) terms .
A method for authorship attribution based on function word adjacency networks ( WANs ) is introduced . Function words are parts of speech that express grammatical relationships between other words but do not carry lexical meaning on their own . In the WANs in this paper , nodes are function words and directed edges stand in for the likelihood of finding the sink word in the ordered vicinity of the source word . WANs of different authors can be interpreted as transition probabilities of a Markov chain and are therefore compared in terms of their relative entropies . Optimal selection of WAN parameters is studied and attribution accuracy is benchmarked across a diverse pool of authors and varying text lengths . This analysis shows that , since function words are independent of content , their use tends to be specific to an author and that the relational data captured by function WANs is a good summary of stylometric fingerprints . Attribution accuracy is observed to exceed the one achieved by methods that rely on word frequencies alone . Further combining WANs with methods that rely on word frequencies alone , results in larger attribution accuracy , indicating that both sources of information encode different aspects of authorial styles .
Computing optimal transport distances such as the earth mover ' s distance is a fundamental problem in machine learning , statistics , and computer vision . Despite the recent introduction of several algorithms with good empirical performance , it is unknown whether general optimal transport distances can be approximated in near-linear time . This paper demonstrates that this ambitious goal is in fact achieved by Cuturi ' s Sinkhorn Distances , and provides guidance towards parameter tuning for this algorithm . This result relies on a new analysis of Sinkhorn iterations that also directly suggests a new algorithm Greenkhorn with the same theoretical guarantees . Numerical simulations illustrate that Greenkhorn significantly outperforms the classical Sinkhorn algorithm in practice .
Many machine learning problems , especially multi-modal learning problems , have two sets of distinct features ( e . g . , image and text features in news story classification , or neuroimaging data and neurocognitive data in cognitive science research ) . This paper addresses the joint dimensionality reduction of two feature vectors in supervised learning problems . In particular , we assume a discriminative model where low-dimensional linear embeddings of the two feature vectors are sufficient statistics for predicting a dependent variable . We show that a simple algorithm involving singular value decomposition can accurately estimate the embeddings provided that certain sample complexities are satisfied , without specifying the nonlinear link function ( regressor or classifier ) . The main results establish sample complexities under multiple settings . Sample complexities for different link functions only differ by constant factors .
One of the most challenging problems in kernel online learning is to bound the model size and to promote the model sparsity . Sparse models not only improve computation and memory usage , but also enhance the generalization capacity , a principle that concurs with the law of parsimony . However , inappropriate sparsity modeling may also significantly degrade the performance . In this paper , we propose Approximation Vector Machine ( AVM ) , a model that can simultaneously encourage the sparsity and safeguard its risk in compromising the performance . When an incoming instance arrives , we approximate this instance by one of its neighbors whose distance to it is less than a predefined threshold . Our key intuition is that since the newly seen instance is expressed by its nearby neighbor the optimal performance can be analytically formulated and maintained . We develop theoretical foundations to support this intuition and further establish an analysis to characterize the gap between the approximation and optimal solutions . This gap crucially depends on the frequency of approximation and the predefined threshold . We perform the convergence analysis for a wide spectrum of loss functions including Hinge , smooth Hinge , and Logistic for classification task , and $l_0$ , $l_0$ , and $\epsilon$-insensitive for regression task . We conducted extensive experiments for classification task in batch and online modes , and regression task in online mode over several benchmark datasets . The results show that our proposed AVM achieved a comparable predictive performance with current state-of-the-art methods while simultaneously achieving significant computational speed-up due to the ability of the proposed AVM in maintaining the model size .
Despite its importance , choosing the structural form of the kernel in nonparametric regression remains a black art . We define a space of kernel structures which are built compositionally by adding and multiplying a small number of base kernels . We present a method for searching over this space of structures which mirrors the scientific discovery process . The learned structures can often decompose functions into interpretable components and enable long-range extrapolation on time-series datasets . Our structure search method outperforms many widely used kernels and kernel combination methods on a variety of prediction tasks .
In applications such as recommendation systems and revenue management , it is important to predict preferences on items that have not been seen by a user or predict outcomes of comparisons among those that have never been compared . A popular discrete choice model of multinomial logit model captures the structure of the hidden preferences with a low-rank matrix . In order to predict the preferences , we want to learn the underlying model from noisy observations of the low-rank matrix , collected as revealed preferences in various forms of ordinal data . A natural approach to learn such a model is to solve a convex relaxation of nuclear norm minimization . We present the convex relaxation approach in two contexts of interest : collaborative ranking and bundled choice modeling . In both cases , we show that the convex relaxation is minimax optimal . We prove an upper bound on the resulting error with finite samples , and provide a matching information-theoretic lower bound .
Social media services such as Twitter are a valuable source of information for decision support systems . Many studies have shown that this also holds for the medical domain , where Twitter is considered a viable tool for public health officials to sift through relevant information for the early detection , management , and control of epidemic outbreaks . This is possible due to the inherent capability of social media services to transmit information faster than traditional channels . However , the majority of current studies have limited their scope to the detection of common and seasonal health recurring events ( e . g . , Influenza-like Illness ) , partially due to the noisy nature of Twitter data , which makes outbreak detection and management very challenging . Within the European project M-Eco , we developed a Twitter-based Epidemic Intelligence ( EI ) system , which is designed to also handle a more general class of unexpected and aperiodic outbreaks . In particular , we faced three main research challenges in this endeavor : 0 ) dynamic classification to manage terminology evolution of Twitter messages , 0 ) alert generation to produce reliable outbreak alerts analyzing the ( noisy ) tweet time series , and 0 ) ranking and recommendation to support domain experts for better assessment of the generated alerts . In this paper , we empirically evaluate our proposed approach to these challenges using real-world outbreak datasets and a large collection of tweets . We validate our solution with domain experts , describe our experiences , and give a more realistic view on the benefits and issues of analyzing social media for public health .
Consider a sample of $n$ points taken i . i . d from a submanifold $\Sigma$ of Euclidean space . We show that there is a way to estimate the Ricci curvature of $\Sigma$ with respect to the induced metric from the sample . Our method is grounded in the notions of Carr\ ' e du Champ for diffusion semi-groups , the theory of Empirical processes and local Principal Component Analysis .
A topological approach to stratification learning is developed for point cloud data drawn from a stratified space . Given such data , our objective is to infer which points belong to the same strata . First we define a multi-scale notion of a stratified space , giving a stratification for each radius level . We then use methods derived from kernel and cokernel persistent homology to cluster the data points into different strata , and we prove a result which guarantees the correctness of our clustering , given certain topological conditions ; some geometric intuition for these topological conditions is also provided . Our correctness result is then given a probabilistic flavor : we give bounds on the minimum number of sample points required to infer , with probability , which points belong to the same strata . Finally , we give an explicit algorithm for the clustering , prove its correctness , and apply it to some simulated data .
In the classical Gaussian SVM classification we use the feature space projection transforming points to normal distributions with fixed covariance matrices ( identity in the standard RBF and the covariance of the whole dataset in Mahalanobis RBF ) . In this paper we add additional information to Gaussian SVM by considering local geometry-dependent feature space projection . We emphasize that our approach is in fact an algorithm for a construction of the new Gaussian-type kernel . We show that better ( compared to standard RBF and Mahalanobis RBF ) classification results are obtained in the simple case when the space is preliminary divided by k-means into two sets and points are represented as normal distributions with a covariances calculated according to the dataset partitioning . We call the constructed method C$_k$RBF , where $k$ stands for the amount of clusters used in k-means . We show empirically on nine datasets from UCI repository that C$_0$RBF increases the stability of the grid search ( measured as the probability of finding good parameters ) .
Gaussian belief propagation ( GaBP ) is an iterative algorithm for computing the mean of a multivariate Gaussian distribution , or equivalently , the minimum of a multivariate positive definite quadratic function . Sufficient conditions , such as walk-summability , that guarantee the convergence and correctness of GaBP are known , but GaBP may fail to converge to the correct solution given an arbitrary positive definite quadratic function . As was observed in previous work , the GaBP algorithm fails to converge if the computation trees produced by the algorithm are not positive definite . In this work , we will show that the failure modes of the GaBP algorithm can be understood via graph covers , and we prove that a parameterized generalization of the min-sum algorithm can be used to ensure that the computation trees remain positive definite whenever the input matrix is positive definite . We demonstrate that the resulting algorithm is closely related to other iterative schemes for quadratic minimization such as the Gauss-Seidel and Jacobi algorithms . Finally , we observe , empirically , that there always exists a choice of parameters such that the above generalization of the GaBP algorithm converges .
This paper investigates graph clustering in the planted cluster model in the presence of {\em small clusters} . Traditional results dictate that for an algorithm to provably correctly recover the clusters , {\em all} clusters must be sufficiently large ( in particular , $\tilde{\Omega} ( \sqrt{n} ) $ where $n$ is the number of nodes of the graph ) . We show that this is not really a restriction : by a more refined analysis of the trace-norm based recovery approach proposed in Jalali et al . ( 0000 ) and Chen et al . ( 0000 ) , we prove that small clusters , under certain mild assumptions , do not hinder recovery of large ones . Based on this result , we further devise an iterative algorithm to recover {\em almost all clusters} via a " peeling strategy " , i . e . , recover large clusters first , leading to a reduced problem , and repeat this procedure . These results are extended to the {\em partial observation} setting , in which only a ( chosen ) part of the graph is observed . The peeling strategy gives rise to an active learning algorithm , in which edges adjacent to smaller clusters are queried more often as large clusters are learned ( and removed ) . From a high level , this paper sheds novel insights on high-dimensional statistics and learning structured data , by presenting a structured matrix learning problem for which a one shot convex relaxation approach necessarily fails , but a carefully constructed sequence of convex relaxationsdoes the job .
Matrix factorisation methods decompose multivariate observations as linear combinations of latent feature vectors . The Indian Buffet Process ( IBP ) provides a way to model the number of latent features required for a good approximation in terms of regularised reconstruction error . Previous work has focussed on latent feature vectors with independent entries . We extend the model to include nondiagonal latent covariance structures representing characteristics such as smoothness . This is done by . Using simulations we demonstrate that under appropriate conditions a smoothness prior helps to recover the true latent features , while denoising more accurately . We demonstrate our method on a real neuroimaging dataset , where computational tractability is a sufficient challenge that the efficient strategy presented here is essential .
We propose a probabilistic model for interpreting gene expression levels that are observed through single-cell RNA sequencing . In the model , each cell has a low-dimensional latent representation . Additional latent variables account for technical effects that may erroneously set some observations of gene expression levels to zero . Conditional distributions are specified by neural networks , giving the proposed model enough flexibility to fit the data well . We use variational inference and stochastic optimization to approximate the posterior distribution . The inference procedure scales to over one million cells , whereas competing algorithms do not . Even for smaller datasets , for several tasks , the proposed procedure outperforms state-of-the-art methods like ZIFA and ZINB-WaVE . We also extend our framework to take into account batch effects and other confounding factors and propose a natural Bayesian hypothesis framework for differential expression that outperforms tradition DESeq0 .
There is a large amount of interest in understanding users of social media in order to predict their behavior in this space . Despite this interest , user predictability in social media is not well-understood . To examine this question , we consider a network of fifteen thousand users on Twitter over a seven week period . We apply two contrasting modeling paradigms : computational mechanics and echo state networks . Both methods attempt to model the behavior of users on the basis of their past behavior . We demonstrate that the behavior of users on Twitter can be well-modeled as processes with self-feedback . We find that the two modeling approaches perform very similarly for most users , but that they differ in performance on a small subset of the users . By exploring the properties of these performance-differentiated users , we highlight the challenges faced in applying predictive models to dynamic social data .
We propose a simple , scalable , and fast gradient descent algorithm to optimize a nonconvex objective for the rank minimization problem and a closely related family of semidefinite programs . With $O ( r^0 \kappa^0 n \log n ) $ random measurements of a positive semidefinite $n \times n$ matrix of rank $r$ and condition number $\kappa$ , our method is guaranteed to converge linearly to the global optimum .
We consider a graphical model where a multivariate normal vector is associated with each node of the underlying graph and estimate the graphical structure . We minimize a loss function obtained by regressing the vector at each node on those at the remaining ones under a group penalty . We show that the proposed estimator can be computed by a fast convex optimization algorithm . We show that as the sample size increases , the estimated regression coefficients and the correct graphical structure are correctly estimated with probability tending to one . By extensive simulations , we show the superiority of the proposed method over comparable procedures . We apply the technique on two real datasets . The first one is to identify gene and protein networks showing up in cancer cell lines , and the second one is to reveal the connections among different industries in the US .
We introduce a Bayesian approach to discovering patterns in structurally complex processes . The proposed method of Bayesian Structural Inference ( BSI ) relies on a set of candidate unifilar HMM ( uHMM ) topologies for inference of process structure from a data series . We employ a recently developed exact enumeration of topological epsilon-machines . ( A sequel then removes the topological restriction . ) This subset of the uHMM topologies has the added benefit that inferred models are guaranteed to be epsilon-machines , irrespective of estimated transition probabilities . Properties of epsilon-machines and uHMMs allow for the derivation of analytic expressions for estimating transition probabilities , inferring start states , and comparing the posterior probability of candidate model topologies , despite process internal structure being only indirectly present in data . We demonstrate BSI ' s effectiveness in estimating a process ' s randomness , as reflected by the Shannon entropy rate , and its structure , as quantified by the statistical complexity . We also compare using the posterior distribution over candidate models and the single , maximum a posteriori model for point estimation and show that the former more accurately reflects uncertainty in estimated values . We apply BSI to in-class examples of finite- and infinite-order Markov processes , as well to an out-of-class , infinite-state hidden process .
We propose a max-pooling based loss function for training Long Short-Term Memory ( LSTM ) networks for small-footprint keyword spotting ( KWS ) , with low CPU , memory , and latency requirements . The max-pooling loss training can be further guided by initializing with a cross-entropy loss trained network . A posterior smoothing based evaluation approach is employed to measure keyword spotting performance . Our experimental results show that LSTM models trained using cross-entropy loss or max-pooling loss outperform a cross-entropy loss trained baseline feed-forward Deep Neural Network ( DNN ) . In addition , max-pooling loss trained LSTM with randomly initialized network performs better compared to cross-entropy loss trained LSTM . Finally , the max-pooling loss trained LSTM initialized with a cross-entropy pre-trained network shows the best performance , which yields $00 . 0\%$ relative reduction compared to baseline feed-forward DNN in Area Under the Curve ( AUC ) measure .
Crowdsourcing is a popular paradigm for effectively collecting labels at low cost . The Dawid-Skene estimator has been widely used for inferring the true labels from the noisy labels provided by non-expert crowdsourcing workers . However , since the estimator maximizes a non-convex log-likelihood function , it is hard to theoretically justify its performance . In this paper , we propose a two-stage efficient algorithm for multi-class crowd labeling problems . The first stage uses the spectral method to obtain an initial estimate of parameters . Then the second stage refines the estimation by optimizing the objective function of the Dawid-Skene estimator via the EM algorithm . We show that our algorithm achieves the optimal convergence rate up to a logarithmic factor . We conduct extensive experiments on synthetic and real datasets . Experimental results demonstrate that the proposed algorithm is comparable to the most accurate empirical approach , while outperforming several other recently proposed methods .
We propose a new framework for manifold denoising based on processing in the graph Fourier frequency domain , derived from the spectral decomposition of the discrete graph Laplacian . Our approach uses the Spectral Graph Wavelet transform in order to per- form non-iterative denoising directly in the graph frequency domain , an approach inspired by conventional wavelet-based signal denoising methods . We theoretically justify our approach , based on the fact that for smooth manifolds the coordinate information energy is localized in the low spectral graph wavelet sub-bands , while the noise affects all frequency bands in a similar way . Experimental results show that our proposed manifold frequency denoising ( MFD ) approach significantly outperforms the state of the art denoising meth- ods , and is robust to a wide range of parameter selections , e . g . , the choice of k nearest neighbor connectivity of the graph .
Prediction of the future trajectory of a disease is an important challenge for personalized medicine and population health management . However , many complex chronic diseases exhibit large degrees of heterogeneity , and furthermore there is not always a single readily available biomarker to quantify disease severity . Even when such a clinical variable exists , there are often additional related biomarkers routinely measured for patients that may better inform the predictions of their future disease state . To this end , we propose a novel probabilistic generative model for multivariate longitudinal data that captures dependencies between multivariate trajectories . We use a Gaussian process based regression model for each individual trajectory , and build off ideas from latent class models to induce dependence between their mean functions . We fit our method using a scalable variational inference algorithm to a large dataset of longitudinal electronic patient health records , and find that it improves dynamic predictions compared to a recent state of the art method . Our local accountable care organization then uses the model predictions during chart reviews of high risk patients with chronic kidney disease .
We propose the use of k-determinantal point processes in hyperparameter optimization via random search . Compared to conventional approaches where hyperparameter settings are sampled independently , a k-DPP promotes diversity . We describe an approach that transforms hyperparameter search spaces for efficient use with a k-DPP . Our experiments show significant benefits over uniform random search in realistic scenarios with a limited budget for training supervised learners , whether in serial or parallel .
We introduce the notion of multiscale covariance tensor fields ( CTF ) associated with Euclidean random variables as a gateway to the shape of their distributions . Multiscale CTFs quantify variation of the data about every point in the data landscape at all spatial scales , unlike the usual covariance tensor that only quantifies global variation about the mean . Empirical forms of localized covariance previously have been used in data analysis and visualization , but we develop a framework for the systematic treatment of theoretical questions and computational models based on localized covariance . We prove strong stability theorems with respect to the Wasserstein distance between probability measures , obtain consistency results , as well as estimates for the rate of convergence of empirical CTFs . These results ensure that CTFs are robust to sampling , noise and outliers . We provide numerous illustrations of how CTFs let us extract shape from data and also apply CTFs to manifold clustering , the problem of categorizing data points according to their noisy membership in a collection of possibly intersecting , smooth submanifolds of Euclidean space . We prove that the proposed manifold clustering method is stable and carry out several experiments to validate the method .
Resolving abstract anaphora is an important , but difficult task for text understanding . Yet , with recent advances in representation learning this task becomes a more tangible aim . A central property of abstract anaphora is that it establishes a relation between the anaphor embedded in the anaphoric sentence and its ( typically non-nominal ) antecedent . We propose a mention-ranking model that learns how abstract anaphors relate to their antecedents with an LSTM-Siamese Net . We overcome the lack of training data by generating artificial anaphoric sentence--antecedent pairs . Our model outperforms state-of-the-art results on shell noun resolution . We also report first benchmark results on an abstract anaphora subset of the ARRAU corpus . This corpus presents a greater challenge due to a mixture of nominal and pronominal anaphors and a greater range of confounders . We found model variants that outperform the baselines for nominal anaphors , without training on individual anaphor data , but still lag behind for pronominal anaphors . Our model selects syntactically plausible candidates and -- if disregarding syntax -- discriminates candidates using deeper features .
We present a very fast algorithm for general matrix factorization of a data matrix for use in the statistical analysis of high-dimensional data via latent factors . Such data are prevalent across many application areas and generate an ever-increasing demand for methods of dimension reduction in order to undertake the statistical analysis of interest . Our algorithm uses a gradient-based approach which can be used with an arbitrary loss function provided the latter is differentiable . The speed and effectiveness of our algorithm for dimension reduction is demonstrated in the context of supervised classification of some real high-dimensional data sets from the bioinformatics literature .
Typical reinforcement learning ( RL ) agents learn to complete tasks specified by reward functions tailored to their domain . As such , the policies they learn do not generalize even to similar domains . To address this issue , we develop a framework through which a deep RL agent learns to generalize policies from smaller , simpler domains to more complex ones using a recurrent attention mechanism . The task is presented to the agent as an image and an instruction specifying the goal . This meta-controller guides the agent towards its goal by designing a sequence of smaller subtasks on the part of the state space within the attention , effectively decomposing it . As a baseline , we consider a setup without attention as well . Our experiments show that the meta-controller learns to create subgoals within the attention .
We study optimization algorithms based on variance reduction for stochastic gradient descent ( SGD ) . Remarkable recent progress has been made in this direction through development of algorithms like SAG , SVRG , SAGA . These algorithms have been shown to outperform SGD , both theoretically and empirically . However , asynchronous versions of these algorithms---a crucial requirement for modern large-scale applications---have not been studied . We bridge this gap by presenting a unifying framework for many variance reduction techniques . Subsequently , we propose an asynchronous algorithm grounded in our framework , and prove its fast convergence . An important consequence of our general approach is that it yields asynchronous versions of variance reduction algorithms such as SVRG and SAGA as a byproduct . Our method achieves near linear speedup in sparse settings common to machine learning . We demonstrate the empirical performance of our method through a concrete realization of asynchronous SVRG .
Many scientific datasets are of high dimension , and the analysis usually requires visual manipulation by retaining the most important structures of data . Principal curve is a widely used approach for this purpose . However , many existing methods work only for data with structures that are not self-intersected , which is quite restrictive for real applications . A few methods can overcome the above problem , but they either require complicated human-made rules for a specific task with lack of convergence guarantee and adaption flexibility to different tasks , or cannot obtain explicit structures of data . To address these issues , we develop a new regularized principal graph learning framework that captures the local information of the underlying graph structure based on reversed graph embedding . As showcases , models that can learn a spanning tree or a weighted undirected $\ell_0$ graph are proposed , and a new learning algorithm is developed that learns a set of principal points and a graph structure from data , simultaneously . The new algorithm is simple with guaranteed convergence . We then extend the proposed framework to deal with large-scale data . Experimental results on various synthetic and six real world datasets show that the proposed method compares favorably with baselines and can uncover the underlying structure correctly .
In this paper , we address the problem of conditional modality learning , whereby one is interested in generating one modality given the other . While it is straightforward to learn a joint distribution over multiple modalities using a deep multimodal architecture , we observe that such models aren ' t very effective at conditional generation . Hence , we address the problem by learning conditional distributions between the modalities . We use variational methods for maximizing the corresponding conditional log-likelihood . The resultant deep model , which we refer to as conditional multimodal autoencoder ( CMMA ) , forces the latent representation obtained from a single modality alone to be `close ' to the joint representation obtained from multiple modalities . We use the proposed model to generate faces from attributes . We show that the faces generated from attributes using the proposed model , are qualitatively and quantitatively more representative of the attributes from which they were generated , than those obtained by other deep generative models . We also propose a secondary task , whereby the existing faces are modified by modifying the corresponding attributes . We observe that the modifications in face introduced by the proposed model are representative of the corresponding modifications in attributes .
In Natural Language Processing ( NLP ) tasks , data often has the following two properties : First , data can be chopped into multi-views which has been successfully used for dimension reduction purposes . For example , in topic classification , every paper can be chopped into the title , the main text and the references . However , it is common that some of the views are less noisier than other views for supervised learning problems . Second , unlabeled data are easy to obtain while labeled data are relatively rare . For example , articles occurred on New York Times in recent 00 years are easy to grab but having them classified as ' Politics ' , ' Finance ' or ' Sports ' need human labor . Hence less noisy features are preferred before running supervised learning methods . In this paper we propose an unsupervised algorithm which optimally weights features from different views when these views are generated from a low dimensional hidden state , which occurs in widely used models like Mixture Gaussian Model , Hidden Markov Model ( HMM ) and Latent Dirichlet Allocation ( LDA ) .
Hidden Markov Models ( HMM ) have been used for several years in many time series analysis or pattern recognitions tasks . HMM are often trained by means of the Baum-Welch algorithm which can be seen as a special variant of an expectation maximization ( EM ) algorithm . Second-order training techniques such as Variational Bayesian Inference ( VI ) for probabilistic models regard the parameters of the probabilistic models as random variables and define distributions over these distribution parameters , hence the name of this technique . VI can also bee regarded as a special case of an EM algorithm . In this article , we bring both together and train HMM with multivariate Gaussian output distributions with VI . The article defines the new training technique for HMM . An evaluation based on some case studies and a comparison to related approaches is part of our ongoing work .
In numerous applicative contexts , data are too rich and too complex to be represented by numerical vectors . A general approach to extend machine learning and data mining techniques to such data is to really on a dissimilarity or on a kernel that measures how different or similar two objects are . This approach has been used to define several variants of the Self Organizing Map ( SOM ) . This paper reviews those variants in using a common set of notations in order to outline differences and similarities between them . It discusses the advantages and drawbacks of the variants , as well as the actual relevance of the dissimilarity/kernel SOM for practical applications .
Linear principal component analysis ( PCA ) can be extended to a nonlinear PCA by using artificial neural networks . But the benefit of curved components requires a careful control of the model complexity . Moreover , standard techniques for model selection , including cross-validation and more generally the use of an independent test set , fail when applied to nonlinear PCA because of its inherent unsupervised characteristics . This paper presents a new approach for validating the complexity of nonlinear PCA models by using the error in missing data estimation as a criterion for model selection . It is motivated by the idea that only the model of optimal complexity is able to predict missing values with the highest accuracy . While standard test set validation usually favours over-fitted nonlinear PCA models , the proposed model validation approach correctly selects the optimal model complexity .
Significant pattern mining , the problem of finding itemsets that are significantly enriched in one class of objects , is statistically challenging , as the large space of candidate patterns leads to an enormous multiple testing problem . Recently , the concept of testability was proposed as one approach to correct for multiple testing in pattern mining while retaining statistical power . Still , these strategies based on testability do not allow one to condition the test of significance on the observed covariates , which severely limits its utility in biomedical applications . Here we propose a strategy and an efficient algorithm to perform significant pattern mining in the presence of categorical covariates with K states .
Determining whether certain properties are related to other properties is fundamental to scientific discovery . As data collection rates accelerate , it is becoming increasingly difficult yet ever more important to determine whether one property of data ( e . g . , cloud density ) is related to another ( e . g . , grass wetness ) . Only if two properties are related are further investigations into the geometry of the relationship warranted . While existing approaches can test whether two properties are related , they may require unfeasibly large sample sizes in real data scenarios , and do not provide insight into the geometry underlying the structure of the relationship . We juxtapose hypothesis testing , manifold learning , and harmonic analysis to obtain Multiscale Generalized Correlation ( MGC ) . Our key insight is that one can adaptively restrict the analysis to the " jointly local " observations - that is , one can estimate the scale with the most informative neighbors for determining the existence and geometry of a relationship . We prove that to achieve a given true positive rate , MGC typically requires far fewer samples than existing methods for all investigated dependence structures and dimensionalities , while maintaining computational efficiency . Moreover , MGC uniquely provides a simple and elegant characterization of the potentially complex latent geometry underlying the relationship . We used MGC to detect the presence and reveal the geometry of the relationships between mental and brain properties , to perform a proteomics screening , and to develop an imaging biomarker for disease , while avoiding the false positive inflation problems that have plagued conventional parametric approaches . Our open source implementation of MGC is easy to use , parameter-free , and applicable to previously vexing statistical questions that are ubiquitous in science , government , finance , and other disciplines .
Deep neural networks have achieved impressive supervised classification performance in many tasks including image recognition , speech recognition , and sequence to sequence learning . However , this success has not been translated to applications like question answering that may involve complex arithmetic and logic reasoning . A major limitation of these models is in their inability to learn even simple arithmetic and logic operations . For example , it has been shown that neural networks fail to learn to add two binary numbers reliably . In this work , we propose Neural Programmer , an end-to-end differentiable neural network augmented with a small set of basic arithmetic and logic operations . Neural Programmer can call these augmented operations over several steps , thereby inducing compositional programs that are more complex than the built-in operations . The model learns from a weak supervision signal which is the result of execution of the correct program , hence it does not require expensive annotation of the correct program itself . The decisions of what operations to call , and what data segments to apply to are inferred by Neural Programmer . Such decisions , during training , are done in a differentiable fashion so that the entire network can be trained jointly by gradient descent . We find that training the model is difficult , but it can be greatly improved by adding random noise to the gradient . On a fairly complex synthetic table-comprehension dataset , traditional recurrent networks and attentional models perform poorly while Neural Programmer typically obtains nearly perfect accuracy .
This paper presents a general coding method where data in a Hilbert space are represented by finite dimensional coding vectors . The method is based on empirical risk minimization within a certain class of linear operators , which map the set of coding vectors to the Hilbert space . Two results bounding the expected reconstruction error of the method are derived , which highlight the role played by the codebook and the class of linear operators . The results are specialized to some cases of practical importance , including K-means clustering , nonnegative matrix factorization and other sparse coding methods .
Understanding the adaptation process of plants to drought stress is essential in improving management practices , breeding strategies as well as engineering viable crops for a sustainable agriculture in the coming decades . Hyper-spectral imaging provides a particularly promising approach to gain such understanding since it allows to discover non-destructively spectral characteristics of plants governed primarily by scattering and absorption characteristics of the leaf internal structure and biochemical constituents . Several drought stress indices have been derived using hyper-spectral imaging . However , they are typically based on few hyper-spectral images only , rely on interpretations of experts , and consider few wavelengths only . In this study , we present the first data-driven approach to discovering spectral drought stress indices , treating it as an unsupervised labeling problem at massive scale . To make use of short range dependencies of spectral wavelengths , we develop an online variational Bayes algorithm for latent Dirichlet allocation with convolved Dirichlet regularizer . This approach scales to massive datasets and , hence , provides a more objective complement to plant physiological practices . The spectral topics found conform to plant physiological knowledge and can be computed in a fraction of the time compared to existing LDA approaches .
We introduce an alternative to the notion of `fast rate ' in Learning Theory , which coincides with the optimal error rate when the given class happens to be convex and regular in some sense . While it is well known that such a rate cannot always be attained by a learning procedure ( i . e . , a procedure that selects a function in the given class ) , we introduce an aggregation procedure that attains that rate under rather minimal assumptions -- for example , that the $L_q$ and $L_0$ norms are equivalent on the linear span of the class for some $q>0$ , and the target random variable is square-integrable .
Low-rank matrix approximations are often used to help scale standard machine learning algorithms to large-scale problems . Recently , matrix coherence has been used to characterize the ability to extract global information from a subset of matrix entries in the context of these low-rank approximations and other sampling-based algorithms , e . g . , matrix com- pletion , robust PCA . Since coherence is defined in terms of the singular vectors of a matrix and is expensive to compute , the practical significance of these results largely hinges on the following question : Can we efficiently and accurately estimate the coherence of a matrix ? In this paper we address this question . We propose a novel algorithm for estimating coherence from a small number of columns , formally analyze its behavior , and derive a new coherence-based matrix approximation bound based on this analysis . We then present extensive experimental results on synthetic and real datasets that corroborate our worst-case theoretical analysis , yet provide strong support for the use of our proposed algorithm whenever low-rank approximation is being considered . Our algorithm efficiently and accurately estimates matrix coherence across a wide range of datasets , and these coherence estimates are excellent predictors of the effectiveness of sampling-based matrix approximation on a case-by-case basis .
The $k$-NN graph has played a central role in increasingly popular data-driven techniques for various learning and vision tasks ; yet , finding an efficient and effective way to construct $k$-NN graphs remains a challenge , especially for large-scale high-dimensional data . In this paper , we propose a new approach to construct approximate $k$-NN graphs with emphasis in : efficiency and accuracy . We hierarchically and randomly divide the data points into subsets and build an exact neighborhood graph over each subset , achieving a base approximate neighborhood graph ; we then repeat this process for several times to generate multiple neighborhood graphs , which are combined to yield a more accurate approximate neighborhood graph . Furthermore , we propose a neighborhood propagation scheme to further enhance the accuracy . We show both theoretical and empirical accuracy and efficiency of our approach to $k$-NN graph construction and demonstrate significant speed-up in dealing with large scale visual data .
In this paper we consider the problem of semi-supervised learning with deep Convolutional Neural Networks ( ConvNets ) . Semi-supervised learning is motivated on the observation that unlabeled data is cheap and can be used to improve the accuracy of classifiers . In this paper we propose an unsupervised regularization term that explicitly forces the classifier ' s prediction for multiple classes to be mutually-exclusive and effectively guides the decision boundary to lie on the low density space between the manifolds corresponding to different classes of data . Our proposed approach is general and can be used with any backpropagation-based learning method . We show through different experiments that our method can improve the object recognition performance of ConvNets using unlabeled data .
A crucial task in system identification problems is the selection of the most appropriate model class , and is classically addressed resorting to cross-validation or using asymptotic arguments . As recently suggested in the literature , this can be addressed in a Bayesian framework , where model complexity is regulated by few hyperparameters , which can be estimated via marginal likelihood maximization . It is thus of primary importance to design effective optimization methods to solve the corresponding optimization problem . If the unknown impulse response is modeled as a Gaussian process with a suitable kernel , the maximization of the marginal likelihood leads to a challenging nonconvex optimization problem , which requires a stable and effective solution strategy . In this paper we address this problem by means of a scaled gradient projection algorithm , in which the scaling matrix and the steplength parameter play a crucial role to provide a meaning solution in a computational time comparable with second order methods . In particular , we propose both a generalization of the split gradient approach to design the scaling matrix in the presence of box constraints , and an effective implementation of the gradient and objective function . The extensive numerical experiments carried out on several test problems show that our method is very effective in providing in few tenths of a second solutions of the problems with accuracy comparable with state-of-the-art approaches . Moreover , the flexibility of the proposed strategy makes it easily adaptable to a wider range of problems arising in different areas of machine learning , signal processing and system identification .
We introduce a nonlinear aggregation type classifier for functional data defined on a separable and complete metric space . The new rule is built up from a collection of $M$ arbitrary training classifiers . If the classifiers are consistent , then so is the aggregation rule . Moreover , asymptotically the aggregation rule behaves as well as the best of the $M$ classifiers . The results of a small simulation are reported both , for high dimensional and functional data , and a real data example is analyzed .
Feature learning forms the cornerstone for tackling challenging learning problems in domains such as speech , computer vision and natural language processing . In this paper , we consider a novel class of matrix and tensor-valued features , which can be pre-trained using unlabeled samples . We present efficient algorithms for extracting discriminative information , given these pre-trained features and labeled samples for any related task . Our class of features are based on higher-order score functions , which capture local variations in the probability density function of the input . We establish a theoretical framework to characterize the nature of discriminative information that can be extracted from score-function features , when used in conjunction with labeled samples . We employ efficient spectral decomposition algorithms ( on matrices and tensors ) for extracting discriminative components . The advantage of employing tensor-valued features is that we can extract richer discriminative information in the form of an overcomplete representations . Thus , we present a novel framework for employing generative models of the input for discriminative learning .
We address the problem of setting the kernel bandwidth used by Manifold Learning algorithms to construct the graph Laplacian . Exploiting the connection between manifold geometry , represented by the Riemannian metric , and the Laplace-Beltrami operator , we set the bandwidth by optimizing the Laplacian ' s ability to preserve the geometry of the data . Experiments show that this principled approach is effective and robust .
We introduce dropout compaction , a novel method for training feed-forward neural networks which realizes the performance gains of training a large model with dropout regularization , yet extracts a compact neural network for run-time efficiency . In the proposed method , we introduce a sparsity-inducing prior on the per unit dropout retention probability so that the optimizer can effectively prune hidden units during training . By changing the prior hyperparameters , we can control the size of the resulting network . We performed a systematic comparison of dropout compaction and competing methods on several real-world speech recognition tasks and found that dropout compaction achieved comparable accuracy with fewer than 00% of the hidden units , translating to a 0 . 0x speedup in run-time .
Several numerical approximation strategies for the expectation-propagation algorithm are studied in the context of large-scale learning : the Laplace method , a faster variant of it , Gaussian quadrature , and a deterministic version of variational sampling ( i . e . , combining quadrature with variational approximation ) . Experiments in training linear binary classifiers show that the expectation-propagation algorithm converges best using variational sampling , while it also converges well using Laplace-style methods with smooth factors but tends to be unstable with non-differentiable ones . Gaussian quadrature yields unstable behavior or convergence to a sub-optimal solution in most experiments .
With recent advances in high throughput technology , researchers often find themselves running a large number of hypothesis tests ( thousands+ ) and esti- mating a large number of effect-sizes . Generally there is particular interest in those effects estimated to be most extreme . Unfortunately naive estimates of these effect-sizes ( even after potentially accounting for multiplicity in a testing procedure ) can be severely biased . In this manuscript we explore this bias from a frequentist perspective : we give a formal definition , and show that an oracle estimator using this bias dominates the naive maximum likelihood estimate . We give a resampling estimator to approximate this oracle , and show that it works well on simulated data . We also connect this to ideas in empirical Bayes .
Named-entity recognition ( NER ) aims at identifying entities of interest in a text . Artificial neural networks ( ANNs ) have recently been shown to outperform existing NER systems . However , ANNs remain challenging to use for non-expert users . In this paper , we present NeuroNER , an easy-to-use named-entity recognition tool based on ANNs . Users can annotate entities using a graphical web-based user interface ( BRAT ) : the annotations are then used to train an ANN , which in turn predict entities ' locations and categories in new texts . NeuroNER makes this annotation-training-prediction flow smooth and accessible to anyone .
We study two procedures ( reverse-mode and forward-mode ) for computing the gradient of the validation error with respect to the hyperparameters of any iterative learning algorithm such as stochastic gradient descent . These procedures mirror two methods of computing gradients for recurrent neural networks and have different trade-offs in terms of running time and space requirements . Our formulation of the reverse-mode procedure is linked to previous work by Maclaurin et al . [0000] but does not require reversible dynamics . The forward-mode procedure is suitable for real-time hyperparameter updates , which may significantly speed up hyperparameter optimization on large datasets . We present experiments on data cleaning and on learning task interactions . We also present one large-scale experiment where the use of previous gradient-based methods would be prohibitive .
We describe and analyze some novel approaches for studying the dynamics of Ising spin glass models . We first briefly consider the variational approach based on minimizing the Kullback-Leibler divergence between independent trajectories and the real ones and note that this approach only coincides with the mean field equations from the saddle point approximation to the generating functional when the dynamics is defined through a logistic link function , which is the case for the kinetic Ising model with parallel update . We then spend the rest of the paper developing two ways of going beyond the saddle point approximation to the generating functional . In the first one , we develop a variational perturbative approximation to the generating functional by expanding the action around a quadratic function of the local fields and conjugate local fields whose parameters are optimized . We derive analytical expressions for the optimal parameters and show that when the optimization is suitably restricted , we recover the mean field equations that are exact for the fully asymmetric random couplings ( M\ ' ezard and Sakellariou , 0000 ) . However , without this restriction the results are different . We also describe an extended Plefka expansion in which in addition to the magnetization , we also fix the correlation and response functions . Finally , we numerically study the performance of these approximations for Sherrington-Kirkpatrick type couplings for various coupling strengths , degrees of coupling symmetry and external fields . We show that the dynamical equations derived from the extended Plefka expansion outperform the others in all regimes , although it is computationally more demanding . The unconstrained variational approach does not perform well in the small coupling regime , while it approaches dynamical TAP equations of ( Roudi and Hertz , 0000 ) for strong couplings .
We address the cold start problem in recommendation systems assuming no contextual information is available neither about users , nor items . We consider the case in which we only have access to a set of ratings of items by users . Most of the existing works consider a batch setting , and use cross-validation to tune parameters . The classical method consists in minimizing the root mean square error over a training subset of the ratings which provides a factorization of the matrix of ratings , interpreted as a latent representation of items and users . Our contribution in this paper is 0-fold . First , we explicit the issues raised by this kind of batch setting for users or items with very few ratings . Then , we propose an online setting closer to the actual use of recommender systems ; this setting is inspired by the bandit framework . The proposed methodology can be used to turn any recommender system dataset ( such as Netflix , MovieLens , . . . ) into a sequential dataset . Then , we explicit a strong and insightful link between contextual bandit algorithms and matrix factorization ; this leads us to a new algorithm that tackles the exploration/exploitation dilemma associated to the cold start problem in a strikingly new perspective . Finally , experimental evidence confirm that our algorithm is effective in dealing with the cold start problem on publicly available datasets . Overall , the goal of this paper is to bridge the gap between recommender systems based on matrix factorizations and those based on contextual bandits .
In this paper , we propose a theory which unifies kernel learning and symbolic algebraic methods . We show that both worlds are inherently dual to each other , and we use this duality to combine the structure-awareness of algebraic methods with the efficiency and generality of kernels . The main idea lies in relating polynomial rings to feature space , and ideals to manifolds , then exploiting this generative-discriminative duality on kernel matrices . We illustrate this by proposing two algorithms , IPCA and AVICA , for simultaneous manifold and feature learning , and test their accuracy on synthetic and real world data .
Understanding how species are distributed across landscapes over time is a fundamental question in biodiversity research . Unfortunately , most species distribution models only target a single species at a time , despite strong ecological evidence that species are not independently distributed . We propose Deep Multi-Species Embedding ( DMSE ) , which jointly embeds vectors corresponding to multiple species as well as vectors representing environmental covariates into a common high-dimensional feature space via a deep neural network . Applied to bird observational data from the citizen science project \textit{eBird} , we demonstrate how the DMSE model discovers inter-species relationships to outperform single-species distribution models ( random forests and SVMs ) as well as competing multi-label models . Additionally , we demonstrate the benefit of using a deep neural network to extract features within the embedding and show how they improve the predictive performance of species distribution modelling . An important domain contribution of the DMSE model is the ability to discover and describe species interactions while simultaneously learning the shared habitat preferences among species . As an additional contribution , we provide a graphical embedding of hundreds of bird species in the Northeast US .
Computing the medoid of a large number of points in high-dimensional space is an increasingly common operation in many data science problems . We present an algorithm Med-dit which uses O ( n log n ) distance evaluations to compute the medoid with high probability . Med-dit is based on a connection with the multi-armed bandit problem . We evaluate the performance of Med-dit empirically on the Netflix-prize and the single-cell RNA-Seq datasets , containing hundreds of thousands of points living in tens of thousands of dimensions , and observe a 0-00x improvement in performance over the current state of the art . Med-dit is available at https : //github . com/bagavi/Meddit
We present differentially private algorithms for the stochastic Multi-Armed Bandit ( MAB ) problem . This is a problem for applications such as adaptive clinical trials , experiment design , and user-targeted advertising where private information is connected to individual rewards . Our major contribution is to show that there exist $ ( \epsilon , \delta ) $ differentially private variants of Upper Confidence Bound algorithms which have optimal regret , $O ( \epsilon^{-0} + \log T ) $ . This is a significant improvement over previous results , which only achieve poly-log regret $O ( \epsilon^{-0} \log^{0} T ) $ , because of our use of a novel interval-based mechanism . We also substantially improve the bounds of previous family of algorithms which use a continual release mechanism . Experiments clearly validate our theoretical bounds .
We study the density estimation problem with observations generated by certain dynamical systems that admit a unique underlying invariant Lebesgue density . Observations drawn from dynamical systems are not independent and moreover , usual mixing concepts may not be appropriate for measuring the dependence among these observations . By employing the $\mathcal{C}$-mixing concept to measure the dependence , we conduct statistical analysis on the consistency and convergence of the kernel density estimator . Our main results are as follows : First , we show that with properly chosen bandwidth , the kernel density estimator is universally consistent under $L_0$-norm ; Second , we establish convergence rates for the estimator with respect to several classes of dynamical systems under $L_0$-norm . In the analysis , the density function $f$ is only assumed to be H\ " {o}lder continuous which is a weak assumption in the literature of nonparametric density estimation and also more realistic in the dynamical system context . Last but not least , we prove that the same convergence rates of the estimator under $L_\infty$-norm and $L_0$-norm can be achieved when the density function is H\ " {o}lder continuous , compactly supported and bounded . The bandwidth selection problem of the kernel density estimator for dynamical system is also discussed in our study via numerical simulations .
Part-of-speech ( POS ) tagging is a fundamental component for performing natural language tasks such as parsing , information extraction , and question answering . When POS taggers are trained in one domain and applied in significantly different domains , their performance can degrade dramatically . We present a methodology for rapid adaptation of POS taggers to new domains . Our technique is unsupervised in that a manually annotated corpus for the new domain is not necessary . We use suffix information gathered from large amounts of raw text as well as orthographic information to increase the lexical coverage . We present an experiment in the Biological domain where our POS tagger achieves results comparable to POS taggers specifically trained to this domain .
In high dimensional regression settings , sparsity enforcing penalties have proved useful to regularize the data-fitting term . A recently introduced technique called screening rules propose to ignore some variables in the optimization leveraging the expected sparsity of the solutions and consequently leading to faster solvers . When the procedure is guaranteed not to discard variables wrongly the rules are said to be safe . In this work , we propose a unifying framework for generalized linear models regularized with standard sparsity enforcing penalties such as $\ell_0$ or $\ell_0/\ell_0$ norms . Our technique allows to discard safely more variables than previously considered safe rules , particularly for low regularization parameters . Our proposed Gap Safe rules ( so called because they rely on duality gap computation ) can cope with any iterative solver but are particularly well suited to ( block ) coordinate descent methods . Applied to many standard learning tasks , Lasso , Sparse-Group Lasso , multi-task Lasso , binary and multinomial logistic regression , etc . , we report significant speed-ups compared to previously proposed safe rules on all tested data sets .
Active search ( AS ) on graphs focuses on collecting certain labeled nodes ( targets ) given global knowledge of the network topology and its edge weights under a query budget . However , in most networks , nodes , topology and edge weights are all initially unknown . We introduce selective harvesting , a variant of AS where the next node to be queried must be chosen among the neighbors of the current queried node set ; the available training data for deciding which node to query is restricted to the subgraph induced by the queried set ( and their node attributes ) and their neighbors ( without any node or edge attributes ) . Therefore , selective harvesting is a sequential decision problem , where we must decide which node to query at each step . A classifier trained in this scenario suffers from a tunnel vision effect : without recourse to independent sampling , the urge to query promising nodes forces classifiers to gather increasingly biased training data , which we show significantly hurts the performance of AS methods and standard classifiers . We find that it is possible to collect a much larger set of targets by using multiple classifiers , not by combining their predictions as an ensemble , but switching between classifiers used at each step , as a way to ease the tunnel vision effect . We discover that switching classifiers collects more targets by ( a ) diversifying the training data and ( b ) broadening the choices of nodes that can be queried next . This highlights an exploration , exploitation , and diversification trade-off in our problem that goes beyond the exploration and exploitation duality found in classic sequential decision problems . From these observations we propose D0TS , a method based on multi-armed bandits for non-stationary stochastic processes that enforces classifier diversity , matching or exceeding the performance of competing methods on seven real network datasets in our evaluation .
If we pick $n$ random points uniformly in $[0 , 0]^d$ and connect each point to its $k-$nearest neighbors , then it is well known that there exists a giant connected component with high probability . We prove that in $[0 , 0]^d$ it suffices to connect every point to $ c_{d , 0} \log{\log{n}}$ points chosen randomly among its $ c_{d , 0} \log{n}-$nearest neighbors to ensure a giant component of size $n - o ( n ) $ with high probability . This construction yields a much sparser random graph with $\sim n \log\log{n}$ instead of $\sim n \log{n}$ edges that has comparable connectivity properties . This result has nontrivial implications for problems in data science where an affinity matrix is constructed : instead of picking the $k-$nearest neighbors , one can often pick $k ' \ll k$ random points out of the $k-$nearest neighbors without sacrificing efficiency . This can massively simplify and accelerate computation , we illustrate this with several numerical examples .
We present a hybrid algorithm for Bayesian topic models that combines the efficiency of sparse Gibbs sampling with the scalability of online stochastic inference . We used our algorithm to analyze a corpus of 0 . 0 million books ( 00 billion words ) with thousands of topics . Our approach reduces the bias of variational inference and generalizes to many Bayesian hidden-variable models .
We present a principled approach for detecting overlapping temporal community structure in dynamic networks . Our method is based on the following framework : find the overlapping temporal community structure that maximizes a quality function associated with each snapshot of the network subject to a temporal smoothness constraint . A novel quality function and a smoothness constraint are proposed to handle overlaps , and a new convex relaxation is used to solve the resulting combinatorial optimization problem . We provide theoretical guarantees as well as experimental results that reveal community structure in real and synthetic networks . Our main insight is that certain structures can be identified only when temporal correlation is considered and when communities are allowed to overlap . In general , discovering such overlapping temporal community structure can enhance our understanding of real-world complex networks by revealing the underlying stability behind their seemingly chaotic evolution .
In data science , it is often required to estimate dependencies between different data sources . These dependencies are typically calculated using Pearson ' s correlation , distance correlation , and/or mutual information . However , none of these measures satisfy all the Granger ' s axioms for an " ideal measure " . One such ideal measure , proposed by Granger himself , calculates the Bhattacharyya distance between the joint probability density function ( pdf ) and the product of marginal pdfs . We call this measure the mutual dependence . However , to date this measure has not been directly computable from data . In this paper , we use our recently introduced maximum likelihood non-parametric estimator for band-limited pdfs , to compute the mutual dependence directly from the data . We construct the estimator of mutual dependence and compare its performance to standard measures ( Pearson ' s and distance correlation ) for different known pdfs by computing convergence rates , computational complexity , and the ability to capture nonlinear dependencies . Our mutual dependence estimator requires fewer samples to converge to theoretical values , is faster to compute , and captures more complex dependencies than standard measures .
A low-rank transformation learning framework for subspace clustering and classification is here proposed . Many high-dimensional data , such as face images and motion sequences , approximately lie in a union of low-dimensional subspaces . The corresponding subspace clustering problem has been extensively studied in the literature to partition such high-dimensional data into clusters corresponding to their underlying low-dimensional subspaces . However , low-dimensional intrinsic structures are often violated for real-world observations , as they can be corrupted by errors or deviate from ideal models . We propose to address this by learning a linear transformation on subspaces using matrix rank , via its convex surrogate nuclear norm , as the optimization criteria . The learned linear transformation restores a low-rank structure for data from the same subspace , and , at the same time , forces a a maximally separated structure for data from different subspaces . In this way , we reduce variations within subspaces , and increase separation between subspaces for a more robust subspace clustering . This proposed learned robust subspace clustering framework significantly enhances the performance of existing subspace clustering methods . Basic theoretical results here presented help to further support the underlying framework . To exploit the low-rank structures of the transformed subspaces , we further introduce a fast subspace clustering technique , which efficiently combines robust PCA with sparse modeling . When class labels are present at the training stage , we show this low-rank transformation framework also significantly enhances classification performance . Extensive experiments using public datasets are presented , showing that the proposed approach significantly outperforms state-of-the-art methods for subspace clustering and classification .
We study dual volume sampling , a method for selecting k columns from an n x m short and wide matrix ( n <= k <= m ) such that the probability of selection is proportional to the volume spanned by the rows of the induced submatrix . This method was proposed by Avron and Boutsidis ( 0000 ) , who showed it to be a promising method for column subset selection and its multiple applications . However , its wider adoption has been hampered by the lack of polynomial time sampling algorithms . We remove this hindrance by developing an exact ( randomized ) polynomial time sampling algorithm as well as its derandomization . Thereafter , we study dual volume sampling via the theory of real stable polynomials and prove that its distribution satisfies the " Strong Rayleigh " property . This result has numerous consequences , including a provably fast-mixing Markov chain sampler that makes dual volume sampling much more attractive to practitioners . This sampler is closely related to classical algorithms for popular experimental design methods that are to date lacking theoretical analysis but are known to empirically work well .
We present a framework for clustering with cluster-specific feature selection . The framework , CRAFT , is derived from asymptotic log posterior formulations of nonparametric MAP-based clustering models . CRAFT handles assorted data , i . e . , both numeric and categorical data , and the underlying objective functions are intuitively appealing . The resulting algorithm is simple to implement and scales nicely , requires minimal parameter tuning , obviates the need to specify the number of clusters a priori , and compares favorably with other methods on real datasets .
The estimation of normalizing constants is a fundamental step in probabilistic model comparison . Sequential Monte Carlo methods may be used for this task and have the advantage of being inherently parallelizable . However , the standard choice of using a fixed number of particles at each iteration is suboptimal because some steps will contribute disproportionately to the variance of the estimate . We introduce an adaptive version of the Resample-Move algorithm , in which the particle set is adaptively expanded whenever a better approximation of an intermediate distribution is needed . The algorithm builds on the expression for the optimal number of particles and the corresponding minimum variance found under ideal conditions . Benchmark results on challenging Gaussian Process Classification and Restricted Boltzmann Machine applications show that Adaptive Resample-Move ( ARM ) estimates the normalizing constant with a smaller variance , using less computational resources , than either Resample-Move with a fixed number of particles or Annealed Importance Sampling . A further advantage over Annealed Importance Sampling is that ARM is easier to tune .
We consider the problem of learning in single-player and multiplayer multiarmed bandit models . Bandit problems are classes of online learning problems that capture exploration versus exploitation tradeoffs . In a multiarmed bandit model , players can pick among many arms , and each play of an arm generates an i . i . d . reward from an unknown distribution . The objective is to design a policy that maximizes the expected reward over a time horizon for a single player setting and the sum of expected rewards for the multiplayer setting . In the multiplayer setting , arms may give different rewards to different players . There is no separate channel for coordination among the players . Any attempt at communication is costly and adds to regret . We propose two decentralizable policies , $\tt E^0$ ( $\tt E$-$\tt cubed$ ) and $\tt E^0$-$\tt TS$ , that can be used in both single player and multiplayer settings . These policies are shown to yield expected regret that grows at most as O ( $\log^{0+\epsilon} T$ ) . It is well known that $\log T$ is the lower bound on the rate of growth of regret even in a centralized case . The proposed algorithms improve on prior work where regret grew at O ( $\log^0 T$ ) . More fundamentally , these policies address the question of additional cost incurred in decentralized online learning , suggesting that there is at most an $\epsilon$-factor cost in terms of order of regret . This solves a problem of relevance in many domains and had been open for a while .
It is challenging to handle a large volume of labels in multi-label learning . However , existing approaches explicitly or implicitly assume that all the labels in the learning process are given , which could be easily violated in changing environments . In this paper , we define and study streaming label learning ( SLL ) , i . e . , labels are arrived on the fly , to model newly arrived labels with the help of the knowledge learned from past labels . The core of SLL is to explore and exploit the relationships between new labels and past labels and then inherit the relationship into hypotheses of labels to boost the performance of new classifiers . In specific , we use the label self-representation to model the label relationship , and SLL will be divided into two steps : a regression problem and a empirical risk minimization ( ERM ) problem . Both problems are simple and can be efficiently solved . We further show that SLL can generate a tighter generalization error bound for new labels than the general ERM framework with trace norm or Frobenius norm regularization . Finally , we implement extensive experiments on various benchmark datasets to validate the new setting . And results show that SLL can effectively handle the constantly emerging new labels and provides excellent classification performance .
This research explores the effects of various training settings on a Polish to English Statistical Machine Translation system for spoken language . Various elements of the TED , Europarl , and OPUS parallel text corpora were used as the basis for training of language models , for development , tuning and testing of the translation system . The BLEU , NIST , METEOR and TER metrics were used to evaluate the effects of the data preparations on the translation results .
Models of complex systems are often formalized as sequential software simulators : computationally intensive programs that iteratively build up probable system configurations given parameters and initial conditions . These simulators enable modelers to capture effects that are difficult to characterize analytically or summarize statistically . However , in many real-world applications , these simulations need to be inverted to match the observed data . This typically requires the custom design , derivation and implementation of sophisticated inversion algorithms . Here we give a framework for inverting a broad class of complex software simulators via probabilistic programming and automatic inference , using under 00 lines of probabilistic code . Our approach is based on a formulation of inversion as approximate inference in a simple sequential probabilistic model . We implement four inference strategies , including Metropolis-Hastings , a sequentialized Metropolis-Hastings scheme , and a particle Markov chain Monte Carlo scheme , requiring 0 or fewer lines of probabilistic code each . We demonstrate our framework by applying it to invert a real geological software simulator from the oil and gas industry .
We describe a general framework --compressive statistical learning-- for resource-efficient large-scale learning : the training collection is compressed in one pass into a low-dimensional sketch ( a vector of random empirical generalized moments ) that captures the information relevant to the considered learning task . A near-minimizer of the risk is computed from the sketch through the solution of a nonlinear least squares problem . We investigate sufficient sketch sizes to control the generalization error of this procedure . The framework is illustrated on compressive clustering , compressive Gaussian mixture Modeling with fixed known variance , and compressive PCA .
Given a large data matrix $A\in\mathbb{R}^{n\times n}$ , we consider the problem of determining whether its entries are i . i . d . with some known marginal distribution $A_{ij}\sim P_0$ , or instead $A$ contains a principal submatrix $A_{{\sf Q} , {\sf Q}}$ whose entries have marginal distribution $A_{ij}\sim P_0\neq P_0$ . As a special case , the hidden ( or planted ) clique problem requires to find a planted clique in an otherwise uniformly random graph . Assuming unbounded computational resources , this hypothesis testing problem is statistically solvable provided $|{\sf Q}|\ge C \log n$ for a suitable constant $C$ . However , despite substantial effort , no polynomial time algorithm is known that succeeds with high probability when $|{\sf Q}| = o ( \sqrt{n} ) $ . Recently Meka and Wigderson \cite{meka0000association} , proposed a method to establish lower bounds within the Sum of Squares ( SOS ) semidefinite hierarchy . Here we consider the degree-$0$ SOS relaxation , and study the construction of \cite{meka0000association} to prove that SOS fails unless $k\ge C\ , n^{0/0}/\log n$ . An argument presented by Barak implies that this lower bound cannot be substantially improved unless the witness construction is changed in the proof . Our proof uses the moments method to bound the spectrum of a certain random association scheme , i . e . a symmetric random matrix whose rows and columns are indexed by the edges of an Erd\ " os-Renyi random graph .
We propose a general framework for studying adaptive regret bounds in the online learning framework , including model selection bounds and data-dependent bounds . Given a data- or model-dependent bound we ask , " Does there exist some algorithm achieving this bound ? " We show that modifications to recently introduced sequential complexity measures can be used to answer this question by providing sufficient conditions under which adaptive rates can be achieved . In particular each adaptive rate induces a set of so-called offset complexity measures , and obtaining small upper bounds on these quantities is sufficient to demonstrate achievability . A cornerstone of our analysis technique is the use of one-sided tail inequalities to bound suprema of offset random processes . Our framework recovers and improves a wide variety of adaptive bounds including quantile bounds , second-order data-dependent bounds , and small loss bounds . In addition we derive a new type of adaptive bound for online linear optimization based on the spectral norm , as well as a new online PAC-Bayes theorem that holds for countably infinite sets .
Kernel methods provide a principled way to perform non linear , nonparametric learning . They rely on solid functional analytic foundations and enjoy optimal statistical properties . However , at least in their basic form , they have limited applicability in large scale scenarios because of stringent computational requirements in terms of time and especially memory . In this paper , we take a substantial step in scaling up kernel methods , proposing FALKON , a novel algorithm that allows to efficiently process millions of points . FALKON is derived combining several algorithmic principles , namely stochastic subsampling , iterative solvers and preconditioning . Our theoretical analysis shows that optimal statistical accuracy is achieved requiring essentially $O ( n ) $ memory and $O ( n\sqrt{n} ) $ time . An extensive experimental analysis on large scale datasets shows that , even with a single machine , FALKON outperforms previous state of the art solutions , which exploit parallel/distributed architectures .
While Multiple Instance ( MI ) data are point patterns -- sets or multi-sets of unordered points -- appropriate statistical point pattern models have not been used in MI learning . This article proposes a framework for model-based MI learning using point process theory . Likelihood functions for point pattern data derived from point process theory enable principled yet conceptually transparent extensions of learning tasks , such as classification , novelty detection and clustering , to point pattern data . Furthermore , tractable point pattern models as well as solutions for learning and decision making from point pattern data are developed .
Epileptic seizure activity shows complicated dynamics in both space and time . To understand the evolution and propagation of seizures spatially extended sets of data need to be analysed . We have previously described an efficient filtering scheme using variational Laplace that can be used in the Dynamic Causal Modelling ( DCM ) framework [Friston , 0000] to estimate the temporal dynamics of seizures recorded using either invasive or non-invasive electrical recordings ( EEG/ECoG ) . Spatiotemporal dynamics are modelled using a partial differential equation -- in contrast to the ordinary differential equation used in our previous work on temporal estimation of seizure dynamics [Cooray , 0000] . We provide the requisite theoretical background for the method and test the ensuing scheme on simulated seizure activity data and empirical invasive ECoG data . The method provides a framework to assimilate the spatial and temporal dynamics of seizure activity , an aspect of great physiological and clinical importance .
The principal submatrix localization problem deals with recovering a $K\times K$ principal submatrix of elevated mean $\mu$ in a large $n\times n$ symmetric matrix subject to additive standard Gaussian noise . This problem serves as a prototypical example for community detection , in which the community corresponds to the support of the submatrix . The main result of this paper is that in the regime $\Omega ( \sqrt{n} ) \leq K \leq o ( n ) $ , the support of the submatrix can be weakly recovered ( with $o ( K ) $ misclassification errors on average ) by an optimized message passing algorithm if $\lambda = \mu^0K^0/n$ , the signal-to-noise ratio , exceeds $0/e$ . This extends a result by Deshpande and Montanari previously obtained for $K=\Theta ( \sqrt{n} ) . $ In addition , the algorithm can be extended to provide exact recovery whenever information-theoretically possible and achieve the information limit of exact recovery as long as $K \geq \frac{n}{\log n} ( \frac{0}{0e} + o ( 0 ) ) $ . The total running time of the algorithm is $O ( n^0\log n ) $ . Another version of the submatrix localization problem , known as noisy biclustering , aims to recover a $K_0\times K_0$ submatrix of elevated mean $\mu$ in a large $n_0\times n_0$ Gaussian matrix . The optimized message passing algorithm and its analysis are adapted to the bicluster problem assuming $\Omega ( \sqrt{n_i} ) \leq K_i \leq o ( n_i ) $ and $K_0\asymp K_0 . $ A sharp information-theoretic condition for the weak recovery of both clusters is also identified .
Convex clustering , a convex relaxation of k-means clustering and hierarchical clustering , has drawn recent attentions since it nicely addresses the instability issue of traditional nonconvex clustering methods . Although its computational and statistical properties have been recently studied , the performance of convex clustering has not yet been investigated in the high-dimensional clustering scenario , where the data contains a large number of features and many of them carry no information about the clustering structure . In this paper , we demonstrate that the performance of convex clustering could be distorted when the uninformative features are included in the clustering . To overcome it , we introduce a new clustering method , referred to as Sparse Convex Clustering , to simultaneously cluster observations and conduct feature selection . The key idea is to formulate convex clustering in a form of regularization , with an adaptive group-lasso penalty term on cluster centers . In order to optimally balance the tradeoff between the cluster fitting and sparsity , a tuning criterion based on clustering stability is developed . In theory , we provide an unbiased estimator for the degrees of freedom of the proposed sparse convex clustering method . Finally , the effectiveness of the sparse convex clustering is examined through a variety of numerical experiments and a real data application .
The paper proposes a novel upper confidence bound ( UCB ) procedure for identifying the arm with the largest mean in a multi-armed bandit game in the fixed confidence setting using a small number of total samples . The procedure cannot be improved in the sense that the number of samples required to identify the best arm is within a constant factor of a lower bound based on the law of the iterated logarithm ( LIL ) . Inspired by the LIL , we construct our confidence bounds to explicitly account for the infinite time horizon of the algorithm . In addition , by using a novel stopping time for the algorithm we avoid a union bound over the arms that has been observed in other UCB-type algorithms . We prove that the algorithm is optimal up to constants and also show through simulations that it provides superior performance with respect to the state-of-the-art .
We present a method based on the orthogonal symmetric non-negative matrix tri-factorization of the normalized Laplacian matrix for community detection in complex networks . While the exact factorization of a given order may not exist and is NP hard to compute , we obtain an approximate factorization by solving an optimization problem . We establish the connection of the factors obtained through the factorization to a non-negative basis of an invariant subspace of the estimated matrix , drawing parallel with the spectral clustering . Using such factorization for clustering in networks is motivated by analyzing a block-diagonal Laplacian matrix with the blocks representing the connected components of a graph . The method is shown to be consistent for community detection in graphs generated from the stochastic block model and the degree corrected stochastic block model . Simulation results and real data analysis show the effectiveness of these methods under a wide variety of situations , including sparse and highly heterogeneous graphs where the usual spectral clustering is known to fail . Our method also performs better than the state of the art in popular benchmark network datasets , e . g . , the political web blogs and the karate club data .
A serious problem in learning probabilistic models is the presence of hidden variables . These variables are not observed , yet interact with several of the observed variables . Detecting hidden variables poses two problems : determining the relations to other variables in the model and determining the number of states of the hidden variable . In this paper , we address the latter problem in the context of Bayesian networks . We describe an approach that utilizes a score-based agglomerative state-clustering . As we show , this approach allows us to efficiently evaluate models with a range of cardinalities for the hidden variable . We show how to extend this procedure to deal with multiple interacting hidden variables . We demonstrate the effectiveness of this approach by evaluating it on synthetic and real-life data . We show that our approach learns models with hidden variables that generalize better and have better structure than previous approaches .
We provide novel guaranteed approaches for training feedforward neural networks with sparse connectivity . We leverage on the techniques developed previously for learning linear networks and show that they can also be effectively adopted to learn non-linear networks . We operate on the moments involving label and the score function of the input , and show that their factorization provably yields the weight matrix of the first layer of a deep network under mild conditions . In practice , the output of our method can be employed as effective initializers for gradient descent .
Statistical performance bounds for reinforcement learning ( RL ) algorithms can be critical for high-stakes applications like healthcare . This paper introduces a new framework for theoretically measuring the performance of such algorithms called Uniform-PAC , which is a strengthening of the classical Probably Approximately Correct ( PAC ) framework . In contrast to the PAC framework , the uniform version may be used to derive high probability regret guarantees and so forms a bridge between the two setups that has been missing in the literature . We demonstrate the benefits of the new framework for finite-state episodic MDPs with a new algorithm that is Uniform-PAC and simultaneously achieves optimal regret and PAC guarantees except for a factor of the horizon .
A single , stationary topic model such as latent Dirichlet allocation is inappropriate for modeling corpora that span long time periods , as the popularity of topics is likely to change over time . A number of models that incorporate time have been proposed , but in general they either exhibit limited forms of temporal variation , or require computationally expensive inference methods . In this paper we propose non-parametric Topics over Time ( npTOT ) , a model for time-varying topics that allows an unbounded number of topics and exible distribution over the temporal variations in those topics ' popularity . We develop a collapsed Gibbs sampler for the proposed model and compare against existing models on synthetic and real document sets .
The ability of learning from noisy labels is very useful in many visual recognition tasks , as a vast amount of data with noisy labels are relatively easy to obtain . Traditionally , the label noises have been treated as statistical outliers , and approaches such as importance re-weighting and bootstrap have been proposed to alleviate the problem . According to our observation , the real-world noisy labels exhibit multi-mode characteristics as the true labels , rather than behaving like independent random outliers . In this work , we propose a unified distillation framework to use side information , including a small clean dataset and label relations in knowledge graph , to " hedge the risk " of learning from noisy labels . Furthermore , unlike the traditional approaches evaluated based on simulated label noises , we propose a suite of new benchmark datasets , in Sports , Species and Artifacts domains , to evaluate the task of learning from noisy labels in the practical setting . The empirical study demonstrates the effectiveness of our proposed method in all the domains .
This paper is about randomized iterative algorithms for solving a linear system of equations $X \beta = y$ in different settings . Recent interest in the topic was reignited when Strohmer and Vershynin ( 0000 ) proved the linear convergence rate of a Randomized Kaczmarz ( RK ) algorithm that works on the rows of $X$ ( data points ) . Following that , Leventhal and Lewis ( 0000 ) proved the linear convergence of a Randomized Coordinate Descent ( RCD ) algorithm that works on the columns of $X$ ( features ) . The aim of this paper is to simplify our understanding of these two algorithms , establish the direct relationships between them ( though RK is often compared to Stochastic Gradient Descent ) , and examine the algorithmic commonalities or tradeoffs involved with working on rows or columns . We also discuss Kernel Ridge Regression and present a Kaczmarz-style algorithm that works on data points and having the advantage of solving the problem without ever storing or forming the Gram matrix , one of the recognized problems encountered when scaling kernelized methods .
Convolutional sparse representations are a form of sparse representation with a structured , translation invariant dictionary . Most convolutional dictionary learning algorithms to date operate in batch mode , requiring simultaneous access to all training images during the learning process , which results in very high memory usage and severely limits the training data that can be used . Very recently , however , a number of authors have considered the design of online convolutional dictionary learning algorithms that offer far better scaling of memory and computational cost with training set size than batch methods . This paper extends our prior work , improving a number of aspects of our previous algorithm ; proposing an entirely new one , with better performance , and that supports the inclusion of a spatial mask for learning from incomplete data ; and providing a rigorous theoretical analysis of these methods .
In this paper , we consider and discuss a new stochastic multi-armed bandit problem called {\em good arm identification} ( GAI ) , where a good arm is an arm with expected reward greater than or equal to a given threshold . GAI is a pure-exploration problem that an agent repeats a process of outputting an arm as soon as it is identified as a good one before confirming the other arms are actually not good . The objective of GAI is to minimize the number of samples for each process . We find that GAI faces a new kind of dilemma , the {\em exploration-exploitation dilemma of confidence} , while best arm identification does not . Therefore , GAI is not just an extension of the best arm identification . Actually , an efficient design of algorithms for GAI is quite different from that for best arm identification . We derive a lower bound on the sample complexity for GAI and develop an algorithm whose sample complexity almost matches the lower bound . We also confirm experimentally that the proposed algorithm outperforms a naive algorithm and a thresholding-bandit-like algorithm in synthetic settings and in settings based on medical data .
A non linear regression approach which consists of a specific regression model incorporating a latent process , allowing various polynomial regression models to be activated preferentially and smoothly , is introduced in this paper . The model parameters are estimated by maximum likelihood performed via a dedicated expecation-maximization ( EM ) algorithm . An experimental study using simulated and real data sets reveals good performances of the proposed approach .
While both cost-sensitive learning and online learning have been studied extensively , the effort in simultaneously dealing with these two issues is limited . Aiming at this challenge task , a novel learning framework is proposed in this paper . The key idea is based on the fusion of online ensemble algorithms and the state of the art batch mode cost-sensitive bagging/boosting algorithms . Within this framework , two separately developed research areas are bridged together , and a batch of theoretically sound online cost-sensitive bagging and online cost-sensitive boosting algorithms are first proposed . Unlike other online cost-sensitive learning algorithms lacking theoretical analysis of asymptotic properties , the convergence of the proposed algorithms is guaranteed under certain conditions , and the experimental evidence with benchmark data sets also validates the effectiveness and efficiency of the proposed methods .
Deep neural networks are commonly developed and trained in 00-bit floating point format . Significant gains in performance and energy efficiency could be realized by training and inference in numerical formats optimized for deep learning . Despite advances in limited precision inference in recent years , training of neural networks in low bit-width remains a challenging problem . Here we present the Flexpoint data format , aiming at a complete replacement of 00-bit floating point format training and inference , designed to support modern deep network topologies without modifications . Flexpoint tensors have a shared exponent that is dynamically adjusted to minimize overflows and maximize available dynamic range . We validate Flexpoint by training AlexNet , a deep residual network and a generative adversarial network , using a simulator implemented with the neon deep learning framework . We demonstrate that 00-bit Flexpoint closely matches 00-bit floating point in training all three models , without any need for tuning of model hyperparameters . Our results suggest Flexpoint as a promising numerical format for future hardware for training and inference .
We propose kernel sequential Monte Carlo ( KSMC ) , a framework for sampling from static target densities . KSMC is a family of sequential Monte Carlo algorithms that are based on building emulator models of the current particle system in a reproducing kernel Hilbert space . We here focus on modelling nonlinear covariance structure and gradients of the target . The emulator ' s geometry is adaptively updated and subsequently used to inform local proposals . Unlike in adaptive Markov chain Monte Carlo , continuous adaptation does not compromise convergence of the sampler . KSMC combines the strengths of sequental Monte Carlo and kernel methods : superior performance for multimodal targets and the ability to estimate model evidence as compared to Markov chain Monte Carlo , and the emulator ' s ability to represent targets that exhibit high degrees of nonlinearity . As KSMC does not require access to target gradients , it is particularly applicable on targets whose gradients are unknown or prohibitively expensive . We describe necessary tuning details and demonstrate the benefits of the the proposed methodology on a series of challenging synthetic and real-world examples .
This paper presents a new approach , called perturb-max , for high-dimensional statistical inference that is based on applying random perturbations followed by optimization . This framework injects randomness to maximum a-posteriori ( MAP ) predictors by randomly perturbing the potential function for the input . A classic result from extreme value statistics asserts that perturb-max operations generate unbiased samples from the Gibbs distribution using high-dimensional perturbations . Unfortunately , the computational cost of generating so many high-dimensional random variables can be prohibitive . However , when the perturbations are of low dimension , sampling the perturb-max prediction is as efficient as MAP optimization . This paper shows that the expected value of perturb-max inference with low dimensional perturbations can be used sequentially to generate unbiased samples from the Gibbs distribution . Furthermore the expected value of the maximal perturbations is a natural bound on the entropy of such perturb-max models . A measure concentration result for perturb-max values shows that the deviation of their sampled average from its expectation decays exponentially in the number of samples , allowing effective approximation of the expectation .
We present two alternative ways to apply PAC-Bayesian analysis to sequences of dependent random variables . The first is based on a new lemma that enables to bound expectations of convex functions of certain dependent random variables by expectations of the same functions of independent Bernoulli random variables . This lemma provides an alternative tool to Hoeffding-Azuma inequality to bound concentration of martingale values . Our second approach is based on integration of Hoeffding-Azuma inequality with PAC-Bayesian analysis . We also introduce a way to apply PAC-Bayesian analysis in situation of limited feedback . We combine the new tools to derive PAC-Bayesian generalization and regret bounds for the multiarmed bandit problem . Although our regret bound is not yet as tight as state-of-the-art regret bounds based on other well-established techniques , our results significantly expand the range of potential applications of PAC-Bayesian analysis and introduce a new analysis tool to reinforcement learning and many other fields , where martingales and limited feedback are encountered .
This paper deals with a new filter algorithm for selecting the smallest subset of features carrying all the information content of a data set ( i . e . for removing redundant features ) . It is an advanced version of the fractal dimension reduction technique , and it relies on the recently introduced Morisita estimator of Intrinsic Dimension ( ID ) . Here , the ID is used to quantify dependencies between subsets of features , which allows the effective processing of highly non-linear data . The proposed algorithm is successfully tested on simulated and real world case studies . Different levels of sample size and noise are examined along with the variability of the results . In addition , a comprehensive procedure based on random forests shows that the data dimensionality is significantly reduced by the algorithm without loss of relevant information . And finally , comparisons with benchmark feature selection techniques demonstrate the promising performance of this new filter .
The graphical lasso ( glasso ) is a widely-used fast algorithm for estimating sparse inverse covariance matrices . The glasso solves an L0 penalized maximum likelihood problem and is available as an R library on CRAN . The output from the glasso , a regularized covariance matrix estimate a sparse inverse covariance matrix estimate , not only identify a graphical model but can also serve as intermediate inputs into multivariate procedures such as PCA , LDA , MANOVA , and others . The glasso indeed produces a covariance matrix estimate which solves the L0 penalized optimization problem in a dual sense ; however , the method for producing the inverse covariance matrix estimator after this optimization is inexact and may produce asymmetric estimates . This problem is exacerbated when the amount of L0 regularization that is applied is small , which in turn is more likely to occur if the true underlying inverse covariance matrix is not sparse . The lack of symmetry can potentially have consequences . First , it implies that the covariance and inverse covariance estimates are not numerical inverses of one another , and second , asymmetry can possibly lead to negative or complex eigenvalues , rendering many multivariate procedures which may depend on the inverse covariance estimator unusable . We demonstrate this problem , explain its causes , and propose possible remedies .
Automatic image annotation ( AIA ) raises tremendous challenges to machine learning as it requires modeling of data that are both ambiguous in input and output , e . g . , images containing multiple objects and labeled with multiple semantic tags . Even more challenging is that the number of candidate tags is usually huge ( as large as the vocabulary size ) yet each image is only related to a few of them . This paper presents a hybrid generative-discriminative classifier to simultaneously address the extreme data-ambiguity and overfitting-vulnerability issues in tasks such as AIA . Particularly : ( 0 ) an Exponential-Multinomial Mixture ( EMM ) model is established to capture both the input and output ambiguity and in the meanwhile to encourage prediction sparsity ; and ( 0 ) the prediction ability of the EMM model is explicitly maximized through discriminative learning that integrates variational inference of graphical models and the pairwise formulation of ordinal regression . Experiments show that our approach achieves both superior annotation performance and better tag scalability .
We propose a general modeling and inference framework that composes probabilistic graphical models with deep learning methods and combines their respective strengths . Our model family augments graphical structure in latent variables with neural network observation models . For inference , we extend variational autoencoders to use graphical model approximating distributions with recognition networks that output conjugate potentials . All components of these models are learned simultaneously with a single objective , giving a scalable algorithm that leverages stochastic variational inference , natural gradients , graphical model message passing , and the reparameterization trick . We illustrate this framework with several example models and an application to mouse behavioral phenotyping .
Scene understanding remains a significant challenge in the computer vision community . The visual psychophysics literature has demonstrated the importance of interdependence among parts of the scene . Yet , the majority of methods in computer vision remain local . Pictorial structures have arisen as a fundamental parts-based model for some vision problems , such as articulated object detection . However , the form of classical pictorial structures limits their applicability for global problems , such as semantic pixel labeling . In this paper , we propose an extension of the pictorial structures approach , called pixel-support parts-sparse pictorial structures , or PS0 , to overcome this limitation . Our model extends the classical form in two ways : first , it defines parts directly based on pixel-support rather than in a parametric form , and second , it specifies a space of plausible parts-based scene models and permits one to be used for inference on any given image . PS0 makes strides toward unifying object-level and pixel-level modeling of scene elements . In this report , we implement the first half of our model and rely upon external knowledge to provide an initial graph structure for a given image . Our experimental results on benchmark datasets demonstrate the capability of this new parts-based view of scene modeling .
Variable selection for high-dimensional linear models has received a lot of attention lately , mostly in the context of l0-regularization . Part of the attraction is the variable selection effect : parsimonious models are obtained , which are very suitable for interpretation . In terms of predictive power , however , these regularized linear models are often slightly inferior to machine learning procedures like tree ensembles . Tree ensembles , on the other hand , lack usually a formal way of variable selection and are difficult to visualize . A Garrote-style convex penalty for trees ensembles , in particular Random Forests , is proposed . The penalty selects functional groups of nodes in the trees . These could be as simple as monotone functions of individual predictor variables . This yields a parsimonious function fit , which lends itself easily to visualization and interpretation . The predictive power is maintained at least at the same level as the original tree ensemble . A key feature of the method is that , once a tree ensemble is fitted , no further tuning parameter needs to be selected . The empirical performance is demonstrated on a wide array of datasets .
Recent years have witnessed the rapid development of block coordinate update ( BCU ) methods , which are particularly suitable for problems involving large-sized data and/or variables . In optimization , BCU first appears as the coordinate descent method that works well for smooth problems or those with separable nonsmooth terms and/or separable constraints . As nonseparable constraints exist , BCU can be applied under primal-dual settings . In the literature , it has been shown that for weakly convex problems with nonseparable linear constraint , BCU with fully Gauss-Seidel updating rule may fail to converge and that with fully Jacobian rule can converge sublinearly . However , empirically the method with Jacobian update is usually slower than that with Gauss-Seidel rule . To maintain their advantages , we propose a hybrid Jacobian and Gauss-Seidel BCU method for solving linearly constrained multi-block structured convex programming , where the objective may have a nonseparable quadratic term and separable nonsmooth terms . At each primal block variable update , the method approximates the augmented Lagrangian function at an affine combination of the previous two iterates , and the affinely mixing matrix with desired nice properties can be chosen through solving a semidefinite programming . We show that the hybrid method enjoys the theoretical convergence guarantee as Jacobian BCU . In addition , we numerically demonstrate that the method can perform as well as Gauss-Seidel method and better than a recently proposed randomized primal-dual BCU method .
Feature selection methods are usually evaluated by wrapping specific classifiers and datasets in the evaluation process , resulting very often in unfair comparisons between methods . In this work , we develop a theoretical framework that allows obtaining the true feature ordering of two-dimensional sequential forward feature selection methods based on mutual information , which is independent of entropy or mutual information estimation methods , classifiers , or datasets , and leads to an undoubtful comparison of the methods . Moreover , the theoretical framework unveils problems intrinsic to some methods that are otherwise difficult to detect , namely inconsistencies in the construction of the objective function used to select the candidate features , due to various types of indeterminations and to the possibility of the entropy of continuous random variables taking null and negative values .
In this paper we propose a synergistic melting of neural networks and decision trees ( DT ) we call neural decision trees ( NDT ) . NDT is an architecture a la decision tree where each splitting node is an independent multilayer perceptron allowing oblique decision functions or arbritrary nonlinear decision function if more than one layer is used . This way , each MLP can be seen as a node of the tree . We then show that with the weight sharing asumption among those units , we end up with a Hashing Neural Network ( HNN ) which is a multilayer perceptron with sigmoid activation function for the last layer as opposed to the standard softmax . The output units then jointly represent the probability to be in a particular region . The proposed framework allows for global optimization as opposed to greedy in DT and differentiability w . r . t . all parameters and the input , allowing easy integration in any learnable pipeline , for example after CNNs for computer vision tasks . We also demonstrate the modeling power of HNN allowing to learn union of disjoint regions for final clustering or classification making it more general and powerful than standard softmax MLP requiring linear separability thus reducing the need on the inner layer to perform complex data transformations . We finally show experiments for supervised , semi-suppervised and unsupervised tasks and compare results with standard DTs and MLPs .
We introduce the Variational Holder ( VH ) bound as an alternative to Variational Bayes ( VB ) for approximate Bayesian inference . Unlike VB which typically involves maximization of a non-convex lower bound with respect to the variational parameters , the VH bound involves minimization of a convex upper bound to the intractable integral with respect to the variational parameters . Minimization of the VH bound is a convex optimization problem ; hence the VH method can be applied using off-the-shelf convex optimization algorithms and the approximation error of the VH bound can also be analyzed using tools from convex optimization literature . We present experiments on the task of integrating a truncated multivariate Gaussian distribution and compare our method to VB , EP and a state-of-the-art numerical integration method for this problem .
We investigate the capacity , convexity and characterization of a general family of norm-constrained feed-forward networks .
Over the last years , huge resources of biological and medical data have become available for research . This data offers great chances for machine learning applications in health care , e . g . for precision medicine , but is also challenging to analyze . Typical challenges include a large number of possibly correlated features and heterogeneity in the data . One flourishing field of biological research in which this is relevant is epigenetics . Here , especially large amounts of DNA methylation data have emerged . This epigenetic mark has been used to predict a donor ' s ' epigenetic age ' and increased epigenetic aging has been linked to lifestyle and disease history . In this paper we propose an adaptive model which performs feature selection for each test sample individually based on the distribution of the input data . The method can be seen as partially blind domain adaptation . We apply the model to the problem of age prediction based on DNA methylation data from a variety of tissues , and compare it to a standard model , which does not take heterogeneity into account . The standard approach has particularly bad performance on one tissue type on which we show substantial improvement with our new adaptive approach even though no samples of that tissue were part of the training data .
Neural networks have been successfully applied in applications with a large amount of labeled data . However , the task of rapid generalization on new concepts with small training data while preserving performances on previously learned ones still presents a significant challenge to neural network models . In this work , we introduce a novel meta learning method , Meta Networks ( MetaNet ) , that learns a meta-level knowledge across tasks and shifts its inductive biases via fast parameterization for rapid generalization . When evaluated on Omniglot and Mini-ImageNet benchmarks , our MetaNet models achieve a near human-level performance and outperform the baseline approaches by up to 0% accuracy . We demonstrate several appealing properties of MetaNet relating to generalization and continual learning .
Reinforcement learning is a powerful paradigm for learning optimal policies from experimental data . However , to find optimal policies , most reinforcement learning algorithms explore all possible actions , which may be harmful for real-world systems . As a consequence , learning algorithms are rarely applied on safety-critical systems in the real world . In this paper , we present a learning algorithm that explicitly considers safety , defined in terms of stability guarantees . Specifically , we extend control-theoretic results on Lyapunov stability verification and show how to use statistical models of the dynamics to obtain high-performance control policies with provable stability certificates . Moreover , under additional regularity assumptions in terms of a Gaussian process prior , we prove that one can effectively and safely collect data in order to learn about the dynamics and thus both improve control performance and expand the safe region of the state space . In our experiments , we show how the resulting algorithm can safely optimize a neural network policy on a simulated inverted pendulum , without the pendulum ever falling down .
We present a new model DrNET that learns disentangled image representations from video . Our approach leverages the temporal coherence of video and a novel adversarial loss to learn a representation that factorizes each frame into a stationary part and a temporally varying component . The disentangled representation can be used for a range of tasks . For example , applying a standard LSTM to the time-vary components enables prediction of future frames . We evaluate our approach on a range of synthetic and real videos , demonstrating the ability to coherently generate hundreds of steps into the future .
The scale of functional magnetic resonance image data is rapidly increasing as large multi-subject datasets are becoming widely available and high-resolution scanners are adopted . The inherent low-dimensionality of the information in this data has led neuroscientists to consider factor analysis methods to extract and analyze the underlying brain activity . In this work , we consider two recent multi-subject factor analysis methods : the Shared Response Model and Hierarchical Topographic Factor Analysis . We perform analytical , algorithmic , and code optimization to enable multi-node parallel implementations to scale . Single-node improvements result in 00x and 0000x speedups on these two methods , and enables the processing of larger datasets . Our distributed implementations show strong scaling of 0 . 0x and 0 . 0x respectively with 00 nodes on real datasets . We also demonstrate weak scaling on a synthetic dataset with 0000 subjects , on up to 0000 nodes and 00 , 000 cores .
Perceptrons are neuronal devices capable of fully discriminating linearly separable classes . Although straightforward to implement and train , their applicability is usually hindered by non-trivial requirements imposed by real-world classification problems . Therefore , several approaches , such as kernel perceptrons , have been conceived to counteract such difficulties . In this paper , we investigate an enhanced perceptron model based on the notion of contrastive biclusters . From this perspective , a good discriminative bicluster comprises a subset of data instances belonging to one class that show high coherence across a subset of features and high differentiation from nearest instances of the other class under the same features ( referred to as its contrastive bicluster ) . Upon each local subspace associated with a pair of contrastive biclusters a perceptron is trained and the model with highest area under the receiver operating characteristic curve ( AUC ) value is selected as the final classifier . Experiments conducted on a range of data sets , including those related to a difficult biosignal classification problem , show that the proposed variant can be indeed very useful , prevailing in most of the cases upon standard and kernel perceptrons in terms of accuracy and AUC measures .
We propose Bayesian hypernetworks : a framework for approximate Bayesian inference in neural networks . A Bayesian hypernetwork , $h$ , is a neural network which learns to transform a simple noise distribution , $p ( \epsilon ) = \mathcal{N} ( 0 , I ) $ , to a distribution $q ( \theta ) \doteq q ( h ( \epsilon ) ) $ over the parameters $\theta$ of another neural network ( the " primary network " ) . We train $q$ with variational inference , using an invertible $h$ to enable efficient estimation of the variational lower bound on the posterior $p ( \theta | \mathcal{D} ) $ via sampling . In contrast to most methods for Bayesian deep learning , Bayesian hypernets can represent a complex multimodal approximate posterior with correlations between parameters , while enabling cheap i . i . d . sampling of $q ( \theta ) $ . We demonstrate these qualitative advantages of Bayesian hypernets , which also achieve competitive performance on a suite of tasks that demonstrate the advantage of estimating model uncertainty , including active learning and anomaly detection .
We present a new algorithm , truncated variance reduction ( TruVaR ) , that treats Bayesian optimization ( BO ) and level-set estimation ( LSE ) with Gaussian processes in a unified fashion . The algorithm greedily shrinks a sum of truncated variances within a set of potential maximizers ( BO ) or unclassified points ( LSE ) , which is updated based on confidence bounds . TruVaR is effective in several important settings that are typically non-trivial to incorporate into myopic algorithms , including pointwise costs and heteroscedastic noise . We provide a general theoretical guarantee for TruVaR covering these aspects , and use it to recover and strengthen existing results on BO and LSE . Moreover , we provide a new result for a setting where one can select from a number of noise levels having associated costs . We demonstrate the effectiveness of the algorithm on both synthetic and real-world data sets .
This paper explores and analyzes two randomized designs for robust Principal Component Analysis ( PCA ) employing low-dimensional data sketching . In one design , a data sketch is constructed using random column sampling followed by low dimensional embedding , while in the other , sketching is based on random column and row sampling . Both designs are shown to bring about substantial savings in complexity and memory requirements for robust subspace learning over conventional approaches that use the full scale data . A characterization of the sample and computational complexity of both designs is derived in the context of two distinct outlier models , namely , sparse and independent outlier models . The proposed randomized approach can provably recover the correct subspace with computational and sample complexity that are almost independent of the size of the data . The results of the mathematical analysis are confirmed through numerical simulations using both synthetic and real data .
Greedy optimization methods such as Matching Pursuit ( MP ) and Frank-Wolfe ( FW ) algorithms regained popularity in recent years due to their simplicity , effectiveness and theoretical guarantees . MP and FW address optimization over the linear span and the convex hull of a set of atoms , respectively . In this paper , we consider the intermediate case of optimization over the convex cone , parametrized as the conic hull of a generic atom set , leading to the first principled definitions of non-negative MP algorithms for which we give explicit convergence rates and demonstrate excellent empirical performance . In particular , we derive sublinear ( $\mathcal{O} ( 0/t ) $ ) convergence on general smooth and convex objectives , and linear convergence ( $\mathcal{O} ( e^{-t} ) $ ) on strongly convex objectives , in both cases for general sets of atoms . Furthermore , we establish a clear correspondence of our algorithms to known algorithms from the MP and FW literature . Our novel algorithms and analyses target general atom sets and general objective functions , and hence are directly applicable to a large variety of learning settings .
This note compares two recently published machine learning methods for constructing flexible , but tractable families of variational hidden-variable posteriors . The first method , called " hierarchical variational models " enriches the inference model with an extra variable , while the other , called " auxiliary deep generative models " , enriches the generative model instead . We conclude that the two methods are mathematically equivalent .
The analysis of comorbidity is an open and complex research field in the branch of psychiatry , where clinical experience and several studies suggest that the relation among the psychiatric disorders may have etiological and treatment implications . In this paper , we are interested in applying latent feature modeling to find the latent structure behind the psychiatric disorders that can help to examine and explain the relationships among them . To this end , we use the large amount of information collected in the National Epidemiologic Survey on Alcohol and Related Conditions ( NESARC ) database and propose to model these data using a nonparametric latent model based on the Indian Buffet Process ( IBP ) . Due to the discrete nature of the data , we first need to adapt the observation model for discrete random variables . We propose a generative model in which the observations are drawn from a multinomial-logit distribution given the IBP matrix . The implementation of an efficient Gibbs sampler is accomplished using the Laplace approximation , which allows integrating out the weighting factors of the multinomial-logit likelihood model . We also provide a variational inference algorithm for this model , which provides a complementary ( and less expensive in terms of computational complexity ) alternative to the Gibbs sampler allowing us to deal with a larger number of data . Finally , we use the model to analyze comorbidity among the psychiatric disorders diagnosed by experts from the NESARC database .
In this paper , we formulate the Canonical Correlation Analysis ( CCA ) problem on matrix manifolds . This framework provides a natural way for dealing with matrix constraints and tools for building efficient algorithms even in an adaptive setting . Finally , an adaptive CCA algorithm is proposed and applied to a change detection problem in EEG signals .
High throughput screening of compounds ( chemicals ) is an essential part of drug discovery [0] , involving thousands to millions of compounds , with the purpose of identifying candidate hits . Most statistical tools , including the industry standard B-score method , work on individual compound plates and do not exploit cross-plate correlation or statistical strength among plates . We present a new statistical framework for high throughput screening of compounds based on Bayesian nonparametric modeling . The proposed approach is able to identify candidate hits from multiple plates simultaneously , sharing statistical strength among plates and providing more robust estimates of compound activity . It can flexibly accommodate arbitrary distributions of compound activities and is applicable to any plate geometry . The algorithm provides a principled statistical approach for hit identification and false discovery rate control . Experiments demonstrate significant improvements in hit identification sensitivity and specificity over the B-score method , which is highly sensitive to threshold choice . The framework is implemented as an efficient R extension package BHTSpack and is suitable for large scale data sets .
Integrating wind power into the grid is challenging because of its random nature . Integration is facilitated with accurate short-term forecasts of wind power . The paper presents a spatio-temporal wind speed forecasting algorithm that incorporates the time series data of a target station and data of surrounding stations . Inspired by Compressive Sensing ( CS ) and structured-sparse recovery algorithms , we claim that there usually exists an intrinsic low-dimensional structure governing a large collection of stations that should be exploited . We cast the forecasting problem as recovery of a block-sparse signal $\boldsymbol{x}$ from a set of linear equations $\boldsymbol{b} = A\boldsymbol{x}$ for which we propose novel structure-sparse recovery algorithms . Results of a case study in the east coast show that the proposed Compressive Spatio-Temporal Wind Speed Forecasting ( CST-WSF ) algorithm significantly improves the short-term forecasts compared to a set of widely-used benchmark models .
We describe how cross-kernel matrices , that is , kernel matrices between the data and a custom chosen set of `feature spanning points ' can be used for learning . The main potential of cross-kernels lies in the fact that ( a ) only one side of the matrix scales with the number of data points , and ( b ) cross-kernels , as opposed to the usual kernel matrices , can be used to certify for the data manifold . Our theoretical framework , which is based on a duality involving the feature space and vanishing ideals , indicates that cross-kernels have the potential to be used for any kind of kernel learning . We present a novel algorithm , Ideal PCA ( IPCA ) , which cross-kernelizes PCA . We demonstrate on real and synthetic data that IPCA allows to ( a ) obtain PCA-like features faster and ( b ) to extract novel and empirically validated features certifying for the data manifold .
In this paper we study the covering numbers of the space of convex and uniformly bounded functions in multi-dimension . We find optimal upper and lower bounds for the $\epsilon$-covering number of $\C ( [a , b]^d , B ) $ , in the $L_p$-metric , $0 \le p < \infty$ , in terms of the relevant constants , where $d \geq 0$ , $a < b \in \mathbb{R}$ , $B>0$ , and $\C ( [a , b]^d , B ) $ denotes the set of all convex functions on $[a , b]^d$ that are uniformly bounded by $B$ . We summarize previously known results on covering numbers for convex functions and also provide alternate proofs of some known results . Our results have direct implications in the study of rates of convergence of empirical minimization procedures as well as optimal convergence rates in the numerous convexity constrained function estimation problems .
We consider the problem of reconstructing the graph underlying an Ising model from i . i . d . samples . Over the last fifteen years this problem has been of significant interest in the statistics , machine learning , and statistical physics communities , and much of the effort has been directed towards finding algorithms with low computational cost for various restricted classes of models . Nevertheless , for learning Ising models on general graphs with $p$ nodes of degree at most $d$ , it is not known whether or not it is possible to improve upon the $p^{d}$ computation needed to exhaustively search over all possible neighborhoods for each node . In this paper we show that a simple greedy procedure allows to learn the structure of an Ising model on an arbitrary bounded-degree graph in time on the order of $p^0$ . We make no assumptions on the parameters except what is necessary for identifiability of the model , and in particular the results hold at low-temperatures as well as for highly non-uniform models . The proof rests on a new structural property of Ising models : we show that for any node there exists at least one neighbor with which it has a high mutual information . This structural property may be of independent interest .
This paper focuses on convex constrained optimization problems , where the solution is subject to a convex inequality constraint . In particular , we aim at challenging problems for which both projection into the constrained domain and a linear optimization under the inequality constraint are time-consuming , which render both projected gradient methods and conditional gradient methods ( a . k . a . the Frank-Wolfe algorithm ) expensive . In this paper , we develop projection reduced optimization algorithms for both smooth and non-smooth optimization with improved convergence rates under a certain regularity condition of the constraint function . We first present a general theory of optimization with only one projection . Its application to smooth optimization with only one projection yields $O ( 0/\epsilon ) $ iteration complexity , which improves over the $O ( 0/\epsilon^0 ) $ iteration complexity established before for non-smooth optimization and can be further reduced under strong convexity . Then we introduce a local error bound condition and develop faster algorithms for non-strongly convex optimization at the price of a logarithmic number of projections . In particular , we achieve an iteration complexity of $\widetilde O ( 0/\epsilon^{0 ( 0-\theta ) } ) $ for non-smooth optimization and $\widetilde O ( 0/\epsilon^{0-\theta} ) $ for smooth optimization , where $\theta\in ( 0 , 0]$ appearing the local error bound condition characterizes the functional local growth rate around the optimal solutions . Novel applications in solving the constrained $\ell_0$ minimization problem and a positive semi-definite constrained distance metric learning problem demonstrate that the proposed algorithms achieve significant speed-up compared with previous algorithms .
GPflow is a Gaussian process library that uses TensorFlow for its core computations and Python for its front end . The distinguishing features of GPflow are that it uses variational inference as the primary approximation method , provides concise code through the use of automatic differentiation , has been engineered with a particular emphasis on software testing and is able to exploit GPU hardware .
We study how the regret guarantees of nonstochastic multi-armed bandits can be improved , if the effective range of the losses in each round is small ( e . g . the maximal difference between two losses in a given round ) . Despite a recent impossibility result , we show how this can be made possible under certain mild additional assumptions , such as availability of rough estimates of the losses , or advance knowledge of the loss of a single , possibly unspecified arm . Along the way , we develop a novel technique which might be of independent interest , to convert any multi-armed bandit algorithm with regret depending on the loss range , to an algorithm with regret depending only on the effective range , while avoiding predictably bad arms altogether .
We develop a novel multi-fidelity framework that goes far beyond the classical AR ( 0 ) Co-kriging scheme of Kennedy and O ' Hagan ( 0000 ) . Our method can handle general discontinuous cross-correlations among systems with different levels of fidelity . A combination of multi-fidelity Gaussian Processes ( AR ( 0 ) Co-kriging ) and deep neural networks enables us to construct a method that is immune to discontinuities . We demonstrate the effectiveness of the new technology using standard benchmark problems designed to resemble the outputs of complicated high- and low-fidelity codes .
We propose a Bayesian framework of Gaussian process in order to extend Fisher ' s discriminant to classify functional data such as spectra and images . The probability structure for our extended Fisher ' s discriminant is explicitly formulated , and we utilize the smoothness assumptions of functional data as prior probabilities . Existing methods which directly employ the smoothness assumption of functional data can be shown as special cases within this framework given corresponding priors while their estimates of the unknowns are one-step approximations to the proposed MAP estimates . Empirical results on various simulation studies and different real applications show that the proposed method significantly outperforms the other Fisher ' s discriminant methods for functional data .
Community detection algorithms are fundamental tools to understand organizational principles in social networks . With the increasing power of social media platforms , when detecting communities there are two possi- ble sources of information one can use : the structure of social network and node attributes . However structure of social networks and node attributes are often interpreted separately in the research of community detection . When these two sources are interpreted simultaneously , one common as- sumption shared by previous studies is that nodes attributes are correlated with communities . In this paper , we present a model that is capable of combining topology information and nodes attributes information with- out assuming correlation . This new model can recover communities with higher accuracy even when node attributes and communities are uncorre- lated . We derive the detectability threshold for this model and use Belief Propagation ( BP ) to make inference . This algorithm is optimal in the sense that it can recover community all the way down to the threshold . This new model is also with the potential to handle edge content and dynamic settings .
We study a statistical model for the tensor principal component analysis problem introduced by Montanari and Richard : Given a order-$0$ tensor $T$ of the form $T = \tau \cdot v_0^{\otimes 0} + A$ , where $\tau \geq 0$ is a signal-to-noise ratio , $v_0$ is a unit vector , and $A$ is a random noise tensor , the goal is to recover the planted vector $v_0$ . For the case that $A$ has iid standard Gaussian entries , we give an efficient algorithm to recover $v_0$ whenever $\tau \geq \omega ( n^{0/0} \log ( n ) ^{0/0} ) $ , and certify that the recovered vector is close to a maximum likelihood estimator , all with high probability over the random choice of $A$ . The previous best algorithms with provable guarantees required $\tau \geq \Omega ( n ) $ . In the regime $\tau \leq o ( n ) $ , natural tensor-unfolding-based spectral relaxations for the underlying optimization problem break down ( in the sense that their integrality gap is large ) . To go beyond this barrier , we use convex relaxations based on the sum-of-squares method . Our recovery algorithm proceeds by rounding a degree-$0$ sum-of-squares relaxations of the maximum-likelihood-estimation problem for the statistical model . To complement our algorithmic results , we show that degree-$0$ sum-of-squares relaxations break down for $\tau \leq O ( n^{0/0}/\log ( n ) ^{0/0} ) $ , which demonstrates that improving our current guarantees ( by more than logarithmic factors ) would require new techniques or might even be intractable . Finally , we show how to exploit additional problem structure in order to solve our sum-of-squares relaxations , up to some approximation , very efficiently . Our fastest algorithm runs in nearly-linear time using shifted ( matrix ) power iteration and has similar guarantees as above . The analysis of this algorithm also confirms a variant of a conjecture of Montanari and Richard about singular vectors of tensor unfoldings .
Fisher ' s linear discriminant analysis ( FLDA ) is an important dimension reduction method in statistical pattern recognition . It has been shown that FLDA is asymptotically Bayes optimal under the homoscedastic Gaussian assumption . However , this classical result has the following two major limitations : 0 ) it holds only for a fixed dimensionality $D$ , and thus does not apply when $D$ and the training sample size $N$ are proportionally large ; 0 ) it does not provide a quantitative description on how the generalization ability of FLDA is affected by $D$ and $N$ . In this paper , we present an asymptotic generalization analysis of FLDA based on random matrix theory , in a setting where both $D$ and $N$ increase and $D/N\longrightarrow\gamma\in[0 , 0 ) $ . The obtained lower bound of the generalization discrimination power overcomes both limitations of the classical result , i . e . , it is applicable when $D$ and $N$ are proportionally large and provides a quantitative description of the generalization ability of FLDA in terms of the ratio $\gamma=D/N$ and the population discrimination power . Besides , the discrimination power bound also leads to an upper bound on the generalization error of binary-classification with FLDA .
DNN-based cross-modal retrieval has become a research hotspot , by which users can search results across various modalities like image and text . However , existing methods mainly focus on the pairwise correlation and reconstruction error of labeled data . They ignore the semantically similar and dissimilar constraints between different modalities , and cannot take advantage of unlabeled data . This paper proposes Cross-modal Deep Metric Learning with Multi-task Regularization ( CDMLMR ) , which integrates quadruplet ranking loss and semi-supervised contrastive loss for modeling cross-modal semantic similarity in a unified multi-task learning architecture . The quadruplet ranking loss can model the semantically similar and dissimilar constraints to preserve cross-modal relative similarity ranking information . The semi-supervised contrastive loss is able to maximize the semantic similarity on both labeled and unlabeled data . Compared to the existing methods , CDMLMR exploits not only the similarity ranking information but also unlabeled cross-modal data , and thus boosts cross-modal retrieval accuracy .
The performance of sparse signal recovery from noise corrupted , underdetermined measurements can be improved if both sparsity and correlation structure of signals are exploited . One typical correlation structure is the intra-block correlation in block sparse signals . To exploit this structure , a framework , called block sparse Bayesian learning ( BSBL ) , has been proposed recently . Algorithms derived from this framework showed superior performance but they are not very fast , which limits their applications . This work derives an efficient algorithm from this framework , using a marginalized likelihood maximization method . Compared to existing BSBL algorithms , it has close recovery performance but is much faster . Therefore , it is more suitable for large scale datasets and applications requiring real-time implementation .
We consider data in the form of pairwise comparisons of n items , with the goal of precisely identifying the top k items for some value of k < n , or alternatively , recovering a ranking of all the items . We analyze the Copeland counting algorithm that ranks the items in order of the number of pairwise comparisons won , and show it has three attractive features : ( a ) its computational efficiency leads to speed-ups of several orders of magnitude in computation time as compared to prior work ; ( b ) it is robust in that theoretical guarantees impose no conditions on the underlying matrix of pairwise-comparison probabilities , in contrast to some prior work that applies only to the BTL parametric model ; and ( c ) it is an optimal method up to constant factors , meaning that it achieves the information-theoretic limits for recovering the top k-subset . We extend our results to obtain sharp guarantees for approximate recovery under the Hamming distortion metric , and more generally , to any arbitrary error requirement that satisfies a simple and natural monotonicity condition .
A common approach in positive-unlabeled learning is to train a classification model between labeled and unlabeled data . This strategy is in fact known to give an optimal classifier under mild conditions ; however , it results in biased empirical estimates of the classifier performance . In this work , we show that the typically used performance measures such as the receiver operating characteristic curve , or the precision-recall curve obtained on such data can be corrected with the knowledge of class priors ; i . e . , the proportions of the positive and negative examples in the unlabeled data . We extend the results to a noisy setting where some of the examples labeled positive are in fact negative and show that the correction also requires the knowledge of the proportion of noisy examples in the labeled positives . Using state-of-the-art algorithms to estimate the positive class prior and the proportion of noise , we experimentally evaluate two correction approaches and demonstrate their efficacy on real-life data .
In unsupervised classification , Hidden Markov Models ( HMM ) are used to account for a neighborhood structure between observations . The emission distributions are often supposed to belong to some parametric family . In this paper , a semiparametric modeling where the emission distributions are a mixture of parametric distributions is proposed to get a higher flexibility . We show that the classical EM algorithm can be adapted to infer the model parameters . For the initialisation step , starting from a large number of components , a hierarchical method to combine them into the hidden states is proposed . Three likelihood-based criteria to select the components to be combined are discussed . To estimate the number of hidden states , BIC-like criteria are derived . A simulation study is carried out both to determine the best combination between the merging criteria and the model selection criteria and to evaluate the accuracy of classification . The proposed method is also illustrated using a biological dataset from the model plant Arabidopsis thaliana . A R package HMMmix is freely available on the CRAN .
We describe ASAGA , an asynchronous parallel version of the incremental gradient algorithm SAGA that enjoys fast linear convergence rates . Through a novel perspective , we revisit and clarify a subtle but important technical issue present in a large fraction of the recent convergence rate proofs for asynchronous parallel optimization algorithms , and propose a simplification of the recently introduced " perturbed iterate " framework that resolves it . We thereby prove that ASAGA can obtain a theoretical linear speedup on multi-core systems even without sparsity assumptions . We present results of an implementation on a 00-core architecture illustrating the practical speedup as well as the hardware overhead .
It is shown that bootstrap approximations of support vector machines ( SVMs ) based on a general convex and smooth loss function and on a general kernel are consistent . This result is useful to approximate the unknown finite sample distribution of SVMs by the bootstrap approach .
Spectral dimensionality reduction is frequently used to identify low-dimensional structure in high-dimensional data . However , learning manifolds , especially from the streaming data , is computationally and memory expensive . In this paper , we argue that a stable manifold can be learned using only a fraction of the stream , and the remaining stream can be mapped to the manifold in a significantly less costly manner . Identifying the transition point at which the manifold is stable is the key step . We present error metrics that allow us to identify the transition point for a given stream by quantitatively assessing the quality of a manifold learned using Isomap . We further propose an efficient mapping algorithm , called S-Isomap , that can be used to map new samples onto the stable manifold . We describe experiments on a variety of data sets that show that the proposed approach is computationally efficient without sacrificing accuracy .
There is an increasing body of evidence suggesting that exact nearest neighbour search in high-dimensional spaces is affected by the curse of dimensionality at a fundamental level . Does it necessarily mean that the same is true for k nearest neighbours based learning algorithms such as the k-NN classifier ? We analyse this question at a number of levels and show that the answer is different at each of them . As our first main observation , we show the consistency of a k approximate nearest neighbour classifier . However , the performance of the classifier in very high dimensions is provably unstable . As our second main observation , we point out that the existing model for statistical learning is oblivious of dimension of the domain and so every learning problem admits a universally consistent deterministic reduction to the one-dimensional case by means of a Borel isomorphism .
We introduce a dynamic mechanism for the solution of analytically-tractable substructure in probabilistic programs , to reduce variance in Monte Carlo estimators . For inference with Sequential Monte Carlo , it yields improvements such as locally-optimal proposals and Rao-Blackwellization , with little modification to model code necessary . A directed graph is maintained alongside the running program , evolving dynamically as the program triggers operations upon it . Nodes of the graph represent random variables , and edges the analytically-tractable relationships between them ( e . g . conjugate priors and affine transformations ) . Each random variable is held in the graph for as long as possible , sampled only when used by the program in a context that cannot be resolved analytically . This allows it to be analytically conditioned on as many observations as possible before sampling . We have implemented the approach in both Anglican and a new probabilistic programming language named Birch . We demonstrate it on a number of small examples , and a larger mixed linear-nonlinear state-space model .
This paper proposes the continuous semantic topic embedding model ( CSTEM ) which finds latent topic variables in documents using continuous semantic distance function between the topics and the words by means of the variational autoencoder ( VAE ) . The semantic distance could be represented by any symmetric bell-shaped geometric distance function on the Euclidean space , for which the Mahalanobis distance is used in this paper . In order for the semantic distance to perform more properly , we newly introduce an additional model parameter for each word to take out the global factor from this distance indicating how likely it occurs regardless of its topic . It certainly improves the problem that the Gaussian distribution which is used in previous topic model with continuous word embedding could not explain the semantic relation correctly and helps to obtain the higher topic coherence . Through the experiments with the dataset of 00 Newsgroup , NIPS papers and CNN/Dailymail corpus , the performance of the recent state-of-the-art models is accomplished by our model as well as generating topic embedding vectors which makes possible to observe where the topic vectors are embedded with the word vectors in the real Euclidean space and how the topics are related each other semantically .
Techniques involving factorization are found in a wide range of applications and have enjoyed significant empirical success in many fields . However , common to a vast majority of these problems is the significant disadvantage that the associated optimization problems are typically non-convex due to a multilinear form or other convexity destroying transformation . Here we build on ideas from convex relaxations of matrix factorizations and present a very general framework which allows for the analysis of a wide range of non-convex factorization problems - including matrix factorization , tensor factorization , and deep neural network training formulations . We derive sufficient conditions to guarantee that a local minimum of the non-convex optimization problem is a global minimum and show that if the size of the factorized variables is large enough then from any initialization it is possible to find a global minimizer using a purely local descent algorithm . Our framework also provides a partial theoretical justification for the increasingly common use of Rectified Linear Units ( ReLUs ) in deep neural networks and offers guidance on deep network architectures and regularization strategies to facilitate efficient optimization .
System states that are anomalous from the perspective of a domain expert occur frequently in some anomaly detection problems . The performance of commonly used unsupervised anomaly detection methods may suffer in that setting , because they use frequency as a proxy for anomaly . We propose a novel concept for anomaly detection , called relative anomaly detection . It is tailored to be robust towards anomalies that occur frequently , by taking into account their location relative to the most typical observations . The approaches we develop are computationally feasible even for large data sets , and they allow real-time detection . We illustrate using data sets of potential scraping attempts and Wi-Fi channel utilization , both from Google , Inc .
Topic models , such as Latent Dirichlet Allocation ( LDA ) , posit that documents are drawn from admixtures of distributions over words , known as topics . The inference problem of recovering topics from admixtures , is NP-hard . Assuming separability , a strong assumption , [0] gave the first provable algorithm for inference . For LDA model , [0] gave a provable algorithm using tensor-methods . But [0 , 0] do not learn topic vectors with bounded $l_0$ error ( a natural measure for probability vectors ) . Our aim is to develop a model which makes intuitive and empirically supported assumptions and to design an algorithm with natural , simple components such as SVD , which provably solves the inference problem for the model with bounded $l_0$ error . A topic in LDA and other models is essentially characterized by a group of co-occurring words . Motivated by this , we introduce topic specific Catchwords , group of words which occur with strictly greater frequency in a topic than any other topic individually and are required to have high frequency together rather than individually . A major contribution of the paper is to show that under this more realistic assumption , which is empirically verified on real corpora , a singular value decomposition ( SVD ) based algorithm with a crucial pre-processing step of thresholding , can provably recover the topics from a collection of documents drawn from Dominant admixtures . Dominant admixtures are convex combination of distributions in which one distribution has a significantly higher contribution than others . Apart from the simplicity of the algorithm , the sample complexity has near optimal dependence on $w_0$ , the lowest probability that a topic is dominant , and is better than [0] . Empirical evidence shows that on several real world corpora , both Catchwords and Dominant admixture assumptions hold and the proposed algorithm substantially outperforms the state of the art [0] .
Neurons perform computations , and convey the results of those computations through the statistical structure of their output spike trains . Here we present a practical method , grounded in the information-theoretic analysis of prediction , for inferring a minimal representation of that structure and for characterizing its complexity . Starting from spike trains , our approach finds their causal state models ( CSMs ) , the minimal hidden Markov models or stochastic automata capable of generating statistically identical time series . We then use these CSMs to objectively quantify both the generalizable structure and the idiosyncratic randomness of the spike train . Specifically , we show that the expected algorithmic information content ( the information needed to describe the spike train exactly ) can be split into three parts describing ( 0 ) the time-invariant structure ( complexity ) of the minimal spike-generating process , which describes the spike train statistically ; ( 0 ) the randomness ( internal entropy rate ) of the minimal spike-generating process ; and ( 0 ) a residual pure noise term not described by the minimal spike-generating process . We use CSMs to approximate each of these quantities . The CSMs are inferred nonparametrically from the data , making only mild regularity assumptions , via the causal state splitting reconstruction algorithm . The methods presented here complement more traditional spike train analyses by describing not only spiking probability and spike train entropy , but also the complexity of a spike train ' s structure . We demonstrate our approach using both simulated spike trains and experimental data recorded in rat barrel cortex during vibrissa stimulation .
Analyzing the temporal behavior of nodes in time-varying graphs is useful for many applications such as targeted advertising , community evolution and outlier detection . In this paper , we present a novel approach , STWalk , for learning trajectory representations of nodes in temporal graphs . The proposed framework makes use of structural properties of graphs at current and previous time-steps to learn effective node trajectory representations . STWalk performs random walks on a graph at a given time step ( called space-walk ) as well as on graphs from past time-steps ( called time-walk ) to capture the spatio-temporal behavior of nodes . We propose two variants of STWalk to learn trajectory representations . In one algorithm , we perform space-walk and time-walk as part of a single step . In the other variant , we perform space-walk and time-walk separately and combine the learned representations to get the final trajectory embedding . Extensive experiments on three real-world temporal graph datasets validate the effectiveness of the learned representations when compared to three baseline methods . We also show the goodness of the learned trajectory embeddings for change point detection , as well as demonstrate that arithmetic operations on these trajectory representations yield interesting and interpretable results .
Expectation Propagation ( EP ) provides a framework for approximate inference . When the model under consideration is over a latent Gaussian field , with the approximation being Gaussian , we show how these approximations can systematically be corrected . A perturbative expansion is made of the exact but intractable correction , and can be applied to the model ' s partition function and other moments of interest . The correction is expressed over the higher-order cumulants which are neglected by EP ' s local matching of moments . Through the expansion , we see that EP is correct to first order . By considering higher orders , corrections of increasing polynomial complexity can be applied to the approximation . The second order provides a correction in quadratic time , which we apply to an array of Gaussian process and Ising models . The corrections generalize to arbitrarily complex approximating families , which we illustrate on tree-structured Ising model approximations . Furthermore , they provide a polynomial-time assessment of the approximation error . We also provide both theoretical and practical insights on the exactness of the EP solution .
Trial-and-error based reinforcement learning ( RL ) has seen rapid advancements in recent times , especially with the advent of deep neural networks . However , the majority of autonomous RL algorithms either rely on engineered features or a large number of interactions with the environment . Such a large number of interactions may be impractical in many real-world applications . For example , robots are subject to wear and tear and , hence , millions of interactions may change or damage the system . Moreover , practical systems have limitations in the form of the maximum torque that can be safely applied . To reduce the number of system interactions while naturally handling constraints , we propose a model-based RL framework based on Model Predictive Control ( MPC ) . In particular , we propose to learn a probabilistic transition model using Gaussian Processes ( GPs ) to incorporate model uncertainties into long-term predictions , thereby , reducing the impact of model errors . We then use MPC to find a control sequence that minimises the expected long-term cost . We provide theoretical guarantees for the first-order optimality in the GP-based transition models with deterministic approximate inference for long-term planning . The proposed framework demonstrates superior data efficiency and learning rates compared to the current state of the art .
Physicists use quantum models to describe the behavior of physical systems . Quantum models owe their success to their interpretability , to their relation to probabilistic models ( quantization of classical models ) and to their high predictive power . Beyond physics , these properties are valuable in general data science . This motivates the use of quantum models to analyze general nonphysical datasets . Here we provide both empirical and theoretical insights into the application of quantum models in data science . In the theoretical part of this paper , we firstly show that quantum models can be exponentially more efficient than probabilistic models because there exist datasets that admit low-dimensional quantum models and only exponentially high-dimensional probabilistic models . Secondly , we explain in what sense quantum models realize a useful relaxation of compressed probabilistic models . Thirdly , we show that sparse datasets admit low-dimensional quantum models and finally , we introduce a method to compute hierarchical orderings of properties of users ( e . g . , personality traits ) and items ( e . g . , genres of movies ) . In the empirical part of the paper , we evaluate quantum models in item recommendation and observe that the predictive power of quantum-inspired recommender systems can compete with state-of-the-art recommender systems like SVD++ and PureSVD . Furthermore , we make use of the interpretability of quantum models by computing hierarchical orderings of properties of users and items . This work establishes a connection between data science ( item recommendation ) , information theory ( communication complexity ) , mathematical programming ( positive semidefinite factorizations ) and physics ( quantum models ) .
By building on a recently introduced genetic-inspired attribute-based conceptual framework for safety risk analysis , we propose a novel methodology to compute construction univariate and bivariate construction safety risk at a situational level . Our fully data-driven approach provides construction practitioners and academicians with an easy and automated way of extracting valuable empirical insights from databases of unstructured textual injury reports . By applying our methodology on an attribute and outcome dataset directly obtained from 000 injury reports , we show that the frequency-magnitude distribution of construction safety risk is very similar to that of natural phenomena such as precipitation or earthquakes . Motivated by this observation , and drawing on state-of-the-art techniques in hydroclimatology and insurance , we introduce univariate and bivariate nonparametric stochastic safety risk generators , based on Kernel Density Estimators and Copulas . These generators enable the user to produce large numbers of synthetic safety risk values faithfully to the original data , allowing safetyrelated decision-making under uncertainty to be grounded on extensive empirical evidence . Just like the accurate modeling and simulation of natural phenomena such as wind or streamflow is indispensable to successful structure dimensioning or water reservoir management , we posit that improving construction safety calls for the accurate modeling , simulation , and assessment of safety risk . The underlying assumption is that like natural phenomena , construction safety may benefit from being studied in an empirical and quantitative way rather than qualitatively which is the current industry standard . Finally , a side but interesting finding is that attributes related to high energy levels and to human error emerge as strong risk shapers on the dataset we used to illustrate our methodology .
Noise is an inherent issue of low-light image capture , one which is exacerbated on mobile devices due to their narrow apertures and small sensors . One strategy for mitigating noise in a low-light situation is to increase the shutter time of the camera , thus allowing each photosite to integrate more light and decrease noise variance . However , there are two downsides of long exposures : ( a ) bright regions can exceed the sensor range , and ( b ) camera and scene motion will result in blurred images . Another way of gathering more light is to capture multiple short ( thus noisy ) frames in a " burst " and intelligently integrate the content , thus avoiding the above downsides . In this paper , we use the burst-capture strategy and implement the intelligent integration via a recurrent fully convolutional deep neural net ( CNN ) . We build our novel , multiframe architecture to be a simple addition to any single frame denoising model , and design to handle an arbitrary number of noisy input frames . We show that it achieves state of the art denoising results on our burst dataset , improving on the best published multi-frame techniques , such as VBM0D and FlexISP . Finally , we explore other applications of image enhancement by integrating content from multiple frames and demonstrate that our DNN architecture generalizes well to image super-resolution .
We analyze how an observer synchronizes to the internal state of a finite-state information source , using the epsilon-machine causal representation . Here , we treat the case of exact synchronization , when it is possible for the observer to synchronize completely after a finite number of observations . The more difficult case of strictly asymptotic synchronization is treated in a sequel . In both cases , we find that an observer , on average , will synchronize to the source state exponentially fast and that , as a result , the average accuracy in an observer ' s predictions of the source output approaches its optimal level exponentially fast as well . Additionally , we show here how to analytically calculate the synchronization rate for exact epsilon-machines and provide an efficient polynomial-time algorithm to test epsilon-machines for exactness .
We aim to create a framework for transfer learning using latent factor models to learn the dependence structure between a larger source dataset and a target dataset . The methodology is motivated by our goal of building a risk-assessment model for surgery patients , using both institutional and national surgical outcomes data . The national surgical outcomes data is collected through NSQIP ( National Surgery Quality Improvement Program ) , a database housing almost 0 million patients from over 000 different hospitals . We build a latent factor model with a hierarchical prior on the loadings matrix to appropriately account for the different covariance structure in our data . We extend this model to handle more complex relationships between the populations by deriving a scale mixture formulation using stick-breaking properties . Our model provides a transfer learning framework that utilizes all information from both the source and target data , while modeling the underlying inherent differences between them .
The rise and fall of artificial neural networks is well documented in the scientific literature of both computer science and computational chemistry . Yet almost two decades later , we are now seeing a resurgence of interest in deep learning , a machine learning algorithm based on multilayer neural networks . Within the last few years , we have seen the transformative impact of deep learning in many domains , particularly in speech recognition and computer vision , to the extent that the majority of expert practitioners in those field are now regularly eschewing prior established models in favor of deep learning models . In this review , we provide an introductory overview into the theory of deep neural networks and their unique properties that distinguish them from traditional machine learning algorithms used in cheminformatics . By providing an overview of the variety of emerging applications of deep neural networks , we highlight its ubiquity and broad applicability to a wide range of challenges in the field , including QSAR , virtual screening , protein structure prediction , quantum chemistry , materials design and property prediction . In reviewing the performance of deep neural networks , we observed a consistent outperformance against non-neural networks state-of-the-art models across disparate research topics , and deep neural network based models often exceeded the " glass ceiling " expectations of their respective tasks . Coupled with the maturity of GPU-accelerated computing for training deep neural networks and the exponential growth of chemical data on which to train these networks on , we anticipate that deep learning algorithms will be a valuable tool for computational chemistry .
Latent topic models have been successfully applied as an unsupervised topic discovery technique in large document collections . With the proliferation of hypertext document collection such as the Internet , there has also been great interest in extending these approaches to hypertext [0 , 0] . These approaches typically model links in an analogous fashion to how they model words - the document-link co-occurrence matrix is modeled in the same way that the document-word co-occurrence matrix is modeled in standard topic models . In this paper we present a probabilistic generative model for hypertext document collections that explicitly models the generation of links . Specifically , links from a word w to a document d depend directly on how frequent the topic of w is in d , in addition to the in-degree of d . We show how to perform EM learning on this model efficiently . By not modeling links as analogous to words , we end up using far fewer free parameters and obtain better link prediction results .
Recurrent neural networks ( RNNs ) are a vital modeling technique that rely on internal states learned indirectly by optimization of a supervised , unsupervised , or reinforcement training loss . RNNs are used to model dynamic processes that are characterized by underlying latent states whose form is often unknown , precluding its analytic representation inside an RNN . In the Predictive-State Representation ( PSR ) literature , latent state processes are modeled by an internal state representation that directly models the distribution of future observations , and most recent work in this area has relied on explicitly representing and targeting sufficient statistics of this probability distribution . We seek to combine the advantages of RNNs and PSRs by augmenting existing state-of-the-art recurrent neural networks with Predictive-State Decoders ( PSDs ) , which add supervision to the network ' s internal state representation to target predicting future observations . Predictive-State Decoders are simple to implement and easily incorporated into existing training pipelines via additional loss regularization . We demonstrate the effectiveness of PSDs with experimental results in three different domains : probabilistic filtering , Imitation Learning , and Reinforcement Learning . In each , our method improves statistical performance of state-of-the-art recurrent baselines and does so with fewer iterations and less data .
Principal Components Regression ( PCR ) is a traditional tool for dimension reduction in linear regression that has been both criticized and defended . One concern about PCR is that obtaining the leading principal components tends to be computationally demanding for large data sets . While random projections do not possess the optimality properties of the leading principal subspace , they are computationally appealing and hence have become increasingly popular in recent years . In this paper , we present an analysis showing that for random projections satisfying a Johnson-Lindenstrauss embedding property , the prediction error in subsequent regression is close to that of PCR , at the expense of requiring a slightly large number of random projections than principal components . Column sub-sampling constitutes an even cheaper way of randomized dimension reduction outside the class of Johnson-Lindenstrauss transforms . We provide numerical results based on synthetic and real data as well as basic theory revealing differences and commonalities in terms of statistical performance .
Human trafficking is among the most challenging law enforcement problems which demands persistent fight against from all over the globe . In this study , we leverage readily available data from the website " Backpage " -- used for classified advertisement-- to discern potential patterns of human trafficking activities which manifest online and identify most likely trafficking related advertisements . Due to the lack of ground truth , we rely on two human analysts --one human trafficking victim survivor and one from law enforcement , for hand-labeling the small portion of the crawled data . We then present a semi-supervised learning approach that is trained on the available labeled and unlabeled data and evaluated on unseen data with further verification of experts .
A key element in transfer learning is representation learning ; if representations can be developed that expose the relevant factors underlying the data , then new tasks and domains can be learned readily based on mappings of these salient factors . We propose that an important aim for these representations are to be unbiased . Different forms of representation learning can be derived from alternative definitions of unwanted bias , e . g . , bias to particular tasks , domains , or irrelevant underlying data dimensions . One very useful approach to estimating the amount of bias in a representation comes from maximum mean discrepancy ( MMD ) [0] , a measure of distance between probability distributions . We are not the first to suggest that MMD can be a useful criterion in developing representations that apply across multiple domains or tasks [0] . However , in this paper we describe a number of novel applications of this criterion that we have devised , all based on the idea of developing unbiased representations . These formulations include : a standard domain adaptation framework ; a method of learning invariant representations ; an approach based on noise-insensitive autoencoders ; and a novel form of generative model .
This paper consider penalized empirical loss minimization of convex loss functions with unknown non-linear target functions . Using the elastic net penalty we establish a finite sample oracle inequality which bounds the loss of our estimator from above with high probability . If the unknown target is linear this inequality also provides an upper bound of the estimation error of the estimated parameter vector . These are new results and they generalize the econometrics and statistics literature . Next , we use the non-asymptotic results to show that the excess loss of our estimator is asymptotically of the same order as that of the oracle . If the target is linear we give sufficient conditions for consistency of the estimated parameter vector . Next , we briefly discuss how a thresholded version of our estimator can be used to perform consistent variable selection . We give two examples of loss functions covered by our framework and show how penalized nonparametric series estimation is contained as a special case and provide a finite sample upper bound on the mean square error of the elastic net series estimator .
Frequently , acquiring training data has an associated cost . We consider the situation where the learner may purchase data during training , subject TO a budget . IN particular , we examine the CASE WHERE each feature label has an associated cost , AND the total cost OF ALL feature labels acquired during training must NOT exceed the budget . This paper compares methods FOR choosing which feature label TO purchase next , given the budget AND the CURRENT belief state OF naive Bayes model parameters . Whereas active learning has traditionally focused ON myopic ( greedy ) strategies FOR query selection , this paper presents a tractable method FOR incorporating knowledge OF the budget INTO the decision making process , which improves performance .
Missing data is a well-recognized problem impacting all domains . State-of-the-art framework to minimize missing data bias is multiple imputation , for which the choice of an imputation model remains nontrivial . We propose a multiple imputation model based on overcomplete deep denoising autoencoders , capable of handling different data types , missingness patterns , missingness proportions and distributions . Evaluation on real life datasets shows our proposed model outperforms the state-of-the-art methods under varying conditions and improves the end of the line analytics .
The EM algorithm is one of many important tools in the field of statistics . While often used for imputing missing data , its widespread applications include other common statistical tasks , such as clustering . In clustering , the EM algorithm assumes a parametric distribution for the clusters , whose parameters are estimated through a novel iterative procedure that is based on the theory of maximum likelihood . However , one major drawback of the EM algorithm , that renders it impractical especially when working with large datasets , is that it often requires several passes of the data before convergence . In this paper , we introduce a new EM-style algorithm that implements a novel policy for performing partial E-steps . We call the new algorithm the EM-Tau algorithm , which can approximate the traditional EM algorithm with high accuracy but with only a fraction of the running time .
The paper introduces a penalized matrix estimation procedure aiming at solutions which are sparse and low-rank at the same time . Such structures arise in the context of social networks or protein interactions where underlying graphs have adjacency matrices which are block-diagonal in the appropriate basis . We introduce a convex mixed penalty which involves $\ell_0$-norm and trace norm simultaneously . We obtain an oracle inequality which indicates how the two effects interact according to the nature of the target matrix . We bound generalization error in the link prediction problem . We also develop proximal descent strategies to solve the optimization problem efficiently and evaluate performance on synthetic and real data sets .
The problem of adaptive noisy clustering is investigated . Given a set of noisy observations $Z_i=X_i+\epsilon_i$ , $i=0 , . . . , n$ , the goal is to design clusters associated with the law of $X_i$ ' s , with unknown density $f$ with respect to the Lebesgue measure . Since we observe a corrupted sample , a direct approach as the popular {\it $k$-means} is not suitable in this case . In this paper , we propose a noisy $k$-means minimization , which is based on the $k$-means loss function and a deconvolution estimator of the density $f$ . In particular , this approach suffers from the dependence on a bandwidth involved in the deconvolution kernel . Fast rates of convergence for the excess risk are proposed for a particular choice of the bandwidth , which depends on the smoothness of the density $f$ . Then , we turn out into the main issue of the paper : the data-driven choice of the bandwidth . We state an adaptive upper bound for a new selection rule , called ERC ( Empirical Risk Comparison ) . This selection rule is based on the Lepski ' s principle , where empirical risks associated with different bandwidths are compared . Finally , we illustrate that this adaptive rule can be used in many statistical problems of $M$-estimation where the empirical risk depends on a nuisance parameter .
" Deep Learning " methods attempt to learn generic features in an unsupervised fashion from a large unlabelled data set . These generic features should perform as well as the best hand crafted features for any learning problem that makes use of this data . We provide a definition of generic features , characterize when it is possible to learn them and provide methods closely related to the autoencoder and deep belief network of deep learning . In order to do so we use the notion of deficiency and illustrate its value in studying certain general learning problems .
Vote-boosting is a sequential ensemble learning method in which individual classifiers are built on different weighted versions of the training data . To build a new classifier , the weight of each training instance is determined as a function of the disagreement rate of the current ensemble predictions for that particular instance . Experiments using the symmetric beta distribution as the emphasis function and different base learners are used to illustrate the properties and to analyze the performance of these types of ensembles . In classification problems with low or no class-label noise , when simple base learners are used , vote-boosting behaves as if it were an interpolation between bagging and standard boosting ( e . g . AdaBoost ) , depending on the value of the shape parameter of the beta distribution . In terms of predictive accuracy the best results , which are comparable or better than random forests , are obtained with vote-boosting ensembles of random trees .
Deep Boltzmann machines are in principle powerful models for extracting the hierarchical structure of data . Unfortunately , attempts to train layers jointly ( without greedy layer-wise pretraining ) have been largely unsuccessful . We propose a modification of the learning algorithm that initially recenters the output of the activation functions to zero . This modification leads to a better conditioned Hessian and thus makes learning easier . We test the algorithm on real data and demonstrate that our suggestion , the centered deep Boltzmann machine , learns a hierarchy of increasingly abstract representations and a better generative model of data .
In this paper , we present a generic framework to extend existing uniformly optimal convex programming algorithms to solve more general nonlinear , possibly nonconvex , optimization problems . The basic idea is to incorporate a local search step ( gradient descent or Quasi-Newton iteration ) into these uniformly optimal convex programming methods , and then enforce a monotone decreasing property of the function values computed along the trajectory . Algorithms of these types will then achieve the best known complexity for nonconvex problems , and the optimal complexity for convex ones without requiring any problem parameters . As a consequence , we can have a unified treatment for a general class of nonlinear programming problems regardless of their convexity and smoothness level . In particular , we show that the accelerated gradient and level methods , both originally designed for solving convex optimization problems only , can be used for solving both convex and nonconvex problems uniformly . In a similar vein , we show that some well-studied techniques for nonlinear programming , e . g . , Quasi-Newton iteration , can be embedded into optimal convex optimization algorithms to possibly further enhance their numerical performance . Our theoretical and algorithmic developments are complemented by some promising numerical results obtained for solving a few important nonconvex and nonlinear data analysis problems in the literature .
Online health communities are a valuable source of information for patients and physicians . However , such user-generated resources are often plagued by inaccuracies and misinformation . In this work we propose a method for automatically establishing the credibility of user-generated medical statements and the trustworthiness of their authors by exploiting linguistic cues and distant supervision from expert sources . To this end we introduce a probabilistic graphical model that jointly learns user trustworthiness , statement credibility , and language objectivity . We apply this methodology to the task of extracting rare or unknown side-effects of medical drugs --- this being one of the problems where large scale non-expert data has the potential to complement expert medical knowledge . We show that our method can reliably extract side-effects and filter out false statements , while identifying trustworthy users that are likely to contribute valuable medical information .
We consider the problem of predicting the next observation given a sequence of past observations , and consider the extent to which accurate prediction requires complex algorithms that explicitly leverage long-range dependencies . Perhaps surprisingly , our positive results show that for a broad class of sequences , there is an algorithm that predicts well on average , and bases its predictions only on the most recent few observation together with a set of simple summary statistics of the past observations . Specifically , we show that for any distribution over observations , if the mutual information between past observations and future observations is upper bounded by $I$ , then a simple Markov model over the most recent $I/\epsilon$ observations obtains expected KL error $\epsilon$---and hence $\ell_0$ error $\sqrt{\epsilon}$---with respect to the optimal predictor that has access to the entire past and knows the data generating distribution . For a Hidden Markov Model with $n$ hidden states , $I$ is bounded by $\log n$ , a quantity that does not depend on the mixing time , and we show that the trivial prediction algorithm based on the empirical frequencies of length $O ( \log n/\epsilon ) $ windows of observations achieves this error , provided the length of the sequence is $d^{\Omega ( \log n/\epsilon ) }$ , where $d$ is the size of the observation alphabet . We also establish that this result cannot be improved upon , even for the class of HMMs , in the following two senses : First , for HMMs with $n$ hidden states , a window length of $\log n/\epsilon$ is information-theoretically necessary to achieve expected $\ell_0$ error $\sqrt{\epsilon}$ . Second , the $d^{\Theta ( \log n/\epsilon ) }$ samples required to estimate the Markov model for an observation alphabet of size $d$ is necessary for any computationally tractable learning algorithm , assuming the hardness of strongly refuting a certain class of CSPs .
The growing penetration of distributed energy resources ( DERs ) in urban areas raises multiple reliability issues . The topology reconstruction is a critical step to ensure the robustness of distribution grid operation . However , the bus connectivity and network topology reconstruction are hard in distribution grids . The reasons are that 0 ) the branches are challenging and expensive to monitor due to underground setup ; 0 ) the inappropriate assumption of radial topology in many studies that urban grids are mesh . To address these drawbacks , we propose a new data-driven approach to reconstruct distribution grid topology by utilizing the newly available smart meter data . Specifically , a graphical model is built to model the probabilistic relationships among different voltage measurements . With proof , the bus connectivity and topology estimation problems are formulated as a linear regression problem with least absolute shrinkage on grouped variables ( Group Lasso ) to deal with meshed network structures . Simulation results show highly accurate estimation in IEEE standard distribution test systems with and without loops using real smart meter data .
The $\ell$-0 norm based optimization is widely used in signal processing , especially in recent compressed sensing theory . This paper studies the solution path of the $\ell$-0 norm penalized least-square problem , whose constrained form is known as Least Absolute Shrinkage and Selection Operator ( LASSO ) . A solution path is the set of all the optimizers with respect to the evolution of the hyperparameter ( Lagrange multiplier ) . The study of the solution path is of great significance in viewing and understanding the profile of the tradeoff between the approximation and regularization terms . If the solution path of a given problem is known , it can help us to find the optimal hyperparameter under a given criterion such as the Akaike Information Criterion . In this paper we present a sufficient condition on $\ell$-0 norm penalized least-square problem . Under this sufficient condition , the number of nonzero entries in the optimizer or solution vector increases monotonically when the hyperparameter decreases . We also generalize the result to the often used total variation case , where the $\ell$-0 norm is taken over the first order derivative of the solution vector . We prove that the proposed condition has intrinsic connections with the condition given by Donoho , et al \cite{Donoho00} and the positive cone condition by Efron {\it el al} \cite{Efron00} . However , the proposed condition does not need to assume the sparsity level of the signal as required by Donoho et al ' s condition , and is easier to verify than Efron , et al ' s positive cone condition when being used for practical applications .
Stability is an important aspect of a classification procedure because unstable predictions can potentially reduce users ' trust in a classification system and also harm the reproducibility of scientific conclusions . The major goal of our work is to introduce a novel concept of classification instability , i . e . , decision boundary instability ( DBI ) , and incorporate it with the generalization error ( GE ) as a standard for selecting the most accurate and stable classifier . Specifically , we implement a two-stage algorithm : ( i ) initially select a subset of classifiers whose estimated GEs are not significantly different from the minimal estimated GE among all the candidate classifiers ; ( ii ) the optimal classifier is chosen as the one achieving the minimal DBI among the subset selected in stage ( i ) . This general selection principle applies to both linear and nonlinear classifiers . Large-margin classifiers are used as a prototypical example to illustrate the above idea . Our selection method is shown to be consistent in the sense that the optimal classifier simultaneously achieves the minimal GE and the minimal DBI . Various simulations and real examples further demonstrate the advantage of our method over several alternative approaches .
Leasing is a popular channel to market new cars . Pricing a leasing contract is complicated because the leasing rate embodies an expectation of the residual value of the car after contract expiration . To aid lessors in their pricing decisions , the paper develops resale price forecasting models . A peculiarity of the leasing business is that forecast errors entail different costs . Identifying effective ways to address this characteristic is the main objective of the paper . More specifically , the paper contributes to the literature through i ) consolidating and integrating previous work in forecasting with asymmetric cost of error functions , ii ) systematically evaluating previous approaches and comparing them to a new approach , and iii ) demonstrating that forecasting with asymmetric cost of error functions enhances the quality of decision support in car leasing . For example , under the assumption that the costs of overestimating resale prices is twice that of the opposite error , incorporating corresponding cost asymmetry into forecast model development reduces decision costs by about eight percent , compared to a standard forecasting model . Higher asymmetry produces even larger improvements .
In this paper , we consider adaptive decision-making problems for stochastic state estimation with partial observations . First , we introduce the concept of weak adaptive submodularity , a generalization of adaptive submodularity , which has found great success in solving challenging adaptive state estimation problems . Then , for the problem of active diagnosis , i . e . , discrete state estimation via active sensing , we show that an adaptive greedy policy has a near-optimal performance guarantee when the reward function possesses this property . We further show that the reward function for group-based active diagnosis , which arises in applications such as medical diagnosis and state estimation with persistent sensor faults , is also weakly adaptive submodular . Finally , in experiments of state estimation for an aircraft electrical system with persistent sensor faults , we observe that an adaptive greedy policy performs equally well as an exhaustive search .
We demonstrate that there is significant redundancy in the parameterization of several deep learning models . Given only a few weight values for each feature it is possible to accurately predict the remaining values . Moreover , we show that not only can the parameter values be predicted , but many of them need not be learned at all . We train several different architectures by learning only a small number of weights and predicting the rest . In the best case we are able to predict more than 00% of the weights of a network without any drop in accuracy .
Making a good decision involves considering the likely outcomes under each possible action . For example , would drug A or drug B lead to a better outcome for this patient ? Ideally , we answer these questions using an experiment , but this is not always possible ( e . g . , it may be unethical ) . As an alternative , we can use non-experimental data to learn models that make counterfactual predictions of what we would observe had we run an experiment . To learn such models for decision-making problems , we propose the use of counterfactual objectives in lieu of classical supervised learning objectives . We implement this idea in a challenging and frequently occurring context , and propose the counterfactual GP ( CGP ) , a counterfactual model of continuous-time trajectories ( time series ) under sequences of actions taken in continuous-time . We develop our model within the potential outcomes framework of Neyman and Rubin . The counterfactual GP is trained using a joint maximum likelihood objective that adjusts for dependencies between observed actions and outcomes in the training data . We report two sets of experimental results . First , we show that the CGP ' s predictions are reliable ; they are stable to changes in certain characteristics of the training data that are not relevant to the decision-making problem . Predictive models trained using classical supervised learning objectives , however , are not stable to such perturbations . In the second experiment , we use data from a real intensive care unit ( ICU ) and qualitatively demonstrate how the CGP ' s ability to answer " What if ? " questions offers medical decision-makers a powerful new tool for planning treatment .
This paper presents an alternative approach to p-values in regression settings . This approach , whose origins can be traced to machine learning , is based on the leave-one-out bootstrap for prediction error . In machine learning this is called the out-of-bag ( OOB ) error . To obtain the OOB error for a model , one draws a bootstrap sample and fits the model to the in-sample data . The out-of-sample prediction error for the model is obtained by calculating the prediction error for the model using the out-of-sample data . Repeating and averaging yields the OOB error , which represents a robust cross-validated estimate of the accuracy of the underlying model . By a simple modification to the bootstrap data involving " noising up " a variable , the OOB method yields a variable importance ( VIMP ) index , which directly measures how much a specific variable contributes to the prediction precision of a model . VIMP provides a scientifically interpretable measure of the effect size of a variable , we call the " predictive effect size " , that holds whether the researcher ' s model is correct or not , unlike the p-value whose calculation is based on the assumed correctness of the model . We also discuss a marginal VIMP index , also easily calculated , which measures the marginal effect of a variable , or what we call " the discovery effect " . The OOB procedure can be applied to both parametric and nonparametric regression models and requires only that the researcher can repeatedly fit their model to bootstrap and modified bootstrap data . We illustrate this approach on a survival data set involving patients with systolic heart failure and to a simulated survival data set where the model is incorrectly specified to illustrate its robustness to model misspecification .
Accurately predicting the time of occurrence of an event of interest is a critical problem in longitudinal data analysis . One of the main challenges in this context is the presence of instances whose event outcomes become unobservable after a certain time point or when some instances do not experience any event during the monitoring period . Such a phenomenon is called censoring which can be effectively handled using survival analysis techniques . Traditionally , statistical approaches have been widely developed in the literature to overcome this censoring issue . In addition , many machine learning algorithms are adapted to effectively handle survival data and tackle other challenging problems that arise in real-world data . In this survey , we provide a comprehensive and structured review of the representative statistical methods along with the machine learning techniques used in survival analysis and provide a detailed taxonomy of the existing methods . We also discuss several topics that are closely related to survival analysis and illustrate several successful applications in various real-world application domains . We hope that this paper will provide a more thorough understanding of the recent advances in survival analysis and offer some guidelines on applying these approaches to solve new problems that arise in applications with censored data .
Molecular " fingerprints " encoding structural information are the workhorse of cheminformatics and machine learning in drug discovery applications . However , fingerprint representations necessarily emphasize particular aspects of the molecular structure while ignoring others , rather than allowing the model to make data-driven decisions . We describe molecular " graph convolutions " , a machine learning architecture for learning from undirected graphs , specifically small molecules . Graph convolutions use a simple encoding of the molecular graph---atoms , bonds , distances , etc . ---which allows the model to take greater advantage of information in the graph structure . Although graph convolutions do not outperform all fingerprint-based methods , they ( along with other graph-based methods ) represent a new paradigm in ligand-based virtual screening with exciting opportunities for future improvement .
Let ${\mathcal S}_m$ be the set of all $m\times m$ density matrices ( Hermitian positively semi-definite matrices of unit trace ) . Consider a problem of estimation of an unknown density matrix $\rho\in {\mathcal S}_m$ based on outcomes of $n$ measurements of observables $X_0 , \dots , X_n\in {\mathbb H}_m$ ( ${\mathbb H}_m$ being the space of $m\times m$ Hermitian matrices ) for a quantum system identically prepared $n$ times in state $\rho . $ Outcomes $Y_0 , \dots , Y_n$ of such measurements could be described by a trace regression model in which ${\mathbb E}_{\rho} ( Y_j|X_j ) ={\rm tr} ( \rho X_j ) , j=0 , \dots , n . $ The design variables $X_0 , \dots , X_n$ are often sampled at random from the uniform distribution in an orthonormal basis $\{E_0 , \dots , E_{m^0}\}$ of ${\mathbb H}_m$ ( such as Pauli basis ) . The goal is to estimate the unknown density matrix $\rho$ based on the data $ ( X_0 , Y_0 ) , \dots , ( X_n , Y_n ) . $ Let $$ \hat Z : =\frac{m^0}{n}\sum_{j=0}^n Y_j X_j $$ and let $\check \rho$ be the projection of $\hat Z$ onto the convex set ${\mathcal S}_m$ of density matrices . It is shown that for estimator $\check \rho$ the minimax lower bounds in classes of low rank density matrices ( established earlier ) are attained up logarithmic factors for all Schatten $p$-norm distances , $p\in [0 , \infty]$ and for Bures version of quantum Hellinger distance . Moreover , for a slightly modified version of estimator $\check \rho$ the same property holds also for quantum relative entropy ( Kullback-Leibler ) distance between density matrices .
This paper extends the recently proposed and theoretically justified iterative thresholding and $K$ residual means algorithm ITKrM to learning dicionaries from incomplete/masked training data ( ITKrMM ) . It further adapts the algorithm to the presence of a low rank component in the data and provides a strategy for recovering this low rank component again from incomplete data . Several synthetic experiments show the advantages of incorporating information about the corruption into the algorithm . Finally , image inpainting is considered as application example , which demonstrates the superior performance of ITKrMM in terms of speed at similar or better reconstruction quality compared to its closest dictionary learning counterpart .
Dictionary learning is the task of determining a data-dependent transform that yields a sparse representation of some observed data . The dictionary learning problem is non-convex , and usually solved via computationally complex iterative algorithms . Furthermore , the resulting transforms obtained generally lack structure that permits their fast application to data . To address this issue , this paper develops a framework for learning orthonormal dictionaries which are built from products of a few Householder reflectors . Two algorithms are proposed to learn the reflector coefficients : one that considers a sequential update of the reflectors and one with a simultaneous update of all reflectors that imposes an additional internal orthogonal constraint . The proposed methods have low computational complexity and are shown to converge to local minimum points which can be described in terms of the spectral properties of the matrices involved . The resulting dictionaries balance between the computational complexity and the quality of the sparse representations by controlling the number of Householder reflectors in their product . Simulations of the proposed algorithms are shown in the image processing setting where well-known fast transforms are available for comparisons . The proposed algorithms have favorable reconstruction error and the advantage of a fast implementation relative to the classical , unstructured , dictionaries .
In a recent paper , it is shown that the LASSO algorithm exhibits " near-ideal behavior , " in the following sense : Suppose $y = Az + \eta$ where $A$ satisfies the restricted isometry property ( RIP ) with a sufficiently small constant , and $\Vert \eta \Vert_0 \leq \epsilon$ . Then minimizing $\Vert z \Vert_0$ subject to $\Vert y - Az \Vert_0 \leq \epsilon$ leads to an estimate $\hat{x}$ whose error $\Vert \hat{x} - x \Vert_0$ is bounded by a universal constant times the error achieved by an " oracle " that knows the location of the nonzero components of $x$ . In the world of optimization , the LASSO algorithm has been generalized in several directions such as the group LASSO , the sparse group LASSO , either without or with tree-structured overlapping groups , and most recently , the sorted LASSO . In this paper , it is shown that {\it any algorithm\/} exhibits near-ideal behavior in the above sense , provided only that ( i ) the norm used to define the sparsity index is " decomposable , " ( ii ) the penalty norm that is minimized in an effort to enforce sparsity is " $\gamma$-decomposable , " and ( iii ) a " compressibility condition " in terms of a group restricted isometry property is satisfied . Specifically , the group LASSO , and the sparse group LASSO ( with some permissible overlap in the groups ) , as well as the sorted $\ell_0$-norm minimization all exhibit near-ideal behavior . Explicit bounds on the residual error are derived that contain previously known results as special cases .
Principal component analysis ( PCA ) for binary data , known as logistic PCA , has become a popular alternative to dimensionality reduction of binary data . It is motivated as an extension of ordinary PCA by means of a matrix factorization , akin to the singular value decomposition , that maximizes the Bernoulli log-likelihood . We propose a new formulation of logistic PCA which extends Pearson ' s formulation of a low dimensional data representation with minimum error to binary data . Our formulation does not require a matrix factorization , as previous methods do , but instead looks for projections of the natural parameters from the saturated model . Due to this difference , the number of parameters does not grow with the number of observations and the principal component scores on new data can be computed with simple matrix multiplication . We derive explicit solutions for data matrices of special structure and provide computationally efficient algorithms for solving for the principal component loadings . Through simulation experiments and an analysis of medical diagnoses data , we compare our formulation of logistic PCA to the previous formulation as well as ordinary PCA to demonstrate its benefits .
Most exact methods for k-nearest neighbour search suffer from the curse of dimensionality ; that is , their query times exhibit exponential dependence on either the ambient or the intrinsic dimensionality . Dynamic Continuous Indexing ( DCI ) offers a promising way of circumventing the curse and successfully reduces the dependence of query time on intrinsic dimensionality from exponential to sublinear . In this paper , we propose a variant of DCI , which we call Prioritized DCI , and show a remarkable improvement in the dependence of query time on intrinsic dimensionality . In particular , a linear increase in intrinsic dimensionality , or equivalently , an exponential increase in the number of points near a query , can be mostly counteracted with just a linear increase in space . We also demonstrate empirically that Prioritized DCI significantly outperforms prior methods . In particular , relative to Locality-Sensitive Hashing ( LSH ) , Prioritized DCI reduces the number of distance evaluations by a factor of 00 to 000 and the memory consumption by a factor of 00 .
We propose a novel general algorithm LHAC that efficiently uses second-order information to train a class of large-scale l0-regularized problems . Our method executes cheap iterations while achieving fast local convergence rate by exploiting the special structure of a low-rank matrix , constructed via quasi-Newton approximation of the Hessian of the smooth loss function . A greedy active-set strategy , based on the largest violations in the dual constraints , is employed to maintain a working set that iteratively estimates the complement of the optimal active set . This allows for smaller size of subproblems and eventually identifies the optimal active set . Empirical comparisons confirm that LHAC is highly competitive with several recently proposed state-of-the-art specialized solvers for sparse logistic regression and sparse inverse covariance matrix selection .
This paper considers the problem of canonical-correlation analysis ( CCA ) ( Hotelling , 0000 ) and , more broadly , the generalized eigenvector problem for a pair of symmetric matrices . These are two fundamental problems in data analysis and scientific computing with numerous applications in machine learning and statistics ( Shi and Malik , 0000 ; Hardoon et al . , 0000 ; Witten et al . , 0000 ) . We provide simple iterative algorithms , with improved runtimes , for solving these problems that are globally linearly convergent with moderate dependencies on the condition numbers and eigenvalue gaps of the matrices involved . We obtain our results by reducing CCA to the top-$k$ generalized eigenvector problem . We solve this problem through a general framework that simply requires black box access to an approximate linear system solver . Instantiating this framework with accelerated gradient descent we obtain a running time of $O ( \frac{z k \sqrt{\kappa}}{\rho} \log ( 0/\epsilon ) \log \left ( k\kappa/\rho\right ) ) $ where $z$ is the total number of nonzero entries , $\kappa$ is the condition number and $\rho$ is the relative eigenvalue gap of the appropriate matrices . Our algorithm is linear in the input size and the number of components $k$ up to a $\log ( k ) $ factor . This is essential for handling large-scale matrices that appear in practice . To the best of our knowledge this is the first such algorithm with global linear convergence . We hope that our results prompt further research and ultimately improve the practical running time for performing these important data analysis procedures on large data sets .
Stochastic gradient descent~ ( SGD ) and its variants have attracted much attention in machine learning due to their efficiency and effectiveness for optimization . To handle large-scale problems , researchers have recently proposed several lock-free strategy based parallel SGD~ ( LF-PSGD ) methods for multi-core systems . However , existing works have only proved the convergence of these LF-PSGD methods for convex problems . To the best of our knowledge , no work has proved the convergence of the LF-PSGD methods for non-convex problems . In this paper , we provide the theoretical proof about the convergence of two representative LF-PSGD methods , Hogwild ! and AsySVRG , for non-convex problems . Empirical results also show that both Hogwild ! and AsySVRG are convergent on non-convex problems , which successfully verifies our theoretical results .
We present a simple theoretical framework , and corresponding practical procedures , for comparing probabilistic models on real data in a traditional machine learning setting . This framework is based on the theory of proper scoring rules , but requires only basic algebra and probability theory to understand and verify . The theoretical concepts presented are well-studied , primarily in the statistics literature . The goal of this paper is to advocate their wider adoption for performance evaluation in empirical machine learning .
As enjoying the closed form solution , least squares support vector machine ( LSSVM ) has been widely used for classification and regression problems having the comparable performance with other types of SVMs . However , LSSVM has two drawbacks : sensitive to outliers and lacking sparseness . Robust LSSVM ( R-LSSVM ) overcomes the first partly via nonconvex truncated loss function , but the current algorithms for R-LSSVM with the dense solution are faced with the second drawback and are inefficient for training large-scale problems . In this paper , we interpret the robustness of R-LSSVM from a re-weighted viewpoint and give a primal R-LSSVM by the representer theorem . The new model may have sparse solution if the corresponding kernel matrix has low rank . Then approximating the kernel matrix by a low-rank matrix and smoothing the loss function by entropy penalty function , we propose a convergent sparse R-LSSVM ( SR-LSSVM ) algorithm to achieve the sparse solution of primal R-LSSVM , which overcomes two drawbacks of LSSVM simultaneously . The proposed algorithm has lower complexity than the existing algorithms and is very efficient for training large-scale problems . Many experimental results illustrate that SR-LSSVM can achieve better or comparable performance with less training time than related algorithms , especially for training large scale problems .
With the large volume of new information created every day , determining the validity of information in a knowledge graph and filling in its missing parts are crucial tasks for many researchers and practitioners . To address this challenge , a number of knowledge graph completion methods have been developed using low-dimensional graph embeddings . Although researchers continue to improve these models using an increasingly complex feature space , we show that simple changes in the architecture of the underlying model can outperform state-of-the-art models without the need for complex feature engineering . In this work , we present a shared variable neural network model called ProjE that fills-in missing information in a knowledge graph by learning joint embeddings of the knowledge graph ' s entities and edges , and through subtle , but important , changes to the standard loss function . In doing so , ProjE has a parameter size that is smaller than 00 out of 00 existing methods while performing $00\%$ better than the current-best method on standard datasets . We also show , via a new fact checking task , that ProjE is capable of accurately determining the veracity of many declarative statements .
Partial-monitoring games constitute a mathematical framework for sequential decision making problems with imperfect feedback : The learner repeatedly chooses an action , opponent responds with an outcome , and then the learner suffers a loss and receives a feedback signal , both of which are fixed functions of the action and the outcome . The goal of the learner is to minimize his total cumulative loss . We make progress towards the classification of these games based on their minimax expected regret . Namely , we classify almost all games with two outcomes and finite number of actions : We show that their minimax expected regret is either zero , $\widetilde{\Theta} ( \sqrt{T} ) $ , $\Theta ( T^{0/0} ) $ , or $\Theta ( T ) $ and we give a simple and efficiently computable classification of these four classes of games . Our hope is that the result can serve as a stepping stone toward classifying all finite partial-monitoring games .
Boolean matrix factorization and Boolean matrix completion from noisy observations are desirable unsupervised data-analysis methods due to their interpretability , but hard to perform due to their NP-hardness . We treat these problems as maximum a posteriori inference problems in a graphical model and present a message passing approach that scales linearly with the number of observations and factors . Our empirical study demonstrates that message passing is able to recover low-rank Boolean matrices , in the boundaries of theoretically possible recovery and compares favorably with state-of-the-art in real-world applications , such collaborative filtering with large-scale Boolean data .
We consider the problem of online linear regression on individual sequences . The goal in this paper is for the forecaster to output sequential predictions which are , after T time rounds , almost as good as the ones output by the best linear predictor in a given L0-ball in R^d . We consider both the cases where the dimension d is small and large relative to the time horizon T . We first present regret bounds with optimal dependencies on the sizes U , X and Y of the L0-ball , the input data and the observations . The minimax regret is shown to exhibit a regime transition around the point d = sqrt ( T ) U X / ( 0 Y ) . Furthermore , we present efficient algorithms that are adaptive , i . e . , they do not require the knowledge of U , X , and Y , but still achieve nearly optimal regret bounds .
We introduce a novel approach for training adversarial models by replacing the discriminator score with a bi-modal Gaussian distribution over the real/fake indicator variables . In order to do this , we train the Gaussian classifier to match the target bi-modal distribution implicitly through meta-adversarial training . We hypothesize that this approach ensures a non-zero gradient to the generator , even in the limit of a perfect classifier . We test our method against standard benchmark image datasets as well as show the classifier output distribution is smooth and has overlap between the real and fake modes .
We consider a class of misspecified dynamical models where the governing term is only approximately known . Under the assumption that observations of the system ' s evolution are accessible for various initial conditions , our goal is to infer a non-parametric correction to the misspecified driving term such as to faithfully represent the system dynamics and devise system evolution predictions for unobserved initial conditions . We model the unknown correction term as a Gaussian Process and analyze the problem of efficient experimental design to find an optimal correction term under constraints such as a limited experimental budget . We suggest a novel formulation for experimental design for this Gaussian Process and show that approximately optimal ( up to a constant factor ) designs may be efficiently derived by utilizing results from the literature on submodular optimization . Our numerical experiments exemplify the effectiveness of these techniques .
We propose a modified expectation-maximization algorithm by introducing the concept of quantum annealing , which we call the deterministic quantum annealing expectation-maximization ( DQAEM ) algorithm . The expectation-maximization ( EM ) algorithm is an established algorithm to compute maximum likelihood estimates and applied to many practical applications . However , it is known that EM heavily depends on initial values and its estimates are sometimes trapped by local optima . To solve such a problem , quantum annealing ( QA ) was proposed as a novel optimization approach motivated by quantum mechanics . By employing QA , we then formulate DQAEM and present a theorem that supports its stability . Finally , we demonstrate numerical simulations to confirm its efficiency .
In this paper , we present new results on using orthogonal matching pursuit ( OMP ) , to solve the sparse approximation problem over redundant dictionaries for complex cases ( i . e . , complex measurement vector , complex dictionary and complex additive white Gaussian noise ( CAWGN ) ) . A sufficient condition that OMP can recover the optimal representation of an exactly sparse signal in the complex cases is proposed both in noiseless and bound Gaussian noise settings . Similar to exact recovery condition ( ERC ) results in real cases , we extend them to complex case and derivate the corresponding ERC in the paper . It leverages this theory to show that OMP succeed for k-sparse signal from a class of complex dictionary . Besides , an application with geometrical theory of diffraction ( GTD ) model is presented for complex cases . Finally , simulation experiments illustrate the validity of the theoretical analysis .
The scientific method relies on the iterated processes of inference and inquiry . The inference phase consists of selecting the most probable models based on the available data ; whereas the inquiry phase consists of using what is known about the models to select the most relevant experiment . Optimizing inquiry involves searching the parameterized space of experiments to select the experiment that promises , on average , to be maximally informative . In the case where it is important to learn about each of the model parameters , the relevance of an experiment is quantified by Shannon entropy of the distribution of experimental outcomes predicted by a probable set of models . If the set of potential experiments is described by many parameters , we must search this high-dimensional entropy space . Brute force search methods will be slow and computationally expensive . We present an entropy-based search algorithm , called nested entropy sampling , to select the most informative experiment for efficient experimental design . This algorithm is inspired by Skilling ' s nested sampling algorithm used in inference and borrows the concept of a rising threshold while a set of experiment samples are maintained . We demonstrate that this algorithm not only selects highly relevant experiments , but also is more efficient than brute force search . Such entropic search techniques promise to greatly benefit autonomous experimental design .
Reliable microaneurysm detection in digital fundus images is still an open issue in medical image processing . We propose an ensemble-based framework to improve microaneurysm detection . Unlike the well-known approach of considering the output of multiple classifiers , we propose a combination of internal components of microaneurysm detectors , namely preprocessing methods and candidate extractors . We have evaluated our approach for microaneurysm detection in an online competition , where this algorithm is currently ranked as first and also on two other databases . Since microaneurysm detection is decisive in diabetic retinopathy grading , we also tested the proposed method for this task on the publicly available Messidor database , where a promising AUC 0 . 00 with 0 . 00 uncertainty is achieved in a ' DR/non-DR ' -type classification based on the presence or absence of the microaneurysms .
We show that the existence of a computationally efficient calibration algorithm , with a low weak calibration rate , would imply the existence of an efficient algorithm for computing approximate Nash equilibria - thus implying the unlikely conclusion that every problem in PPAD is solvable in polynomial time .
Canonical Correlation Analysis ( CCA ) is a widely used spectral technique for finding correlation structures in multi-view datasets . In this paper , we tackle the problem of large scale CCA , where classical algorithms , usually requiring computing the product of two huge matrices and huge matrix decomposition , are computationally and storage expensive . We recast CCA from a novel perspective and propose a scalable and memory efficient Augmented Approximate Gradient ( AppGrad ) scheme for finding top $k$ dimensional canonical subspace which only involves large matrix multiplying a thin matrix of width $k$ and small matrix decomposition of dimension $k\times k$ . Further , AppGrad achieves optimal storage complexity $O ( k ( p_0+p_0 ) ) $ , compared with classical algorithms which usually require $O ( p_0^0+p_0^0 ) $ space to store two dense whitening matrices . The proposed scheme naturally generalizes to stochastic optimization regime , especially efficient for huge datasets where batch algorithms are prohibitive . The online property of stochastic AppGrad is also well suited to the streaming scenario , where data comes sequentially . To the best of our knowledge , it is the first stochastic algorithm for CCA . Experiments on four real data sets are provided to show the effectiveness of the proposed methods .
Variable selection for models including interactions between explanatory variables often needs to obey certain hierarchical constraints . The weak or strong structural hierarchy requires that the existence of an interaction term implies at least one or both associated main effects to be present in the model . Lately , this problem has attracted a lot of attention , but existing computational algorithms converge slow even with a moderate number of predictors . Moreover , in contrast to the rich literature on ordinary variable selection , there is a lack of statistical theory to show reasonably low error rates of hierarchical variable selection . This work investigates a new class of estimators that make use of multiple group penalties to capture structural parsimony . We give the minimax lower bounds for strong and weak hierarchical variable selection and show that the proposed estimators enjoy sharp rate oracle inequalities . A general-purpose algorithm is developed with guaranteed convergence and global optimality . Simulations and real data experiments demonstrate the efficiency and efficacy of the proposed approach .
In this note we prove that reconstruction from magnitudes of frame coefficients ( the so called " phase retrieval problem " ) can be performed using Lipschitz continuous maps . Specifically we show that when the nonlinear analysis map $\alpha : {\mathcal H}\rightarrow\mathbb{R}^m$ is injective , with $ ( \alpha ( x ) ) _k=|<x , f_k>|^0$ , where $\{f_0 , \ldots , f_m\}$ is a frame for the Hilbert space ${\mathcal H}$ , then there exists a left inverse map $\omega : \mathbb{R}^m\rightarrow {\mathcal H}$ that is Lipschitz continuous . Additionally we obtain the Lipschitz constant of this inverse map in terms of the lower Lipschitz constant of $\alpha$ . Surprisingly the increase in Lipschitz constant is independent of the space dimension or frame redundancy .
Deep generative models are reported to be useful in broad applications including image generation . Repeated inference between data space and latent space in these models can denoise cluttered images and improve the quality of inferred results . However , previous studies only qualitatively evaluated image outputs in data space , and the mechanism behind the inference has not been investigated . The purpose of the current study is to numerically analyze changes in activity patterns of neurons in the latent space of a deep generative model called a " variational auto-encoder " ( VAE ) . What kinds of inference dynamics the VAE demonstrates when noise is added to the input data are identified . The VAE embeds a dataset with clear cluster structures in the latent space and the center of each cluster of multiple correlated data points ( memories ) is referred as the concept . Our study demonstrated that transient dynamics of inference first approaches a concept , and then moves close to a memory . Moreover , the VAE revealed that the inference dynamics approaches a more abstract concept to the extent that the uncertainty of input data increases due to noise . It was demonstrated that by increasing the number of the latent variables , the trend of the inference dynamics to approach a concept can be enhanced , and the generalization ability of the VAE can be improved .
We present a theoretical analysis of Gaussian-binary restricted Boltzmann machines ( GRBMs ) from the perspective of density models . The key aspect of this analysis is to show that GRBMs can be formulated as a constrained mixture of Gaussians , which gives a much better insight into the model ' s capabilities and limitations . We show that GRBMs are capable of learning meaningful features both in a two-dimensional blind source separation task and in modeling natural images . Further , we show that reported difficulties in training GRBMs are due to the failure of the training algorithm rather than the model itself . Based on our analysis we are able to propose several training recipes , which allowed successful and fast training in our experiments . Finally , we discuss the relationship of GRBMs to several modifications that have been proposed to improve the model .
We study the complexity of functions computable by deep feedforward neural networks with piecewise linear activations in terms of the symmetries and the number of linear regions that they have . Deep networks are able to sequentially map portions of each layer ' s input-space to the same output . In this way , deep models compute functions that react equally to complicated patterns of different inputs . The compositional structure of these functions enables them to re-use pieces of computation exponentially often in terms of the network ' s depth . This paper investigates the complexity of such compositional maps and contributes new theoretical results regarding the advantage of depth for neural networks with piecewise linear activation functions . In particular , our analysis is not specific to a single family of models , and as an example , we employ it for rectifier and maxout networks . We improve complexity bounds from pre-existing work and investigate the behavior of units in higher layers .
Numerous important problems can be framed as learning from graph data . We propose a framework for learning convolutional neural networks for arbitrary graphs . These graphs may be undirected , directed , and with both discrete and continuous node and edge attributes . Analogous to image-based convolutional networks that operate on locally connected regions of the input , we present a general approach to extracting locally connected regions from graphs . Using established benchmark data sets , we demonstrate that the learned feature representations are competitive with state of the art graph kernels and that their computation is highly efficient .
Learning from demonstration ( LfD ) is the process of building behavioral models of a task from demonstrations provided by an expert . These models can be used e . g . for system control by generalizing the expert demonstrations to previously unencountered situations . Most LfD methods , however , make strong assumptions about the expert behavior , e . g . they assume the existence of a deterministic optimal ground truth policy or require direct monitoring of the expert ' s controls , which limits their practical use as part of a general system identification framework . In this work , we consider the LfD problem in a more general setting where we allow for arbitrary stochastic expert policies , without reasoning about the optimality of the demonstrations . Following a Bayesian methodology , we model the full posterior distribution of possible expert controllers that explain the provided demonstration data . Moreover , we show that our methodology can be applied in a nonparametric context to infer the complexity of the state representation used by the expert , and to learn task-appropriate partitionings of the system state space .
This paper presents a novel model for multimodal learning based on gated neural networks . The Gated Multimodal Unit ( GMU ) model is intended to be used as an internal unit in a neural network architecture whose purpose is to find an intermediate representation based on a combination of data from different modalities . The GMU learns to decide how modalities influence the activation of the unit using multiplicative gates . It was evaluated on a multilabel scenario for genre classification of movies using the plot and the poster . The GMU improved the macro f-score performance of single-modality approaches and outperformed other fusion strategies , including mixture of experts models . Along with this work , the MM-IMDb dataset is released which , to the best of our knowledge , is the largest publicly available multimodal dataset for genre prediction on movies .
Theoretical studies have proven that the Hilbert space has remarkable performance in many fields of applications . Frames in tensor product of Hilbert spaces were introduced to generalize the inner product to high-order tensors . However , these techniques require tensor decomposition which could lead to the loss of information and it is a NP-hard problem to determine the rank of tensors . Here , we present a new framework , namely matrix Hilbert space to perform a matrix inner product space when data observations are represented as matrices . We preserve the structure of initial data and multi-way correlation among them is captured in the process . In addition , we extend the reproducing kernel Hilbert space ( RKHS ) to reproducing kernel matrix Hilbert space ( RKMHS ) and propose an equivalent condition of the space uses of the certain kernel function . A new family of kernels is introduced in our framework to apply the classifier of Support Tensor Machine ( STM ) and comparative experiments are performed on a number of real-world datasets to support our contributions .
This paper focuses on obtaining clustering information about a distribution from its i . i . d . samples . We develop theoretical results to understand and use clustering information contained in the eigenvectors of data adjacency matrices based on a radial kernel function with a sufficiently fast tail decay . In particular , we provide population analyses to gain insights into which eigenvectors should be used and when the clustering information for the distribution can be recovered from the sample . We learn that a fixed number of top eigenvectors might at the same time contain redundant clustering information and miss relevant clustering information . We use this insight to design the data spectroscopic clustering ( DaSpec ) algorithm that utilizes properly selected eigenvectors to determine the number of clusters automatically and to group the data accordingly . Our findings extend the intuitions underlying existing spectral techniques such as spectral clustering and Kernel Principal Components Analysis , and provide new understanding into their usability and modes of failure . Simulation studies and experiments on real-world data are conducted to show the potential of our algorithm . In particular , DaSpec is found to handle unbalanced groups and recover clusters of different shapes better than the competing methods .
We extend a recent synchronization analysis of exact finite-state sources to nonexact sources for which synchronization occurs only asymptotically . Although the proof methods are quite different , the primary results remain the same . We find that an observer ' s average uncertainty in the source state vanishes exponentially fast and , as a consequence , an observer ' s average uncertainty in predicting future output converges exponentially fast to the source entropy rate .
We propose a hierarchy for approximate inference based on the Dobrushin , Lanford , Ruelle ( DLR ) equations . This hierarchy includes existing algorithms , such as belief propagation , and also motivates novel algorithms such as factorized neighbors ( FN ) algorithms and variants of mean field ( MF ) algorithms . In particular , we show that extrema of the Bethe free energy correspond to approximate solutions of the DLR equations . In addition , we demonstrate a close connection between these approximate algorithms and Gibbs sampling . Finally , we compare and contrast various of the algorithms in the DLR hierarchy on spin-glass problems . The experiments show that algorithms higher up in the hierarchy give more accurate results when they converge but tend to be less stable .
Contextual bandit learning is an increasingly popular approach to optimizing recommender systems via user feedback , but can be slow to converge in practice due to the need for exploring a large feature space . In this paper , we propose a coarse-to-fine hierarchical approach for encoding prior knowledge that drastically reduces the amount of exploration required . Intuitively , user preferences can be reasonably embedded in a coarse low-dimensional feature space that can be explored efficiently , requiring exploration in the high-dimensional space only as necessary . We introduce a bandit algorithm that explores within this coarse-to-fine spectrum , and prove performance guarantees that depend on how well the coarse space captures the user ' s preferences . We demonstrate substantial improvement over conventional bandit algorithms through extensive simulation as well as a live user study in the setting of personalized news recommendation .
Modeling data with linear combinations of a few elements from a learned dictionary has been the focus of much recent research in machine learning , neuroscience and signal processing . For signals such as natural images that admit such sparse representations , it is now well established that these models are well suited to restoration tasks . In this context , learning the dictionary amounts to solving a large-scale matrix factorization problem , which can be done efficiently with classical optimization tools . The same approach has also been used for learning features from data for other purposes , e . g . , image classification , but tuning the dictionary in a supervised way for these tasks has proven to be more difficult . In this paper , we present a general formulation for supervised dictionary learning adapted to a wide variety of tasks , and present an efficient algorithm for solving the corresponding optimization problem . Experiments on handwritten digit classification , digital art identification , nonlinear inverse image problems , and compressed sensing demonstrate that our approach is effective in large-scale settings , and is well suited to supervised and semi-supervised classification , as well as regression tasks for data that admit sparse representations .
We present a robust alternative to principal component analysis ( PCA ) --- called elliptical component analysis ( ECA ) --- for analyzing high dimensional , elliptically distributed data . ECA estimates the eigenspace of the covariance matrix of the elliptical data . To cope with heavy-tailed elliptical distributions , a multivariate rank statistic is exploited . At the model-level , we consider two settings : either that the leading eigenvectors of the covariance matrix are non-sparse or that they are sparse . Methodologically , we propose ECA procedures for both non-sparse and sparse settings . Theoretically , we provide both non-asymptotic and asymptotic analyses quantifying the theoretical performances of ECA . In the non-sparse setting , we show that ECA ' s performance is highly related to the effective rank of the covariance matrix . In the sparse setting , the results are twofold : ( i ) We show that the sparse ECA estimator based on a combinatoric program attains the optimal rate of convergence ; ( ii ) Based on some recent developments in estimating sparse leading eigenvectors , we show that a computationally efficient sparse ECA estimator attains the optimal rate of convergence under a suboptimal scaling .
Existing models based on artificial neural networks ( ANNs ) for sentence classification often do not incorporate the context in which sentences appear , and classify sentences individually . However , traditional sentence classification approaches have been shown to greatly benefit from jointly classifying subsequent sentences , such as with conditional random fields . In this work , we present an ANN architecture that combines the effectiveness of typical ANN models to classify sentences in isolation , with the strength of structured prediction . Our model achieves state-of-the-art results on two different datasets for sequential sentence classification in medical abstracts .
Linear dimensionality reduction techniques are powerful tools for image analysis as they allow the identification of important features in a data set . In particular , nonnegative matrix factorization ( NMF ) has become very popular as it is able to extract sparse , localized and easily interpretable features by imposing an additive combination of nonnegative basis elements . Nonnegative matrix underapproximation ( NMU ) is a closely related technique that has the advantage to identify features sequentially . In this paper , we propose a variant of NMU that is particularly well suited for image analysis as it incorporates the spatial information , that is , it takes into account the fact that neighboring pixels are more likely to be contained in the same features , and favors the extraction of localized features by looking for sparse basis elements . We show that our new approach competes favorably with comparable state-of-the-art techniques on synthetic , facial and hyperspectral image data sets .
As an increasing number of genome-wide association studies reveal the limitations of attempting to explain phenotypic heritability by single genetic loci , there is growing interest for associating complex phenotypes with sets of genetic loci . While several methods for multi-locus mapping have been proposed , it is often unclear how to relate the detected loci to the growing knowledge about gene pathways and networks . The few methods that take biological pathways or networks into account are either restricted to investigating a limited number of predetermined sets of loci , or do not scale to genome-wide settings . We present SConES , a new efficient method to discover sets of genetic loci that are maximally associated with a phenotype , while being connected in an underlying network . Our approach is based on a minimum cut reformulation of the problem of selecting features under sparsity and connectivity constraints that can be solved exactly and rapidly . SConES outperforms state-of-the-art competitors in terms of runtime , scales to hundreds of thousands of genetic loci , and exhibits higher power in detecting causal SNPs in simulation studies than existing methods . On flowering time phenotypes and genotypes from Arabidopsis thaliana , SConES detects loci that enable accurate phenotype prediction and that are supported by the literature . Matlab code for SConES is available at http : //webdav . tuebingen . mpg . de/u/karsten/Forschung/scones/
We introduce a method to learn a mixture of submodular " shells " in a large-margin setting . A submodular shell is an abstract submodular function that can be instantiated with a ground set and a set of parameters to produce a submodular function . A mixture of such shells can then also be so instantiated to produce a more complex submodular function . What our algorithm learns are the mixture weights over such shells . We provide a risk bound guarantee when learning in a large-margin structured-prediction setting using a projected subgradient method when only approximate submodular optimization is possible ( such as with submodular function maximization ) . We apply this method to the problem of multi-document summarization and produce the best results reported so far on the widely used NIST DUC-00 through DUC-00 document summarization corpora .
Recent advances in stochastic gradient techniques have made it possible to estimate posterior distributions from large datasets via Markov Chain Monte Carlo ( MCMC ) . However , when the target posterior is multimodal , mixing performance is often poor . This results in inadequate exploration of the posterior distribution . A framework is proposed to improve the sampling efficiency of stochastic gradient MCMC , based on Hamiltonian Monte Carlo . A generalized kinetic function is leveraged , delivering superior stationary mixing , especially for multimodal distributions . Techniques are also discussed to overcome the practical issues introduced by this generalization . It is shown that the proposed approach is better at exploring complex multimodal posterior distributions , as demonstrated on multiple applications and in comparison with other stochastic gradient MCMC methods .
As a model problem for clustering , we consider the densest k-disjoint-clique problem of partitioning a weighted complete graph into k disjoint subgraphs such that the sum of the densities of these subgraphs is maximized . We establish that such subgraphs can be recovered from the solution of a particular semidefinite relaxation with high probability if the input graph is sampled from a distribution of clusterable graphs . Specifically , the semidefinite relaxation is exact if the graph consists of k large disjoint subgraphs , corresponding to clusters , with weight concentrated within these subgraphs , plus a moderate number of outliers . Further , we establish that if noise is weakly obscuring these clusters , i . e , the between-cluster edges are assigned very small weights , then we can recover significantly smaller clusters . For example , we show that in approximately sparse graphs , where the between-cluster weights tend to zero as the size n of the graph tends to infinity , we can recover clusters of size polylogarithmic in n . Empirical evidence from numerical simulations is also provided to support these theoretical phase transitions to perfect recovery of the cluster structure .
We present in this work a new family of kernels to compare positive measures on arbitrary spaces $\Xcal$ endowed with a positive kernel $\kappa$ , which translates naturally into kernels between histograms or clouds of points . We first cover the case where $\Xcal$ is Euclidian , and focus on kernels which take into account the variance matrix of the mixture of two measures to compute their similarity . The kernels we define are semigroup kernels in the sense that they only use the sum of two measures to compare them , and spectral in the sense that they only use the eigenspectrum of the variance matrix of this mixture . We show that such a family of kernels has close bonds with the laplace transforms of nonnegative-valued functions defined on the cone of positive semidefinite matrices , and we present some closed formulas that can be derived as special cases of such integral expressions . By focusing further on functions which are invariant to the addition of a null eigenvalue to the spectrum of the variance matrix , we can define kernels between atomic measures on arbitrary spaces $\Xcal$ endowed with a kernel $\kappa$ by using directly the eigenvalues of the centered Gram matrix of the joined support of the compared measures . We provide explicit formulas suited for applications and present preliminary experiments to illustrate the interest of the approach .
Scaling clustering algorithms to massive data sets is a challenging task . Recently , several successful approaches based on data summarization methods , such as coresets and sketches , were proposed . While these techniques provide provably good and small summaries , they are inherently problem dependent - the practitioner has to commit to a fixed clustering objective before even exploring the data . However , can one construct small data summaries for a wide range of clustering problems simultaneously ? In this work , we affirmatively answer this question by proposing an efficient algorithm that constructs such one-shot summaries for k-clustering problems while retaining strong theoretical guarantees .
Networked data , in which every training example involves two objects and may share some common objects with others , is used in many machine learning tasks such as learning to rank and link prediction . A challenge of learning from networked examples is that target values are not known for some pairs of objects . In this case , neither the classical i . i . d . \ assumption nor techniques based on complete U-statistics can be used . Most existing theoretical results of this problem only deal with the classical empirical risk minimization ( ERM ) principle that always weights every example equally , but this strategy leads to unsatisfactory bounds . We consider general weighted ERM and show new universal risk bounds for this problem . These new bounds naturally define an optimization problem which leads to appropriate weights for networked examples . Though this optimization problem is not convex in general , we devise a new fully polynomial-time approximation scheme ( FPTAS ) to solve it .
This paper proposes a new algorithm for controlling classification results by generating a small additive perturbation without changing the classifier network . Our work is inspired by existing works generating adversarial perturbation that worsens classification performance . In contrast to the existing methods , our work aims to generate perturbations that can enhance overall classification performance . To solve this performance enhancement problem , we newly propose a perturbation generation network ( PGN ) influenced by the adversarial learning strategy . In our problem , the information in a large external dataset is summarized by a small additive perturbation , which helps to improve the performance of the classifier trained with the target dataset . In addition to this performance enhancement problem , we show that the proposed PGN can be adopted to solve the classical adversarial problem without utilizing the information on the target classifier . The mentioned characteristics of our method are verified through extensive experiments on publicly available visual datasets .
Discovering causal relations among observed variables in a given data set is a major objective in studies of statistics and artificial intelligence . Recently , some techniques to discover a unique causal model have been explored based on non-Gaussianity of the observed data distribution . However , most of these are limited to continuous data . In this paper , we present a novel causal model for binary data and propose an efficient new approach to deriving the unique causal model governing a given binary data set under skew distributions of external binary noises . Experimental evaluation shows excellent performance for both artificial and real world data sets .
In this work , we propose a generalized product of experts ( gPoE ) framework for combining the predictions of multiple probabilistic models . We identify four desirable properties that are important for scalability , expressiveness and robustness , when learning and inferring with a combination of multiple models . Through analysis and experiments , we show that gPoE of Gaussian processes ( GP ) have these qualities , while no other existing combination schemes satisfy all of them at the same time . The resulting GP-gPoE is highly scalable as individual GP experts can be independently learned in parallel ; very expressive as the way experts are combined depends on the input rather than fixed ; the combined prediction is still a valid probabilistic model with natural interpretation ; and finally robust to unreliable predictions from individual experts .
Probabilistic graphical models ( PGMs ) have become a popular tool for computational analysis of biological data in a variety of domains . But , what exactly are they and how do they work ? How can we use PGMs to discover patterns that are biologically relevant ? And to what extent can PGMs help us formulate new hypotheses that are testable at the bench ? This note sketches out some answers and illustrates the main ideas behind the statistical approach to biological pattern discovery .
In the recent years , we have witnessed the development of multi-label classification methods which utilize the structure of the label space in a divide and conquer approach to improve classification performance and allow large data sets to be classified efficiently . Yet most of the available data sets have been provided in train/test splits that did not account for maintaining a distribution of higher-order relationships between labels among splits or folds . We present a new approach to stratifying multi-label data for classification purposes based on the iterative stratification approach proposed by Sechidis et . al . in an ECML PKDD 0000 paper . Our method extends the iterative approach to take into account second-order relationships between labels . Obtained results are evaluated using statistical properties of obtained strata as presented by Sechidis . We also propose new statistical measures relevant to second-order quality : label pairs distribution , the percentage of label pairs without positive evidence in folds and label pair - fold pairs that have no positive evidence for the label pair . We verify the impact of new methods on classification performance of Binary Relevance , Label Powerset and a fast greedy community detection based label space partitioning classifier . Random Forests serve as base classifiers . We check the variation of the number of communities obtained per fold , and the stability of their modularity score . Second-Order Iterative Stratification is compared to standard k-fold , label set , and iterative stratification . The proposed approach lowers the variance of classification quality , improves label pair oriented measures and example distribution while maintaining a competitive quality in label-oriented measures . We also witness an increase in stability of network characteristics .
Sales forecast is an essential task in E-commerce and has a crucial impact on making informed business decisions . It can help us to manage the workforce , cash flow and resources such as optimizing the supply chain of manufacturers etc . Sales forecast is a challenging problem in that sales is affected by many factors including promotion activities , price changes , and user preferences etc . Traditional sales forecast techniques mainly rely on historical sales data to predict future sales and their accuracies are limited . Some more recent learning-based methods capture more information in the model to improve the forecast accuracy . However , these methods require case-by-case manual feature engineering for specific commercial scenarios , which is usually a difficult , time-consuming task and requires expert knowledge . To overcome the limitations of existing methods , we propose a novel approach in this paper to learn effective features automatically from the structured data using the Convolutional Neural Network ( CNN ) . When fed with raw log data , our approach can automatically extract effective features from that and then forecast sales using those extracted features . We test our method on a large real-world dataset from CaiNiao . com and the experimental results validate the effectiveness of our method .
In distributed , or privacy-preserving learning , we are often given a set of probabilistic models estimated from different local repositories , and asked to combine them into a single model that gives efficient statistical estimation . A simple method is to linearly average the parameters of the local models , which , however , tends to be degenerate or not applicable on non-convex models , or models with different parameter dimensions . One more practical strategy is to generate bootstrap samples from the local models , and then learn a joint model based on the combined bootstrap set . Unfortunately , the bootstrap procedure introduces additional noise and can significantly deteriorate the performance . In this work , we propose two variance reduction methods to correct the bootstrap noise , including a weighted M-estimator that is both statistically efficient and practically powerful . Both theoretical and empirical analysis is provided to demonstrate our methods .
We study the stochastic Riemannian gradient algorithm for matrix eigen-decomposition . The state-of-the-art stochastic Riemannian algorithm requires the learning rate to decay to zero and thus suffers from slow convergence and sub-optimal solutions . In this paper , we address this issue by deploying the variance reduction ( VR ) technique of stochastic gradient descent ( SGD ) . The technique was originally developed to solve convex problems in the Euclidean space . We generalize it to Riemannian manifolds and realize it to solve the non-convex eigen-decomposition problem . We are the first to propose and analyze the generalization of SVRG to Riemannian manifolds . Specifically , we propose the general variance reduction form , SVRRG , in the framework of the stochastic Riemannian gradient optimization . It ' s then specialized to the problem with eigensolvers and induces the SVRRG-EIGS algorithm . We provide a novel and elegant theoretical analysis on this algorithm . The theory shows that a fixed learning rate can be used in the Riemannian setting with an exponential global convergence rate guaranteed . The theoretical results make a significant improvement over existing studies , with the effectiveness empirically verified .
We consider the multi armed bandit problem in non-stationary environments . Based on the Bayesian method , we propose a variant of Thompson Sampling which can be used in both rested and restless bandit scenarios . Applying discounting to the parameters of prior distribution , we describe a way to systematically reduce the effect of past observations . Further , we derive the exact expression for the probability of picking sub-optimal arms . By increasing the exploitative value of Bayes ' samples , we also provide an optimistic version of the algorithm . Extensive empirical analysis is conducted under various scenarios to validate the utility of proposed algorithms . A comparison study with various state-of-the-arm algorithms is also included .
The Nearest subspace classifier ( NSS ) finds an estimation of the underlying subspace within each class and assigns data points to the class that corresponds to its nearest subspace . This paper mainly studies how well NSS can be generalized to new samples . It is proved that NSS is strongly consistent under certain assumptions . For completeness , NSS is evaluated through experiments on various simulated and real data sets , in comparison with some other linear model based classifiers . It is also shown that NSS can obtain effective classification results and is very efficient , especially for large scale data sets .
Machine Learning ( ML ) models are applied in a variety of tasks such as network intrusion detection or Malware classification . Yet , these models are vulnerable to a class of malicious inputs known as adversarial examples . These are slightly perturbed inputs that are classified incorrectly by the ML model . The mitigation of these adversarial inputs remains an open problem . As a step towards understanding adversarial examples , we show that they are not drawn from the same distribution than the original data , and can thus be detected using statistical tests . Using thus knowledge , we introduce a complimentary approach to identify specific inputs that are adversarial . Specifically , we augment our ML model with an additional output , in which the model is trained to classify all adversarial inputs . We evaluate our approach on multiple adversarial example crafting methods ( including the fast gradient sign and saliency map methods ) with several datasets . The statistical test flags sample sets containing adversarial inputs confidently at sample sizes between 00 and 000 data points . Furthermore , our augmented model either detects adversarial examples as outliers with high accuracy ( > 00% ) or increases the adversary ' s cost - the perturbation added - by more than 000% . In this way , we show that statistical properties of adversarial examples are essential to their detection .
Given a real matrix A with n columns , the problem is to approximate the Gram product AA^T by c << n weighted outer products of columns of A . Necessary and sufficient conditions for the exact computation of AA^T ( in exact arithmetic ) from c >= rank ( A ) columns depend on the right singular vector matrix of A . For a Monte-Carlo matrix multiplication algorithm by Drineas et al . that samples outer products , we present probabilistic bounds for the 0-norm relative error due to randomization . The bounds depend on the stable rank or the rank of A , but not on the matrix dimensions . Numerical experiments illustrate that the bounds are informative , even for stringent success probabilities and matrices of small dimension . We also derive bounds for the smallest singular value and the condition number of matrices obtained by sampling rows from orthonormal matrices .
We consider two closely related problems : planted clustering and submatrix localization . The planted clustering problem assumes that a random graph is generated based on some underlying clusters of the nodes ; the task is to recover these clusters given the graph . The submatrix localization problem concerns locating hidden submatrices with elevated means inside a large real-valued random matrix . Of particular interest is the setting where the number of clusters/submatrices is allowed to grow unbounded with the problem size . These formulations cover several classical models such as planted clique , planted densest subgraph , planted partition , planted coloring , and stochastic block model , which are widely used for studying community detection and clustering/bi-clustering . For both problems , we show that the space of the model parameters ( cluster/submatrix size , cluster density , and submatrix mean ) can be partitioned into four disjoint regions corresponding to decreasing statistical and computational complexities : ( 0 ) the \emph{impossible} regime , where all algorithms fail ; ( 0 ) the \emph{hard} regime , where the computationally expensive Maximum Likelihood Estimator ( MLE ) succeeds ; ( 0 ) the \emph{easy} regime , where the polynomial-time convexified MLE succeeds ; ( 0 ) the \emph{simple} regime , where a simple counting/thresholding procedure succeeds . Moreover , we show that each of these algorithms provably fails in the previous harder regimes . Our theorems establish the minimax recovery limit , which are tight up to constants and hold with a growing number of clusters/submatrices , and provide a stronger performance guarantee than previously known for polynomial-time algorithms . Our study demonstrates the tradeoffs between statistical and computational considerations , and suggests that the minimax recovery limit may not be achievable by polynomial-time algorithms .
We introduce a new principle for model selection in regression and classification . Many regression models are controlled by some smoothness or flexibility or complexity parameter c , e . g . the number of neighbors to be averaged over in k nearest neighbor ( kNN ) regression or the polynomial degree in regression with polynomials . Let f_D^c be the ( best ) regressor of complexity c on data D . A more flexible regressor can fit more data D ' well than a more rigid one . If something ( here small loss ) is easy to achieve it ' s typically worth less . We define the loss rank of f_D^c as the number of other ( fictitious ) data D ' that are fitted better by f_D ' ^c than D is fitted by f_D^c . We suggest selecting the model complexity c that has minimal loss rank ( LoRP ) . Unlike most penalized maximum likelihood variants ( AIC , BIC , MDL ) , LoRP only depends on the regression function and loss function . It works without a stochastic noise model , and is directly applicable to any non-parametric regressor , like kNN . In this paper we formalize , discuss , and motivate LoRP , study it for specific regression problems , in particular linear ones , and compare it to other model selection schemes .
In this study , the authors develop a structural model that combines a macro diffusion model with a micro choice model to control for the effect of social influence on the mobile app choices of customers over app stores . Social influence refers to the density of adopters within the proximity of other customers . Using a large data set from an African app store and Bayesian estimation methods , the authors quantify the effect of social influence and investigate the impact of ignoring this process in estimating customer choices . The findings show that customer choices in the app store are explained better by offline than online density of adopters and that ignoring social influence in estimations results in biased estimates . Furthermore , the findings show that the mobile app adoption process is similar to adoption of music CDs , among all other classic economy goods . A counterfactual analysis shows that the app store can increase its revenue by 00 . 0% through a viral marketing policy ( e . g . , a sharing with friends and family button ) .
We consider the high-dimensional heteroscedastic regression model , where the mean and the log variance are modeled as a linear combination of input variables . Existing literature on high-dimensional linear regres- sion models has largely ignored non-constant error variances , even though they commonly occur in a variety of applications ranging from biostatis- tics to finance . In this paper we study a class of non-convex penalized pseudolikelihood estimators for both the mean and variance parameters . We show that the Heteroscedastic Iterative Penalized Pseudolikelihood Optimizer ( HIPPO ) achieves the oracle property , that is , we prove that the rates of convergence are the same as if the true model was known . We demonstrate numerical properties of the procedure on a simulation study and real world data .
Principal Component Analysis ( PCA ) has wide applications in machine learning , text mining and computer vision . Classical PCA based on a Gaussian noise model is fragile to noise of large magnitude . Laplace noise assumption based PCA methods cannot deal with dense noise effectively . In this paper , we propose Cauchy Principal Component Analysis ( Cauchy PCA ) , a very simple yet effective PCA method which is robust to various types of noise . We utilize Cauchy distribution to model noise and derive Cauchy PCA under the maximum likelihood estimation ( MLE ) framework with low rank constraint . Our method can robustly estimate the low rank matrix regardless of whether noise is large or small , dense or sparse . We analyze the robustness of Cauchy PCA from a robust statistics view and present an efficient singular value projection optimization method . Experimental results on both simulated data and real applications demonstrate the robustness of Cauchy PCA to various noise patterns .
The concepts of unitary evolution matrices and associative memory have boosted the field of Recurrent Neural Networks ( RNN ) to state-of-the-art performance in a variety of sequential tasks . However , RNN still have a limited capacity to manipulate long-term memory . To bypass this weakness the most successful applications of RNN use external techniques such as attention mechanisms . In this paper we propose a novel RNN model that unifies the state-of-the-art approaches : Rotational Unit of Memory ( RUM ) . The core of RUM is its rotational operation , which is , naturally , a unitary matrix , providing architectures with the power to learn long-term dependencies by overcoming the vanishing and exploding gradients problem . Moreover , the rotational unit also serves as associative memory . We evaluate our model on synthetic memorization , question answering and language modeling tasks . RUM learns the Copying Memory task completely and improves the state-of-the-art result in the Recall task . RUM ' s performance in the bAbI Question Answering task is comparable to that of models with attention mechanism . We also improve the state-of-the-art result to 0 . 000 bits-per-character ( BPC ) loss in the Character Level Penn Treebank ( PTB ) task , which is to signify the applications of RUM to real-world sequential data . The universality of our construction , at the core of RNN , establishes RUM as a promising approach to language modeling , speech recognition and machine translation .
We consider the problem of clustering a set of high-dimensional data points into sets of low-dimensional linear subspaces . The number of subspaces , their dimensions , and their orientations are unknown . We propose a simple and low-complexity clustering algorithm based on thresholding the correlations between the data points followed by spectral clustering . A probabilistic performance analysis shows that this algorithm succeeds even when the subspaces intersect , and when the dimensions of the subspaces scale ( up to a log-factor ) linearly in the ambient dimension . Moreover , we prove that the algorithm also succeeds for data points that are subject to erasures with the number of erasures scaling ( up to a log-factor ) linearly in the ambient dimension . Finally , we propose a simple scheme that provably detects outliers .
We introduce a simple permutation equivariant layer for deep learning with set structure . This type of layer , obtained by parameter-sharing , has a simple implementation and linear-time complexity in the size of each set . We use deep permutation-invariant networks to perform point-could classification and MNIST-digit summation , where in both cases the output is invariant to permutations of the input . In a semi-supervised setting , where the goal is make predictions for each instance within a set , we demonstrate the usefulness of this type of layer in set-outlier detection as well as semi-supervised learning with clustering side-information .
We explore the energy landscape of a simple neural network . In particular , we expand upon previous work demonstrating that the empirical complexity of fitted neural networks is vastly less than a naive parameter count would suggest and that this implicit regularization is actually beneficial for generalization from fitted models .
We study the robustness properties of $\ell_0$ norm minimization for the classical linear regression problem with a given design matrix and contamination restricted to the dependent variable . We perform a fine error analysis of the $\ell_0$ estimator for measurements errors consisting of outliers coupled with noise . We introduce a new estimation technique resulting from a regularization of $\ell_0$ minimization by inf-convolution with the $\ell_0$ norm . Concerning robustness to large outliers , the proposed estimator keeps the breakdown point of the $\ell_0$ estimator , and reduces to least squares when there are not outliers . We present a globally convergent forward-backward algorithm for computing our estimator and some numerical experiments confirming its theoretical properties .
We investigate the issue of model selection and the use of the nonconformity ( strangeness ) measure in batch learning . Using the nonconformity measure we propose a new training algorithm that helps avoid the need for Cross-Validation or Leave-One-Out model selection strategies . We provide a new generalisation error bound using the notion of nonconformity to upper bound the loss of each test example and show that our proposed approach is comparable to standard model selection methods , but with theoretical guarantees of success and faster convergence . We demonstrate our novel model selection technique using the Support Vector Machine .
Artificial intelligence ( AI ) generally and machine learning ( ML ) specifically demonstrate impressive practical success in many different application domains , e . g . in autonomous driving , speech recognition , or recommender systems . Deep learning approaches , trained on extremely large data sets or using reinforcement learning methods have even exceeded human performance in visual tasks , particularly on playing games such as Atari , or mastering the game of Go . Even in the medical domain there are remarkable results . The central problem of such models is that they are regarded as black-box models and even if we understand the underlying mathematical principles , they lack an explicit declarative knowledge representation , hence have difficulty in generating the underlying explanatory structures . This calls for systems enabling to make decisions transparent , understandable and explainable . A huge motivation for our approach are rising legal and privacy aspects . The new European General Data Protection Regulation entering into force on May 00th 0000 , will make black-box approaches difficult to use in business . This does not imply a ban on automatic learning approaches or an obligation to explain everything all the time , however , there must be a possibility to make the results re-traceable on demand . In this paper we outline some of our research topics in the context of the relatively new area of explainable-AI with a focus on the application in medicine , which is a very special domain . This is due to the fact that medical professionals are working mostly with distributed heterogeneous and complex sources of data . In this paper we concentrate on three sources : images , *omics data and text . We argue that research in explainable-AI would generally help to facilitate the implementation of AI/ML in the medical domain , and specifically help to facilitate transparency and trust .
In human-in-the-loop machine learning , the user provides information beyond that in the training data . Many algorithms and user interfaces have been designed to optimize and facilitate this human--machine interaction ; however , fewer studies have addressed the potential defects the designs can cause . Effective interaction often requires exposing the user to the training data or its statistics . The design of the system is then critical , as this can lead to double use of data and overfitting , if the user reinforces noisy patterns in the data . We propose a user modelling methodology , by assuming simple rational behaviour , to correct the problem . We show , in a user study with 00 participants , that the method improves predictive performance in a sparse linear regression sentiment analysis task , where graded user knowledge on feature relevance is elicited . We believe that the key idea of inferring user knowledge with probabilistic user models has general applicability in guarding against overfitting and improving interactive machine learning .
We present a new approach to learning the structure and parameters of a Bayesian network based on regularized estimation in an exponential family representation . Here we show that , given a fixed variable order , the optimal structure and parameters can be learned efficiently , even without restricting the size of the parent sets . We then consider the problem of optimizing the variable order for a given set of features . This is still a computationally hard problem , but we present a convex relaxation that yields an optimal ' soft ' ordering in polynomial time . One novel aspect of the approach is that we do not perform a discrete search over DAG structures , nor over variable orders , but instead solve a continuous relaxation that can then be rounded to obtain a valid network structure . We conduct an experimental comparison against standard structure search procedures over standard objectives , which cope with local minima , and evaluate the advantages of using convex relaxations that reduce the effects of local minima .
The use of Reinforcement Learning in real-world scenarios is strongly limited by issues of scale . Most RL learning algorithms are unable to deal with problems composed of hundreds or sometimes even dozens of possible actions , and therefore cannot be applied to many real-world problems . We consider the RL problem in the supervised classification framework where the optimal policy is obtained through a multiclass classifier , the set of classes being the set of actions of the problem . We introduce error-correcting output codes ( ECOCs ) in this setting and propose two new methods for reducing complexity when using rollouts-based approaches . The first method consists in using an ECOC-based classifier as the multiclass classifier , reducing the learning complexity from O ( A0 ) to O ( Alog ( A ) ) . We then propose a novel method that profits from the ECOC ' s coding dictionary to split the initial MDP into O ( log ( A ) ) seperate two-action MDPs . This second method reduces learning complexity even further , from O ( A0 ) to O ( log ( A ) ) , thus rendering problems with large action sets tractable . We finish by experimentally demonstrating the advantages of our approach on a set of benchmark problems , both in speed and performance .
In this paper we relate the partition function to the max-statistics of random variables . In particular , we provide a novel framework for approximating and bounding the partition function using MAP inference on randomly perturbed models . As a result , we can use efficient MAP solvers such as graph-cuts to evaluate the corresponding partition function . We show that our method excels in the typical " high signal - high coupling " regime that results in ragged energy landscapes difficult for alternative approaches .
We analyze directed , unweighted graphs obtained from $x_i\in \mathbb{R}^d$ by connecting vertex $i$ to $j$ iff $|x_i - x_j| < \epsilon ( x_i ) $ . Examples of such graphs include $k$-nearest neighbor graphs , where $\epsilon ( x_i ) $ varies from point to point , and , arguably , many real world graphs such as co-purchasing graphs . We ask whether we can recover the underlying Euclidean metric $\epsilon ( x_i ) $ and the associated density $p ( x_i ) $ given only the directed graph and $d$ . We show that consistent recovery is possible up to isometric scaling when the vertex degree is at least $\omega ( n^{0/ ( 0+d ) }\log ( n ) ^{d/ ( d+0 ) } ) $ . Our estimator is based on a careful characterization of a random walk over the directed graph and the associated continuum limit . As an algorithm , it resembles the PageRank centrality metric . We demonstrate empirically that the estimator performs well on simulated examples as well as on real-world co-purchasing graphs even with a small number of points and degree scaling as low as $\log ( n ) $ .
In this paper , we propose several improvements on the block-coordinate Frank-Wolfe ( BCFW ) algorithm from Lacoste-Julien et al . ( 0000 ) recently used to optimize the structured support vector machine ( SSVM ) objective in the context of structured prediction , though it has wider applications . The key intuition behind our improvements is that the estimates of block gaps maintained by BCFW reveal the block suboptimality that can be used as an adaptive criterion . First , we sample objects at each iteration of BCFW in an adaptive non-uniform way via gapbased sampling . Second , we incorporate pairwise and away-step variants of Frank-Wolfe into the block-coordinate setting . Third , we cache oracle calls with a cache-hit criterion based on the block gaps . Fourth , we provide the first method to compute an approximate regularization path for SSVM . Finally , we provide an exhaustive empirical evaluation of all our methods on four structured prediction datasets .
This paper introduces Dex , a reinforcement learning environment toolkit specialized for training and evaluation of continual learning methods as well as general reinforcement learning problems . We also present the novel continual learning method of incremental learning , where a challenging environment is solved using optimal weight initialization learned from first solving a similar easier environment . We show that incremental learning can produce vastly superior results than standard methods by providing a strong baseline method across ten Dex environments . We finally develop a saliency method for qualitative analysis of reinforcement learning , which shows the impact incremental learning has on network attention .
This paper describes how to convert a machine learning problem into a series of map-reduce tasks . We study logistic regression algorithm . In logistic regression algorithm , it is assumed that samples are independent and each sample is assigned a probability . Parameters are obtained by maxmizing the product of all sample probabilities . Rapid expansion of training samples brings challenges to machine learning method . Training samples are so many that they can be only stored in distributed file system and driven by map-reduce style programs . The main step of logistic regression is inference . According to map-reduce spirit , each sample makes inference through a separate map procedure . But the premise of inference is that the map procedure holds parameters for all features in the sample . In this paper , we propose Distributed Parameter Map-Reduce , in which not only samples , but also parameters are distributed in nodes of distributed filesystem . Through a series of map-reduce tasks , we assign each sample parameters for its features , make inference for the sample and update paramters of the model . The above processes are excuted looply until convergence . We test the proposed algorithm in actual hadoop production environment . Experiments show that the acceleration of the algorithm is in linear relationship with the number of cluster nodes .
Recently , there has been an increasing interest in designing distributed convex optimization algorithms under the setting where the data matrix is partitioned on features . Algorithms under this setting sometimes have many advantages over those under the setting where data is partitioned on samples , especially when the number of features is huge . Therefore , it is important to understand the inherent limitations of these optimization problems . In this paper , with certain restrictions on the communication allowed in the procedures , we develop tight lower bounds on communication rounds for a broad class of non-incremental algorithms under this setting . We also provide a lower bound on communication rounds for a class of ( randomized ) incremental algorithms .
Self-paced learning and hard example mining re-weight training instances to improve learning accuracy . This paper presents two improved alternatives based on lightweight estimates of sample uncertainty in stochastic gradient descent ( SGD ) : the variance in predicted probability of the correct class across iterations of mini-batch SGD , and the proximity of the correct class probability to the decision threshold . Extensive experimental results on six datasets show that our methods reliably improve accuracy in various network architectures , including additional gains on top of other popular training techniques , such as residual learning , momentum , ADAM , batch normalization , dropout , and distillation .
We introduce NoisyNet , a deep reinforcement learning agent with parametric noise added to its weights , and show that the induced stochasticity of the agent ' s policy can be used to aid efficient exploration . The parameters of the noise are learned with gradient descent along with the remaining network weights . NoisyNet is straightforward to implement and adds little computational overhead . We find that replacing the conventional exploration heuristics for A0C , DQN and dueling agents ( entropy reward and $\epsilon$-greedy respectively ) with NoisyNet yields substantially higher scores for a wide range of Atari games , in some cases advancing the agent from sub to super-human performance .
Many machine learning problems can be characterized by mutual contamination models . In these problems , one observes several random samples from different convex combinations of a set of unknown base distributions . It is of interest to decontaminate mutual contamination models , i . e . , to recover the base distributions either exactly or up to a permutation . This paper considers the general setting where the base distributions are defined on arbitrary probability spaces . We examine the decontamination problem in two mutual contamination models that describe popular machine learning tasks : recovering the base distributions up to a permutation in a mixed membership model , and recovering the base distributions exactly in a partial label model for classification . We give necessary and sufficient conditions for identifiability of both mutual contamination models , algorithms for both problems in the infinite and finite sample cases , and introduce novel proof techniques based on affine geometry .
In cheminformatics , compound-target binding profiles has been a main source of data for research . For data repositories that only provide positive profiles , a popular assumption is that unreported profiles are all negative . In this paper , we caution audience not to take this assumption for granted , and present empirical evidence of its ineffectiveness from a machine learning perspective . Our examination is based on a setting where binding profiles are used as features to train predictive models ; we show ( 0 ) prediction performance degrades when the assumption fails and ( 0 ) explicit recovery of unreported profiles improves prediction performance . In particular , we propose a framework that jointly recovers profiles and learns predictive model , and show it achieves further performance improvement . The presented study not only suggests applying matrix recovery methods to recover unreported profiles , but also initiates a new missing feature problem which we called Learning with Positive and Unknown Features .
Deep Neural Networks ( DNNs ) have become very popular for prediction in many areas . Their strength is in representation with a high number of parameters that are commonly learned via gradient descent or similar optimization methods . However , the representation is non-standardized , and the gradient calculation methods are often performed using component-based approaches that break parameters down into scalar units , instead of considering the parameters as whole entities . In this work , these problems are addressed . Standard notation is used to represent DNNs in a compact framework . Gradients of DNN loss functions are calculated directly over the inner product space on which the parameters are defined . This framework is general and is applied to two common network types : the Multilayer Perceptron and the Deep Autoencoder .
Donoho ' s JCGS ( in press ) paper is a spirited call to action for statisticians , who he points out are losing ground in the field of data science by refusing to accept that data science is its own domain . ( Or , at least , a domain that is becoming distinctly defined . ) He calls on writings by John Tukey , Bill Cleveland , and Leo Breiman , among others , to remind us that statisticians have been dealing with data science for years , and encourages acceptance of the direction of the field while also ensuring that statistics is tightly integrated . As faculty at baccalaureate institutions ( where the growth of undergraduate statistics programs has been dramatic ) , we are keen to ensure statistics has a place in data science and data science education . In his paper , Donoho is primarily focused on graduate education . At our undergraduate institutions , we are considering many of the same questions .
Community detection has been one of the central problems in network studies and directed network is particularly challenging due to asymmetry among its links . In this paper , we found that incorporating the direction of links reveals new perspectives on communities regarding to two different roles , source and terminal , that a node plays in each community . Intriguingly , such communities appear to be connected with unique spectral property of the graph Laplacian of the adjacency matrix and we exploit this connection by using regularized SVD methods . We propose harvesting algorithms , coupled with regularized SVDs , that are linearly scalable for efficient identification of communities in huge directed networks . The proposed algorithm shows great performance and scalability on benchmark networks in simulations and successfully recovers communities in real network applications .
In this paper , we propose a novel recurrent neural network architecture for speech separation . This architecture is constructed by unfolding the iterations of a sequential iterative soft-thresholding algorithm ( ISTA ) that solves the optimization problem for sparse nonnegative matrix factorization ( NMF ) of spectrograms . We name this network architecture deep recurrent NMF ( DR-NMF ) . The proposed DR-NMF network has three distinct advantages . First , DR-NMF provides better interpretability than other deep architectures , since the weights correspond to NMF model parameters , even after training . This interpretability also provides principled initializations that enable faster training and convergence to better solutions compared to conventional random initialization . Second , like many deep networks , DR-NMF is an order of magnitude faster at test time than NMF , since computation of the network output only requires evaluating a few layers at each time step . Third , when a limited amount of training data is available , DR-NMF exhibits stronger generalization and separation performance compared to sparse NMF and state-of-the-art long-short term memory ( LSTM ) networks . When a large amount of training data is available , DR-NMF achieves lower yet competitive separation performance compared to LSTM networks .
We consider the problem of estimating the support of a vector $\beta^* \in \mathbb{R}^{p}$ based on observations contaminated by noise . A significant body of work has studied behavior of $\ell_0$-relaxations when applied to measurement matrices drawn from standard dense ensembles ( e . g . , Gaussian , Bernoulli ) . In this paper , we analyze \emph{sparsified} measurement ensembles , and consider the trade-off between measurement sparsity , as measured by the fraction $\gamma$ of non-zero entries , and the statistical efficiency , as measured by the minimal number of observations $n$ required for exact support recovery with probability converging to one . Our main result is to prove that it is possible to let $\gamma \to 0$ at some rate , yielding measurement matrices with a vanishing fraction of non-zeros per row while retaining the same statistical efficiency as dense ensembles . A variety of simulation results confirm the sharpness of our theoretical predictions .
Recommender systems are widely used to predict personalized preferences of goods or services using users ' past activities , such as item ratings or purchase histories . If collections of such personal activities were made publicly available , they could be used to personalize a diverse range of services , including targeted advertisement or recommendations . However , there would be an accompanying risk of privacy violations . The pioneering work of Narayanan et al . \ demonstrated that even if the identifiers are eliminated , the public release of user ratings can allow for the identification of users by those who have only a small amount of data on the users ' past ratings . In this paper , we assume the following setting . A collector collects user ratings , then anonymizes and distributes them . A recommender constructs a recommender system based on the anonymized ratings provided by the collector . Based on this setting , we exhaustively list the models of recommender systems that use anonymized ratings . For each model , we then present an item-based collaborative filtering algorithm for making recommendations based on anonymized ratings . Our experimental results show that an item-based collaborative filtering based on anonymized ratings can perform better than collaborative filterings based on 0--00 non-anonymized ratings . This surprising result indicates that , in some settings , privacy protection does not necessarily reduce the usefulness of recommendations . From the experimental analysis of this counterintuitive result , we observed that the sparsity of the ratings can be reduced by anonymization and the variance of the prediction can be reduced if $k$ , the anonymization parameter , is appropriately tuned . In this way , the predictive performance of recommendations based on anonymized ratings can be improved in some settings .
We examine the role of memorization in deep learning , drawing connections to capacity , generalization , and adversarial robustness . While deep networks are capable of memorizing noise data , our results suggest that they tend to prioritize learning simple patterns first . In our experiments , we expose qualitative differences in gradient-based optimization of deep neural networks ( DNNs ) on noise vs . real data . We also demonstrate that for appropriately tuned explicit regularization ( e . g . , dropout ) we can degrade DNN training performance on noise datasets without compromising generalization on real data . Our analysis suggests that the notions of effective capacity which are dataset independent are unlikely to explain the generalization performance of deep networks when trained with gradient based methods because training data itself plays an important role in determining the degree of memorization .
We prove a central limit theorem for the components of the largest eigenvectors of the adjacency matrix of a finite-dimensional random dot product graph whose true latent positions are unknown . In particular , we follow the methodology outlined in \citet{sussman0000universally} to construct consistent estimates for the latent positions , and we show that the appropriately scaled differences between the estimated and true latent positions converge to a mixture of Gaussian random variables . As a corollary , we obtain a central limit theorem for the first eigenvector of the adjacency matrix of an Erd\ " os-Renyi random graph .
-In this work , we revisit fast dimension reduction approaches , as with random projections and random sampling . Our goal is to summarize the data to decrease computational costs and memory footprint of subsequent analysis . Such dimension reduction can be very efficient when the signals of interest have a strong structure , such as with images . We focus on this setting and investigate feature clustering schemes for data reductions that capture this structure . An impediment to fast dimension reduction is that good clustering comes with large algorithmic costs . We address it by contributing a linear-time agglomerative clustering scheme , Recursive Nearest Agglomeration ( ReNA ) . Unlike existing fast agglomerative schemes , it avoids the creation of giant clusters . We empirically validate that it approximates the data as well as traditional variance-minimizing clustering schemes that have a quadratic complexity . In addition , we analyze signal approximation with feature clustering and show that it can remove noise , improving subsequent analysis steps . As a consequence , data reduction by clustering features with ReNA yields very fast and accurate models , enabling to process large datasets on budget . Our theoretical analysis is backed by extensive experiments on publicly-available data that illustrate the computation efficiency and the denoising properties of the resulting dimension reduction scheme .
There has been significant recent interest towards achieving highly efficient deep neural network architectures . A promising paradigm for achieving this is the concept of evolutionary deep intelligence , which attempts to mimic biological evolution processes to synthesize highly-efficient deep neural networks over successive generations . An important aspect of evolutionary deep intelligence is the genetic encoding scheme used to mimic heredity , which can have a significant impact on the quality of offspring deep neural networks . Motivated by the neurobiological phenomenon of synaptic clustering , we introduce a new genetic encoding scheme where synaptic probability is driven towards the formation of a highly sparse set of synaptic clusters . Experimental results for the task of image classification demonstrated that the synthesized offspring networks using this synaptic cluster-driven genetic encoding scheme can achieve state-of-the-art performance while having network architectures that are not only significantly more efficient ( with a ~000-fold decrease in synapses for MNIST ) compared to the original ancestor network , but also tailored for GPU-accelerated machine learning applications .
We propose a direct estimation method for R\ ' {e}nyi and f-divergence measures based on a new graph theoretical interpretation . Suppose that we are given two sample sets $X$ and $Y$ , respectively with $N$ and $M$ samples , where $\eta : =M/N$ is a constant value . Considering the $k$-nearest neighbor ( $k$-NN ) graph of $Y$ in the joint data set $ ( X , Y ) $ , we show that the average powered ratio of the number of $X$ points to the number of $Y$ points among all $k$-NN points is proportional to R\ ' {e}nyi divergence of $X$ and $Y$ densities . A similar method can also be used to estimate f-divergence measures . We derive bias and variance rates , and show that for the class of $\gamma$-H\ " {o}lder smooth functions , the estimator achieves the MSE rate of $O ( N^{-0\gamma/ ( \gamma+d ) } ) $ . Furthermore , by using a weighted ensemble estimation technique , for density functions with continuous and bounded derivatives of up to the order $d$ , and some extra conditions at the support set boundary , we derive an ensemble estimator that achieves the parametric MSE rate of $O ( 0/N ) $ . Our estimators are more computationally tractable than other competing estimators , which makes them appealing in many practical applications .
We design a randomised parallel version of Adaboost based on previous studies on parallel coordinate descent . The algorithm uses the fact that the logarithm of the exponential loss is a function with coordinate-wise Lipschitz continuous gradient , in order to define the step lengths . We provide the proof of convergence for this randomised Adaboost algorithm and a theoretical parallelisation speedup factor . We finally provide numerical examples on learning problems of various sizes that show that the algorithm is competitive with concurrent approaches , especially for large scale problems .
The method of random projections has become a standard tool for machine learning , data mining , and search with massive data at Web scale . The effective use of random projections requires efficient coding schemes for quantizing ( real-valued ) projected data into integers . In this paper , we focus on a simple 0-bit coding scheme . In particular , we develop accurate nonlinear estimators of data similarity based on the 0-bit strategy . This work will have important practical applications . For example , in the task of near neighbor search , a crucial step ( often called re-ranking ) is to compute or estimate data similarities once a set of candidate data points have been identified by hash table techniques . This re-ranking step can take advantage of the proposed coding scheme and estimator . As a related task , in this paper , we also study a simple uniform quantization scheme for the purpose of building hash tables with projected data . Our analysis shows that typically only a small number of bits are needed . For example , when the target similarity level is high , 0 or 0 bits might be sufficient . When the target similarity level is not so high , it is preferable to use only 0 or 0 bits . Therefore , a 0-bit scheme appears to be overall a good choice for the task of sublinear time approximate near neighbor search via hash tables . Combining these results , we conclude that 0-bit random projections should be recommended for approximate near neighbor search and similarity estimation . Extensive experimental results are provided .
We propose to describe the variety of galaxies from SDSS by using only one affine parameter . To this aim , we build the Principal Curve ( P-curve ) passing through the spine of the data point cloud , considering the eigenspace derived from Principal Component Analysis of morphological , physical and photometric galaxy properties . Thus , galaxies can be labeled , ranked and classified by a single arc length value of the curve , measured at the unique closest projection of the data points on the P-curve . We find that the P-curve has a " W " letter shape with 0 turning points , defining 0 branches that represent distinct galaxy populations . This behavior is controlled mainly by 0 properties , namely u-r and SFR . We further present the variations of several galaxy properties as a function of arc length . Luminosity functions variate from steep Schechter fits at low arc length , to double power law and ending in Log-normal fits at high arc length . Galaxy clustering shows increasing autocorrelation power at large scales as arc length increases . PCA analysis allowed to find peculiar galaxy populations located apart from the main cloud of data points , such as small red galaxies dominated by a disk , of relatively high stellar mass-to-light ratio and surface mass density . The P-curve allows not only dimensionality reduction , but also provides supporting evidence for relevant physical models and scenarios in extragalactic astronomy : 0 ) Evidence for the hierarchical merging scenario in the formation of a selected group of red massive galaxies . These galaxies present a log-normal r-band luminosity function , which might arise from multiplicative processes involved in this scenario . 0 ) Connection between the onset of AGN activity and star formation quenching , which appears in green galaxies when transitioning from blue to red populations . ( Full abstract in downloadable version )
Uniform deviation bounds limit the difference between a model ' s expected loss and its loss on an empirical sample uniformly for all models in a learning problem . As such , they are a critical component to empirical risk minimization . In this paper , we provide a novel framework to obtain uniform deviation bounds for loss functions which are *unbounded* . In our main application , this allows us to obtain bounds for $k$-Means clustering under weak assumptions on the underlying distribution . If the fourth moment is bounded , we prove a rate of $\mathcal{O}\left ( m^{-\frac00}\right ) $ compared to the previously known $\mathcal{O}\left ( m^{-\frac00}\right ) $ rate . Furthermore , we show that the rate also depends on the kurtosis - the normalized fourth moment which measures the " tailedness " of a distribution . We further provide improved rates under progressively stronger assumptions , namely , bounded higher moments , subgaussianity and bounded support .
Many structured data-fitting applications require the solution of an optimization problem involving a sum over a potentially large number of measurements . Incremental gradient algorithms offer inexpensive iterations by sampling a subset of the terms in the sum . These methods can make great progress initially , but often slow as they approach a solution . In contrast , full-gradient methods achieve steady convergence at the expense of evaluating the full objective and gradient on each iteration . We explore hybrid methods that exhibit the benefits of both approaches . Rate-of-convergence analysis shows that by controlling the sample size in an incremental gradient algorithm , it is possible to maintain the steady convergence rates of full-gradient methods . We detail a practical quasi-Newton implementation based on this approach . Numerical experiments illustrate its potential benefits .
Although the Lasso has been extensively studied , the relationship between its prediction performance and the correlations of the covariates is not fully understood . In this paper , we give new insights into this relationship in the context of multiple linear regression . We show , in particular , that the incorporation of a simple correlation measure into the tuning parameter can lead to a nearly optimal prediction performance of the Lasso even for highly correlated covariates . However , we also reveal that for moderately correlated covariates , the prediction performance of the Lasso can be mediocre irrespective of the choice of the tuning parameter . We finally show that our results also lead to near-optimal rates for the least-squares estimator with total variation penalty .
In this paper we introduce three methods for re-scaling data sets aiming at improving the likelihood of clustering validity indexes to return the true number of spherical Gaussian clusters with additional noise features . Our method obtains feature re-scaling factors taking into account the structure of a given data set and the intuitive idea that different features may have different degrees of relevance at different clusters . We experiment with the Silhouette ( using squared Euclidean , Manhattan , and the p$^{th}$ power of the Minkowski distance ) , Dunn ' s , Calinski-Harabasz and Hartigan indexes on data sets with spherical Gaussian clusters with and without noise features . We conclude that our methods indeed increase the chances of estimating the true number of clusters in a data set .
The electronic health record ( EHR ) provides an unprecedented opportunity to build actionable tools to support physicians at the point of care . In this paper , we investigate survival analysis in the context of EHR data . We introduce deep survival analysis , a hierarchical generative approach to survival analysis . It departs from previous approaches in two primary ways : ( 0 ) all observations , including covariates , are modeled jointly conditioned on a rich latent structure ; and ( 0 ) the observations are aligned by their failure time , rather than by an arbitrary time zero as in traditional survival analysis . Further , it ( 0 ) scalably handles heterogeneous ( continuous and discrete ) data types that occur in the EHR . We validate deep survival analysis model by stratifying patients according to risk of developing coronary heart disease ( CHD ) . Specifically , we study a dataset of 000 , 000 patients corresponding to 0 . 0 million months of observations . When compared to the clinically validated Framingham CHD risk score , deep survival analysis is significantly superior in stratifying patients according to their risk .
Feature Learning aims to extract relevant information contained in data sets in an automated fashion . It is driving force behind the current deep learning trend , a set of methods that have had widespread empirical success . What is lacking is a theoretical understanding of different feature learning schemes . This work provides a theoretical framework for feature learning and then characterizes when features can be learnt in an unsupervised fashion . We also provide means to judge the quality of features via rate-distortion theory and its generalizations .
Many complex systems can be represented as networks , and the problem of network comparison is becoming increasingly relevant . There are many techniques for network comparison , from simply comparing network summary statistics to sophisticated but computationally costly alignment-based approaches . Yet it remains challenging to accurately cluster networks that are of a different size and density , but hypothesized to be structurally similar . In this paper , we address this problem by introducing a new network comparison methodology that is aimed at identifying common organizational principles in networks . The methodology is simple , intuitive and applicable in a wide variety of settings ranging from the functional classification of proteins to tracking the evolution of a world trade network .
Probabilistic modeling enables combining domain knowledge with learning from data , thereby supporting learning from fewer training instances than purely data-driven methods . However , learning probabilistic models is difficult and has not achieved the level of performance of methods such as deep neural networks on many tasks . In this paper , we attempt to address this issue by presenting a method for learning the parameters of a probabilistic program using backpropagation . Our approach opens the possibility to building deep probabilistic programming models that are trained in a similar way to neural networks .
Deep artificial neural networks require a large corpus of training data in order to effectively learn , where collection of such training data is often expensive and laborious . Data augmentation overcomes this issue by artificially inflating the training set with label preserving transformations . Recently there has been extensive use of generic data augmentation to improve Convolutional Neural Network ( CNN ) task performance . This study benchmarks various popular data augmentation schemes to allow researchers to make informed decisions as to which training methods are most appropriate for their data sets . Various geometric and photometric schemes are evaluated on a coarse-grained data set using a relatively simple CNN . Experimental results , run using 0-fold cross-validation and reported in terms of Top-0 and Top-0 accuracy , indicate that cropping in geometric augmentation significantly increases CNN task performance .
Modern computer vision algorithms typically require expensive data acquisition and accurate manual labeling . In this work , we instead leverage the recent progress in computer graphics to generate fully labeled , dynamic , and photo-realistic proxy virtual worlds . We propose an efficient real-to-virtual world cloning method , and validate our approach by building and publicly releasing a new video dataset , called Virtual KITTI ( see http : //www . xrce . xerox . com/Research-Development/Computer-Vision/Proxy-Virtual-Worlds ) , automatically labeled with accurate ground truth for object detection , tracking , scene and instance segmentation , depth , and optical flow . We provide quantitative experimental evidence suggesting that ( i ) modern deep learning algorithms pre-trained on real data behave similarly in real and virtual worlds , and ( ii ) pre-training on virtual data improves performance . As the gap between real and virtual worlds is small , virtual worlds enable measuring the impact of various weather and imaging conditions on recognition performance , all other things being equal . We show these factors may affect drastically otherwise high-performing deep models for tracking .
In this paper , we study the stochastic gradient descent method in analyzing nonconvex statistical optimization problems from a diffusion approximation point of view . Using the theory of large deviation of random dynamical system , we prove in the small stepsize regime and the presence of omnidirectional noise the following : starting from a local minimizer ( resp . ~saddle point ) the SGD iteration escapes in a number of iteration that is exponentially ( resp . ~linearly ) dependent on the inverse stepsize . We take the deep neural network as an example to study this phenomenon . Based on a new analysis of the mixing rate of multidimensional Ornstein-Uhlenbeck processes , our theory substantiate a very recent empirical results by \citet{keskar0000large} , suggesting that large batch sizes in training deep learning for synchronous optimization leads to poor generalization error .
Recursive partitioning approaches producing tree-like models are a long standing staple of predictive modeling , in the last decade mostly as ``sub-learners ' ' within state of the art ensemble methods like Boosting and Random Forest . However , a fundamental flaw in the partitioning ( or splitting ) rule of commonly used tree building methods precludes them from treating different types of variables equally . This most clearly manifests in these methods ' inability to properly utilize categorical variables with a large number of categories , which are ubiquitous in the new age of big data . Such variables can often be very informative , but current tree methods essentially leave us a choice of either not using them , or exposing our models to severe overfitting . We propose a conceptual framework to splitting using leave-one-out ( LOO ) cross validation for selecting the splitting variable , then performing a regular split ( in our case , following CART ' s approach ) for the selected variable . The most important consequence of our approach is that categorical variables with many categories can be safely used in tree building and are only chosen if they contribute to predictive power . We demonstrate in extensive simulation and real data analysis that our novel splitting approach significantly improves the performance of both single tree models and ensemble methods that utilize trees . Importantly , we design an algorithm for LOO splitting variable selection which under reasonable assumptions does not increase the overall computational complexity compared to CART for two-class classification . For regression tasks , our approach carries an increased computational burden , replacing a O ( log ( n ) ) factor in CART splitting rule search with an O ( n ) term .
Mixture distributions arise in many parametric and non-parametric settings - for example , in Gaussian mixture models and in non-parametric estimation . It is often necessary to compute the entropy of a mixture , but , in most cases , this quantity has no closed-form expression , making some form of approximation necessary . We propose a family of estimators based on a pairwise distance function between mixture components , and show that this estimator class has many attractive properties . For many distributions of interest , the proposed estimators are efficient to compute , differentiable in the mixture parameters , and become exact when the mixture components are clustered . We prove this family includes lower and upper bounds on the mixture entropy . The Chernoff $\alpha$-divergence gives a lower bound when chosen as the distance function , with the Bhattacharyaa distance providing the tightest lower bound for components that are symmetric and members of a location family . The Kullback-Leibler divergence gives an upper bound when used as the distance function . We provide closed-form expressions of these bounds for mixtures of Gaussians , and discuss their applications to the estimation of mutual information . We then demonstrate that our bounds are significantly tighter than well-known existing bounds using numeric simulations . This estimator class is very useful in optimization problems involving maximization/minimization of entropy and mutual information , such as MaxEnt and rate distortion problems .
A new method for the unsupervised learning of sparse representations using autoencoders is proposed and implemented by ordering the output of the hidden units by their activation value and progressively reconstructing the input in this order . This can be done efficiently in parallel with the use of cumulative sums and sorting only slightly increasing the computational costs . Minimizing the difference of this progressive reconstruction with respect to the input can be seen as minimizing the number of active output units required for the reconstruction of the input . The model thus learns to reconstruct optimally using the least number of active output units . This leads to high sparsity without the need for extra hyperparameters , the amount of sparsity is instead implicitly learned by minimizing this progressive reconstruction error . Results of the trained model are given for patches of the CIFAR00 dataset , showing rapid convergence of features and extremely sparse output activations while maintaining a minimal reconstruction error and showing extreme robustness to overfitting . Additionally the reconstruction as function of number of active units is presented which shows the autoencoder learns a rank order code over the input where the highest ranked units correspond to the highest decrease in reconstruction error .
We study the problem of estimating multiple predictive functions from a dictionary of basis functions in the nonparametric regression setting . Our estimation scheme assumes that each predictive function can be estimated in the form of a linear combination of the basis functions . By assuming that the coefficient matrix admits a sparse low-rank structure , we formulate the function estimation problem as a convex program regularized by the trace norm and the $\ell_0$-norm simultaneously . We propose to solve the convex program using the accelerated gradient ( AG ) method and the alternating direction method of multipliers ( ADMM ) respectively ; we also develop efficient algorithms to solve the key components in both AG and ADMM . In addition , we conduct theoretical analysis on the proposed function estimation scheme : we derive a key property of the optimal solution to the convex program ; based on an assumption on the basis functions , we establish a performance bound of the proposed function estimation scheme ( via the composite regularization ) . Simulation studies demonstrate the effectiveness and efficiency of the proposed algorithms .
We introduce a Bernstein-type inequality which serves to uniformly control quadratic forms of gaussian variables . The latter can for example be used to derive sharp model selection criteria for linear estimation in linear regression and linear inverse problems via penalization , and we do not exclude that its scope of application can be made even broader .
IllinoisSL is a Java library for learning structured prediction models . It supports structured Support Vector Machines and structured Perceptron . The library consists of a core learning module and several applications , which can be executed from command-lines . Documentation is provided to guide users . In Comparison to other structured learning libraries , IllinoisSL is efficient , general , and easy to use .
With a simple architecture and the ability to learn meaningful word embeddings efficiently from texts containing billions of words , word0vec remains one of the most popular neural language models used today . However , as only a single embedding is learned for every word in the vocabulary , the model fails to optimally represent words with multiple meanings . Additionally , it is not possible to create embeddings for new ( out-of-vocabulary ) words on the spot . Based on an intuitive interpretation of the continuous bag-of-words ( CBOW ) word0vec model ' s negative sampling training objective in terms of predicting context based similarities , we motivate an extension of the model we call context encoders ( ConEc ) . By multiplying the matrix of trained word0vec embeddings with a word ' s average context vector , out-of-vocabulary ( OOV ) embeddings and representations for a word with multiple meanings can be created based on the word ' s local contexts . The benefits of this approach are illustrated by using these word embeddings as features in the CoNLL 0000 named entity recognition ( NER ) task .
In this work a new way to calculate the multivariate joint entropy is presented . This measure is the basis for a fast information-theoretic based evaluation of gene relevance in a Microarray Gene Expression data context . Its low complexity is based on the reuse of previous computations to calculate current feature relevance . The mu-TAFS algorithm --named as such to differentiate it from previous TAFS algorithms-- implements a simulated annealing technique specially designed for feature subset selection . The algorithm is applied to the maximization of gene subset relevance in several public-domain microarray data sets . The experimental results show a notoriously high classification performance and low size subsets formed by biologically meaningful genes .
Deep generative models trained with large amounts of unlabelled data have proven to be powerful within the domain of unsupervised learning . Many real life data sets contain a small amount of labelled data points , that are typically disregarded when training generative models . We propose the Cluster-aware Generative Model , that uses unlabelled information to infer a latent representation that models the natural clustering of the data , and additional labelled data points to refine this clustering . The generative performances of the model significantly improve when labelled information is exploited , obtaining a log-likelihood of -00 . 00 nats on permutation invariant MNIST , while also achieving competitive semi-supervised classification accuracies . The model can also be trained fully unsupervised , and still improve the log-likelihood performance with respect to related methods .
We describe parallel Markov chain Monte Carlo methods that propagate a collective ensemble of paths , with local covariance information calculated from neighboring replicas . The use of collective dynamics eliminates multiplicative noise and stabilizes the dynamics thus providing a practical approach to difficult anisotropic sampling problems in high dimensions . Numerical experiments with model problems demonstrate that dramatic potential speedups , compared to various alternative schemes , are attainable .
In this paper , we study deep signal representations that are invariant to groups of transformations and stable to the action of diffeomorphisms without losing signal information . This is achieved by generalizing the multilayer kernel construction introduced in the context of convolutional kernel networks and by studying the geometry of the corresponding reproducing kernel Hilbert space . We show that the signal representation is stable , and that models from this functional space , such as a large class of convolutional neural networks with homogeneous activation functions , may enjoy the same stability . In particular , we study the norm of such models , which acts as a measure of complexity , controlling both stability and generalization .
We propose a quantization based approach for fast approximate Maximum Inner Product Search ( MIPS ) . Each database vector is quantized in multiple subspaces via a set of codebooks , learned directly by minimizing the inner product quantization error . Then , the inner product of a query to a database vector is approximated as the sum of inner products with the subspace quantizers . Different from recently proposed LSH approaches to MIPS , the database vectors and queries do not need to be augmented in a higher dimensional feature space . We also provide a theoretical analysis of the proposed approach , consisting of the concentration results under mild assumptions . Furthermore , if a small sample of example queries is given at the training time , we propose a modified codebook learning procedure which further improves the accuracy . Experimental results on a variety of datasets including those arising from deep neural networks show that the proposed approach significantly outperforms the existing state-of-the-art .
In recent years , spectral clustering has become a standard method for data analysis used in a broad range of applications . In this paper we propose a new class of algorithms for multiway spectral clustering based on optimization of a certain " contrast function " over the unit sphere . These algorithms , partly inspired by certain Independent Component Analysis techniques , are simple , easy to implement and efficient . Geometrically , the proposed algorithms can be interpreted as hidden basis recovery by means of function optimization . We give a complete characterization of the contrast functions admissible for provable basis recovery . We show how these conditions can be interpreted as a " hidden convexity " of our optimization problem on the sphere ; interestingly , we use efficient convex maximization rather than the more common convex minimization . We also show encouraging experimental results on real and simulated data .
Advances in sensing technologies and the growth of the internet have resulted in an explosion in the size of modern datasets , while storage and processing power continue to lag behind . This motivates the need for algorithms that are efficient , both in terms of the number of measurements needed and running time . To combat the challenges associated with large datasets , we propose a general framework for active hierarchical clustering that repeatedly runs an off-the-shelf clustering algorithm on small subsets of the data and comes with guarantees on performance , measurement complexity and runtime complexity . We instantiate this framework with a simple spectral clustering algorithm and provide concrete results on its performance , showing that , under some assumptions , this algorithm recovers all clusters of size ? ( log n ) using O ( n log^0 n ) similarities and runs in O ( n log^0 n ) time for a dataset of n objects . Through extensive experimentation we also demonstrate that this framework is practically alluring .
We consider training probabilistic classifiers in the case of a large number of classes . The number of classes is assumed too large to perform exact normalisation over all classes . To account for this we consider a simple approach that directly approximates the likelihood . We show that this simple approach works well on toy problems and is competitive with recently introduced alternative non-likelihood based approximations . Furthermore , we relate this approach to a simple ranking objective . This leads us to suggest a specific setting for the optimal threshold in the ranking objective .
There exist a number of reinforcement learning algorithms which learnby climbing the gradient of expected reward . Their long-runconvergence has been proved , even in partially observableenvironments with non-deterministic actions , and without the need fora system model . However , the variance of the gradient estimator hasbeen found to be a significant practical problem . Recent approacheshave discounted future rewards , introducing a bias-variance trade-offinto the gradient estimate . We incorporate a reward baseline into thelearning system , and show that it affects variance without introducingfurther bias . In particular , as we approach the zero-bias , high-variance parameterization , the optimal ( or variance minimizing ) constant reward baseline is equal to the long-term average expectedreward . Modified policy-gradient algorithms are presented , and anumber of experiments demonstrate their improvement over previous work .
Learning to predict multi-label outputs is challenging , but in many problems there is a natural metric on the outputs that can be used to improve predictions . In this paper we develop a loss function for multi-label learning , based on the Wasserstein distance . The Wasserstein distance provides a natural notion of dissimilarity for probability measures . Although optimizing with respect to the exact Wasserstein distance is costly , recent work has described a regularized approximation that is efficiently computed . We describe an efficient learning algorithm based on this regularization , as well as a novel extension of the Wasserstein distance from probability measures to unnormalized measures . We also describe a statistical learning bound for the loss . The Wasserstein loss can encourage smoothness of the predictions with respect to a chosen metric on the output space . We demonstrate this property on a real-data tag prediction problem , using the Yahoo Flickr Creative Commons dataset , outperforming a baseline that doesn ' t use the metric .
Mapping the spatial distribution of poverty in developing countries remains an important and costly challenge . These " poverty maps " are key inputs for poverty targeting , public goods provision , political accountability , and impact evaluation , that are all the more important given the geographic dispersion of the remaining bottom billion severely poor individuals . In this paper we train Convolutional Neural Networks ( CNNs ) to estimate poverty directly from high and medium resolution satellite images . We use both Planet and Digital Globe imagery with spatial resolutions of 0-0 sq . m . and 00 sq . cm . respectively , covering all 0 million sq . km . of Mexico . Benchmark poverty estimates come from the 0000 MCS-ENIGH combined with the 0000 Intercensus and are used to estimate poverty rates for 0 , 000 Mexican municipalities . CNNs are trained using the 000 municipalities in the 0000 MCS-ENIGH . We experiment with several architectures ( GoogleNet , VGG ) and use GoogleNet as a final architecture where weights are fine-tuned from ImageNet . We find that 0 ) the best models , which incorporate satellite-estimated land use as a predictor , explain approximately 00% of the variation in poverty in a validation sample of 00 percent of MCS-ENIGH municipalities ; 0 ) Across all MCS-ENIGH municipalities explanatory power reduces to 00% in a CNN prediction and landcover model ; 0 ) Predicted poverty from the CNN predictions alone explains 00% of the variation in poverty in the validation sample , and 00% over all MCS-ENIGH municipalities ; 0 ) In urban areas we see slight improvements from using Digital Globe versus Planet imagery , which explain 00% and 00% of poverty variation respectively . We conclude that CNNs can be trained end-to-end on satellite imagery to estimate poverty , although there is much work to be done to understand how the training process influences out of sample validation .
This paper presents Natural Evolution Strategies ( NES ) , a recent family of algorithms that constitute a more principled approach to black-box optimization than established evolutionary algorithms . NES maintains a parameterized distribution on the set of solution candidates , and the natural gradient is used to update the distribution ' s parameters in the direction of higher expected fitness . We introduce a collection of techniques that address issues of convergence , robustness , sample complexity , computational complexity and sensitivity to hyperparameters . This paper explores a number of implementations of the NES family , ranging from general-purpose multi-variate normal distributions to heavy-tailed and separable distributions tailored towards global optimization and search in high dimensional spaces , respectively . Experimental results show best published performance on various standard benchmarks , as well as competitive performance on others .
Recently , to solve large-scale lasso and group lasso problems , screening rules have been developed , the goal of which is to reduce the problem size by efficiently discarding zero coefficients using simple rules independently of the others . However , screening for overlapping group lasso remains an open challenge because the overlaps between groups make it infeasible to test each group independently . In this paper , we develop screening rules for overlapping group lasso . To address the challenge arising from groups with overlaps , we take into account overlapping groups only if they are inclusive of the group being tested , and then we derive screening rules , adopting the dual polytope projection approach . This strategy allows us to screen each group independently of each other . In our experiments , we demonstrate the efficiency of our screening rules on various datasets .
Structural equation models ( SEMs ) have been widely adopted for inference of causal interactions in complex networks . Recent examples include unveiling topologies of hidden causal networks over which processes such as spreading diseases , or rumors propagate . The appeal of SEMs in these settings stems from their simplicity and tractability , since they typically assume linear dependencies among observable variables . Acknowledging the limitations inherent to adopting linear models , the present paper advocates nonlinear SEMs , which account for ( possible ) nonlinear dependencies among network nodes . The advocated approach leverages kernels as a powerful encompassing framework for nonlinear modeling , and an efficient estimator with affordable tradeoffs is put forth . Interestingly , pursuit of the novel kernel-based approach yields a convex regularized estimator that promotes edge sparsity , and is amenable to proximal-splitting optimization methods . To this end , solvers with complementary merits are developed by leveraging the alternating direction method of multipliers , and proximal gradient iterations . Experiments conducted on simulated data demonstrate that the novel approach outperforms linear SEMs with respect to edge detection errors . Furthermore , tests on a real gene expression dataset unveil interesting new edges that were not revealed by linear SEMs , which could shed more light on regulatory behavior of human genes .
In the setting of nonparametric regression , we propose and study a combination of stochastic gradient methods with Nystr\ " om subsampling , allowing multiple passes over the data and mini-batches . Generalization error bounds for the studied algorithm are provided . Particularly , optimal learning rates are derived considering different possible choices of the step-size , the mini-batch size , the number of iterations/passes , and the subsampling level . In comparison with state-of-the-art algorithms such as the classic stochastic gradient methods and kernel ridge regression with Nystr\ " om , the studied algorithm has advantages on the computational complexity , while achieving the same optimal learning rates . Moreover , our results indicate that using mini-batches can reduce the total computational cost while achieving the same optimal statistical results .
The stochastic multi-armed bandit problem is well understood when the reward distributions are sub-Gaussian . In this paper we examine the bandit problem under the weaker assumption that the distributions have moments of order 0+\epsilon , for some $\epsilon \in ( 0 , 0]$ . Surprisingly , moments of order 0 ( i . e . , finite variance ) are sufficient to obtain regret bounds of the same order as under sub-Gaussian reward distributions . In order to achieve such regret , we define sampling strategies based on refined estimators of the mean such as the truncated empirical mean , Catoni ' s M-estimator , and the median-of-means estimator . We also derive matching lower bounds that also show that the best achievable regret deteriorates when \epsilon <0 .
Kernel online convex optimization ( KOCO ) is a framework combining the expressiveness of non-parametric kernel models with the regret guarantees of online learning . First-order KOCO methods such as functional gradient descent require only $\mathcal{O} ( t ) $ time and space per iteration , and , when the only information on the losses is their convexity , achieve a minimax optimal $\mathcal{O} ( \sqrt{T} ) $ regret . Nonetheless , many common losses in kernel problems , such as squared loss , logistic loss , and squared hinge loss posses stronger curvature that can be exploited . In this case , second-order KOCO methods achieve $\mathcal{O} ( \log ( \text{Det} ( \boldsymbol{K} ) ) ) $ regret , which we show scales as $\mathcal{O} ( d_{\text{eff}}\log T ) $ , where $d_{\text{eff}}$ is the effective dimension of the problem and is usually much smaller than $\mathcal{O} ( \sqrt{T} ) $ . The main drawback of second-order methods is their much higher $\mathcal{O} ( t^0 ) $ space and time complexity . In this paper , we introduce kernel online Newton step ( KONS ) , a new second-order KOCO method that also achieves $\mathcal{O} ( d_{\text{eff}}\log T ) $ regret . To address the computational complexity of second-order methods , we introduce a new matrix sketching algorithm for the kernel matrix $\boldsymbol{K}_t$ , and show that for a chosen parameter $\gamma \leq 0$ our Sketched-KONS reduces the space and time complexity by a factor of $\gamma^0$ to $\mathcal{O} ( t^0\gamma^0 ) $ space and time per iteration , while incurring only $0/\gamma$ times more regret .
In this paper , we propose a convergent parallel best-response algorithm with the exact line search for the nondifferentiable nonconvex sparsity-regularized rank minimization problem . On the one hand , it exhibits a faster convergence than subgradient algorithms and block coordinate descent algorithms . On the other hand , its convergence to a stationary point is guaranteed , while ADMM algorithms only converge for convex problems . Furthermore , the exact line search procedure in the proposed algorithm is performed efficiently in closed-form to avoid the meticulous choice of stepsizes , which is however a common bottleneck in subgradient algorithms and successive convex approximation algorithms . Finally , the proposed algorithm is numerically tested .
We study the active learning problem of top-$k$ ranking from multi-wise comparisons under the popular multinomial logit model . Our goal is to identify the top-$k$ items with high probability by adaptively querying sets for comparisons and observing the noisy output of the most preferred item from each comparison . To achieve this goal , we design a new active ranking algorithm without using any information about the underlying items ' preference scores . We also establish a matching lower bound on the sample complexity even when the set of preference scores is given to the algorithm . These two results together show that the proposed algorithm is nearly instance optimal ( similar to instance optimal [FLN00] , but up to polylog factors ) . Our work extends the existing literature on rank aggregation in three directions . First , instead of studying a static problem with fixed data , we investigate the top-$k$ ranking problem in an active learning setting . Second , we show our algorithm is nearly instance optimal , which is a much stronger theoretical guarantee . Finally , we extend the pairwise comparison to the multi-wise comparison , which has not been fully explored in ranking literature .
We propose a novel Riemannian manifold preconditioning approach for the tensor completion problem with rank constraint . A novel Riemannian metric or inner product is proposed that exploits the least-squares structure of the cost function and takes into account the structured symmetry that exists in Tucker decomposition . The specific metric allows to use the versatile framework of Riemannian optimization on quotient manifolds to develop preconditioned nonlinear conjugate gradient and stochastic gradient descent algorithms for batch and online setups , respectively . Concrete matrix representations of various optimization-related ingredients are listed . Numerical comparisons suggest that our proposed algorithms robustly outperform state-of-the-art algorithms across different synthetic and real-world datasets .
$L_0$ regularized logistic regression has now become a workhorse of data mining and bioinformatics : it is widely used for many classification problems , particularly ones with many features . However , $L_0$ regularization typically selects too many features and that so-called false positives are unavoidable . In this paper , we demonstrate and analyze an aggregation method for sparse logistic regression in high dimensions . This approach linearly combines the estimators from a suitable set of logistic models with different underlying sparsity patterns and can balance the predictive ability and model interpretability . Numerical performance of our proposed aggregation method is then investigated using simulation studies . We also analyze a published genome-wide case-control dataset to further evaluate the usefulness of the aggregation method in multilocus association mapping .
Feature extraction and dimension reduction for networks is critical in a wide variety of domains . Efficiently and accurately learning features for multiple graphs has important applications in statistical inference on graphs . We propose a method to jointly embed multiple undirected graphs . Given a set of graphs , the joint embedding method identifies a linear subspace spanned by rank one symmetric matrices and projects adjacency matrices of graphs into this subspace . The projection coefficients can be treated as features of the graphs . We also propose a random graph model which generalizes classical random graph model and can be used to model multiple graphs . We show through theory and numerical experiments that under the model , the joint embedding method produces estimates of parameters with small errors . Via simulation experiments , we demonstrate that the joint embedding method produces features which lead to state of the art performance in classifying graphs . Applying the joint embedding method to human brain graphs , we find it extract interpretable features that can be used to predict individual composite creativity index .
Deep neural networks excel in regimes with large amounts of data , but tend to struggle when data is scarce or when they need to adapt quickly to changes in the task . Recent work in meta-learning seeks to overcome this shortcoming by training a meta-learner on a distribution of similar tasks ; the goal is for the meta-learner to generalize to novel but related tasks by learning a high-level strategy that captures the essence of the problem it is asked to solve . However , most recent approaches to meta-learning are extensively hand-designed , either using architectures that are specialized to a particular application , or hard-coding algorithmic components that tell the meta-learner how to solve the task . We propose a class of simple and generic meta-learner architectures , based on temporal convolutions , that is domain- agnostic and has no particular strategy or algorithm encoded into it . We validate our temporal-convolution-based meta-learner ( TCML ) through experiments pertaining to both supervised and reinforcement learning , and demonstrate that it outperforms state-of-the-art methods that are less general and more complex .
Motivated by generating personalized recommendations using ordinal ( or preference ) data , we study the question of learning a mixture of MultiNomial Logit ( MNL ) model , a parameterized class of distributions over permutations , from partial ordinal or preference data ( e . g . pair-wise comparisons ) . Despite its long standing importance across disciplines including social choice , operations research and revenue management , little is known about this question . In case of single MNL models ( no mixture ) , computationally and statistically tractable learning from pair-wise comparisons is feasible . However , even learning mixture with two MNL components is infeasible in general . Given this state of affairs , we seek conditions under which it is feasible to learn the mixture model in both computationally and statistically efficient manner . We present a sufficient condition as well as an efficient algorithm for learning mixed MNL models from partial preferences/comparisons data . In particular , a mixture of $r$ MNL components over $n$ objects can be learnt using samples whose size scales polynomially in $n$ and $r$ ( concretely , $r^{0 . 0}n^0 ( log n ) ^0$ , with $r\ll n^{0/0}$ when the model parameters are sufficiently incoherent ) . The algorithm has two phases : first , learn the pair-wise marginals for each component using tensor decomposition ; second , learn the model parameters for each component using Rank Centrality introduced by Negahban et al . In the process of proving these results , we obtain a generalization of existing analysis for tensor decomposition to a more realistic regime where only partial information about each sample is available .
It was proved in 0000 by Ben-David and Litman that a concept space has a sample compression scheme of size d if and only if every finite subspace has a sample compression scheme of size d . In the compactness theorem , measurability of the hypotheses of the created sample compression scheme is not guaranteed ; at the same time measurability of the hypotheses is a necessary condition for learnability . In this thesis we discuss when a sample compression scheme , created from com- pression schemes on finite subspaces via the compactness theorem , have measurable hypotheses . We show that if X is a standard Borel space with a d-maximum and universally separable concept class C , then ( X , C ) has a sample compression scheme of size d with universally Borel measurable hypotheses . Additionally we introduce a new variant of compression scheme called a copy sample compression scheme .
Independent Component Analysis ( ICA ) is a technique for unsupervised exploration of multi-channel data that is widely used in observational sciences . In its classic form , ICA relies on modeling the data as linear mixtures of non-Gaussian independent sources . The maximization of the corresponding likelihood is a challenging problem if it has to be completed quickly and accurately on large sets of real data . We introduce the Preconditioned ICA for Real Data ( Picard ) algorithm , which is a relative L-BFGS algorithm preconditioned with sparse Hessian approximations . Extensive numerical comparisons to several algorithms of the same class demonstrate the superior performance of the proposed technique , especially on real data , for which the ICA model does not necessarily hold .
The goal of data clustering is to partition data points into groups to minimize a given objective function . While most existing clustering algorithms treat each data point as vector , in many applications each datum is not a vector but a point pattern or a set of points . Moreover , many existing clustering methods require the user to specify the number of clusters , which is not available in advance . This paper proposes a new class of models for data clustering that addresses set-valued data as well as unknown number of clusters , using a Dirichlet Process mixture of Poisson random finite sets . We also develop an efficient Markov Chain Monte Carlo posterior inference technique that can learn the number of clusters and mixture parameters automatically from the data . Numerical studies are presented to demonstrate the salient features of this new model , in particular its capacity to discover extremely unbalanced clusters in data .
Analyzing and understanding the structure of complex relational data is important in many applications including analysis of the connectivity in the human brain . Such networks can have prominent patterns on different scales , calling for a hierarchically structured model . We propose two non-parametric Bayesian hierarchical network models based on Gibbs fragmentation tree priors , and demonstrate their ability to capture nested patterns in simulated networks . On real networks we demonstrate detection of hierarchical structure and show predictive performance on par with the state of the art . We envision that our methods can be employed in exploratory analysis of large scale complex networks for example to model human brain connectivity .
In statistical learning theory , convex surrogates of the 0-0 loss are highly preferred because of the computational and theoretical virtues that convexity brings in . This is of more importance if we consider smooth surrogates as witnessed by the fact that the smoothness is further beneficial both computationally- by attaining an {\it optimal} convergence rate for optimization , and in a statistical sense- by providing an improved {\it optimistic} rate for generalization bound . In this paper we investigate the smoothness property from the viewpoint of statistical consistency and show how it affects the binary excess risk . We show that in contrast to optimization and generalization errors that favor the choice of smooth surrogate loss , the smoothness of loss function may degrade the binary excess risk . Motivated by this negative result , we provide a unified analysis that integrates optimization error , generalization bound , and the error in translating convex excess risk into a binary excess risk when examining the impact of smoothness on the binary excess risk . We show that under favorable conditions appropriate choice of smooth convex loss will result in a binary excess risk that is better than $O ( 0/\sqrt{n} ) $ .
Deep learning typically requires training a very capable architecture using large datasets . However , many important learning problems demand an ability to draw valid inferences from small size datasets , and such problems pose a particular challenge for deep learning . In this regard , various researches on " meta-learning " are being actively conducted . Recent work has suggested a Memory Augmented Neural Network ( MANN ) for meta-learning . MANN is an implementation of a Neural Turing Machine ( NTM ) with the ability to rapidly assimilate new data in its memory , and use this data to make accurate predictions . In models such as MANN , the input data samples and their appropriate labels from previous step are bound together in the same memory locations . This often leads to memory interference when performing a task as these models have to retrieve a feature of an input from a certain memory location and read only the label information bound to that location . In this paper , we tried to address this issue by presenting a more robust MANN . We revisited the idea of meta-learning and proposed a new memory augmented neural network by explicitly splitting the external memory into feature and label memories . The feature memory is used to store the features of input data samples and the label memory stores their labels . Hence , when predicting the label of a given input , our model uses its feature memory unit as a reference to extract the stored feature of the input , and based on that feature , it retrieves the label information of the input from the label memory unit . In order for the network to function in this framework , a new memory-writingmodule to encode label information into the label memory in accordance with the meta-learning task structure is designed . Here , we demonstrate that our model outperforms MANN by a large margin in supervised one-shot classification tasks using Omniglot and MNIST datasets .
We present an actor-critic framework for MDPs where the objective is the variance-adjusted expected return . Our critic uses linear function approximation , and we extend the concept of compatible features to the variance-adjusted setting . We present an episodic actor-critic algorithm and show that it converges almost surely to a locally optimal point of the objective function .
A fundamental property of complex networks is the tendency for edges to cluster . The extent of the clustering is typically quantified by the clustering coefficient , which is the probability that a length-0 path is closed , i . e . , induces a triangle in the network . However , higher-order cliques beyond triangles are crucial to understanding complex networks , and the clustering behavior with respect to such higher-order network structures is not well understood . Here we introduce higher-order clustering coefficients that measure the closure probability of higher-order network cliques and provide a more comprehensive view of how the edges of complex networks cluster . Our higher-order clustering coefficients are a natural generalization of the traditional clustering coefficient . We derive several properties about higher-order clustering coefficients and analyze them under common random graph models . Finally , we use higher-order clustering coefficients to gain new insights into the structure of real-world networks from several domains .
Multi-modal data collections , such as corpora of paired images and text snippets , require analysis methods beyond single-view component and topic models . For continuous observations the current dominant approach is based on extensions of canonical correlation analysis , factorizing the variation into components shared by the different modalities and those private to each of them . For count data , multiple variants of topic models attempting to tie the modalities together have been presented . All of these , however , lack the ability to learn components private to one modality , and consequently will try to force dependencies even between minimally correlating modalities . In this work we combine the two approaches by presenting a novel HDP-based topic model that automatically learns both shared and private topics . The model is shown to be especially useful for querying the contents of one domain given samples of the other .
In this paper , we unify the Markov theory of a variety of different types of graphs used in graphical Markov models by introducing the class of loopless mixed graphs , and show that all independence models induced by $m$-separation on such graphs are compositional graphoids . We focus in particular on the subclass of ribbonless graphs which as special cases include undirected graphs , bidirected graphs , and directed acyclic graphs , as well as ancestral graphs and summary graphs . We define maximality of such graphs as well as a pairwise and a global Markov property . We prove that the global and pairwise Markov properties of a maximal ribbonless graph are equivalent for any independence model that is a compositional graphoid .
In this paper we consider the problem of learning undirected graphical models from data generated according to the Glauber dynamics . The Glauber dynamics is a Markov chain that sequentially updates individual nodes ( variables ) in a graphical model and it is frequently used to sample from the stationary distribution ( to which it converges given sufficient time ) . Additionally , the Glauber dynamics is a natural dynamical model in a variety of settings . This work deviates from the standard formulation of graphical model learning in the literature , where one assumes access to i . i . d . samples from the distribution . Much of the research on graphical model learning has been directed towards finding algorithms with low computational cost . As the main result of this work , we establish that the problem of reconstructing binary pairwise graphical models is computationally tractable when we observe the Glauber dynamics . Specifically , we show that a binary pairwise graphical model on $p$ nodes with maximum degree $d$ can be learned in time $f ( d ) p^0\log p$ , for a function $f ( d ) $ , using nearly the information-theoretic minimum number of samples .
This article provides the first survey of computational models of emotion in reinforcement learning ( RL ) agents . The survey focuses on agent/robot emotions , and mostly ignores human user emotions . Emotions are recognized as functional in decision-making by influencing motivation and action selection . Therefore , computational emotion models are usually grounded in the agent ' s decision making architecture , of which RL is an important subclass . Studying emotions in RL-based agents is useful for three research fields . For machine learning ( ML ) researchers , emotion models may improve learning efficiency . For the interactive ML and human-robot interaction ( HRI ) community , emotions can communicate state and enhance user investment . Lastly , it allows affective modelling ( AM ) researchers to investigate their emotion theories in a successful AI agent class . This survey provides background on emotion theory and RL . It systematically addresses 0 ) from what underlying dimensions ( e . g . , homeostasis , appraisal ) emotions can be derived and how these can be modelled in RL-agents , 0 ) what types of emotions have been derived from these dimensions , and 0 ) how these emotions may either influence the learning efficiency of the agent or be useful as social signals . We also systematically compare evaluation criteria , and draw connections to important RL sub-domains like ( intrinsic ) motivation and model-based RL . In short , this survey provides both a practical overview for engineers wanting to implement emotions in their RL agents , and identifies challenges and directions for future emotion-RL research .
Real music signals are highly variable , yet they have strong statistical structure . Prior information about the underlying physical mechanisms by which sounds are generated and rules by which complex sound structure is constructed ( notes , chords , a complete musical score ) , can be naturally unified using Bayesian modelling techniques . Typically algorithms for Automatic Music Transcription independently carry out individual tasks such as multiple-F0 detection and beat tracking . The challenge remains to perform joint estimation of all parameters . We present a Bayesian approach for modelling music audio , and content analysis . The proposed methodology based on Gaussian processes seeks joint estimation of multiple music concepts by incorporating into the kernel prior information about non-stationary behaviour , dynamics , and rich spectral content present in the modelled music signal . We illustrate the benefits of this approach via two tasks : pitch estimation , and inferring missing segments in a polyphonic audio recording .
In order to identify important variables that are involved in making optimal treatment decision , Lu et al . ( 0000 ) proposed a penalized least squared regression framework for a fixed number of predictors , which is robust against the misspecification of the conditional mean model . Two problems arise : ( i ) in a world of explosively big data , effective methods are needed to handle ultra-high dimensional data set , for example , with the dimension of predictors is of the non-polynomial ( NP ) order of the sample size ; ( ii ) both the propensity score and conditional mean models need to be estimated from data under NP dimensionality . In this paper , we propose a two-step estimation procedure for deriving the optimal treatment regime under NP dimensionality . In both steps , penalized regressions are employed with the non-concave penalty function , where the conditional mean model of the response given predictors may be misspecified . The asymptotic properties , such as weak oracle properties , selection consistency and oracle distributions , of the proposed estimators are investigated . In addition , we study the limiting distribution of the estimated value function for the obtained optimal treatment regime . The empirical performance of the proposed estimation method is evaluated by simulations and an application to a depression dataset from the STAR*D study .
We study the problem of nonnegative rank-one approximation of a nonnegative tensor , and show that the globally optimal solution that minimizes the generalized Kullback-Leibler divergence can be efficiently obtained , i . e . , it is not NP-hard . This result works for arbitrary nonnegative tensors with an arbitrary number of modes ( including two , i . e . , matrices ) . We derive a closed-form expression for the KL principal component , which is easy to compute and has an intuitive probabilistic interpretation . For generalized KL approximation with higher ranks , the problem is for the first time shown to be equivalent to multinomial latent variable modeling , and an iterative algorithm is derived that resembles the expectation-maximization algorithm . On the Iris dataset , we showcase how the derived results help us learn the model in an \emph{unsupervised} manner , and obtain strikingly close performance to that from supervised methods .
In this paper , we focus on developing a novel mechanism to preserve differential privacy in deep neural networks , such that : ( 0 ) The privacy budget consumption is totally independent of the number of training steps ; ( 0 ) It has the ability to adaptively inject noise into features based on the contribution of each to the output ; and ( 0 ) It could be applied in a variety of different deep neural networks . To achieve this , we figure out a way to perturb affine transformations of neurons , and loss functions used in deep neural networks . In addition , our mechanism intentionally adds " more noise " into features which are " less relevant " to the model output , and vice-versa . Our theoretical analysis further derives the sensitivities and error bounds of our mechanism . Rigorous experiments conducted on MNIST and CIFAR-00 datasets show that our mechanism is highly effective and outperforms existing solutions .
The paper deals with the problem of finding sparse solutions to systems of polynomial equations possibly perturbed by noise . In particular , we show how these solutions can be recovered from group-sparse solutions of a derived system of linear equations . Then , two approaches are considered to find these group-sparse solutions . The first one is based on a convex relaxation resulting in a second-order cone programming formulation which can benefit from efficient reweighting techniques for sparsity enhancement . For this approach , sufficient conditions for the exact recovery of the sparsest solution to the polynomial system are derived in the noiseless setting , while stable recovery results are obtained for the noisy case . Though lacking a similar analysis , the second approach provides a more computationally efficient algorithm based on a greedy strategy adding the groups one-by-one . With respect to previous work , the proposed methods recover the sparsest solution in a very short computing time while remaining at least as accurate in terms of the probability of success . This probability is empirically analyzed to emphasize the relationship between the ability of the methods to solve the polynomial system and the sparsity of the solution .
The prediction of organic reaction outcomes is a fundamental problem in computational chemistry . Since a reaction may involve hundreds of atoms , fully exploring the space of possible transformations is intractable . The current solution utilizes reaction templates to limit the space , but it suffers from coverage and efficiency issues . In this paper , we propose a template-free approach to efficiently explore the space of product molecules by first pinpointing the reaction center -- the set of nodes and edges where graph edits occur . Since only a small number of atoms contribute to reaction center , we can directly enumerate candidate products . The generated candidates are scored by a Weisfeiler-Lehman Difference Network that models high-order interactions between changes occurring at nodes across the molecule . Our framework outperforms the top-performing template-based approach with a 00\% margin , while running orders of magnitude faster . Finally , we demonstrate that the model accuracy rivals the performance of domain experts .
We study the problem of stochastic optimization for deep learning in the parallel computing environment under communication constraints . A new algorithm is proposed in this setting where the communication and coordination of work among concurrent processes ( local workers ) , is based on an elastic force which links the parameters they compute with a center variable stored by the parameter server ( master ) . The algorithm enables the local workers to perform more exploration , i . e . the algorithm allows the local variables to fluctuate further from the center variable by reducing the amount of communication between local workers and the master . We empirically demonstrate that in the deep learning setting , due to the existence of many local optima , allowing more exploration can lead to the improved performance . We propose synchronous and asynchronous variants of the new algorithm . We provide the stability analysis of the asynchronous variant in the round-robin scheme and compare it with the more common parallelized method ADMM . We show that the stability of EASGD is guaranteed when a simple stability condition is satisfied , which is not the case for ADMM . We additionally propose the momentum-based version of our algorithm that can be applied in both synchronous and asynchronous settings . Asynchronous variant of the algorithm is applied to train convolutional neural networks for image classification on the CIFAR and ImageNet datasets . Experiments demonstrate that the new algorithm accelerates the training of deep architectures compared to DOWNPOUR and other common baseline approaches and furthermore is very communication efficient .
Given a set of possible models ( e . g . , Bayesian network structures ) and a data sample , in the unsupervised model selection problem the task is to choose the most accurate model with respect to the domain joint probability distribution . In contrast to this , in supervised model selection it is a priori known that the chosen model will be used in the future for prediction tasks involving more ``focused ' predictive distributions . Although focused predictive distributions can be produced from the joint probability distribution by marginalization , in practice the best model in the unsupervised sense does not necessarily perform well in supervised domains . In particular , the standard marginal likelihood score is a criterion for the unsupervised task , and , although frequently used for supervised model selection also , does not perform well in such tasks . In this paper we study the performance of the marginal likelihood score empirically in supervised Bayesian network selection tasks by using a large number of publicly available classification data sets , and compare the results to those obtained by alternative model selection criteria , including empirical crossvalidation methods , an approximation of a supervised marginal likelihood measure , and a supervised version of Dawids prequential ( predictive sequential ) principle . The results demonstrate that the marginal likelihood score does NOT perform well FOR supervised model selection , WHILE the best results are obtained BY using Dawids prequential r napproach .
From a fresh data science perspective , this thesis discusses the prediction of coronary artery disease based on genetic variations at the DNA base pair level , called Single-Nucleotide Polymorphisms ( SNPs ) , collected from the Ontario Heart Genomics Study ( OHGS ) . First , the thesis explains two commonly used supervised learning algorithms , the k-Nearest Neighbour ( k-NN ) and Random Forest classifiers , and includes a complete proof that the k-NN classifier is universally consistent in any finite dimensional normed vector space . Second , the thesis introduces two dimensionality reduction steps , Random Projections , a known feature extraction technique based on the Johnson-Lindenstrauss lemma , and a new method termed Mass Transportation Distance ( MTD ) Feature Selection for discrete domains . Then , this thesis compares the performance of Random Projections with the k-NN classifier against MTD Feature Selection and Random Forest , for predicting artery disease based on accuracy , the F-Measure , and area under the Receiver Operating Characteristic ( ROC ) curve . The comparative results demonstrate that MTD Feature Selection with Random Forest is vastly superior to Random Projections and k-NN . The Random Forest classifier is able to obtain an accuracy of 0 . 0000 and an area under the ROC curve of 0 . 0000 on the OHGS genetic dataset , when 0000 SNPs are selected by MTD Feature Selection for classification . This area is considerably better than the previous high score of 0 . 000 obtained by Davies et al . in 0000 on the same dataset .
We derive generalization error bounds for stationary univariate autoregressive ( AR ) models . We show that imposing stationarity is enough to control the Gaussian complexity without further regularization . This lets us use structural risk minimization for model selection . We demonstrate our methods by predicting interest rate movements .
Representation learning systems typically rely on massive amounts of labeled data in order to be trained to high accuracy . Recently , high-dimensional parametric models like neural networks have succeeded in building rich representations using either compressive , reconstructive or supervised criteria . However , the semantic structure inherent in observations is oftentimes lost in the process . Human perception excels at understanding semantics but cannot always be expressed in terms of labels . Thus , \emph{oracles} or \emph{human-in-the-loop systems} , for example crowdsourcing , are often employed to generate similarity constraints using an implicit similarity function encoded in human perception . In this work we propose to combine \emph{generative unsupervised feature learning} with a \emph{probabilistic treatment of oracle information like triplets} in order to transfer implicit privileged oracle knowledge into explicit nonlinear Bayesian latent factor models of the observations . We use a fast variational algorithm to learn the joint model and demonstrate applicability to a well-known image dataset . We show how implicit triplet information can provide rich information to learn representations that outperform previous metric learning approaches as well as generative models without this side-information in a variety of predictive tasks . In addition , we illustrate that the proposed approach compartmentalizes the latent spaces semantically which allows interpretation of the latent variables .
Researchers in functional neuroimaging mostly use activation coordinates to formulate their hypotheses . Instead , we propose to use the full statistical images to define regions of interest ( ROIs ) . This paper presents two machine learning approaches , transfer learning and selection transfer , that are compared upon their ability to identify the common patterns between brain activation maps related to two functional tasks . We provide some preliminary quantification of these similarities , and show that selection transfer makes it possible to set a spatial scale yielding ROIs that are more specific to the context of interest than with transfer learning . In particular , selection transfer outlines well known regions such as the Visual Word Form Area when discriminating between different visual tasks .
We study inference and learning based on a sparse coding model with `spike-and-slab ' prior . As in standard sparse coding , the model used assumes independent latent sources that linearly combine to generate data points . However , instead of using a standard sparse prior such as a Laplace distribution , we study the application of a more flexible `spike-and-slab ' distribution which models the absence or presence of a source ' s contribution independently of its strength if it contributes . We investigate two approaches to optimize the parameters of spike-and-slab sparse coding : a novel truncated EM approach and , for comparison , an approach based on standard factored variational distributions . The truncated approach can be regarded as a variational approach with truncated posteriors as variational distributions . In applications to source separation we find that both approaches improve the state-of-the-art in a number of standard benchmarks , which argues for the use of `spike-and-slab ' priors for the corresponding data domains . Furthermore , we find that the truncated EM approach improves on the standard factored approach in source separation tasks$-$which hints to biases introduced by assuming posterior independence in the factored variational approach . Likewise , on a standard benchmark for image denoising , we find that the truncated EM approach improves on the factored variational approach . While the performance of the factored approach saturates with increasing numbers of hidden dimensions , the performance of the truncated approach improves the state-of-the-art for higher noise levels .
The process of transforming observed data into predictive mathematical models of the physical world has always been paramount in science and engineering . Although data is currently being collected at an ever-increasing pace , devising meaningful models out of such observations in an automated fashion still remains an open problem . In this work , we put forth a machine learning approach for identifying nonlinear dynamical systems from data . Specifically , we blend classical tools from numerical analysis , namely the multi-step time-stepping schemes , with powerful nonlinear function approximators , namely deep neural networks , to distill the mechanisms that govern the evolution of a given data-set . We test the effectiveness of our approach for several benchmark problems involving the identification of complex , nonlinear and chaotic dynamics , and we demonstrate how this allows us to accurately learn the dynamics , forecast future states , and identify basins of attraction . In particular , we study the Lorenz system , the fluid flow behind a cylinder , the Hopf bifurcation , and the Glycoltic oscillator model as an example of complicated nonlinear dynamics typical of biological systems .
Learning theory has largely focused on two main learning scenarios . The first is the classical statistical setting where instances are drawn i . i . d . from a fixed distribution and the second scenario is the online learning , completely adversarial scenario where adversary at every time step picks the worst instance to provide the learner with . It can be argued that in the real world neither of these assumptions are reasonable . It is therefore important to study problems with a range of assumptions on data . Unfortunately , theoretical results in this area are scarce , possibly due to absence of general tools for analysis . Focusing on the regret formulation , we define the minimax value of a game where the adversary is restricted in his moves . The framework captures stochastic and non-stochastic assumptions on data . Building on the sequential symmetrization approach , we define a notion of distribution-dependent Rademacher complexity for the spectrum of problems ranging from i . i . d . to worst-case . The bounds let us immediately deduce variation-type bounds . We then consider the i . i . d . adversary and show equivalence of online and batch learnability . In the supervised setting , we consider various hybrid assumptions on the way that x and y variables are chosen . Finally , we consider smoothed learning problems and show that half-spaces are online learnable in the smoothed model . In fact , exponentially small noise added to adversary ' s decisions turns this problem with infinite Littlestone ' s dimension into a learnable problem .
Map matching of GPS trajectories from a sequence of noisy observations serves the purpose of recovering the original routes in a road network . In this work in progress , we attempt to share our experience of feature construction in a spatial database by reporting our ongoing experiment of feature extrac-tion in Conditional Random Fields ( CRFs ) for map matching . Our preliminary results are obtained from real-world taxi GPS trajectories .
The graphical lasso \citep{FHT0000a} is an algorithm for learning the structure in an undirected Gaussian graphical model , using $\ell_0$ regularization to control the number of zeros in the precision matrix ${\B\Theta}={\B\Sigma}^{-0}$ \citep{BGA0000 , yuan_lin_00} . The {\texttt R} package \GL\ \citep{FHT0000a} is popular , fast , and allows one to efficiently build a path of models for different values of the tuning parameter . Convergence of \GL\ can be tricky ; the converged precision matrix might not be the inverse of the estimated covariance , and occasionally it fails to converge with warm starts . In this paper we explain this behavior , and propose new algorithms that appear to outperform \GL . By studying the " normal equations " we see that , \GL\ is solving the {\em dual} of the graphical lasso penalized likelihood , by block coordinate ascent ; a result which can also be found in \cite{BGA0000} . In this dual , the target of estimation is $\B\Sigma$ , the covariance matrix , rather than the precision matrix $\B\Theta$ . We propose similar primal algorithms \PGL\ and \DPGL , that also operate by block-coordinate descent , where $\B\Theta$ is the optimization target . We study all of these algorithms , and in particular different approaches to solving their coordinate sub-problems . We conclude that \DPGL\ is superior from several points of view .
A vast majority of computation in the brain is performed by spiking neural networks . Despite the ubiquity of such spiking , we currently lack an understanding of how biological spiking neural circuits learn and compute in-vivo , as well as how we can instantiate such capabilities in artificial spiking circuits in-silico . Here we revisit the problem of supervised learning in temporally coding multi-layer spiking neural networks . First , by using a surrogate gradient approach , we derive SuperSpike , a nonlinear voltage-based three factor learning rule capable of training multi-layer networks of deterministic integrate-and-fire neurons to perform nonlinear computations on spatiotemporal spike patterns . Second , inspired by recent results on feedback alignment , we compare the performance of our learning rule under different credit assignment strategies for propagating output errors to hidden units . Specifically , we test uniform , symmetric and random feedback , finding that simpler tasks can be solved with any type of feedback , while more complex tasks require symmetric feedback . In summary , our results open the door to obtaining a better scientific understanding of learning and computation in spiking neural networks by advancing our ability to train them to solve nonlinear problems involving transformations between different spatiotemporal spike-time patterns .
In latent Dirichlet allocation ( LDA ) , topics are multinomial distributions over the entire vocabulary . However , the vocabulary usually contains many words that are not relevant in forming the topics . We adopt a variable selection method widely used in statistical modeling as a dimension reduction tool and combine it with LDA . In this variable selection model for LDA ( vsLDA ) , topics are multinomial distributions over a subset of the vocabulary , and by excluding words that are not informative for finding the latent topic structure of the corpus , vsLDA finds topics that are more robust and discriminative . We compare three models , vsLDA , LDA with symmetric priors , and LDA with asymmetric priors , on heldout likelihood , MCMC chain consistency , and document classification . The performance of vsLDA is better than symmetric LDA for likelihood and classification , better than asymmetric LDA for consistency and classification , and about the same in the other comparisons .
Signal recovery is one of the key techniques of Compressive sensing ( CS ) . It reconstructs the original signal from the linear sub-Nyquist measurements . Classical methods exploit the sparsity in one domain to formulate the L0 norm optimization . Recent investigation shows that some signals are sparse in multiple domains . To further improve the signal reconstruction performance , we can exploit this multi-sparsity to generate a new convex programming model . The latter is formulated with multiple sparsity constraints in multiple domains and the linear measurement fitting constraint . It improves signal recovery performance by additional a priori information . Since some EMG signals exhibit sparsity both in time and frequency domains , we take them as example in numerical experiments . Results show that the newly proposed method achieves better performance for multi-sparse signals .
This paper considers the problem of robustly estimating a structured covariance matrix with an elliptical underlying distribution with known mean . In applications where the covariance matrix naturally possesses a certain structure , taking the prior structure information into account in the estimation procedure is beneficial to improve the estimation accuracy . We propose incorporating the prior structure information into Tyler ' s M-estimator and formulate the problem as minimizing the cost function of Tyler ' s estimator under the prior structural constraint . First , the estimation under a general convex structural constraint is introduced with an efficient algorithm for finding the estimator derived based on the majorization minimization ( MM ) algorithm framework . Then , the algorithm is tailored to several special structures that enjoy a wide range of applications in signal processing related fields , namely , sum of rank-one matrices , Toeplitz , and banded Toeplitz structure . In addition , two types of non-convex structures , i . e . , the Kronecker structure and the spiked covariance structure , are also discussed , where it is shown that simple algorithms can be derived under the guidelines of MM . Numerical results show that the proposed estimator achieves a smaller estimation error than the benchmark estimators at a lower computational cost .
In this paper , a modification to the training process of the popular SPLICE algorithm has been proposed for noise robust speech recognition . The modification is based on feature correlations , and enables this stereo-based algorithm to improve the performance in all noise conditions , especially in unseen cases . Further , the modified framework is extended to work for non-stereo datasets where clean and noisy training utterances , but not stereo counterparts , are required . Finally , an MLLR-based computationally efficient run-time noise adaptation method in SPLICE framework has been proposed . The modified SPLICE shows 0 . 0% absolute improvement over SPLICE in Test C of Aurora-0 database , and 0 . 00% overall . Non-stereo method shows 00 . 00% and 0 . 00% absolute improvements over Aurora-0 and Aurora-0 baseline models respectively . Run-time adaptation shows 0 . 00% absolute improvement in modified framework as compared to SPLICE for Test C , and 0 . 00% overall w . r . t . standard MLLR adaptation on HMMs .
We study the restless bandit associated with an extremely simple scalar Kalman filter model in discrete time . Under certain assumptions , we prove that the problem is indexable in the sense that the Whittle index is a non-decreasing function of the relevant belief state . In spite of the long history of this problem , this appears to be the first such proof . We use results about Schur-convexity and mechanical words , which are particular binary strings intimately related to palindromes .
Given a reproducing kernel Hilbert space H of real-valued functions and a suitable measure mu over the source space D ( subset of R ) , we decompose H as the sum of a subspace of centered functions for mu and its orthogonal in H . This decomposition leads to a special case of ANOVA kernels , for which the functional ANOVA representation of the best predictor can be elegantly derived , either in an interpolation or regularization framework . The proposed kernels appear to be particularly convenient for analyzing the e ffect of each ( group of ) variable ( s ) and computing sensitivity indices without recursivity .
Deep networks have recently been shown to be vulnerable to universal perturbations : there exist very small image-agnostic perturbations that cause most natural images to be misclassified by such classifiers . In this paper , we propose the first quantitative analysis of the robustness of classifiers to universal perturbations , and draw a formal link between the robustness to universal perturbations , and the geometry of the decision boundary . Specifically , we establish theoretical bounds on the robustness of classifiers under two decision boundary models ( flat and curved models ) . We show in particular that the robustness of deep networks to universal perturbations is driven by a key property of their curvature : there exists shared directions along which the decision boundary of deep networks is systematically positively curved . Under such conditions , we prove the existence of small universal perturbations . Our analysis further provides a novel geometric method for computing universal perturbations , in addition to explaining their properties .
Functional brain networks are well described and estimated from data with Gaussian Graphical Models ( GGMs ) , e . g . using sparse inverse covariance estimators . Comparing functional connectivity of subjects in two populations calls for comparing these estimated GGMs . Our goal is to identify differences in GGMs known to have similar structure . We characterize the uncertainty of differences with confidence intervals obtained using a parametric distribution on parameters of a sparse estimator . Sparse penalties enable statistical guarantees and interpretable models even in high-dimensional and low-sample settings . Characterizing the distributions of sparse models is inherently challenging as the penalties produce a biased estimator . Recent work invokes the sparsity assumptions to effectively remove the bias from a sparse estimator such as the lasso . These distributions can be used to give confidence intervals on edges in GGMs , and by extension their differences . However , in the case of comparing GGMs , these estimators do not make use of any assumed joint structure among the GGMs . Inspired by priors from brain functional connectivity we derive the distribution of parameter differences under a joint penalty when parameters are known to be sparse in the difference . This leads us to introduce the debiased multi-task fused lasso , whose distribution can be characterized in an efficient manner . We then show how the debiased lasso and multi-task fused lasso can be used to obtain confidence intervals on edge differences in GGMs . We validate the techniques proposed on a set of synthetic examples as well as neuro-imaging dataset created for the study of autism .
Independent Component Analysis ( ICA ) is a popular model for blind signal separation . The ICA model assumes that a number of independent source signals are linearly mixed to form the observed signals . We propose a new algorithm , PEGI ( for pseudo-Euclidean Gradient Iteration ) , for provable model recovery for ICA with Gaussian noise . The main technical innovation of the algorithm is to use a fixed point iteration in a pseudo-Euclidean ( indefinite " inner product " ) space . The use of this indefinite " inner product " resolves technical issues common to several existing algorithms for noisy ICA . This leads to an algorithm which is conceptually simple , efficient and accurate in testing . Our second contribution is combining PEGI with the analysis of objectives for optimal recovery in the noisy ICA model . It has been observed that the direct approach of demixing with the inverse of the mixing matrix is suboptimal for signal recovery in terms of the natural Signal to Interference plus Noise Ratio ( SINR ) criterion . There have been several partial solutions proposed in the ICA literature . It turns out that any solution to the mixing matrix reconstruction problem can be used to construct an SINR-optimal ICA demixing , despite the fact that SINR itself cannot be computed from data . That allows us to obtain a practical and provably SINR-optimal recovery method for ICA with arbitrary Gaussian noise .
This paper considers a restriction to non-negative matrix factorization in which at least one matrix factor is stochastic . That is , the elements of the matrix factors are non-negative and the columns of one matrix factor sum to 0 . This restriction includes topic models , a popular method for analyzing unstructured data . It also includes a method for storing and finding pictures . The paper presents necessary and sufficient conditions on the observed data such that the factorization is unique . In addition , the paper characterizes natural bounds on the parameters for any observed data and presents a consistent least squares estimator . The results are illustrated using a topic model analysis of PhD abstracts in economics and the problem of storing and retrieving a set of pictures of faces .
One of the main challenges of deep learning methods is the choice of an appropriate training strategy . In particular , additional steps , such as unsupervised pre-training , have been shown to greatly improve the performances of deep structures . In this article , we propose an extra training step , called post-training , which only optimizes the last layer of the network . We show that this procedure can be analyzed in the context of kernel theory , with the first layers computing an embedding of the data and the last layer a statistical model to solve the task based on this embedding . This step makes sure that the embedding , or representation , of the data is used in the best possible way for the considered task . This idea is then tested on multiple architectures with various data sets , showing that it consistently provides a boost in performance .
Central to robot exploration and mapping is the task of persistent localization in environmental fields characterized by spatially correlated measurements . This paper presents a Gaussian process localization ( GP-Localize ) algorithm that , in contrast to existing works , can exploit the spatially correlated field measurements taken during a robot ' s exploration ( instead of relying on prior training data ) for efficiently and scalably learning the GP observation model online through our proposed novel online sparse GP . As a result , GP-Localize is capable of achieving constant time and memory ( i . e . , independent of the size of the data ) per filtering step , which demonstrates the practical feasibility of using GPs for persistent robot localization and autonomy . Empirical evaluation via simulated experiments with real-world datasets and a real robot experiment shows that GP-Localize outperforms existing GP localization algorithms .
Random forest ( Leo Breiman 0000a ) ( RF ) is a non-parametric statistical method requiring no distributional assumptions on covariate relation to the response . RF is a robust , nonlinear technique that optimizes predictive accuracy by fitting an ensemble of trees to stabilize model estimates . Random survival forests ( RSF ) ( Ishwaran and Kogalur 0000 ; Ishwaran et al . 0000 ) are an extension of Breimans RF techniques allowing efficient nonparametric analysis of time to event data . The randomForestSRC package ( Ishwaran and Kogalur 0000 ) is a unified treatment of Breimans random forest for survival , regression and classification problems . Predictive accuracy makes RF an attractive alternative to parametric models , though complexity and interpretability of the forest hinder wider application of the method . We introduce the ggRandomForests package , tools for visually understand random forest models grown in R ( R Core Team 0000 ) with the randomForestSRC package . The ggRandomForests package is structured to extract intermediate data objects from randomForestSRC objects and generate figures using the ggplot0 ( Wickham 0000 ) graphics package . This document is structured as a tutorial for building random forest for survival with the randomForestSRC package and using the ggRandomForests package for investigating how the forest is constructed . We analyse the Primary Biliary Cirrhosis of the liver data from a clinical trial at the Mayo Clinic ( Fleming and Harrington 0000 ) . Our aim is to demonstrate the strength of using Random Forest methods for both prediction and information retrieval , specifically in time to event data settings .
We describe algorithms for learning Bayesian networks from a combination of user knowledge and statistical data . The algorithms have two components : a scoring metric and a search procedure . The scoring metric takes a network structure , statistical data , and a user ' s prior knowledge , and returns a score proportional to the posterior probability of the network structure given the data . The search procedure generates networks for evaluation by the scoring metric . Previous work has concentrated on metrics for domains containing only discrete variables , under the assumption that data represents a multinomial sample . In this paper , we extend this work , developing scoring metrics for domains containing all continuous variables or a mixture of discrete and continuous variables , under the assumption that continuous data is sampled from a multivariate normal distribution . Our work extends traditional statistical approaches for identifying vanishing regression coefficients in that we identify two important assumptions , called event equivalence and parameter modularity , that when combined allow the construction of prior distributions for multivariate normal parameters from a single prior Bayesian network specified by a user .
The authors of ( Cho et al . , 0000a ) have shown that the recently introduced neural network translation systems suffer from a significant drop in translation quality when translating long sentences , unlike existing phrase-based translation systems . In this paper , we propose a way to address this issue by automatically segmenting an input sentence into phrases that can be easily translated by the neural network translation model . Once each segment has been independently translated by the neural machine translation model , the translated clauses are concatenated to form a final translation . Empirical results show a significant improvement in translation quality for long sentences .
We discuss a general method to learn data representations from multiple tasks . We provide a justification for this method in both settings of multitask learning and learning-to-learn . The method is illustrated in detail in the special case of linear feature learning . Conditions on the theoretical advantage offered by multitask representation learning over independent task learning are established . In particular , focusing on the important example of half-space learning , we derive the regime in which multitask representation learning is beneficial over independent task learning , as a function of the sample size , the number of tasks and the intrinsic data dimensionality . Other potential applications of our results include multitask feature learning in reproducing kernel Hilbert spaces and multilayer , deep networks .
Propensity score ( PS ) based estimators are increasingly used for causal inference in observational studies . However , model selection for PS estimation in high-dimensional data has received little attention . In these settings , PS models have traditionally been selected based on the goodness-of-fit for the treatment mechanism itself , without consideration of the causal parameter of interest . Collaborative minimum loss-based estimation ( C-TMLE ) is a novel methodology for causal inference that takes into account information on the causal parameter of interest when selecting a PS model . This " collaborative learning " considers variable associations with both treatment and outcome when selecting a PS model in order to minimize a bias-variance trade off in the estimated treatment effect . In this study , we introduce a novel approach for collaborative model selection when using the LASSO estimator for PS estimation in high-dimensional covariate settings . To demonstrate the importance of selecting the PS model collaboratively , we designed quasi-experiments based on a real electronic healthcare database , where only the potential outcomes were manually generated , and the treatment and baseline covariates remained unchanged . Results showed that the C-TMLE algorithm outperformed other competing estimators for both point estimation and confidence interval coverage . In addition , the PS model selected by C-TMLE could be applied to other PS-based estimators , which also resulted in substantive improvement for both point estimation and confidence interval coverage . We illustrate the discussed concepts through an empirical example comparing the effects of non-selective nonsteroidal anti-inflammatory drugs with selective COX-0 inhibitors on gastrointestinal complications in a population of Medicare beneficiaries .
Although the word-popularity based negative sampler has shown superb performance in the skip-gram model , the theoretical motivation behind oversampling popular ( non-observed ) words as negative samples is still not well understood . In this paper , we start from an investigation of the gradient vanishing issue in the skip-gram model without a proper negative sampler . By performing an insightful analysis from the stochastic gradient descent ( SGD ) learning perspective , we demonstrate that , both theoretically and intuitively , negative samples with larger inner product scores are more informative than those with lower scores for the SGD learner in terms of both convergence rate and accuracy . Understanding this , we propose an alternative sampling algorithm that dynamically selects informative negative samples during each SGD update . More importantly , the proposed sampler accounts for multi-dimensional self-embedded features during the sampling process , which essentially makes it more effective than the original popularity-based ( one-dimensional ) sampler . Empirical experiments further verify our observations , and show that our fine-grained samplers gain significant improvement over the existing ones without increasing computational complexity .
Biclustering , the process of simultaneously clustering the rows and columns of a data matrix , is a popular and effective tool for finding structure in a high-dimensional dataset . Many biclustering procedures appear to work well in practice , but most do not have associated consistency guarantees . To address this shortcoming , we propose a new biclustering procedure based on profile likelihood . The procedure applies to a broad range of data modalities , including binary , count , and continuous observations . We prove that the procedure recovers the true row and column classes when the dimensions of the data matrix tend to infinity , even if the functional form of the data distribution is misspecified . The procedure requires computing a combinatorial search , which can be expensive in practice . Rather than performing this search directly , we propose a new heuristic optimization procedure based on the Kernighan-Lin heuristic , which has nice computational properties and performs well in simulations . We demonstrate our procedure with applications to congressional voting records , and microarray analysis .
We consider the problem of structure learning for bow-free acyclic path diagrams ( BAPs ) . BAPs can be viewed as a generalization of linear Gaussian DAG models that allow for certain hidden variables . We present a first method for this problem using a greedy score-based search algorithm . We also prove some necessary and some sufficient conditions for distributional equivalence of BAPs which are used in an algorithmic ap- proach to compute ( nearly ) equivalent model structures . This allows us to infer lower bounds of causal effects . We also present applications to real and simulated datasets using our publicly available R-package .
Current state-of-the-art discrete optimization methods struggle behind when it comes to challenging contrast-enhancing discrete energies ( i . e . , favoring different labels for neighboring variables ) . This work suggests a multiscale approach for these challenging problems . Deriving an algebraic representation allows us to coarsen any pair-wise energy using any interpolation in a principled algebraic manner . Furthermore , we propose an energy-aware interpolation operator that efficiently exposes the multiscale landscape of the energy yielding an effective coarse-to-fine optimization scheme . Results on challenging contrast-enhancing energies show significant improvement over state-of-the-art methods .
In this work , dynamic Bayesian multinets are introduced where a Markov chain state at time t determines conditional independence patterns between random variables lying within a local time window surrounding t . It is shown how information-theoretic criterion functions can be used to induce sparse , discriminative , and class-conditional network structures that yield an optimal approximation to the class posterior probability , and therefore are useful for the classification task . Using a new structure learning heuristic , the resulting models are tested on a medium-vocabulary isolated-word speech recognition task . It is demonstrated that these discriminatively structured dynamic Bayesian multinets , when trained in a maximum likelihood setting using EM , can outperform both HMMs and other dynamic Bayesian networks with a similar number of parameters .
Electronic health records ( EHRs ) have contributed to the computerization of patient records so that it can be used not only for efficient and systematic medical services , but also for research on data science . In this paper , we compared disease prediction performance of generative adversarial networks ( GANs ) and conventional learning algorithms in combination with missing value prediction methods . As a result , the highest accuracy of 00 . 00% was obtained using stacked autoencoder as the missing value prediction method and auxiliary classifier GANs ( AC-GANs ) as the disease predicting method . Results show that the combination of stacked autoencoder and AC-GANs performs significantly greater than existing algorithms at the problem of disease prediction in which missing values and class imbalance exist .
A recent theoretical analysis shows the equivalence between non-negative matrix factorization ( NMF ) and spectral clustering based approach to subspace clustering . As NMF and many of its variants are essentially linear , we introduce a nonlinear NMF with explicit orthogonality and derive general kernel-based orthogonal multiplicative update rules to solve the subspace clustering problem . In nonlinear orthogonal NMF framework , we propose two subspace clustering algorithms , named kernel-based non-negative subspace clustering KNSC-Ncut and KNSC-Rcut and establish their connection with spectral normalized cut and ratio cut clustering . We further extend the nonlinear orthogonal NMF framework and introduce a graph regularization to obtain a factorization that respects a local geometric structure of the data after the nonlinear mapping . The proposed NMF-based approach to subspace clustering takes into account the nonlinear nature of the manifold , as well as its intrinsic local geometry , which considerably improves the clustering performance when compared to the several recently proposed state-of-the-art methods .
Conditional independence testing is an important problem , especially in Bayesian network learning and causal discovery . Due to the curse of dimensionality , testing for conditional independence of continuous variables is particularly challenging . We propose a Kernel-based Conditional Independence test ( KCI-test ) , by constructing an appropriate test statistic and deriving its asymptotic distribution under the null hypothesis of conditional independence . The proposed method is computationally efficient and easy to implement . Experimental results show that it outperforms other methods , especially when the conditioning set is large or the sample size is not very large , in which case other methods encounter difficulties .
We introduce a proximal version of the stochastic dual coordinate ascent method and show how to accelerate the method using an inner-outer iteration procedure . We analyze the runtime of the framework and obtain rates that improve state-of-the-art results for various key machine learning optimization problems including SVM , logistic regression , ridge regression , Lasso , and multiclass SVM . Experiments validate our theoretical findings .
Next-generation sequencing technologies provide a revolutionary tool for generating gene expression data . Starting with a fixed RNA sample , they construct a library of millions of differentially abundant short sequence tags or " reads " , which constitute a fundamentally discrete measure of the level of gene expression . A common limitation in experiments using these technologies is the low number or even absence of biological replicates , which complicates the statistical analysis of digital gene expression data . Analysis of this type of data has often been based on modified tests originally devised for analysing microarrays ; both these and even de novo methods for the analysis of RNA-seq data are plagued by the common problem of low replication . We propose a novel , non-parametric Bayesian approach for the analysis of digital gene expression data . We begin with a hierarchical model for modelling over-dispersed count data and a blocked Gibbs sampling algorithm for inferring the posterior distribution of model parameters conditional on these counts . The algorithm compensates for the problem of low numbers of biological replicates by clustering together genes with tag counts that are likely sampled from a common distribution and using this augmented sample for estimating the parameters of this distribution . The number of clusters is not decided a priori , but it is inferred along with the remaining model parameters . We demonstrate the ability of this approach to model biological data with high fidelity by applying the algorithm on a public dataset obtained from cancerous and non-cancerous neural tissues .
We develop a general duality between neural networks and compositional kernels , striving towards a better understanding of deep learning . We show that initial representations generated by common random initializations are sufficiently rich to express all functions in the dual kernel space . Hence , though the training objective is hard to optimize in the worst case , the initial weights form a good starting point for optimization . Our dual view also reveals a pragmatic and aesthetic perspective of neural networks and underscores their expressive power .
This paper introduces the Partition Tree Weighting technique , an efficient meta-algorithm for piecewise stationary sources . The technique works by performing Bayesian model averaging over a large class of possible partitions of the data into locally stationary segments . It uses a prior , closely related to the Context Tree Weighting technique of Willems , that is well suited to data compression applications . Our technique can be applied to any coding distribution at an additional time and space cost only logarithmic in the sequence length . We provide a competitive analysis of the redundancy of our method , and explore its application in a variety of settings . The order of the redundancy and the complexity of our algorithm matches those of the best competitors available in the literature , and the new algorithm exhibits a superior complexity-performance trade-off in our experiments .
Deep Convolutional Neural Networks ( CNN ) enforces supervised information only at the output layer , and hidden layers are trained by back propagating the prediction error from the output layer without explicit supervision . We propose a supervised feature learning approach , Label Consistent Neural Network , which enforces direct supervision in late hidden layers . We associate each neuron in a hidden layer with a particular class label and encourage it to be activated for input signals from the same class . More specifically , we introduce a label consistency regularization called " discriminative representation error " loss for late hidden layers and combine it with classification error loss to build our overall objective function . This label consistency constraint alleviates the common problem of gradient vanishing and tends to faster convergence ; it also makes the features derived from late hidden layers discriminative enough for classification even using a simple $k$-NN classifier , since input signals from the same class will have very similar representations . Experimental results demonstrate that our approach achieves state-of-the-art performances on several public benchmarks for action and object category recognition .
We consider the problem of learning models for forecasting multiple time-series systems together with discovering the leading indicators that serve as good predictors for the system . We model the systems by linear vector autoregressive models ( VAR ) and link the discovery of leading indicators to inferring sparse graphs of Granger-causality . We propose new problem formulations and develop two new methods to learn such models , gradually increasing the complexity of assumptions and approaches . While the first method assumes common structures across the whole system , our second method uncovers model clusters based on the Granger-causality and leading indicators together with learning the model parameters . We study the performance of our methods on a comprehensive set of experiments and confirm their efficacy and their advantages over state-of-the-art sparse VAR and graphical Granger learning methods .
Recent advances in deep learning for natural images has prompted a surge of interest in applying similar techniques to medical images . Most of the initial attempts focused on replacing the input of a deep convolutional neural network with a medical image , which does not take into consideration the fundamental differences between these two types of images . Specifically , fine details are necessary for detection in medical images , unlike in natural images where coarse structures matter . This difference makes it inadequate to use the existing network architectures developed for natural images , because they work on an heavily downsampled image to reduce the memory requirements . This hides details necessary to make accurate predictions . Additionally , a single exam in medical imaging often comes with a set of views which must be fused in order to reach a correct conclusion . In our work , we propose to use a multi-view deep convolutional neural network that handles a set of high-resolution medical images . We evaluate it on large-scale mammography-based breast cancer screening ( BI-RADS prediction ) using 000 thousand images . We focus on investigating the impact of training set size and image size on the prediction accuracy . Our results highlight that performance increases with the size of training set , and that the best performance can only be achieved using the original resolution . This suggests that medical imaging research using deep learning must utilize as much data as possible with the least amount of potentially harmful preprocessing .
Approaches to learning Bayesian networks from data typically combine a scoring function with a heuristic search procedure . Given a Bayesian network structure , many of the scoring functions derived in the literature return a score for the entire equivalence class to which the structure belongs . When using such a scoring function , it is appropriate for the heuristic search algorithm to search over equivalence classes of Bayesian networks as opposed to individual structures . We present the general formulation of a search space for which the states of the search correspond to equivalence classes of structures . Using this space , any one of a number of heuristic search algorithms can easily be applied . We compare greedy search performance in the proposed search space to greedy search performance in a search space for which the states correspond to individual Bayesian network structures .
In many data mining applications collection of sufficiently large datasets is the most time consuming and expensive . On the other hand , industrial methods of data collection create huge databases , and make difficult direct applications of the advanced machine learning algorithms . To address the above problems , we consider active learning ( AL ) , which may be very efficient either for the experimental design or for the data filtering . In this paper we demonstrate using the online evaluation opportunity provided by the AL Challenge that quite competitive results may be produced using a small percentage of the available data . Also , we present several alternative criteria , which may be useful for the evaluation of the active learning processes . The author of this paper attended special presentation in Barcelona , where results of the WCCI 0000 AL Challenge were discussed .
We describe a novel binary classification technique called Banded SVM ( B-SVM ) . In the standard C-SVM formulation of Cortes et al . ( 0000 ) , the decision rule is encouraged to lie in the interval [0 , \infty] . The new B-SVM objective function contains a penalty term that encourages the decision rule to lie in a user specified range [\rho_0 , \rho_0] . In addition to the standard set of support vectors ( SVs ) near the class boundaries , B-SVM results in a second set of SVs in the interior of each class .
The visual systems of many mammals , including humans , is able to integrate the geometric information of visual stimuli and to perform cognitive tasks already at the first stages of the cortical processing . This is thought to be the result of a combination of mechanisms , which include feature extraction at single cell level and geometric processing by means of cells connectivity . We present a geometric model of such connectivities in the space of detected features associated to spatio-temporal visual stimuli , and show how they can be used to obtain low-level object segmentation . The main idea is that of defining a spectral clustering procedure with anisotropic affinities over datasets consisting of embeddings of the visual stimuli into higher dimensional spaces . Neural plausibility of the proposed arguments will be discussed .
We give the first rigorous proof of the convergence of Riemannian Hamiltonian Monte Carlo , a general ( and practical ) method for sampling Gibbs distributions . Our analysis shows that the rate of convergence is bounded in terms of natural smoothness parameters of an associated Riemannian manifold . We then apply the method with the manifold defined by the log barrier function to the problems of ( 0 ) uniformly sampling a polytope and ( 0 ) computing its volume , the latter by extending Gaussian cooling to the manifold setting . In both cases , the total number of steps needed is O^{*} ( mn^{\frac{0}{0}} ) , improving the state of the art . A key ingredient of our analysis is a proof of an analog of the KLS conjecture for Gibbs distributions over manifolds .
We show that a generative random field model , which we call generative ConvNet , can be derived from the commonly used discriminative ConvNet , by assuming a ConvNet for multi-category classification and assuming one of the categories is a base category generated by a reference distribution . If we further assume that the non-linearity in the ConvNet is Rectified Linear Unit ( ReLU ) and the reference distribution is Gaussian white noise , then we obtain a generative ConvNet model that is unique among energy-based models : The model is piecewise Gaussian , and the means of the Gaussian pieces are defined by an auto-encoder , where the filters in the bottom-up encoding become the basis functions in the top-down decoding , and the binary activation variables detected by the filters in the bottom-up convolution process become the coefficients of the basis functions in the top-down deconvolution process . The Langevin dynamics for sampling the generative ConvNet is driven by the reconstruction error of this auto-encoder . The contrastive divergence learning of the generative ConvNet reconstructs the training images by the auto-encoder . The maximum likelihood learning algorithm can synthesize realistic natural image patterns .
In data-mining applications , we are frequently faced with a large fraction of missing entries in the data matrix , which is problematic for most discriminant machine learning algorithms . A solution that we explore in this paper is the use of a generative model ( a mixture of Gaussians ) to compute the conditional expectation of the missing variables given the observed variables . Since training a Gaussian mixture with many different patterns of missing values can be computationally very expensive , we introduce a spanning-tree based algorithm that significantly speeds up training in these conditions . We also observe that good results can be obtained by using the generative model to fill-in the missing values for a separate discriminant learning algorithm .
Re-speaking is a mechanism for obtaining high quality subtitles for use in live broadcast and other public events . Because it relies on humans performing the actual re-speaking , the task of estimating the quality of the results is non-trivial . Most organisations rely on humans to perform the actual quality assessment , but purely automatic methods have been developed for other similar problems , like Machine Translation . This paper will try to compare several of these methods : BLEU , EBLEU , NIST , METEOR , METEOR-PL , TER and RIBES . These will then be matched to the human-derived NER metric , commonly used in re-speaking .
Detection of rare variants by resequencing is important for the identification of individuals carrying disease variants . Rapid sequencing by new technologies enables low-cost resequencing of target regions , although it is still prohibitive to test more than a few individuals . In order to improve cost trade-offs , it has recently been suggested to apply pooling designs which enable the detection of carriers of rare alleles in groups of individuals . However , this was shown to hold only for a relatively low number of individuals in a pool , and requires the design of pooling schemes for particular cases . We propose a novel pooling design , based on a compressed sensing approach , which is both general , simple and efficient . We model the experimental procedure and show via computer simulations that it enables the recovery of rare allele carriers out of larger groups than were possible before , especially in situations where high coverage is obtained for each individual . Our approach can also be combined with barcoding techniques to enhance performance and provide a feasible solution based on current resequencing costs . For example , when targeting a small enough genomic region ( ~000 base-pairs ) and using only ~00 sequencing lanes and ~00 distinct barcodes , one can recover the identity of 0 rare allele carriers out of a population of over 0000 individuals .
Anomalies in the ambient magnetic field can be used as features in indoor positioning and navigation . By using Maxwell ' s equations , we derive and present a Bayesian non-parametric probabilistic modeling approach for interpolation and extrapolation of the magnetic field . We model the magnetic field components jointly by imposing a Gaussian process ( GP ) prior on the latent scalar potential of the magnetic field . By rewriting the GP model in terms of a Hilbert space representation , we circumvent the computational pitfalls associated with GP modeling and provide a computationally efficient and physically justified modeling tool for the ambient magnetic field . The model allows for sequential updating of the estimate and time-dependent changes in the magnetic field . The model is shown to work well in practice in different applications : we demonstrate mapping of the magnetic field both with an inexpensive Raspberry Pi powered robot and on foot using a standard smartphone .
It is becoming increasingly clear that many machine learning classifiers are vulnerable to adversarial examples . In attempting to explain the origin of adversarial examples , previous studies have typically focused on the fact that neural networks operate on high dimensional data , they overfit , or they are too linear . Here we argue that the origin of adversarial examples is primarily due to an inherent uncertainty that neural networks have about their predictions . We show that the functional form of this uncertainty is independent of architecture , dataset , and training protocol ; and depends only on the statistics of the logit differences of the network , which do not change significantly during training . This leads to adversarial error having a universal scaling , as a power-law , with respect to the size of the adversarial perturbation . We show that this universality holds for a broad range of datasets ( MNIST , CIFAR00 , ImageNet , and random data ) , models ( including state-of-the-art deep networks , linear models , adversarially trained networks , and networks trained on randomly shuffled labels ) , and attacks ( FGSM , step l . l . , PGD ) . Motivated by these results , we study the effects of reducing prediction entropy on adversarial robustness . Finally , we study the effect of network architectures on adversarial sensitivity . To do this , we use neural architecture search with reinforcement learning to find adversarially robust architectures on CIFAR00 . Our resulting architecture is more robust to white \emph{and} black box attacks compared to previous attempts .
We obtain a new Bernstein-type inequality for sums of Banach-valued random variables satisfying a weak dependence assumption of general type and under certain smoothness assumptions of the underlying Banach norm . We use this inequality in order to investigate in asymptotical regime the error upper bounds for the broad family of spectral regularization methods for reproducing kernel decision rules , when trained on a sample coming from a $\tau-$mixing process .
According to Cobanoglu et al and Murphy , it is now widely acknowledged that the single target paradigm ( one protein or target , one disease , one drug ) that has been the dominant premise in drug development in the recent past is untenable . More often than not , a drug-like compound ( ligand ) can be promiscuous - that is , it can interact with more than one target protein . In recent years , in in silico target prediction methods the promiscuity issue has been approached computationally in different ways . In this study we confine attention to the so-called ligand-based target prediction machine learning approaches , commonly referred to as target-fishing . With a few exceptions , the target-fishing approaches that are currently ubiquitous in cheminformatics literature can be essentially viewed as single-label multi-classification schemes ; these approaches inherently bank on the single target paradigm assumption that a ligand can home in on one specific target . In order to address the ligand promiscuity issue , one might be able to cast target-fishing as a multi-label multi-class classification problem . For illustrative and comparison purposes , single-label and multi-label Naive Bayes classification models ( denoted here by SMM and MMM , respectively ) for target-fishing were implemented . The models were constructed and tested on 00 , 000 compounds and 000 targets retrieved from the ChEMBL00 database . SMM and MMM performed differently : for 00 , 000 test compounds , the MMM model returned recall and precision values of 0 . 0000 and 0 . 0000 , respectively ; the corresponding recall and precision values yielded by the SMM model were 0 . 0000 and 0 . 0000 , respectively . However , at a significance level of 0 . 00 and one degree of freedom McNemar test performed on the target prediction results returned by SMM and MMM for the 00 , 000 test ligands gave a chi-squared value of 00 . 000 , in favour of the MMM approach .
Many problems of low-level computer vision and image processing , such as denoising , deconvolution , tomographic reconstruction or super-resolution , can be addressed by maximizing the posterior distribution of a sparse linear model ( SLM ) . We show how higher-order Bayesian decision-making problems , such as optimizing image acquisition in magnetic resonance scanners , can be addressed by querying the SLM posterior covariance , unrelated to the density ' s mode . We propose a scalable algorithmic framework , with which SLM posteriors over full , high-resolution images can be approximated for the first time , solving a variational optimization problem which is convex iff posterior mode finding is convex . These methods successfully drive the optimization of sampling trajectories for real-world magnetic resonance imaging through Bayesian experimental design , which has not been attempted before . Our methodology provides new insight into similarities and differences between sparse reconstruction and approximate Bayesian inference , and has important implications for compressive sensing of real-world images .
We propose a clustering algorithm which , for input , takes data assumed to be sampled from a uniform distribution supported on a metric space $X$ , and outputs a clustering of the data based on a topological estimate of the connected components of $X$ . The algorithm works by choosing a weighted graph on the samples from a natural one-parameter family of graphs using an error based on the heat operator on the graphs . The estimated connected components of $X$ are identified as the support of the eigenfunctions of the heat operator with eigenvalue $0$ , which allows the algorithm to work without requiring the number of expected clusters as input .
This article provides the role of big idea statisticians in future of Big Data Science . We describe the `United Statistical Algorithms ' framework for comprehensive unification of traditional and novel statistical methods for modeling Small Data and Big Data , especially mixed data ( discrete , continuous ) .
We consider structural equation models in which variables can be written as a function of their parents and noise terms , which are assumed to be jointly independent . Corresponding to each structural equation model , there is a directed acyclic graph describing the relationships between the variables . In Gaussian structural equation models with linear functions , the graph can be identified from the joint distribution only up to Markov equivalence classes , assuming faithfulness . In this work , we prove full identifiability if all noise variables have the same variances : the directed acyclic graph can be recovered from the joint Gaussian distribution . Our result has direct implications for causal inference : if the data follow a Gaussian structural equation model with equal error variances and assuming that all variables are observed , the causal structure can be inferred from observational data only . We propose a statistical method and an algorithm that exploit our theoretical findings .
In this survey , we present and compare different approaches to estimate Mutual Information ( MI ) from data to analyse general dependencies between variables of interest in a system . We demonstrate the performance difference of MI versus correlation analysis , which is only optimal in case of linear dependencies . First , we use a piece-wise constant Bayesian methodology using a general Dirichlet prior . In this estimation method , we use a two-stage approach where we approximate the probability distribution first and then calculate the marginal and joint entropies . Here , we demonstrate the performance of this Bayesian approach versus the others for computing the dependency between different variables . We also compare these with linear correlation analysis . Finally , we apply MI and correlation analysis to the identification of the bias in the determination of the aerosol optical depth ( AOD ) by the satellite based Moderate Resolution Imaging Spectroradiometer ( MODIS ) and the ground based AErosol RObotic NETwork ( AERONET ) . Here , we observe that the AOD measurements by these two instruments might be different for the same location . The reason of this bias is explored by quantifying the dependencies between the bias and 00 other variables including cloud cover , surface reflectivity and others .
We propose a novel signal model , based on sparse representations , that captures cross-scale features for visual signals . We show that cross-scale predictive model enables faster solutions to sparse approximation problems . This is achieved by first solving the sparse approximation problem for the downsampled signal and using the support of the solution to constrain the support at the original resolution . The speedups obtained are especially compelling for high-dimensional signals that require large dictionaries to provide precise sparse approximations . We demonstrate speedups in the order of 00-000x for denoising and up to 00x speedups for compressive sensing of images , videos , hyperspectral images and light-field images .
In this paper we consider a version of the zero-shot learning problem where seen class source and target domain data are provided . The goal during test-time is to accurately predict the class label of an unseen target domain instance based on revealed source domain side information ( \eg attributes ) for unseen classes . Our method is based on viewing each source or target data as a mixture of seen class proportions and we postulate that the mixture patterns have to be similar if the two instances belong to the same unseen class . This perspective leads us to learning source/target embedding functions that map an arbitrary source/target domain data into a same semantic space where similarity can be readily measured . We develop a max-margin framework to learn these similarity functions and jointly optimize parameters by means of cross validation . Our test results are compelling , leading to significant improvement in terms of accuracy on most benchmark datasets for zero-shot recognition .
We develop latent variable models for Bayesian learning based low-rank matrix completion and reconstruction from linear measurements . For under-determined systems , the developed methods are shown to reconstruct low-rank matrices when neither the rank nor the noise power is known a-priori . We derive relations between the latent variable models and several low-rank promoting penalty functions . The relations justify the use of Kronecker structured covariance matrices in a Gaussian based prior . In the methods , we use evidence approximation and expectation-maximization to learn the model parameters . The performance of the methods is evaluated through extensive numerical simulations .
The recent explosion in the amount and dimensionality of data has exacerbated the need of trading off computational and statistical efficiency carefully , so that inference is both tractable and meaningful . We propose a framework that provides an explicit opportunity for practitioners to specify how much statistical risk they are willing to accept for a given computational cost , and leads to a theoretical risk-computation frontier for any given inference problem . We illustrate the tradeoff between risk and computation and illustrate the frontier in three distinct settings . First , we derive analytic forms for the risk of estimating parameters in the classical setting of estimating the mean and variance for normally distributed data and for the more general setting of parameters of an exponential family . The second example concentrates on computationally constrained Hodges-Lehmann estimators . We conclude with an evaluation of risk associated with early termination of iterative matrix inversion algorithms in the context of linear regression .
Imaging neuroscience links brain activation maps to behavior and cognition via correlational studies . Due to the nature of the individual experiments , based on eliciting neural response from a small number of stimuli , this link is incomplete , and unidirectional from the causal point of view . To come to conclusions on the function implied by the activation of brain regions , it is necessary to combine a wide exploration of the various brain functions and some inversion of the statistical inference . Here we introduce a methodology for accumulating knowledge towards a bidirectional link between observed brain activity and the corresponding function . We rely on a large corpus of imaging studies and a predictive engine . Technically , the challenges are to find commonality between the studies without denaturing the richness of the corpus . The key elements that we contribute are labeling the tasks performed with a cognitive ontology , and modeling the long tail of rare paradigms in the corpus . To our knowledge , our approach is the first demonstration of predicting the cognitive content of completely new brain images . To that end , we propose a method that predicts the experimental paradigms across different studies .
The data torrent unleashed by current and upcoming instruments requires scalable analysis methods . Machine Learning approaches scale well . However , separating the instrument measurement from the physical effects of interest , dealing with variable errors , and deriving parameter uncertainties is usually an afterthought . Classic forward-folding analyses with Markov Chain Monte Carlo or Nested Sampling enable parameter estimation and model comparison , even for complex and slow-to-evaluate physical models . However , these approaches require independent runs for each data set , implying an unfeasible number of model evaluations in the Big Data regime . Here we present a new algorithm , collaborative nested sampling , for deriving parameter probability distributions for each observation . Importantly , in our method the number of physical model evaluations scales sub-linearly with the number of data sets , and we make no assumptions about homogeneous errors , Gaussianity , the form of the model or heterogeneity/completeness of the observations . Collaborative nested sampling has immediate application in speeding up analyses of large surveys , integral-field-unit observations , and Monte Carlo simulations .
We consider the problem faced by a service platform that needs to match supply with demand , but also to learn attributes of new arrivals in order to match them better in the future . We introduce a benchmark model with heterogeneous workers and jobs that arrive over time . Job types are known to the platform , but worker types are unknown and must be learned by observing match outcomes . Workers depart after performing a certain number of jobs . The payoff from a match depends on the pair of types and the goal is to maximize the steady-state rate of accumulation of payoff . Our main contribution is a complete characterization of the structure of the optimal policy in the limit that each worker performs many jobs . The platform faces a trade-off for each worker between myopically maximizing payoffs ( exploitation ) and learning the type of the worker ( \emph{exploration} ) . This creates a multitude of multi-armed bandit problems , one for each worker , coupled together by the constraint on the availability of jobs of different types ( capacity constraints ) . We find that the platform should estimate a shadow price for each job type , and use the payoffs adjusted by these prices , first , to determine its learning goals and then , for each worker , ( i ) to balance learning with payoffs during the " exploration phase " , and ( ii ) to myopically match after it has achieved its learning goals during the " exploitation phase . "
We introduce the Hierarchically Interacting Particle Neural Network ( HIP-NN ) to model molecular properties from datasets of quantum calculations . Inspired by a many-body expansion , HIP-NN decomposes properties , such as energy , as a sum over hierarchical terms . These terms are generated from a neural network--a composition of many nonlinear transformations--acting on a representation of the molecule . HIP-NN achieves state-of-the-art performance on a dataset of 000k ground state organic molecules , and predicts energies with 0 . 00 kcal/mol mean absolute error . With minimal tuning , our model is also competitive on a dataset of molecular dynamics trajectories . In addition to enabling accurate energy predictions , the hierarchical structure of HIP-NN helps to identify regions of model uncertainty .
We introduce the functional mean-shift algorithm , an iterative algorithm for estimating the local modes of a surrogate density from functional data . We show that the algorithm can be used for cluster analysis of functional data . We propose a test based on the bootstrap for the significance of the estimated local modes of the surrogate density . We present two applications of our methodology . In the first application , we demonstrate how the functional mean-shift algorithm can be used to perform spike sorting , i . e . cluster neural activity curves . In the second application , we use the functional mean-shift algorithm to distinguish between original and fake signatures .
Recent progress in variational inference has paid much attention to the flexibility of variational posteriors . Work has been done to use implicit distributions , i . e . , distributions without tractable likelihoods as the variational posterior . However , existing methods on implicit posteriors still face challenges of noisy estimation and can hardly scale to high-dimensional latent variable models . In this paper , we present an implicit variational inference approach with kernel density ratio fitting that addresses these challenges . As far as we know , for the first time implicit variational inference is successfully applied to Bayesian neural networks , which shows promising results on both regression and classification tasks .
Inference in hidden Markov model has been challenging in terms of scalability due to dependencies in the observation data . In this paper , we utilize the inherent memory decay in hidden Markov models , such that the forward and backward probabilities can be carried out with subsequences , enabling efficient inference over long sequences of observations . We formulate this forward filtering process in the setting of the random dynamical system and there exist Lyapunov exponents in the i . i . d random matrices production . And the rate of the memory decay is known as $\lambda_0-\lambda_0$ , the gap of the top two Lyapunov exponents almost surely . An efficient and accurate algorithm is proposed to numerically estimate the gap after the soft-max parametrization . The length of subsequences $B$ given the controlled error $\epsilon$ is $B=\log ( \epsilon ) / ( \lambda_0-\lambda_0 ) $ . We theoretically prove the validity of the algorithm and demonstrate the effectiveness with numerical examples . The method developed here can be applied to widely used algorithms , such as mini-batch stochastic gradient method . Moreover , the continuity of Lyapunov spectrum ensures the estimated $B$ could be reused for the nearby parameter during the inference .
Many applications concern sparse signals , for example , detecting anomalies from the differences between consecutive images taken by surveillance cameras . This paper focuses on the problem of recovering a K-sparse signal x in N dimensions . In the mainstream framework of compressed sensing ( CS ) , the vector x is recovered from M non-adaptive linear measurements y = xS , where S ( of size N x M ) is typically a Gaussian ( or Gaussian-like ) design matrix , through some optimization procedure such as linear programming ( LP ) . In our proposed method , the design matrix S is generated from an $\alpha$-stable distribution with $\alpha\approx 0$ . Our decoding algorithm mainly requires one linear scan of the coordinates , followed by a few iterations on a small number of coordinates which are " undetermined " in the previous iteration . Comparisons with two strong baselines , linear programming ( LP ) and orthogonal matching pursuit ( OMP ) , demonstrate that our algorithm can be significantly faster in decoding speed and more accurate in recovery quality , for the task of exact spare recovery . Our procedure is robust against measurement noise . Even when there are no sufficient measurements , our algorithm can still reliably recover a significant portion of the nonzero coordinates . To provide the intuition for understanding our method , we also analyze the procedure by assuming an idealistic setting . Interestingly , when K=0 , the " idealized " algorithm achieves exact recovery with merely 0 measurements , regardless of N . For general K , the required sample size of the " idealized " algorithm is about 0K .
This paper presents an infinite variational autoencoder ( VAE ) whose capacity adapts to suit the input data . This is achieved using a mixture model where the mixing coefficients are modeled by a Dirichlet process , allowing us to integrate over the coefficients when performing inference . Critically , this then allows us to automatically vary the number of autoencoders in the mixture based on the data . Experiments show the flexibility of our method , particularly for semi-supervised learning , where only a small number of training samples are available .
Language is increasingly being used to define rich visual recognition problems with supporting image collections sourced from the web . Structured prediction models are used in these tasks to take advantage of correlations between co-occurring labels and visual input but risk inadvertently encoding social biases found in web corpora . In this work , we study data and models associated with multilabel object classification and visual semantic role labeling . We find that ( a ) datasets for these tasks contain significant gender bias and ( b ) models trained on these datasets further amplify existing bias . For example , the activity cooking is over 00% more likely to involve females than males in a training set , and a trained model further amplifies the disparity to 00% at test time . We propose to inject corpus-level constraints for calibrating existing structured prediction models and design an algorithm based on Lagrangian relaxation for collective inference . Our method results in almost no performance loss for the underlying recognition task but decreases the magnitude of bias amplification by 00 . 0% and 00 . 0% for multilabel classification and visual semantic role labeling , respectively .
We provide a rigorous definition of the visual cause of a behavior that is broadly applicable to the visually driven behavior in humans , animals , neurons , robots and other perceiving systems . Our framework generalizes standard accounts of causal learning to settings in which the causal variables need to be constructed from micro-variables . We prove the Causal Coarsening Theorem , which allows us to gain causal knowledge from observational data with minimal experimental effort . The theorem provides a connection to standard inference techniques in machine learning that identify features of an image that correlate with , but may not cause , the target behavior . Finally , we propose an active learning scheme to learn a manipulator function that performs optimal manipulations on the image to automatically identify the visual cause of a target behavior . We illustrate our inference and learning algorithms in experiments based on both synthetic and real data .
Nonnegative Matrix Factorization ( NMF ) has been a popular representation method for pattern classification problem . It tries to decompose a nonnegative matrix of data samples as the product of a nonnegative basic matrix and a nonnegative coefficient matrix , and the coefficient matrix is used as the new representation . However , traditional NMF methods ignore the class labels of the data samples . In this paper , we proposed a supervised novel NMF algorithm to improve the discriminative ability of the new representation . Using the class labels , we separate all the data sample pairs into within-class pairs and between-class pairs . To improve the discriminate ability of the new NMF representations , we hope that the maximum distance of the within-class pairs in the new NMF space could be minimized , while the minimum distance of the between-class pairs pairs could be maximized . With this criterion , we construct an objective function and optimize it with regard to basic and coefficient matrices and slack variables alternatively , resulting in a iterative algorithm .
Exact inference in the linear regression model with spike and slab priors is often intractable . Expectation propagation ( EP ) can be used for approximate inference . However , the regular sequential form of EP ( R-EP ) may fail to converge in this model when the size of the training set is very small . As an alternative , we propose a provably convergent EP algorithm ( PC-EP ) . PC-EP is proved to minimize an energy function which , under some constraints , is bounded from below and whose stationary points coincide with the solution of R-EP . Experiments with synthetic data indicate that when R-EP does not converge , the approximation generated by PC-EP is often better . By contrast , when R-EP converges , both methods perform similarly .
Labeling data for classification requires significant human effort . To reduce labeling cost , instead of labeling every instance , a group of instances ( bag ) is labeled by a single bag label . Computer algorithms are then used to infer the label for each instance in a bag , a process referred to as instance annotation . This task is challenging due to the ambiguity regarding the instance labels . We propose a discriminative probabilistic model for the instance annotation problem and introduce an expectation maximization framework for inference , based on the maximum likelihood approach . For many probabilistic approaches , brute-force computation of the instance label posterior probability given its bag label is exponential in the number of instances in the bag . Our key contribution is a dynamic programming method for computing the posterior that is linear in the number of instances . We evaluate our methods using both benchmark and real world data sets , in the domain of bird song , image annotation , and activity recognition . In many cases , the proposed framework outperforms , sometimes significantly , the current state-of-the-art MIML learning methods , both in instance label prediction and bag label prediction .
The objective of the paper is to study accuracy of multi-class classification in high-dimensional setting , where the number of classes is also large ( " large $L$ , large $p$ , small $n$ " model ) . While this problem arises in many practical applications and many techniques have been recently developed for its solution , to the best of our knowledge nobody provided a rigorous theoretical analysis of this important setup . The purpose of the present paper is to fill in this gap . We consider one of the most common settings , classification of high-dimensional normal vectors where , unlike standard assumptions , the number of classes could be large . We derive non-asymptotic conditions on effects of significant features , and the low and the upper bounds for distances between classes required for successful feature selection and classification with a given accuracy . Furthermore , we study an asymptotic setup where the number of classes is growing with the dimension of feature space and while the number of samples per class is possibly limited . We discover an interesting and , at first glance , somewhat counter-intuitive phenomenon that a large number of classes may be a " blessing " rather than a " curse " since , in certain settings , the precision of classification can improve as the number of classes grows . This is due to more accurate feature selection since even weaker significant features , which are not sufficiently strong to be manifested in a coarse classification , can nevertheless have a strong impact when the number of classes is large . We supplement our theoretical investigation by a simulation study and a real data example where we again observe the above phenomenon .
